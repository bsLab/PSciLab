var CoreModule = {};
CoreModule['com/io']='com/io.browser';
CoreModule['crypto']='os/crypto';
CoreModule['util']='os/util';
CoreModule['http']='os/http.browser';
CoreModule['url']='os/url';
CoreModule['path']='os/path';
CoreModule['string_decoder']='os/string_decoder';
CoreModule['fs']='';
CoreModule['stream']='';
CoreModule['zlib']='';
CoreModule['dgram']='';
CoreModule['net']='';
CoreModule['child_process']='';
CoreModule['dns']='';
CoreModule['buffer']='os/buffer';

var BundleModuleCode=[];
var BundleObjectCode=[];
var BundleModules = [];
// PATH=[".","/home/sbosse/proj/workbook/src"];
if (typeof global == "undefined")  global=(typeof window != "undefined"?window:{})
if (typeof process == "undefined") var process={browser:true};
Require=function(modupath) {
  if (CoreModule[modupath]!=undefined) modupath=CoreModule[modupath];
  if (modupath=='') return undefined;
  if (BundleModules[modupath]) return BundleModules[modupath];
  var exports={}, module={exports:exports};
  if (BundleModuleCode[modupath]) BundleModuleCode[modupath](module,exports,window,process);
  else if (BundleObjectCode[modupath]) BundleObjectCode[modupath](module,exports,window,process);
  else return undefined;
  BundleModules[modupath]=module.exports||module;
  return module.exports||module;};
var FilesEmbedded = {};
var FileEmbedd = function (path,format) {};
var FileEmbedded = function (path,format) {return FilesEmbedded[path](format);};
global.TARGET='browser';
Script=function(){};

BundleModuleCode['os/buffer']=function (module,exports,global,process){
var Ieee754 = Require('os/buffer_ieee754');

/* ------- base64-js -------- */
var lookup = []
var revLookup = []
var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array

function init () {
  var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'
  for (var i = 0, len = code.length; i < len; ++i) {
    lookup[i] = code[i]
    revLookup[code.charCodeAt(i)] = i
  }

  revLookup['-'.charCodeAt(0)] = 62
  revLookup['_'.charCodeAt(0)] = 63
}

init()

function toByteArray (b64) {
  var i, j, l, tmp, placeHolders, arr
  var len = b64.length

  if (len % 4 > 0) {
    throw new Error('Invalid string. Length must be a multiple of 4')
  }

  // the number of equal signs (place holders)
  // if there are two placeholders, than the two characters before it
  // represent one byte
  // if there is only one, then the three characters before it represent 2 bytes
  // this is just a cheap hack to not do indexOf twice
  placeHolders = b64[len - 2] === '=' ? 2 : b64[len - 1] === '=' ? 1 : 0

  // base64 is 4/3 + up to two characters of the original data
  arr = new Arr(len * 3 / 4 - placeHolders)

  // if there are placeholders, only get up to the last complete 4 chars
  l = placeHolders > 0 ? len - 4 : len

  var L = 0

  for (i = 0, j = 0; i < l; i += 4, j += 3) {
    tmp = (revLookup[b64.charCodeAt(i)] << 18) | (revLookup[b64.charCodeAt(i + 1)] << 12) | (revLookup[b64.charCodeAt(i + 2)] << 6) | revLookup[b64.charCodeAt(i + 3)]
    arr[L++] = (tmp >> 16) & 0xFF
    arr[L++] = (tmp >> 8) & 0xFF
    arr[L++] = tmp & 0xFF
  }

  if (placeHolders === 2) {
    tmp = (revLookup[b64.charCodeAt(i)] << 2) | (revLookup[b64.charCodeAt(i + 1)] >> 4)
    arr[L++] = tmp & 0xFF
  } else if (placeHolders === 1) {
    tmp = (revLookup[b64.charCodeAt(i)] << 10) | (revLookup[b64.charCodeAt(i + 1)] << 4) | (revLookup[b64.charCodeAt(i + 2)] >> 2)
    arr[L++] = (tmp >> 8) & 0xFF
    arr[L++] = tmp & 0xFF
  }

  return arr
}

function tripletToBase64 (num) {
  return lookup[num >> 18 & 0x3F] + lookup[num >> 12 & 0x3F] + lookup[num >> 6 & 0x3F] + lookup[num & 0x3F]
}

function encodeChunk (uint8, start, end) {
  var tmp
  var output = []
  for (var i = start; i < end; i += 3) {
    tmp = (uint8[i] << 16) + (uint8[i + 1] << 8) + (uint8[i + 2])
    output.push(tripletToBase64(tmp))
  }
  return output.join('')
}

function fromByteArray (uint8) {
  var tmp
  var len = uint8.length
  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes
  var output = ''
  var parts = []
  var maxChunkLength = 16383 // must be multiple of 3

  // go through the array every three bytes, we'll deal with trailing stuff later
  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
    parts.push(encodeChunk(uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)))
  }

  // pad the end with zeros, but make sure to not forget the extra bytes
  if (extraBytes === 1) {
    tmp = uint8[len - 1]
    output += lookup[tmp >> 2]
    output += lookup[(tmp << 4) & 0x3F]
    output += '=='
  } else if (extraBytes === 2) {
    tmp = (uint8[len - 2] << 8) + (uint8[len - 1])
    output += lookup[tmp >> 10]
    output += lookup[(tmp >> 4) & 0x3F]
    output += lookup[(tmp << 2) & 0x3F]
    output += '='
  }

  parts.push(output)

  return parts.join('')
}
/* ------- base64-js -------- */

var assert;

exports.Buffer = Buffer;
exports.SlowBuffer = Buffer;
Buffer.poolSize = 8192;
exports.INSPECT_MAX_BYTES = 50;

function stringtrim(str) {
  if (str.trim) return str.trim();
  return str.replace(/^\s+|\s+$/g, '');
}

function Buffer(subject, encoding, offset) {
  if(!assert) assert= {
    ok : function(cond,msg) {
      if (cond != true) {
        console.log('** Assertion failed: '+msg+' **');
        throw Error(msg);
      }
    }
  };
  if (!(this instanceof Buffer)) {
    return new Buffer(subject, encoding, offset);
  }
  this.parent = this;
  this.offset = 0;

  // Work-around: node's base64 implementation
  // allows for non-padded strings while base64-js
  // does not..
  if (encoding == "base64" && typeof subject == "string") {
    subject = stringtrim(subject);
    while (subject.length % 4 != 0) {
      subject = subject + "="; 
    }
  }

  var type;

  // Are we slicing?
  if (typeof offset === 'number') {
    this.length = coerce(encoding);
    // slicing works, with limitations (no parent tracking/update)
    // check https://github.com/toots/buffer-browserify/issues/19
    for (var i = 0; i < this.length; i++) {
        this[i] = subject.get(i+offset);
    }
  } else {
    // Find the length
    switch (type = typeof subject) {
      case 'number':
        this.length = coerce(subject);
        break;

      case 'string':
        this.length = Buffer.byteLength(subject, encoding);
        break;

      case 'object': // Assume object is an array
        this.length = coerce(subject.length);
        break;

      default:
        throw new TypeError('First argument needs to be a number, ' +
                            'array or string.');
    }

    // Treat array-ish objects as a byte array.
    if (isArrayIsh(subject)) {
      for (var i = 0; i < this.length; i++) {
        if (subject instanceof Buffer) {
          this[i] = subject.readUInt8(i);
        }
        else {
          // Round-up subject[i] to a UInt8.
          // e.g.: ((-432 % 256) + 256) % 256 = (-176 + 256) % 256
          //                                  = 80
          this[i] = ((subject[i] % 256) + 256) % 256;
        }
      }
    } else if (type == 'string') {
      // We are a string
      this.length = this.write(subject, 0, encoding);
    } else if (type === 'number') {
      for (var i = 0; i < this.length; i++) {
        this[i] = 0;
      }
    }
  }
}

Buffer.prototype.get = function get(i) {
  if (i < 0 || i >= this.length) throw new Error('oob');
  return this[i];
};

Buffer.prototype.set = function set(i, v) {
  if (i < 0 || i >= this.length) throw new Error('oob');
  return this[i] = v;
};

Buffer.byteLength = function (str, encoding) {
  switch (encoding || "utf8") {
    case 'hex':
      return str.length / 2;

    case 'utf8':
    case 'utf-8':
      return utf8ToBytes(str).length;

    case 'ascii':
    case 'binary':
      return str.length;

    case 'base64':
      return base64ToBytes(str).length;

    default:
      throw new Error('Unknown encoding');
  }
};

Buffer.prototype.utf8Write = function (string, offset, length) {
  var bytes, pos;
  return Buffer._charsWritten =  blitBuffer(utf8ToBytes(string), this, offset, length);
};

Buffer.prototype.asciiWrite = function (string, offset, length) {
  var bytes, pos;
  return Buffer._charsWritten =  blitBuffer(asciiToBytes(string), this, offset, length);
};

Buffer.prototype.binaryWrite = Buffer.prototype.asciiWrite;

Buffer.prototype.base64Write = function (string, offset, length) {
  var bytes, pos;
  return Buffer._charsWritten = blitBuffer(base64ToBytes(string), this, offset, length);
};

Buffer.prototype.base64Slice = function (start, end) {
  var bytes = Array.prototype.slice.apply(this, arguments)
  return fromByteArray(bytes);
};

Buffer.prototype.utf8Slice = function () {
  var bytes = Array.prototype.slice.apply(this, arguments);
  var res = "";
  var tmp = "";
  var i = 0;
  while (i < bytes.length) {
    if (bytes[i] <= 0x7F) {
      res += decodeUtf8Char(tmp) + String.fromCharCode(bytes[i]);
      tmp = "";
    } else
      tmp += "%" + bytes[i].toString(16);

    i++;
  }

  return res + decodeUtf8Char(tmp);
}

Buffer.prototype.asciiSlice = function () {
  var bytes = Array.prototype.slice.apply(this, arguments);
  var ret = "";
  for (var i = 0; i < bytes.length; i++)
    ret += String.fromCharCode(bytes[i]);
  return ret;
}

Buffer.prototype.binarySlice = Buffer.prototype.asciiSlice;

Buffer.prototype.inspect = function() {
  var out = [],
      len = this.length;
  for (var i = 0; i < len; i++) {
    out[i] = toHex(this[i]);
    if (i == exports.INSPECT_MAX_BYTES) {
      out[i + 1] = '...';
      break;
    }
  }
  return '<Buffer ' + out.join(' ') + '>';
};


Buffer.prototype.hexSlice = function(start, end) {
  var len = this.length;

  if (!start || start < 0) start = 0;
  if (!end || end < 0 || end > len) end = len;

  var out = '';
  for (var i = start; i < end; i++) {
    out += toHex(this[i]);
  }
  return out;
};


Buffer.prototype.toString = function(encoding, start, end) {
  encoding = String(encoding || 'utf8').toLowerCase();
  start = +start || 0;
  if (typeof end == 'undefined') end = this.length;

  // Fastpath empty strings
  if (+end == start) {
    return '';
  }

  switch (encoding) {
    case 'hex':
      return this.hexSlice(start, end);

    case 'utf8':
    case 'utf-8':
      return this.utf8Slice(start, end);

    case 'ascii':
      return this.asciiSlice(start, end);

    case 'binary':
      return this.binarySlice(start, end);

    case 'base64':
      return this.base64Slice(start, end);

    case 'ucs2':
    case 'ucs-2':
      return this.ucs2Slice(start, end);

    default:
      throw new Error('Unknown encoding');
  }
};


Buffer.prototype.hexWrite = function(string, offset, length) {
  offset = +offset || 0;
  var remaining = this.length - offset;
  if (!length) {
    length = remaining;
  } else {
    length = +length;
    if (length > remaining) {
      length = remaining;
    }
  }

  // must be an even number of digits
  var strLen = string.length;
  if (strLen % 2) {
    throw new Error('Invalid hex string');
  }
  if (length > strLen / 2) {
    length = strLen / 2;
  }
  for (var i = 0; i < length; i++) {
    var b = parseInt(string.substr(i * 2, 2), 16);
    if (isNaN(b)) throw new Error('Invalid hex string');
    this[offset + i] = b;
  }
  Buffer._charsWritten = i * 2;
  return i;
};


Buffer.prototype.write = function(string, offset, length, encoding) {
  // Support both (string, offset, length, encoding)
  // and the legacy (string, encoding, offset, length)
  if (isFinite(offset)) {
    if (!isFinite(length)) {
      encoding = length;
      length = undefined;
    }
  } else {  // legacy
    var swap = encoding;
    encoding = offset;
    offset = length;
    length = swap;
  }

  offset = +offset || 0;
  var remaining = this.length - offset;
  if (!length) {
    length = remaining;
  } else {
    length = +length;
    if (length > remaining) {
      length = remaining;
    }
  }
  encoding = String(encoding || 'utf8').toLowerCase();

  switch (encoding) {
    case 'hex':
      return this.hexWrite(string, offset, length);

    case 'utf8':
    case 'utf-8':
      return this.utf8Write(string, offset, length);

    case 'ascii':
      return this.asciiWrite(string, offset, length);

    case 'binary':
      return this.binaryWrite(string, offset, length);

    case 'base64':
      return this.base64Write(string, offset, length);

    case 'ucs2':
    case 'ucs-2':
      return this.ucs2Write(string, offset, length);

    default:
      throw new Error('Unknown encoding');
  }
};

// slice(start, end)
function clamp(index, len, defaultValue) {
  if (typeof index !== 'number') return defaultValue;
  index = ~~index;  // Coerce to integer.
  if (index >= len) return len;
  if (index >= 0) return index;
  index += len;
  if (index >= 0) return index;
  return 0;
}

Buffer.prototype.slice = function(start, end) {
  var len = this.length;
  start = clamp(start, len, 0);
  end = clamp(end, len, len);
  return new Buffer(this, end - start, +start);
};

// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
Buffer.prototype.copy = function(target, target_start, start, end) {
  var source = this;
  start || (start = 0);
  if (end === undefined || isNaN(end)) {
    end = this.length;
  }
  target_start || (target_start = 0);

  if (end < start) throw new Error('sourceEnd < sourceStart');

  // Copy 0 bytes; we're done
  if (end === start) return 0;
  if (target.length == 0 || source.length == 0) return 0;

  if (target_start < 0 || target_start >= target.length) {
    throw new Error('targetStart out of bounds');
  }

  if (start < 0 || start >= source.length) {
    throw new Error('sourceStart out of bounds');
  }

  if (end < 0 || end > source.length) {
    throw new Error('sourceEnd out of bounds');
  }

  // Are we oob?
  if (end > this.length) {
    end = this.length;
  }

  if (target.length - target_start < end - start) {
    end = target.length - target_start + start;
  }

  var temp = [];
  for (var i=start; i<end; i++) {
    assert.ok(typeof this[i] !== 'undefined', "copying undefined buffer bytes!");
    temp.push(this[i]);
  }

  for (var i=target_start; i<target_start+temp.length; i++) {
    target[i] = temp[i-target_start];
  }
};

// fill(value, start=0, end=buffer.length)
Buffer.prototype.fill = function fill(value, start, end) {
  value || (value = 0);
  start || (start = 0);
  end || (end = this.length);

  if (typeof value === 'string') {
    value = value.charCodeAt(0);
  }
  if (!(typeof value === 'number') || isNaN(value)) {
    throw new Error('value is not a number');
  }

  if (end < start) throw new Error('end < start');

  // Fill 0 bytes; we're done
  if (end === start) return 0;
  if (this.length == 0) return 0;

  if (start < 0 || start >= this.length) {
    throw new Error('start out of bounds');
  }

  if (end < 0 || end > this.length) {
    throw new Error('end out of bounds');
  }

  for (var i = start; i < end; i++) {
    this[i] = value;
  }
}

// Static methods
Buffer.isBuffer = function isBuffer(b) {
  return b instanceof Buffer;
};

Buffer.concat = function (list, totalLength) {
  if (!isArray(list)) {
    throw new Error("Usage: Buffer.concat(list, [totalLength])\n \
      list should be an Array.");
  }

  if (list.length === 0) {
    return new Buffer(0);
  } else if (list.length === 1) {
    return list[0];
  }

  if (typeof totalLength !== 'number') {
    totalLength = 0;
    for (var i = 0; i < list.length; i++) {
      var buf = list[i];
      totalLength += buf.length;
    }
  }

  var buffer = new Buffer(totalLength);
  var pos = 0;
  for (var i = 0; i < list.length; i++) {
    var buf = list[i];
    buf.copy(buffer, pos);
    pos += buf.length;
  }
  return buffer;
};

Buffer.isEncoding = function(encoding) {
  switch ((encoding + '').toLowerCase()) {
    case 'hex':
    case 'utf8':
    case 'utf-8':
    case 'ascii':
    case 'binary':
    case 'base64':
    case 'ucs2':
    case 'ucs-2':
    case 'utf16le':
    case 'utf-16le':
    case 'raw':
      return true;

    default:
      return false;
  }
};

// helpers

function coerce(length) {
  // Coerce length to a number (possibly NaN), round up
  // in case it's fractional (e.g. 123.456) then do a
  // double negate to coerce a NaN to 0. Easy, right?
  length = ~~Math.ceil(+length);
  return length < 0 ? 0 : length;
}

function isArray(subject) {
  return (Array.isArray ||
    function(subject){
      return {}.toString.apply(subject) == '[object Array]'
    })
    (subject)
}

function isArrayIsh(subject) {
  return isArray(subject) || Buffer.isBuffer(subject) ||
         subject && typeof subject === 'object' &&
         typeof subject.length === 'number';
}

function toHex(n) {
  if (n < 16) return '0' + n.toString(16);
  return n.toString(16);
}

function utf8ToBytes(str) {
  var byteArray = [];
  for (var i = 0; i < str.length; i++)
    if (str.charCodeAt(i) <= 0x7F)
      byteArray.push(str.charCodeAt(i));
    else {
      var h = encodeURIComponent(str.charAt(i)).substr(1).split('%');
      for (var j = 0; j < h.length; j++)
        byteArray.push(parseInt(h[j], 16));
    }

  return byteArray;
}

function asciiToBytes(str) {
  var byteArray = []
  for (var i = 0; i < str.length; i++ )
    // Node's code seems to be doing this and not & 0x7F..
    byteArray.push( str.charCodeAt(i) & 0xFF );

  return byteArray;
}

function base64ToBytes(str) {
  return toByteArray(str);
}

function blitBuffer(src, dst, offset, length) {
  var pos, i = 0;
  while (i < length) {
    if ((i+offset >= dst.length) || (i >= src.length))
      break;

    dst[i + offset] = src[i];
    i++;
  }
  return i;
}

function decodeUtf8Char(str) {
  try {
    return decodeURIComponent(str);
  } catch (err) {
    return String.fromCharCode(0xFFFD); // UTF 8 invalid char
  }
}

// read/write bit-twiddling

Buffer.prototype.readUInt8 = function(offset, noAssert) {
  var buffer = this;

  if (!noAssert) {
    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset < buffer.length,
        'Trying to read beyond buffer length');
  }

  if (offset >= buffer.length) return;

  return buffer[offset];
};

function readUInt16(buffer, offset, isBigEndian, noAssert) {
  var val = 0;


  if (!noAssert) {
    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 1 < buffer.length,
        'Trying to read beyond buffer length');
  }

  if (offset >= buffer.length) return 0;

  if (isBigEndian) {
    val = buffer[offset] << 8;
    if (offset + 1 < buffer.length) {
      val |= buffer[offset + 1];
    }
  } else {
    val = buffer[offset];
    if (offset + 1 < buffer.length) {
      val |= buffer[offset + 1] << 8;
    }
  }

  return val;
}

Buffer.prototype.readUInt16LE = function(offset, noAssert) {
  return readUInt16(this, offset, false, noAssert);
};

Buffer.prototype.readUInt16BE = function(offset, noAssert) {
  return readUInt16(this, offset, true, noAssert);
};

function readUInt32(buffer, offset, isBigEndian, noAssert) {
  var val = 0;

  if (!noAssert) {
    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 3 < buffer.length,
        'Trying to read beyond buffer length');
  }

  if (offset >= buffer.length) return 0;

  if (isBigEndian) {
    if (offset + 1 < buffer.length)
      val = buffer[offset + 1] << 16;
    if (offset + 2 < buffer.length)
      val |= buffer[offset + 2] << 8;
    if (offset + 3 < buffer.length)
      val |= buffer[offset + 3];
    val = val + (buffer[offset] << 24 >>> 0);
  } else {
    if (offset + 2 < buffer.length)
      val = buffer[offset + 2] << 16;
    if (offset + 1 < buffer.length)
      val |= buffer[offset + 1] << 8;
    val |= buffer[offset];
    if (offset + 3 < buffer.length)
      val = val + (buffer[offset + 3] << 24 >>> 0);
  }

  return val;
}

Buffer.prototype.readUInt32LE = function(offset, noAssert) {
  return readUInt32(this, offset, false, noAssert);
};

Buffer.prototype.readUInt32BE = function(offset, noAssert) {
  return readUInt32(this, offset, true, noAssert);
};


/*
 * Signed integer types, yay team! A reminder on how two's complement actually
 * works. The first bit is the signed bit, i.e. tells us whether or not the
 * number should be positive or negative. If the two's complement value is
 * positive, then we're done, as it's equivalent to the unsigned representation.
 *
 * Now if the number is positive, you're pretty much done, you can just leverage
 * the unsigned translations and return those. Unfortunately, negative numbers
 * aren't quite that straightforward.
 *
 * At first glance, one might be inclined to use the traditional formula to
 * translate binary numbers between the positive and negative values in two's
 * complement. (Though it doesn't quite work for the most negative value)
 * Mainly:
 *  - invert all the bits
 *  - add one to the result
 *
 * Of course, this doesn't quite work in Javascript. Take for example the value
 * of -128. This could be represented in 16 bits (big-endian) as 0xff80. But of
 * course, Javascript will do the following:
 *
 * > ~0xff80
 * -65409
 *
 * Whoh there, Javascript, that's not quite right. But wait, according to
 * Javascript that's perfectly correct. When Javascript ends up seeing the
 * constant 0xff80, it has no notion that it is actually a signed number. It
 * assumes that we've input the unsigned value 0xff80. Thus, when it does the
 * binary negation, it casts it into a signed value, (positive 0xff80). Then
 * when you perform binary negation on that, it turns it into a negative number.
 *
 * Instead, we're going to have to use the following general formula, that works
 * in a rather Javascript friendly way. I'm glad we don't support this kind of
 * weird numbering scheme in the kernel.
 *
 * (BIT-MAX - (unsigned)val + 1) * -1
 *
 * The astute observer, may think that this doesn't make sense for 8-bit numbers
 * (really it isn't necessary for them). However, when you get 16-bit numbers,
 * you do. Let's go back to our prior example and see how this will look:
 *
 * (0xffff - 0xff80 + 1) * -1
 * (0x007f + 1) * -1
 * (0x0080) * -1
 */
Buffer.prototype.readInt8 = function(offset, noAssert) {
  var buffer = this;
  var neg;

  if (!noAssert) {
    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset < buffer.length,
        'Trying to read beyond buffer length');
  }

  if (offset >= buffer.length) return;

  neg = buffer[offset] & 0x80;
  if (!neg) {
    return (buffer[offset]);
  }

  return ((0xff - buffer[offset] + 1) * -1);
};

function readInt16(buffer, offset, isBigEndian, noAssert) {
  var neg, val;

  if (!noAssert) {
    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 1 < buffer.length,
        'Trying to read beyond buffer length');
  }

  val = readUInt16(buffer, offset, isBigEndian, noAssert);
  neg = val & 0x8000;
  if (!neg) {
    return val;
  }

  return (0xffff - val + 1) * -1;
}

Buffer.prototype.readInt16LE = function(offset, noAssert) {
  return readInt16(this, offset, false, noAssert);
};

Buffer.prototype.readInt16BE = function(offset, noAssert) {
  return readInt16(this, offset, true, noAssert);
};

function readInt32(buffer, offset, isBigEndian, noAssert) {
  var neg, val;

  if (!noAssert) {
    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 3 < buffer.length,
        'Trying to read beyond buffer length');
  }

  val = readUInt32(buffer, offset, isBigEndian, noAssert);
  neg = val & 0x80000000;
  if (!neg) {
    return (val);
  }

  return (0xffffffff - val + 1) * -1;
}

Buffer.prototype.readInt32LE = function(offset, noAssert) {
  return readInt32(this, offset, false, noAssert);
};

Buffer.prototype.readInt32BE = function(offset, noAssert) {
  return readInt32(this, offset, true, noAssert);
};

function readFloat(buffer, offset, isBigEndian, noAssert) {
  if (!noAssert) {
    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset + 3 < buffer.length,
        'Trying to read beyond buffer length');
  }
  // TODO
  return Ieee754.readIEEE754(buffer, offset, isBigEndian,
      23, 4);
}

Buffer.prototype.readFloatLE = function(offset, noAssert) {
  return readFloat(this, offset, false, noAssert);
};

Buffer.prototype.readFloatBE = function(offset, noAssert) {
  return readFloat(this, offset, true, noAssert);
};

function readDouble(buffer, offset, isBigEndian, noAssert) {
  if (!noAssert) {
    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset + 7 < buffer.length,
        'Trying to read beyond buffer length');
  }

  return Ieee754.readIEEE754(buffer, offset, isBigEndian,
      52, 8);
}

Buffer.prototype.readDoubleLE = function(offset, noAssert) {
  return readDouble(this, offset, false, noAssert);
};

Buffer.prototype.readDoubleBE = function(offset, noAssert) {
  return readDouble(this, offset, true, noAssert);
};


/*
 * We have to make sure that the value is a valid integer. This means that it is
 * non-negative. It has no fractional component and that it does not exceed the
 * maximum allowed value.
 *
 *      value           The number to check for validity
 *
 *      max             The maximum value
 */
function verifuint(value, max) {
  assert.ok(typeof (value) == 'number',
      'cannot write a non-number as a number');

  assert.ok(value >= 0,
      'specified a negative value for writing an unsigned value');

  assert.ok(value <= max, 'value is larger than maximum value for type');

  assert.ok(Math.floor(value) === value, 'value has a fractional component');
}

Buffer.prototype.writeUInt8 = function(value, offset, noAssert) {
  var buffer = this;

  if (!noAssert) {
    assert.ok(value !== undefined && value !== null,
        'missing value');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset < buffer.length,
        'trying to write beyond buffer length');

    verifuint(value, 0xff);
  }

  if (offset < buffer.length) {
    buffer[offset] = value;
  }
};

function writeUInt16(buffer, value, offset, isBigEndian, noAssert) {
  if (!noAssert) {
    assert.ok(value !== undefined && value !== null,
        'missing value');

    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 1 < buffer.length,
        'trying to write beyond buffer length');

    verifuint(value, 0xffff);
  }

  for (var i = 0; i < Math.min(buffer.length - offset, 2); i++) {
    buffer[offset + i] =
        (value & (0xff << (8 * (isBigEndian ? 1 - i : i)))) >>>
            (isBigEndian ? 1 - i : i) * 8;
  }

}

Buffer.prototype.writeUInt16LE = function(value, offset, noAssert) {
  writeUInt16(this, value, offset, false, noAssert);
};

Buffer.prototype.writeUInt16BE = function(value, offset, noAssert) {
  writeUInt16(this, value, offset, true, noAssert);
};

function writeUInt32(buffer, value, offset, isBigEndian, noAssert) {
  if (!noAssert) {
    assert.ok(value !== undefined && value !== null,
        'missing value');

    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 3 < buffer.length,
        'trying to write beyond buffer length');

    verifuint(value, 0xffffffff);
  }

  for (var i = 0; i < Math.min(buffer.length - offset, 4); i++) {
    buffer[offset + i] =
        (value >>> (isBigEndian ? 3 - i : i) * 8) & 0xff;
  }
}

Buffer.prototype.writeUInt32LE = function(value, offset, noAssert) {
  writeUInt32(this, value, offset, false, noAssert);
};

Buffer.prototype.writeUInt32BE = function(value, offset, noAssert) {
  writeUInt32(this, value, offset, true, noAssert);
};


/*
 * We now move onto our friends in the signed number category. Unlike unsigned
 * numbers, we're going to have to worry a bit more about how we put values into
 * arrays. Since we are only worrying about signed 32-bit values, we're in
 * slightly better shape. Unfortunately, we really can't do our favorite binary
 * & in this system. It really seems to do the wrong thing. For example:
 *
 * > -32 & 0xff
 * 224
 *
 * What's happening above is really: 0xe0 & 0xff = 0xe0. However, the results of
 * this aren't treated as a signed number. Ultimately a bad thing.
 *
 * What we're going to want to do is basically create the unsigned equivalent of
 * our representation and pass that off to the wuint* functions. To do that
 * we're going to do the following:
 *
 *  - if the value is positive
 *      we can pass it directly off to the equivalent wuint
 *  - if the value is negative
 *      we do the following computation:
 *         mb + val + 1, where
 *         mb   is the maximum unsigned value in that byte size
 *         val  is the Javascript negative integer
 *
 *
 * As a concrete value, take -128. In signed 16 bits this would be 0xff80. If
 * you do out the computations:
 *
 * 0xffff - 128 + 1
 * 0xffff - 127
 * 0xff80
 *
 * You can then encode this value as the signed version. This is really rather
 * hacky, but it should work and get the job done which is our goal here.
 */

/*
 * A series of checks to make sure we actually have a signed 32-bit number
 */
function verifsint(value, max, min) {
  assert.ok(typeof (value) == 'number',
      'cannot write a non-number as a number');

  assert.ok(value <= max, 'value larger than maximum allowed value');

  assert.ok(value >= min, 'value smaller than minimum allowed value');

  assert.ok(Math.floor(value) === value, 'value has a fractional component');
}

function verifIEEE754(value, max, min) {
  assert.ok(typeof (value) == 'number',
      'cannot write a non-number as a number');

  assert.ok(value <= max, 'value larger than maximum allowed value');

  assert.ok(value >= min, 'value smaller than minimum allowed value');
}

Buffer.prototype.writeInt8 = function(value, offset, noAssert) {
  var buffer = this;

  if (!noAssert) {
    assert.ok(value !== undefined && value !== null,
        'missing value');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset < buffer.length,
        'Trying to write beyond buffer length');

    verifsint(value, 0x7f, -0x80);
  }

  if (value >= 0) {
    buffer.writeUInt8(value, offset, noAssert);
  } else {
    buffer.writeUInt8(0xff + value + 1, offset, noAssert);
  }
};

function writeInt16(buffer, value, offset, isBigEndian, noAssert) {
  if (!noAssert) {
    assert.ok(value !== undefined && value !== null,
        'missing value');

    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 1 < buffer.length,
        'Trying to write beyond buffer length');

    verifsint(value, 0x7fff, -0x8000);
  }

  if (value >= 0) {
    writeUInt16(buffer, value, offset, isBigEndian, noAssert);
  } else {
    writeUInt16(buffer, 0xffff + value + 1, offset, isBigEndian, noAssert);
  }
}

Buffer.prototype.writeInt16LE = function(value, offset, noAssert) {
  writeInt16(this, value, offset, false, noAssert);
};

Buffer.prototype.writeInt16BE = function(value, offset, noAssert) {
  writeInt16(this, value, offset, true, noAssert);
};

function writeInt32(buffer, value, offset, isBigEndian, noAssert) {
  if (!noAssert) {
    assert.ok(value !== undefined && value !== null,
        'missing value');

    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 3 < buffer.length,
        'Trying to write beyond buffer length');

    verifsint(value, 0x7fffffff, -0x80000000);
  }

  if (value >= 0) {
    writeUInt32(buffer, value, offset, isBigEndian, noAssert);
  } else {
    writeUInt32(buffer, 0xffffffff + value + 1, offset, isBigEndian, noAssert);
  }
}

Buffer.prototype.writeInt32LE = function(value, offset, noAssert) {
  writeInt32(this, value, offset, false, noAssert);
};

Buffer.prototype.writeInt32BE = function(value, offset, noAssert) {
  writeInt32(this, value, offset, true, noAssert);
};

function writeFloat(buffer, value, offset, isBigEndian, noAssert) {
  if (!noAssert) {
    assert.ok(value !== undefined && value !== null,
        'missing value');

    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 3 < buffer.length,
        'Trying to write beyond buffer length');

    verifIEEE754(value, 3.4028234663852886e+38, -3.4028234663852886e+38);
  }

  Ieee754.writeIEEE754(buffer, value, offset, isBigEndian, 23, 4);
}

Buffer.prototype.writeFloatLE = function(value, offset, noAssert) {
  writeFloat(this, value, offset, false, noAssert);
};

Buffer.prototype.writeFloatBE = function(value, offset, noAssert) {
  writeFloat(this, value, offset, true, noAssert);
};

function writeDouble(buffer, value, offset, isBigEndian, noAssert) {
  if (!noAssert) {
    assert.ok(value !== undefined && value !== null,
        'missing value');

    assert.ok(typeof (isBigEndian) === 'boolean',
        'missing or invalid endian');

    assert.ok(offset !== undefined && offset !== null,
        'missing offset');

    assert.ok(offset + 7 < buffer.length,
        'Trying to write beyond buffer length');

    verifIEEE754(value, 1.7976931348623157E+308, -1.7976931348623157E+308);
  }

  Ieee754.writeIEEE754(buffer, value, offset, isBigEndian,
      52, 8);
}

Buffer.prototype.writeDoubleLE = function(value, offset, noAssert) {
  writeDouble(this, value, offset, false, noAssert);
};

Buffer.prototype.writeDoubleBE = function(value, offset, noAssert) {
  writeDouble(this, value, offset, true, noAssert);
};
};
BundleModuleCode['os/buffer_ieee754']=function (module,exports,global,process){
exports.readIEEE754 = function(buffer, offset, isBE, mLen, nBytes) {
  var e, m,
      eLen = nBytes * 8 - mLen - 1,
      eMax = (1 << eLen) - 1,
      eBias = eMax >> 1,
      nBits = -7,
      i = isBE ? 0 : (nBytes - 1),
      d = isBE ? 1 : -1,
      s = buffer[offset + i];

  i += d;

  e = s & ((1 << (-nBits)) - 1);
  s >>= (-nBits);
  nBits += eLen;
  for (; nBits > 0; e = e * 256 + buffer[offset + i], i += d, nBits -= 8);

  m = e & ((1 << (-nBits)) - 1);
  e >>= (-nBits);
  nBits += mLen;
  for (; nBits > 0; m = m * 256 + buffer[offset + i], i += d, nBits -= 8);

  if (e === 0) {
    e = 1 - eBias;
  } else if (e === eMax) {
    return m ? NaN : ((s ? -1 : 1) * Infinity);
  } else {
    m = m + Math.pow(2, mLen);
    e = e - eBias;
  }
  return (s ? -1 : 1) * m * Math.pow(2, e - mLen);
};

exports.writeIEEE754 = function(buffer, value, offset, isBE, mLen, nBytes) {
  var e, m, c,
      eLen = nBytes * 8 - mLen - 1,
      eMax = (1 << eLen) - 1,
      eBias = eMax >> 1,
      rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0),
      i = isBE ? (nBytes - 1) : 0,
      d = isBE ? -1 : 1,
      s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0;

  value = Math.abs(value);

  if (isNaN(value) || value === Infinity) {
    m = isNaN(value) ? 1 : 0;
    e = eMax;
  } else {
    e = Math.floor(Math.log(value) / Math.LN2);
    if (value * (c = Math.pow(2, -e)) < 1) {
      e--;
      c *= 2;
    }
    if (e + eBias >= 1) {
      value += rt / c;
    } else {
      value += rt * Math.pow(2, 1 - eBias);
    }
    if (value * c >= 2) {
      e++;
      c /= 2;
    }

    if (e + eBias >= eMax) {
      m = 0;
      e = eMax;
    } else if (e + eBias >= 1) {
      m = (value * c - 1) * Math.pow(2, mLen);
      e = e + eBias;
    } else {
      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen);
      e = 0;
    }
  }

  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8);

  e = (e << mLen) | m;
  eLen += mLen;
  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8);

  buffer[offset + i - d] |= s * 128;
};
};
BundleModuleCode['com/io.browser']=function (module,exports,global,process){
    /*
    ************
    ** Browser
    ************
    */

    var tracing = true;
    var stderr_fun = function (str) { console.log(str); };
    var stdout_fun = function (str) { console.log(str); };
    var args=[];

    module.exports = {
        checkOptions : function(options,defaultOptions) {
          return Object.assign({}, defaultOptions||{}, options) },

        checkOption : function (option,defaultOption) { 
          return option==undefined? defaultOption:option },

        config: {
            columns:undefined,
            rows:undefined
        },
        /*
         ** FILE IO
         * TODO WebStorage
         */
        close: function (fd) {
            return;
        },
        exists: function (path) {
            return false;
        },
        open: function (path, mode) {
            var fd = Fs.openSync(path, mode);
            return fd;
        },

        read: function (fd, len, foff) {
            // TODO
        },
        read_file: function (path) {
            return '';
        },

        read_line: function (fd) {
            // TODO
        },
        /**
         *
         * @param fd
         * @param buf
         * @param boff
         * @param len
         * @param [foff]
         * @returns {*}
         */
        read_buf: function (fd, buf, boff, len, foff) {
            return -1;
        },
        sync: function (fd) {
            return;
        },
        
        /**
         *
         * @param fd
         * @param data
         * @param [foff]
         * @returns {*}
         */
        write: function (fd, data, foff) {
            return -1;
        },
        /**
         *
         * @param fd
         * @param buf
         * @param bpos
         * @param blen
         * @param [foff]
         * @returns {*}
         */
        write_buf: function (fd, buf, bpos, blen, foff) {
            return -1;
        },

        /*
         ** CONSOLE IO
         */
        debug: function (msg) {
            stderr_fun('Debug: ' + msg);
        },
        err: function (msg) {
            stderr_fun('Error: ' + msg);
            throw Error(msg);
        },
        fail: function (msg) {
            stderr_fun('Fatal Error: ' + msg);
        },
        inspect: function (obj) {
            return;
        },
        stacktrace: function () {
            var e = new Error('dummy');
            var stack = e.stack.replace(/^[^\(]+?[\n$]/gm, '')
                .replace(/^\s+at\s+/gm, '')
                .replace(/^Object.<anonymous>\s*\(/gm, '{anonymous}()@')
                .split('\n');
            stderr_fun('Stack Trace');
            stderr_fun('--------------------------------');
            for(var i in stack) {
                if (i>0) {
                    var line = stack[i];
                    if(line.indexOf('Module.',0)>=0) break;
                    stderr_fun(line);
                }
            }
            stderr_fun('--------------------------------');
        },
        time : function () {
          return Date.now()
        },
        /**
         *
         * @param e
         * @param where
         */
        printstack: function (e,where) {
            if (where==undefined) stderr_fun(e);
            else stderr_fun(where+': '+e);
        },
        /**
         *
         * @param {boolean|string} condmsg conditional message var log=X;  log((log lt. N)||(msg))
         */
        log: function (condmsg) {
            if (condmsg != true) console.warn(condmsg);
        },
        out: function (msg) {
            stdout_fun(msg)
        },
        warn: function (msg) {
            stderr_fun('Warning: ' + msg);
        },


        set_stderr: function(fun) {
            stderr_fun=fun;
        },
        set_stdout: function(fun) {
            stdout_fun=fun;
        },

        stderr: function (msg) {
            stderr_fun(msg);
        },
        stdout: function (msg) {
            stdout_fun(msg);
        },

        /** Write a message with a time stamp written to the trace file.
         *
         * @param {boolean|string} condmsg conditional message var trace=Io.tracing;  trace(trace||(msg))
         */
        trace: function (condmsg) {
            if (condmsg != true && tracefile != undefined) {
                var date = new Date();
                var time = date.getTime();
                this.log('[' + time + '] ' + condmsg + '\n');
            }
        },
        tracing: tracing,
        /**
         *
         * @param {string} path
         */
        trace_open: function (path) {
            return undefined;
        },

        exit: function (n) {
            return;
        },
        /**
         *
         * @returns {*} RSS HEAP in kBytes {data,heap}
         */
        mem: function () {
            return {data:0,heap:0};
        },

        getenv: function (name, def) {
            return def;
        },
        workdir: function () {
            return '';
        },
        /**
         *  @return {string []}
         */
        getargs: function () {
            return args;
        },
        set_args: function (argv) {
            args=argv;
        }
    };
};
BundleModuleCode['com/path']=function (module,exports,global,process){
var process = process || {};
(function () {
  "use strict";

// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.


var isWindows = process.platform === 'win32';
var util = Require('util');


// resolves . and .. elements in a path array with directory names there
// must be no slashes, empty elements, or device names (c:\) in the array
// (so also no leading and trailing slashes - it does not distinguish
// relative and absolute paths)
function normalizeArray(parts, allowAboveRoot) {
  // if the path tries to go above the root, `up` ends up > 0
  var up = 0;
  for (var i = parts.length - 1; i >= 0; i--) {
    var last = parts[i];
    if (last === '.') {
      parts.splice(i, 1);
    } else if (last === '..') {
      parts.splice(i, 1);
      up++;
    } else if (up) {
      parts.splice(i, 1);
      up--;
    }
  }

  // if the path is allowed to go above the root, restore leading ..s
  if (allowAboveRoot) {
    for (; up--; up) {
      parts.unshift('..');
    }
  }

  return parts;
}


if (isWindows) {
  // Regex to split a windows path into three parts: [*, device, slash,
  // tail] windows-only
  var splitDeviceRe =
      /^([a-zA-Z]:|[\\\/]{2}[^\\\/]+[\\\/]+[^\\\/]+)?([\\\/])?([\s\S]*?)$/;

  // Regex to split the tail part of the above into [*, dir, basename, ext]
  var splitTailRe =
      /^([\s\S]*?)((?:\.{1,2}|[^\\\/]+?|)(\.[^.\/\\]*|))(?:[\\\/]*)$/;

  // Function to split a filename into [root, dir, basename, ext]
  // windows version
  var splitPath = function(filename) {
    // Separate device+slash from tail
    var result = splitDeviceRe.exec(filename),
        device = (result[1] || '') + (result[2] || ''),
        tail = result[3] || '';
    // Split the tail into dir, basename and extension
    var result2 = splitTailRe.exec(tail),
        dir = result2[1],
        basename = result2[2],
        ext = result2[3];
    return [device, dir, basename, ext];
  };

  var normalizeUNCRoot = function(device) {
    return '\\\\' + device.replace(/^[\\\/]+/, '').replace(/[\\\/]+/g, '\\');
  };

  // path.resolve([from ...], to)
  // windows version
  exports.resolve = function() {
    var resolvedDevice = '',
        resolvedTail = '',
        resolvedAbsolute = false;

    for (var i = arguments.length - 1; i >= -1; i--) {
      var path;
      if (i >= 0) {
        path = arguments[i];
      } else if (!resolvedDevice) {
        path = process.cwd();
      } else {
        // Windows has the concept of drive-specific current working
        // directories. If we've resolved a drive letter but not yet an
        // absolute path, get cwd for that drive. We're sure the device is not
        // an unc path at this points, because unc paths are always absolute.
        path = process.env['=' + resolvedDevice];
        // Verify that a drive-local cwd was found and that it actually points
        // to our drive. If not, default to the drive's root.
        if (!path || path.substr(0, 3).toLowerCase() !==
            resolvedDevice.toLowerCase() + '\\') {
          path = resolvedDevice + '\\';
        }
      }

      // Skip empty and invalid entries
      if (!util.isString(path)) {
        throw new TypeError('Arguments to path.resolve must be strings');
      } else if (!path) {
        continue;
      }

      var result = splitDeviceRe.exec(path),
          device = result[1] || '',
          isUnc = device && device.charAt(1) !== ':',
          isAbsolute = exports.isAbsolute(path),
          tail = result[3];

      if (device &&
          resolvedDevice &&
          device.toLowerCase() !== resolvedDevice.toLowerCase()) {
        // This path points to another device so it is not applicable
        continue;
      }

      if (!resolvedDevice) {
        resolvedDevice = device;
      }
      if (!resolvedAbsolute) {
        resolvedTail = tail + '\\' + resolvedTail;
        resolvedAbsolute = isAbsolute;
      }

      if (resolvedDevice && resolvedAbsolute) {
        break;
      }
    }

    // Convert slashes to backslashes when `resolvedDevice` points to an UNC
    // root. Also squash multiple slashes into a single one where appropriate.
    if (isUnc) {
      resolvedDevice = normalizeUNCRoot(resolvedDevice);
    }

    // At this point the path should be resolved to a full absolute path,
    // but handle relative paths to be safe (might happen when process.cwd()
    // fails)

    // Normalize the tail path

    function f(p) {
      return !!p;
    }

    resolvedTail = normalizeArray(resolvedTail.split(/[\\\/]+/).filter(f),
                                  !resolvedAbsolute).join('\\');

    return (resolvedDevice + (resolvedAbsolute ? '\\' : '') + resolvedTail) ||
           '.';
  };

  // windows version
  exports.normalize = function(path) {
    var result = splitDeviceRe.exec(path),
        device = result[1] || '',
        isUnc = device && device.charAt(1) !== ':',
        isAbsolute = exports.isAbsolute(path),
        tail = result[3],
        trailingSlash = /[\\\/]$/.test(tail);

    // If device is a drive letter, we'll normalize to lower case.
    if (device && device.charAt(1) === ':') {
      device = device[0].toLowerCase() + device.substr(1);
    }

    // Normalize the tail path
    tail = normalizeArray(tail.split(/[\\\/]+/).filter(function(p) {
      return !!p;
    }), !isAbsolute).join('\\');

    if (!tail && !isAbsolute) {
      tail = '.';
    }
    if (tail && trailingSlash) {
      tail += '\\';
    }

    // Convert slashes to backslashes when `device` points to an UNC root.
    // Also squash multiple slashes into a single one where appropriate.
    if (isUnc) {
      device = normalizeUNCRoot(device);
    }

    return device + (isAbsolute ? '\\' : '') + tail;
  };

  // windows version
  exports.isAbsolute = function(path) {
    var result = splitDeviceRe.exec(path),
        device = result[1] || '',
        isUnc = !!device && device.charAt(1) !== ':';
    // UNC paths are always absolute
    return !!result[2] || isUnc;
  };

  // windows version
  exports.join = function() {
    function f(p) {
      if (!util.isString(p)) {
        throw new TypeError('Arguments to path.join must be strings');
      }
      return p;
    }

    var paths = Array.prototype.filter.call(arguments, f);
    var joined = paths.join('\\');

    // Make sure that the joined path doesn't start with two slashes, because
    // normalize() will mistake it for an UNC path then.
    //
    // This step is skipped when it is very clear that the user actually
    // intended to point at an UNC path. This is assumed when the first
    // non-empty string arguments starts with exactly two slashes followed by
    // at least one more non-slash character.
    //
    // Note that for normalize() to treat a path as an UNC path it needs to
    // have at least 2 components, so we don't filter for that here.
    // This means that the user can use join to construct UNC paths from
    // a server name and a share name; for example:
    //   path.join('//server', 'share') -> '\\\\server\\share\')
    if (!/^[\\\/]{2}[^\\\/]/.test(paths[0])) {
      joined = joined.replace(/^[\\\/]{2,}/, '\\');
    }

    return exports.normalize(joined);
  };

  // path.relative(from, to)
  // it will solve the relative path from 'from' to 'to', for instance:
  // from = 'C:\\orandea\\test\\aaa'
  // to = 'C:\\orandea\\impl\\bbb'
  // The output of the function should be: '..\\..\\impl\\bbb'
  // windows version
  exports.relative = function(from, to) {
    from = exports.resolve(from);
    to = exports.resolve(to);

    // windows is not case sensitive
    var lowerFrom = from.toLowerCase();
    var lowerTo = to.toLowerCase();

    function trim(arr) {
      var start = 0;
      for (; start < arr.length; start++) {
        if (arr[start] !== '') break;
      }

      var end = arr.length - 1;
      for (; end >= 0; end--) {
        if (arr[end] !== '') break;
      }

      if (start > end) return [];
      return arr.slice(start, end + 1);
    }

    var toParts = trim(to.split('\\'));

    var lowerFromParts = trim(lowerFrom.split('\\'));
    var lowerToParts = trim(lowerTo.split('\\'));

    var length = Math.min(lowerFromParts.length, lowerToParts.length);
    var samePartsLength = length;
    for (var i = 0; i < length; i++) {
      if (lowerFromParts[i] !== lowerToParts[i]) {
        samePartsLength = i;
        break;
      }
    }

    if (samePartsLength == 0) {
      return to;
    }

    var outputParts = [];
    for (var i = samePartsLength; i < lowerFromParts.length; i++) {
      outputParts.push('..');
    }

    outputParts = outputParts.concat(toParts.slice(samePartsLength));

    return outputParts.join('\\');
  };

  exports.sep = '\\';
  exports.delimiter = ';';

} else /* posix */ {

  // Split a filename into [root, dir, basename, ext], unix version
  // 'root' is just a slash, or nothing.
  var splitPathRe =
      /^(\/?|)([\s\S]*?)((?:\.{1,2}|[^\/]+?|)(\.[^.\/]*|))(?:[\/]*)$/;
  var splitPath = function(filename) {
    return splitPathRe.exec(filename).slice(1);
  };

  // path.resolve([from ...], to)
  // posix version
  exports.resolve = function() {
    var resolvedPath = '',
        resolvedAbsolute = false;

    for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {
      var path = (i >= 0) ? arguments[i] : process.cwd();

      // Skip empty and invalid entries
      if (!util.isString(path)) {
        throw new TypeError('Arguments to path.resolve must be strings');
      } else if (!path) {
        continue;
      }

      resolvedPath = path + '/' + resolvedPath;
      resolvedAbsolute = path.charAt(0) === '/';
    }

    // At this point the path should be resolved to a full absolute path, but
    // handle relative paths to be safe (might happen when process.cwd() fails)

    // Normalize the path
    resolvedPath = normalizeArray(resolvedPath.split('/').filter(function(p) {
      return !!p;
    }), !resolvedAbsolute).join('/');

    return ((resolvedAbsolute ? '/' : '') + resolvedPath) || '.';
  };

  // path.normalize(path)
  // posix version
  exports.normalize = function(path) {
    var isAbsolute = exports.isAbsolute(path),
        trailingSlash = path[path.length - 1] === '/',
        segments = path.split('/'),
        nonEmptySegments = [];

    // Normalize the path
    for (var i = 0; i < segments.length; i++) {
      if (segments[i]) {
        nonEmptySegments.push(segments[i]);
      }
    }
    path = normalizeArray(nonEmptySegments, !isAbsolute).join('/');

    if (!path && !isAbsolute) {
      path = '.';
    }
    if (path && trailingSlash) {
      path += '/';
    }

    return (isAbsolute ? '/' : '') + path;
  };

  // posix version
  exports.isAbsolute = function(path) {
    return path.charAt(0) === '/';
  };

  // posix version
  exports.join = function() {
    var path = '';
    for (var i = 0; i < arguments.length; i++) {
      var segment = arguments[i];
      if (!util.isString(segment)) {
        throw new TypeError('Arguments to path.join must be strings');
      }
      if (segment) {
        if (!path) {
          path += segment;
        } else {
          path += '/' + segment;
        }
      }
    }
    return exports.normalize(path);
  };


  // path.relative(from, to)
  // posix version
  exports.relative = function(from, to) {
    from = exports.resolve(from).substr(1);
    to = exports.resolve(to).substr(1);

    function trim(arr) {
      var start = 0;
      for (; start < arr.length; start++) {
        if (arr[start] !== '') break;
      }

      var end = arr.length - 1;
      for (; end >= 0; end--) {
        if (arr[end] !== '') break;
      }

      if (start > end) return [];
      return arr.slice(start, end + 1);
    }

    var fromParts = trim(from.split('/'));
    var toParts = trim(to.split('/'));

    var length = Math.min(fromParts.length, toParts.length);
    var samePartsLength = length;
    for (var i = 0; i < length; i++) {
      if (fromParts[i] !== toParts[i]) {
        samePartsLength = i;
        break;
      }
    }

    var outputParts = [];
    for (var i = samePartsLength; i < fromParts.length; i++) {
      outputParts.push('..');
    }

    outputParts = outputParts.concat(toParts.slice(samePartsLength));

    return outputParts.join('/');
  };

  exports.sep = '/';
  exports.delimiter = ':';
}

exports.dirname = function(path) {
  var result = splitPath(path),
      root = result[0],
      dir = result[1];

  if (!root && !dir) {
    // No dirname whatsoever
    return '.';
  }

  if (dir) {
    // It has a dirname, strip trailing slash
    dir = dir.substr(0, dir.length - 1);
  }

  return root + dir;
};


exports.basename = function(path, ext) {
  var f = splitPath(path)[2];
  // TODO: make this comparison case-insensitive on windows?
  if (ext && f.substr(-1 * ext.length) === ext) {
    f = f.substr(0, f.length - ext.length);
  }
  return f;
};


exports.extname = function(path) {
  return splitPath(path)[3];
};


exports.exists = util.deprecate(function(path, callback) {
  require('fs').exists(path, callback);
}, 'path.exists is now called `fs.exists`.');


exports.existsSync = util.deprecate(function(path) {
  return require('fs').existsSync(path);
}, 'path.existsSync is now called `fs.existsSync`.');


if (isWindows) {
  exports._makeLong = function(path) {
    // Note: this will *probably* throw somewhere.
    if (!util.isString(path))
      return path;

    if (!path) {
      return '';
    }

    var resolvedPath = exports.resolve(path);

    if (/^[a-zA-Z]\:\\/.test(resolvedPath)) {
      // path is local filesystem path, which needs to be converted
      // to long UNC path.
      return '\\\\?\\' + resolvedPath;
    } else if (/^\\\\[^?.]/.test(resolvedPath)) {
      // path is network UNC path, which needs to be converted
      // to long UNC path.
      return '\\\\?\\UNC\\' + resolvedPath.substring(2);
    }

    return path;
  };
} else {
  exports._makeLong = function(path) {
    return path;
  };
}
}());
};
BundleModuleCode['os/util']=function (module,exports,global,process){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

var formatRegExp = /%[sdj%]/g;
exports.format = function(f) {
  if (!isString(f)) {
    var objects = [];
    for (var i = 0; i < arguments.length; i++) {
      objects.push(inspect(arguments[i]));
    }
    return objects.join(' ');
  }

  var i = 1;
  var args = arguments;
  var len = args.length;
  var str = String(f).replace(formatRegExp, function(x) {
    if (x === '%%') return '%';
    if (i >= len) return x;
    switch (x) {
      case '%s': return String(args[i++]);
      case '%d': return Number(args[i++]);
      case '%j':
        try {
          return JSON.stringify(args[i++]);
        } catch (_) {
          return '[Circular]';
        }
      default:
        return x;
    }
  });
  for (var x = args[i]; i < len; x = args[++i]) {
    if (isNull(x) || !isObject(x)) {
      str += ' ' + x;
    } else {
      str += ' ' + inspect(x);
    }
  }
  return str;
};


// Mark that a method should not be used.
// Returns a modified function which warns once by default.
// If --no-deprecation is set, then it is a no-op.
exports.deprecate = function(fn, msg) {
  // Allow for deprecating things in the process of starting up.
  if (isUndefined(global.process)) {
    return function() {
      return exports.deprecate(fn, msg).apply(this, arguments);
    };
  }

  if (process.noDeprecation === true) {
    return fn;
  }

  var warned = false;
  function deprecated() {
    if (!warned) {
      if (process.throwDeprecation) {
        throw new Error(msg);
      } else if (process.traceDeprecation) {
        console.trace(msg);
      } else {
        console.error(msg);
      }
      warned = true;
    }
    return fn.apply(this, arguments);
  }

  return deprecated;
};


var debugs = {};
var debugEnviron;
exports.debuglog = function(set) {
  if (isUndefined(debugEnviron))
    debugEnviron = process.env.NODE_DEBUG || '';
  set = set.toUpperCase();
  if (!debugs[set]) {
    if (new RegExp('\\b' + set + '\\b', 'i').test(debugEnviron)) {
      var pid = process.pid;
      debugs[set] = function() {
        var msg = exports.format.apply(exports, arguments);
        console.error('%s %d: %s', set, pid, msg);
      };
    } else {
      debugs[set] = function() {};
    }
  }
  return debugs[set];
};


/**
 * Echos the value of a value. Trys to print the value out
 * in the best way possible given the different types.
 *
 * @param {Object} obj The object to print out.
 * @param {Object} opts Optional options object that alters the output.
 */
/* legacy: obj, showHidden, depth, colors*/
function inspect(obj, opts) {
  // default options
  var ctx = {
    seen: [],
    stylize: stylizeNoColor
  };
  // legacy...
  if (arguments.length >= 3) ctx.depth = arguments[2];
  if (arguments.length >= 4) ctx.colors = arguments[3];
  if (isBoolean(opts)) {
    // legacy...
    ctx.showHidden = opts;
  } else if (opts) {
    // got an "options" object
    exports._extend(ctx, opts);
  }
  // set default options
  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;
  if (isUndefined(ctx.depth)) ctx.depth = 2;
  if (isUndefined(ctx.colors)) ctx.colors = false;
  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;
  if (ctx.colors) ctx.stylize = stylizeWithColor;
  return formatValue(ctx, obj, ctx.depth);
}
exports.inspect = inspect;


// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics
inspect.colors = {
  'bold' : [1, 22],
  'italic' : [3, 23],
  'underline' : [4, 24],
  'inverse' : [7, 27],
  'white' : [37, 39],
  'grey' : [90, 39],
  'black' : [30, 39],
  'blue' : [34, 39],
  'cyan' : [36, 39],
  'green' : [32, 39],
  'magenta' : [35, 39],
  'red' : [31, 39],
  'yellow' : [33, 39]
};

// Don't use 'blue' not visible on cmd.exe
inspect.styles = {
  'special': 'cyan',
  'number': 'yellow',
  'boolean': 'yellow',
  'undefined': 'grey',
  'null': 'bold',
  'string': 'green',
  'date': 'magenta',
  // "name": intentionally not styling
  'regexp': 'red'
};


function stylizeWithColor(str, styleType) {
  var style = inspect.styles[styleType];

  if (style) {
    return '\u001b[' + inspect.colors[style][0] + 'm' + str +
           '\u001b[' + inspect.colors[style][1] + 'm';
  } else {
    return str;
  }
}


function stylizeNoColor(str, styleType) {
  return str;
}


function arrayToHash(array) {
  var hash = {};

  array.forEach(function(val, idx) {
    hash[val] = true;
  });

  return hash;
}


function formatValue(ctx, value, recurseTimes) {
  // Provide a hook for user-specified inspect functions.
  // Check that value is an object with an inspect function on it
  if (ctx.customInspect &&
      value &&
      isFunction(value.inspect) &&
      // Filter out the util module, it's inspect function is special
      value.inspect !== exports.inspect &&
      // Also filter out any prototype objects using the circular check.
      !(value.constructor && value.constructor.prototype === value)) {
    var ret = value.inspect(recurseTimes, ctx);
    if (!isString(ret)) {
      ret = formatValue(ctx, ret, recurseTimes);
    }
    return ret;
  }

  // Primitive types cannot have properties
  var primitive = formatPrimitive(ctx, value);
  if (primitive) {
    return primitive;
  }

  // Look up the keys of the object.
  var keys = Object.keys(value);
  var visibleKeys = arrayToHash(keys);

  if (ctx.showHidden) {
    keys = Object.getOwnPropertyNames(value);
  }

  // IE doesn't make error fields non-enumerable
  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx
  if (isError(value)
      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {
    return formatError(value);
  }

  // Some type of object without properties can be shortcutted.
  if (keys.length === 0) {
    if (isFunction(value)) {
      var name = value.name ? ': ' + value.name : '';
      return ctx.stylize('[Function' + name + ']', 'special');
    }
    if (isRegExp(value)) {
      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');
    }
    if (isDate(value)) {
      return ctx.stylize(Date.prototype.toString.call(value), 'date');
    }
    if (isError(value)) {
      return formatError(value);
    }
  }

  var base = '', array = false, braces = ['{', '}'];

  // Make Array say that they are Array
  if (isArray(value)) {
    array = true;
    braces = ['[', ']'];
  }

  // Make functions say that they are functions
  if (isFunction(value)) {
    var n = value.name ? ': ' + value.name : '';
    base = ' [Function' + n + ']';
  }

  // Make RegExps say that they are RegExps
  if (isRegExp(value)) {
    base = ' ' + RegExp.prototype.toString.call(value);
  }

  // Make dates with properties first say the date
  if (isDate(value)) {
    base = ' ' + Date.prototype.toUTCString.call(value);
  }

  // Make error with message first say the error
  if (isError(value)) {
    base = ' ' + formatError(value);
  }

  if (keys.length === 0 && (!array || value.length == 0)) {
    return braces[0] + base + braces[1];
  }

  if (recurseTimes < 0) {
    if (isRegExp(value)) {
      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');
    } else {
      return ctx.stylize('[Object]', 'special');
    }
  }

  ctx.seen.push(value);

  var output;
  if (array) {
    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);
  } else {
    output = keys.map(function(key) {
      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);
    });
  }

  ctx.seen.pop();

  return reduceToSingleString(output, base, braces);
}


function formatPrimitive(ctx, value) {
  if (isUndefined(value))
    return ctx.stylize('undefined', 'undefined');
  if (isString(value)) {
    var simple = '\'' + JSON.stringify(value).replace(/^"|"$/g, '')
                                             .replace(/'/g, "\\'")
                                             .replace(/\\"/g, '"') + '\'';
    return ctx.stylize(simple, 'string');
  }
  if (isNumber(value))
    return ctx.stylize('' + value, 'number');
  if (isBoolean(value))
    return ctx.stylize('' + value, 'boolean');
  // For some reason typeof null is "object", so special case here.
  if (isNull(value))
    return ctx.stylize('null', 'null');
}


function formatError(value) {
  return '[' + Error.prototype.toString.call(value) + ']';
}


function formatArray(ctx, value, recurseTimes, visibleKeys, keys) {
  var output = [];
  for (var i = 0, l = value.length; i < l; ++i) {
    if (hasOwnProperty(value, String(i))) {
      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,
          String(i), true));
    } else {
      output.push('');
    }
  }
  keys.forEach(function(key) {
    if (!key.match(/^\d+$/)) {
      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,
          key, true));
    }
  });
  return output;
}


function formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {
  var name, str, desc;
  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };
  if (desc.get) {
    if (desc.set) {
      str = ctx.stylize('[Getter/Setter]', 'special');
    } else {
      str = ctx.stylize('[Getter]', 'special');
    }
  } else {
    if (desc.set) {
      str = ctx.stylize('[Setter]', 'special');
    }
  }
  if (!hasOwnProperty(visibleKeys, key)) {
    name = '[' + key + ']';
  }
  if (!str) {
    if (ctx.seen.indexOf(desc.value) < 0) {
      if (isNull(recurseTimes)) {
        str = formatValue(ctx, desc.value, null);
      } else {
        str = formatValue(ctx, desc.value, recurseTimes - 1);
      }
      if (str.indexOf('\n') > -1) {
        if (array) {
          str = str.split('\n').map(function(line) {
            return '  ' + line;
          }).join('\n').substr(2);
        } else {
          str = '\n' + str.split('\n').map(function(line) {
            return '   ' + line;
          }).join('\n');
        }
      }
    } else {
      str = ctx.stylize('[Circular]', 'special');
    }
  }
  if (isUndefined(name)) {
    if (array && key.match(/^\d+$/)) {
      return str;
    }
    name = JSON.stringify('' + key);
    if (name.match(/^"([a-zA-Z_][a-zA-Z_0-9]*)"$/)) {
      name = name.substr(1, name.length - 2);
      name = ctx.stylize(name, 'name');
    } else {
      name = name.replace(/'/g, "\\'")
                 .replace(/\\"/g, '"')
                 .replace(/(^"|"$)/g, "'");
      name = ctx.stylize(name, 'string');
    }
  }

  return name + ': ' + str;
}


function reduceToSingleString(output, base, braces) {
  var numLinesEst = 0;
  var length = output.reduce(function(prev, cur) {
    numLinesEst++;
    if (cur.indexOf('\n') >= 0) numLinesEst++;
    return prev + cur.replace(/\u001b\[\d\d?m/g, '').length + 1;
  }, 0);

  if (length > 60) {
    return braces[0] +
           (base === '' ? '' : base + '\n ') +
           ' ' +
           output.join(',\n  ') +
           ' ' +
           braces[1];
  }

  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];
}


// NOTE: These type checking functions intentionally don't use `instanceof`
// because it is fragile and can be easily faked with `Object.create()`.
function isArray(ar) {
  return Array.isArray(ar);
}
exports.isArray = isArray;

function isBoolean(arg) {
  return typeof arg === 'boolean';
}
exports.isBoolean = isBoolean;

function isNull(arg) {
  return arg === null;
}
exports.isNull = isNull;

function isNullOrUndefined(arg) {
  return arg == null;
}
exports.isNullOrUndefined = isNullOrUndefined;

function isNumber(arg) {
  return typeof arg === 'number';
}
exports.isNumber = isNumber;

function isString(arg) {
  return typeof arg === 'string';
}
exports.isString = isString;

function isSymbol(arg) {
  return typeof arg === 'symbol';
}
exports.isSymbol = isSymbol;

function isUndefined(arg) {
  return arg === void 0;
}
exports.isUndefined = isUndefined;

function isRegExp(re) {
  return isObject(re) && objectToString(re) === '[object RegExp]';
}
exports.isRegExp = isRegExp;

function isObject(arg) {
  return typeof arg === 'object' && arg !== null;
}
exports.isObject = isObject;

function isDate(d) {
  return isObject(d) && objectToString(d) === '[object Date]';
}
exports.isDate = isDate;

function isError(e) {
  return isObject(e) &&
      (objectToString(e) === '[object Error]' || e instanceof Error);
}
exports.isError = isError;

function isFunction(arg) {
  return typeof arg === 'function';
}
exports.isFunction = isFunction;

function isPrimitive(arg) {
  return arg === null ||
         typeof arg === 'boolean' ||
         typeof arg === 'number' ||
         typeof arg === 'string' ||
         typeof arg === 'symbol' ||  // ES6 symbol
         typeof arg === 'undefined';
}
exports.isPrimitive = isPrimitive;

exports.isBuffer = function isBuffer(arg) {
  return arg && typeof arg === 'object'
             && typeof arg.copy === 'function'
             && typeof arg.fill === 'function'
             && typeof arg.readUInt8 === 'function';
};

function objectToString(o) {
  return Object.prototype.toString.call(o);
}


function pad(n) {
  return n < 10 ? '0' + n.toString(10) : n.toString(10);
}


var months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',
              'Oct', 'Nov', 'Dec'];

// 26 Feb 16:19:34
function timestamp() {
  var d = new Date();
  var time = [pad(d.getHours()),
              pad(d.getMinutes()),
              pad(d.getSeconds())].join(':');
  return [d.getDate(), months[d.getMonth()], time].join(' ');
}


// log is just a thin wrapper to console.log that prepends a timestamp
exports.log = function() {
  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));
};


/**
 * Inherit the prototype methods from one constructor into another.
 *
 * The Function.prototype.inherits from lang.js rewritten as a standalone
 * function (not on Function.prototype). NOTE: If this file is to be loaded
 * during bootstrapping this function needs to be rewritten using some native
 * functions as prototype setup using normal JavaScript does not work as
 * expected during bootstrapping (see mirror.js in r114903).
 *
 * @param {function} ctor Constructor function which needs to inherit the
 *     prototype.
 * @param {function} superCtor Constructor function to inherit prototype from.
 */

exports.inherits = Require('os/inherits');

exports._extend = function(origin, add) {
  // Don't do anything if add isn't an object
  if (!add || !isObject(add)) return origin;

  var keys = Object.keys(add);
  var i = keys.length;
  while (i--) {
    origin[keys[i]] = add[keys[i]];
  }
  return origin;
};

function hasOwnProperty(obj, prop) {
  return Object.prototype.hasOwnProperty.call(obj, prop);
}
};
BundleModuleCode['os/inherits']=function (module,exports,global,process){
if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    ctor.prototype = Object.create(superCtor.prototype, {
      constructor: {
        value: ctor,
        enumerable: false,
        writable: true,
        configurable: true
      }
    });
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    ctor.super_ = superCtor
    var TempCtor = function () {}
    TempCtor.prototype = superCtor.prototype
    ctor.prototype = new TempCtor()
    ctor.prototype.constructor = ctor
  }
}
};
BundleModuleCode['com/sprintf']=function (module,exports,global,process){
(function(window) {
    var re = {
        not_string: /[^s]/,
        number: /[diefg]/,
        json: /[j]/,
        not_json: /[^j]/,
        text: /^[^\x25]+/,
        modulo: /^\x25{2}/,
        placeholder: /^\x25(?:([1-9]\d*)\$|\(([^\)]+)\))?(\+)?(0|'[^$])?(-)?(\d+)?(?:\.(\d+))?([b-gijosuxX])/,
        key: /^([a-z_][a-z_\d]*)/i,
        key_access: /^\.([a-z_][a-z_\d]*)/i,
        index_access: /^\[(\d+)\]/,
        sign: /^[\+\-]/
    }

    function sprintf() {
        var key = arguments[0], cache = sprintf.cache
        if (!(cache[key] && cache.hasOwnProperty(key))) {
            cache[key] = sprintf.parse(key)
        }
        return sprintf.format.call(null, cache[key], arguments)
    }

    sprintf.format = function(parse_tree, argv) {
        var cursor = 1, tree_length = parse_tree.length, node_type = "", arg, output = [], i, k, match, pad, pad_character, pad_length, is_positive = true, sign = ""
        for (i = 0; i < tree_length; i++) {
            node_type = get_type(parse_tree[i])
            if (node_type === "string") {
                output[output.length] = parse_tree[i]
            }
            else if (node_type === "array") {
                match = parse_tree[i] // convenience purposes only
                if (match[2]) { // keyword argument
                    arg = argv[cursor]
                    for (k = 0; k < match[2].length; k++) {
                        if (!arg.hasOwnProperty(match[2][k])) {
                            throw new Error(sprintf("[sprintf] property '%s' does not exist", match[2][k]))
                        }
                        arg = arg[match[2][k]]
                    }
                }
                else if (match[1]) { // positional argument (explicit)
                    arg = argv[match[1]]
                }
                else { // positional argument (implicit)
                    arg = argv[cursor++]
                }

                if (get_type(arg) == "function") {
                    arg = arg()
                }

                if (re.not_string.test(match[8]) && re.not_json.test(match[8]) && (get_type(arg) != "number" && isNaN(arg))) {
                    throw new TypeError(sprintf("[sprintf] expecting number but found %s", get_type(arg)))
                }

                if (re.number.test(match[8])) {
                    is_positive = arg >= 0
                }

                switch (match[8]) {
                    case "b":
                        arg = arg.toString(2)
                    break
                    case "c":
                        arg = String.fromCharCode(arg)
                    break
                    case "d":
                    case "i":
                        arg = parseInt(arg, 10)
                    break
                    case "j":
                        arg = JSON.stringify(arg, null, match[6] ? parseInt(match[6]) : 0)
                    break
                    case "e":
                        arg = match[7] ? arg.toExponential(match[7]) : arg.toExponential()
                    break
                    case "f":
                        arg = match[7] ? parseFloat(arg).toFixed(match[7]) : parseFloat(arg)
                    break
                    case "g":
                        arg = match[7] ? parseFloat(arg).toPrecision(match[7]) : parseFloat(arg)
                    break
                    case "o":
                        arg = arg.toString(8)
                    break
                    case "s":
                        arg = ((arg = String(arg)) && match[7] ? arg.substring(0, match[7]) : arg)
                    break
                    case "u":
                        arg = arg >>> 0
                    break
                    case "x":
                        arg = arg.toString(16)
                    break
                    case "X":
                        arg = arg.toString(16).toUpperCase()
                    break
                }
                if (re.json.test(match[8])) {
                    output[output.length] = arg
                }
                else {
                    if (re.number.test(match[8]) && (!is_positive || match[3])) {
                        sign = is_positive ? "+" : "-"
                        arg = arg.toString().replace(re.sign, "")
                    }
                    else {
                        sign = ""
                    }
                    pad_character = match[4] ? match[4] === "0" ? "0" : match[4].charAt(1) : " "
                    pad_length = match[6] - (sign + arg).length
                    pad = match[6] ? (pad_length > 0 ? str_repeat(pad_character, pad_length) : "") : ""
                    output[output.length] = match[5] ? sign + arg + pad : (pad_character === "0" ? sign + pad + arg : pad + sign + arg)
                }
            }
        }
        return output.join("")
    }

    sprintf.cache = {}

    sprintf.parse = function(fmt) {
        var _fmt = fmt, match = [], parse_tree = [], arg_names = 0
        while (_fmt) {
            if ((match = re.text.exec(_fmt)) !== null) {
                parse_tree[parse_tree.length] = match[0]
            }
            else if ((match = re.modulo.exec(_fmt)) !== null) {
                parse_tree[parse_tree.length] = "%"
            }
            else if ((match = re.placeholder.exec(_fmt)) !== null) {
                if (match[2]) {
                    arg_names |= 1
                    var field_list = [], replacement_field = match[2], field_match = []
                    if ((field_match = re.key.exec(replacement_field)) !== null) {
                        field_list[field_list.length] = field_match[1]
                        while ((replacement_field = replacement_field.substring(field_match[0].length)) !== "") {
                            if ((field_match = re.key_access.exec(replacement_field)) !== null) {
                                field_list[field_list.length] = field_match[1]
                            }
                            else if ((field_match = re.index_access.exec(replacement_field)) !== null) {
                                field_list[field_list.length] = field_match[1]
                            }
                            else {
                                throw new SyntaxError("[sprintf] failed to parse named argument key")
                            }
                        }
                    }
                    else {
                        throw new SyntaxError("[sprintf] failed to parse named argument key")
                    }
                    match[2] = field_list
                }
                else {
                    arg_names |= 2
                }
                if (arg_names === 3) {
                    throw new Error("[sprintf] mixing positional and named placeholders is not (yet) supported")
                }
                parse_tree[parse_tree.length] = match
            }
            else {
                throw new SyntaxError("[sprintf] unexpected placeholder")
            }
            try {_fmt = _fmt.substring(match[0].length)} catch (e) {throw new SyntaxError("[sprintf] unexpected fromat")}
        }
        return parse_tree
    }

    var vsprintf = function(fmt, argv, _argv) {
        _argv = (argv || []).slice(0)
        _argv.splice(0, 0, fmt)
        return sprintf.apply(null, _argv)
    }

    /**
     * helpers
     */
    function get_type(variable) {
        return Object.prototype.toString.call(variable).slice(8, -1).toLowerCase()
    }

    function str_repeat(input, multiplier) {
        return Array(multiplier + 1).join(input)
    }

    /**
     * export to either browser or node.js
     */
    if (typeof exports !== "undefined") {
        exports.sprintf = sprintf
        exports.vsprintf = vsprintf
    }
    else {
        window.sprintf = sprintf
        window.vsprintf = vsprintf

        if (typeof define === "function" && define.amd) {
            define(function() {
                return {
                    sprintf: sprintf,
                    vsprintf: vsprintf
                }
            })
        }
    }
})(typeof window === "undefined" ? this : window);
};
BundleModuleCode['os/base64']=function (module,exports,global,process){
var keyStr = "ABCDEFGHIJKLMNOP" +
               "QRSTUVWXYZabcdef" +
               "ghijklmnopqrstuv" +
               "wxyz0123456789+/" +
               "=";
var Buffer=Require('buffer').Buffer;
var Base64 = {
  encode: function (input) {
     input = escape(input);
     var output = "";
     var chr1, chr2, chr3 = "";
     var enc1, enc2, enc3, enc4 = "";
     var i = 0;

     do {
        chr1 = input.charCodeAt(i++);
        chr2 = input.charCodeAt(i++);
        chr3 = input.charCodeAt(i++);

        enc1 = chr1 >> 2;
        enc2 = ((chr1 & 3) << 4) | (chr2 >> 4);
        enc3 = ((chr2 & 15) << 2) | (chr3 >> 6);
        enc4 = chr3 & 63;

        if (isNaN(chr2)) {
           enc3 = enc4 = 64;
        } else if (isNaN(chr3)) {
           enc4 = 64;
        }

        output = output +
           keyStr.charAt(enc1) +
           keyStr.charAt(enc2) +
           keyStr.charAt(enc3) +
           keyStr.charAt(enc4);
        chr1 = chr2 = chr3 = "";
        enc1 = enc2 = enc3 = enc4 = "";
     } while (i < input.length);

     return output;
  },

  encodeBuf: function (input) {
     var output = "";
     var NaN = output.charCodeAt(2);
     var chr1, chr2, chr3 = "";
     var enc1, enc2, enc3, enc4 = "";
     var i = 0;
     var len = input.length;
     do {
        chr1 = input.readUInt8(i++);
        chr2 = (i<len)?input.readUInt8(i++):NaN;
        chr3 = (i<len)?input.readUInt8(i++):NaN;

        enc1 = chr1 >> 2;
        enc2 = ((chr1 & 3) << 4) | (chr2 >> 4);
        enc3 = ((chr2 & 15) << 2) | (chr3 >> 6);
        enc4 = chr3 & 63;

        if (isNaN(chr2)) {
           enc3 = enc4 = 64;
        } else if (isNaN(chr3)) {
           enc4 = 64;
        }

        output = output +
           keyStr.charAt(enc1) +
           keyStr.charAt(enc2) +
           keyStr.charAt(enc3) +
           keyStr.charAt(enc4);
        chr1 = chr2 = chr3 = "";
        enc1 = enc2 = enc3 = enc4 = "";
     } while (i < len);

     return output;
  },

  decode: function (input) {
     var output = "";
     var chr1, chr2, chr3 = "";
     var enc1, enc2, enc3, enc4 = "";
     var i = 0;

     input = input.replace(/[^A-Za-z0-9\+\/\=]/g, "");

     do {
        enc1 = keyStr.indexOf(input.charAt(i++));
        enc2 = keyStr.indexOf(input.charAt(i++));
        enc3 = keyStr.indexOf(input.charAt(i++));
        enc4 = keyStr.indexOf(input.charAt(i++));

        chr1 = (enc1 << 2) | (enc2 >> 4);
        chr2 = ((enc2 & 15) << 4) | (enc3 >> 2);
        chr3 = ((enc3 & 3) << 6) | enc4;

        output = output + String.fromCharCode(chr1);

        if (enc3 != 64) {
           output = output + String.fromCharCode(chr2);
        }
        if (enc4 != 64) {
           output = output + String.fromCharCode(chr3);
        }

        chr1 = chr2 = chr3 = "";
        enc1 = enc2 = enc3 = enc4 = "";

     } while (i < input.length);

     return unescape(output);
  },
  decodeBuf: function (input) {
     var len = input.length;
     var buf = new Buffer(len);
     var chr1, chr2, chr3 = "";
     var enc1, enc2, enc3, enc4 = "";
     var i = 0;
     var buflen = 0;
     input = input.replace(/[^A-Za-z0-9\+\/\=]/g, "");
     buf.fill(0);
     do {
        enc1 = keyStr.indexOf(input.charAt(i++));
        enc2 = keyStr.indexOf(input.charAt(i++));
        enc3 = keyStr.indexOf(input.charAt(i++));
        enc4 = keyStr.indexOf(input.charAt(i++));

        chr1 = (enc1 << 2) | (enc2 >> 4);
        chr2 = ((enc2 & 15) << 4) | (enc3 >> 2);
        chr3 = ((enc3 & 3) << 6) | enc4;

        buf.writeUInt8(chr1,buflen);
        buflen++;
        if (enc3 != 64) {
          buf.writeUInt8(chr2,buflen);
          buflen++;
        }
        if (enc4 != 64) {
            buf.writeUInt8(chr3,buflen);
            buflen++;
        }

        chr1 = chr2 = chr3 = "";
        enc1 = enc2 = enc3 = enc4 = "";

     } while (i < input.length);

     return buf.slice(0,buflen);
  }

};


module.exports = Base64;
};
BundleModuleCode['plugins/ml/ml.js']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Stefan Bosse
 **    $INITIAL:     (C) 2006-2021 BSSLAB
 **    $CREATED:     8-2-16 by sbosse.
 **    $VERSION:     1.31.1X
 **
 **    $INFO:
 **
 **  JavaScript Machine Learning API
 **
 ** type algorithm = {'dti','dt','id3','c45','kmeans','knn','knn2','mlp','slp','rl','svm','txt','cnn'}
 **
 **
 ** id3: Symbolic Decision Tree algorithm
 ** -------------------------------------
 **
 ** typeof @options = {
 **   algorithm='id3',
 **   data:{x1:number,x2:number,..,y:*} []
 **   target:string is e.g. 'y'
 **   features: string [] is e.g. ['x1','x2',..]
 ** }
 **
 ** ice: decision tree algorithm supporting numbers with eps intervals (hybrid C45/ID3)
 ** -------------------------------------
 **
 ** General feature variable set:
 **
 ** typeof @options = {
 **   algorithm='dt',
 **   data:{x1:number,x2:number,..,y:*} [],
 **   target:string is e.g. 'y',
 **   features: string [] is e.g. ['x1','x2',..],
 **   eps:number is e.g. '5',
 ** }
 ** 
 ** dti: interval decision tree algorithm
 ** -------------------------------------
 **
 ** General feature variable set:
 **
 ** typeof @options = {
 **   algorithm='dti',
 **   data:{x1:number,x2:number,..,y:*} []
 **   target:string is e.g. 'y'
 **   features: string [] is e.g. ['x1','x2',..]
 **   eps:number is e.g. '5',
 **   maxdepth:number,
 ** }
 ** 
 ** Or vector feature variables (i.e., features=[0,1,2,...n-1], target=n):
 **
 ** typeof @options = {
 **   algorithm='dti',
 **   x:* [] [],
 **   y:* [],
 **   eps:number is e.g. '5',
 **   maxdepth:number,
 ** }
 **
 ** knn: k-Nearest-Neighbour Algorithm
 ** ----------------------------------
 **
 ** typeof @options = {
 **   algorithm='knn',
 **   x: number [][], 
 **   y: * []
 ** }
 **
 ** mlp: single/multi layer perceptron Algorithm
 ** ----------------------------------
 **
 ** typeof @options = {
 **   algorithm='mlp',
 **   x: number [][], 
 **   y: number [] [] | * [],
 **   hidden_layers?:number [],
 **   lr?:number,
 **   epochs?:number,
 **   labels?:string [], 
 **   features?: string [], 
 **   normalize?, 
 **   verbose?:number
 ** }
 **
 ** ann: Universal ANN (neataptic)
 ** ----------------------------------
 **
 ** typeof @learner.options = {
 **   algorithm='ann',
 **   layers:number [],
 **   architecture : archtyp string [],
 **   activation? : actfun string | actfun string [] 
 ** }
 ** with actfun = 'RELU'|'LOGISTC'|'IDENTITY'|'STEP'|'TANH'|.. and
         acttyp = 'LSTM'|'GRU'|'Dense'|
 ** typeof @train.options = {
 **   alpah?: number,
 **   gamma?: number,
 **   iterations? : number,
 **   error?: number,
 ** }
 **
 ** cnn: Convolutional Neural Network for numerial (2D) data
 ** -------------------------------------
 **
 ** General feature variable set:
 **
 ** typeof @options = {
 **   algorithm='cnn',
 **   data:{x:[]|[][],y:'a} []
 **   layers: layer [],
 **   trainer:trainer,
 ** }
 ** type layer = 
 **  {type:'input', out_sx:number, out_sy:number, out_depth:number} | // Input Layer
 **  {type:'conv', sx:number, filters:number, stride:number, pad:number, activation:string} | // Convolution Layer
 **  {type:'pool', sx:number, stride:number} | // Pooling Layer
 **  {type:'softmax', num_classes:number} | // Classifier Layers
 **  {type:'svm', num_classes:number| // Classifier Layers
 **  {type:'fc', num_neurons:number, activation:string} // Fully Connected Layer
 **
 ** typeof activation = 'relu'| 'maxout' | 'sigmoid' | 'tanh' ..
 **
 ** type trainer = 
 **  {method: 'sgd', learning_rate:number,  momentum: number, batch_size:number, l2_decay:number} |
 **  {method: 'adadelta', learning_rate:number,  eps: number, ro:number, batch_size:number, l2_decay:number} |
 **  {method: 'adam', learning_rate:number, eps: number, beta1: number, beta2: number, batch_size: number, l2_decay:number} |
 **  ..
 **
 ** text: text analysis (similarity checking)
 ** -----------------------------------------
 **   classify(model,string) -> {match:number [0..1],string:string }
 **   learn({algorithm:ML.TXT, data:string []]) -> model
 **   test({algorithm:ML.TXT,string:string}|model,string) -> number [0..1]
 **   similarity(string,string) -> number [0..1]
 ** 
 **
 ** simulated annealing
 ** -------------------
 **
 **
 **    $ENDOFINFO
 */
var Io = Require('com/io');
var Comp = Require('com/compat');
var _ = undefined;
var none = null;


var ICE = Require('plugins/ml/ice'); // ICE ID3/C45 eps
var DTI = Require('plugins/ml/dti');
var KNN = Require('plugins/ml/knn');
var KMN = Require('plugins/ml/kmeans');
var SVM = Require('plugins/ml/svm');
var MLP = Require('plugins/ml/mlp');
var ID3 = Require('plugins/ml/id3');
var C45 = Require('plugins/ml/C45');
var TXT = Require('plugins/ml/text');
var RF  = Require('plugins/ml/rf');
var RL  = Require('plugins/ml/rl');
var RT  = Require('plugins/ml/rt');
var STAT= Require('plugins/ml/stats');
var CNN = Require('plugins/ml/cnn');
var ANN = Require('plugins/ml/ann');
var PCA = Require('plugins/ml/pca');
var DBCLUST = Require('plugins/ml/dbclust');
var REG = Require('plugins/ml/reg');
var MATH    = Require('plugins/ml/math');
var PRE = Require('plugins/ml/pre');
var SA  = Require('plugins/ml/sa');
var DR  = Require('plugins/math/druid');
var SOM = Require('plugins/ml/som');
var HELP  = Require('plugins/ml/helpers');

var MAN  = FileEmbedded('plugins/ml/help.md','utf8');

var array2Object = PRE.array2Object,
    autoScale = PRE.autoScale,
    getOptions = HELP.getOptions,
    obj2Array = PRE.obj2Array,
    objSlice = PRE.objSlice,
    preprocess = PRE.preprocess,
    relax=PRE.relax,
    _scale = PRE.scale,
    split=PRE.split,
    toScale=PRE.toScale,
    unscale = PRE.unscale,
    updateOptions=HELP.updateOptions,
    wrap=PRE.wrap;
function scale (data, scales) {
  if (Utils.isMatrix(data)) {
    return data.map(function (row) {
      return _scale(row,scales)
    })
  } else if (Utils.isObject(data[0])) {
    return data.map(function (obj) {
      var objS = {}
      for(var key in obj) {
        objS[key]=_scale(obj[key],scales[key]||scales);
      }
      return objS
    })
  } return _scale(data,scales)
}
function scale0 (data,lower,upper) {
  if (Utils.isMatrix(data)) {
    return Object.keys(data[0]).map(function (attr) {
      var min,max;
      for(var i in data) {
        if (i==0) { min=max=data[i][attr] }
        else { 
          min=Math.min(min,data[i][attr]); 
          max=Math.max(max,data[i][attr]); 
        }
      }
      return toScale(min,max,lower,upper);
    })
  } else if (Utils.isObject(data[0])) {
    var scales=[]
    Object.keys(data[0]).map(function (attr) {
      var min,max;
      for(var i in data) {
        if (i==0) { min=max=data[i][attr] }
        else { 
          min=Math.min(min,data[i][attr]); 
          max=Math.max(max,data[i][attr]); 
        }
      }
      scales[attr]=toScale(min,max,lower,upper);
    })
    return scales;
  }
}
var current=none;
var Aios=none;

var options = {
  version: '1.31.1X'
}

// Some definitions
var ML = {
  // Algorithms
  ANN   : 'ann',    // neataptic NN 
  C45   : 'c45',
  CNN   : 'cnn',
  ICE   : 'ice',   // ICE ID3/C45 eps
  DT    : 'ice',   // ICE ID3/C45 eps
  DTI   : 'dti',
  ID3   : 'id3',
  KMN   : 'kmeans',
  KNN   : 'knn',
  KNN2  :'knn2',
  MLP   : 'mlp',
  REG   : 'reg',   // Function Rregression
  RF    : 'rf',    // Random Forest
  RL    : 'rl',    // Reinforcement Leerner
  RT    : 'rt',    // Regression Tree
  SLP   : 'slp',  // Synonym for MLP (but single layer)
  SVM   : 'svm',
  TXT   : 'txt',
  SA    : 'simuan', // Simulated Annelaing optimisation
  SOM   : 'som',  // Self-orga. maps, Kohonen network
  // Some Functions
  EUCL  : 'euclidean',
  PEAR  : 'pearson',
  
  // loaded on demand (wasm)
  XGBOOST : 'xgboost',
  
  // RL agents
  DPAgent   : 'DPAgent',
  TDAgent   : 'TDAgent',
  DQNAgent  : 'DQNAgent',
};


// API
var  ml = {
  // only RL
  action : function (model,arg) {
    switch (model.algorithm) {
      // Selects and returns next action from set of actions
      case ML.RL:
        switch (model.kind) {
          case ML.DQNAgent:
            // arg == state array
            return model.actions[RL.DQNAgent.code.act(model,arg)];   
            break;
          case ML.DPAgent:
            // arg == state (integer number)
            return model.actions[RL.DPAgent.code.act(model,arg)];   
            break;
          case ML.TDAgent:
            // arg == state (integer number)
            return model.actions[RL.TDAgent.code.act(model,arg)];   
            break;
        }
        break;   
    }
  },
  
  compact: function (model) {
    switch (model.algorithm) {
      case ML.DTI:
      default:
        return DTI.compactTree(model);
    }
  },
  
  depth: function (model) {
    switch (model.algorithm) {
      case ML.DTI:
        return DTI.depth(model);
      case ML.DT:
      case ML.ICE:
        return ICE.depth(model);
      case ML.C45:
        return C45.depth(model);
      case ML.ID3:
        return ID3.depth(model);
    }
  },
  
  
  evaluate: function (model,target,samples) {
    switch (model.algorithm) {
      case ML.DTI:
      default:
        return DTI.evaluate(model,target,samples);
    }
  },

  
  info: function (model) {
    switch (model.algorithm) {
      case ML.C45:
        return C45.info(model);
      case ML.DT:
      case ML.ICE:
        return ICE.info(model);
      case ML.ID3:
        return ID3.info(model);
    }
  },
  
  help : function (topic) {
    var i,j,Models = Object.keys(ML),
        models = Models.map(function(k) { return ML[k] });
    if ((i=Models.indexOf(topic))!=-1 || (j=models.indexOf(topic))!=-1) {
      if (j!=undefined && j!=-1) topic=Models[j]
      var result=[],start=MAN.indexOf('\n## '+topic),stop=MAN.indexOf('\n##',start+3);
      if (start!=-1 && stop!=-1) return MAN.slice(start+1,stop-1);
      else if (start!=-1) return MAN.slice(start+1);
    }
    return MAN
  },
  /** Learning: Create a learner instance and a classification model from training data (or an empty model that can be updated/trained later)
   *
   */
  learner: function (options) {
    var model,data,data2,x,y,features,featureTypes,test,target,more,
        result,cols,n_ins,n_outs,x,y,xscale,xoffset,xshift,yscale,yoffset,yshift,key,err,
        t0=Io.time();
    if (!options.algorithm || typeof options.algorithm != 'string') throw 'ML.learner: Invalid options (algorithm is missing)';
    switch (options.algorithm) {
    
      case ML.ANN:
        // Neataptic ANN Framework
        // typeof options = { x,y,features?,target?, 
        //                    equal?, iterations?:number, error?:number, rate?:number, clear?:boolean,  
        //                    layers:number [], architect?:string|string []}
        if (options.x && options.y) data = preprocess(options,'io',options);
        model={};
        model.algorithm=options.algorithm
        if (!options.layers && !options.network) throw 'ML.learn.ANN: Invalid options';
        if (options.architect) {
          // Special MLP
          if (options.architect instanceof Array) {
            // Different architectures in each layer
            if (options.architect.length != options.layers.length) throw "ML.trainer.ANN: layers & architect array must have same size";
            var layers = ANN.architect.Layers(options);
            model.network = ANN.architect.Construct(layers);
          } else {
            switch (options.architect) {
              case 'LSTM':
                more={}; // memoryToMemory, outputToMemory, outputToGates, inputToOutput, inputToDeep
                // model.network = new (Constructor(ANN.architect.LSTM,options.layers.concat(more)));
                model.network = ANN.architect.LSTM.apply(null,options.layers.concat(options));
                if (data) model.network.train(data,options);
                break;
              case 'GRU':
                more={}; // memoryToMemory, outputToMemory, outputToGates, inputToOutput, inputToDeep
                // model.network = new (Constructor(ANN.architect.LSTM,options.layers.concat(more)));
                model.network = ANN.architect.GRU.apply(null,options.layers);
                if (data) model.network.train(data,options);
                break;
            }
          }
        } else {
          // SLP/MLP
          if (options.network)
            model.network = new ANN.Network.fromJSON(options.network);
          else {
            model.network = ANN.architect.Network.apply(null,options.layers);
            model.network.configure({
              activation:options.activation,  // act. function
            });
          }
          if (data) model.network.train(data,options);
        }
        model.options=options;
        model.time=Io.time()-t0;
        return model;
        break;      
        

      case ML.CNN:
        // typeof options = {x:[][],y:[],targets?:[],..}
        model = CNN.create(options);
        model.algorithm=options.algorithm;
        model.time=Io.time()-t0;
        return model;
        break;

      case ML.C45:
        // typeof options = {data: {}[], target:string, features: string []} |
        //                  {data: [][], target?:string, features?: string []} |
        //                  {x: number [][], y:[]} |
        //                  {data: {x,y}[] }
        var model = C45.create();
        if (options.x && options.y) {
          features=options.x[0].map(function (col,i) { return String(i) }); 
          featureTypes=options.x[0].map(function (col,i) { return 'number' });
          data=options.x.map(function (row,i) { row=row.slice(); row.push(options.y[i]); return row});
          target='y';
        } else if (options.data && Comp.obj.isMatrix(options.data)) {
          data=options.data;
          features=options.features||options.data[0].slice(0,-1).map(function (col,i) { return String(i) });
          featureTypes=options.data[0].slice(0,-1).map(function (col,i) { return typeof col == 'number'?'number':'category' });
          target=options.target||'y';
        } else if (options.data && Comp.obj.isObj(options.data[0]) && options.data[0].x && options.data[0].y!=undefined) {
          data=options.data.map(function (row) { return row.x.concat(row.y) });
          features=options.features||options.data[0].x.slice(0,-1).map(function (col,i) { return String(i) });
          featureTypes=options.data[0].x.slice(0,-1).map(function (col,i) { return typeof col == 'number'?'number':'category' });
          target=options.target||'y';
        } else if (options.data && Comp.obj.isArray(options.data) && Comp.obj.isObj(options.data[0]) && 
                   options.target && options.features) {
          rowNames=Comp.obj.isArray(options.target)?options.features.concat(options.target):
                                                    options.features.concat([options.target]);
          data=options.data.map(function (row) { return obj2Array(row,rowNames) })
          features=options.features;
          featureTypes=data[0].slice(0,-1).map(function (col,i) { return typeof col == 'number'?'number':'category' });
          target=options.target;
        } else throw 'ML.learn.C45: Invalid options';

        C45.train(model,{
          data: data,
          target: target,
          features: features,
          featureTypes: featureTypes
        });
        model.algorithm=options.algorithm
        model.time=Io.time()-t0;
        return model;
        break;


      case ML.DTI:
        // typeof options = {data: {}[], target:string, features: string [], eps;number, maxdepth} |
        //                   {x: number [][], y:[], eps;number, maxdepth}
        if (options.eps==_) options.eps=0;
        if (options.maxdepth==_) options.maxdepth=20;
        if (options.data && options.target && options.features)
          model = DTI.create(options);
        else if (options.x && options.y) {
          if (options.x.length != options.y.length) throw 'ML.learn.DTI: X and Y vector have different length';
          data=options.x.map(function (row,i) { row=row.slice(); row.push(options.y[i]); return row});
          features=Comp.array.init(data[0].length-1,function (i) { return String(i)});
          target=String(data[0].length-1);
          // console.log(data,features,target)
          model = DTI.create({
            data:data,
            features:features,
            target:target,
            eps:options.eps,
            maxdepth:options.maxdepth
          });
        } else throw 'ML.learn.DTI: Invalid options';
        model.algorithm=options.algorithm;
        model.time=Io.time()-t0;
        return model;


      case ML.ICE:
      case ML.DT:
        if (options.eps==_) options.eps=0;
        if (options.data && options.target && options.features)
          model = ICE.create(options);                  
        else if (options.x && options.y) {
          if (options.x.length != options.y.length) throw 'ML.learn.ICE: X and Y vector have different length';
          data=options.x.map(function (row,i) { row=row.slice(); row.push(options.y[i]); return row});
          features=Comp.array.init(data[0].length-1,function (i) { return String(i)});
          target=String(data[0].length-1);
          model = ICE.create({
            data:data,
            features:features,
            target:target,
            eps:options.eps,
          });
        } else throw 'ML.learn.ICE: Invalid options';
        model.algorithm=options.algorithm;
        model.eps=options.eps;
        model.time=Io.time()-t0;
        return model;
        break;      

      case ML.ID3:
        if (options.data && options.target && options.features)
          model = ID3.createTree(options.data,options.target,
                                 options.features);
        else throw 'ML.learn.ID3: Invalid options';
        model.algorithm=options.algorithm
        model.time=Io.time()-t0;
        return model;
        break;      
          
      case ML.KNN:
        // typeof @options = {data: {}[]|[][], distance?:function|string,k?:number}
        // typeof @options = {x:number [][], y:number [], 
        //                    distance?:function|string,k?:number}
        if (options.features && options.target) target=options.target,features = options.features;
        else {
          features = [];
          if (options.data) {
            for(key in options.data[0]) features.push(key);
            target = features.pop()
          } else if (options.x) {
            for(key in options.x[0]) features.push('x'+key);
            target='y';
          }
        }
        if (options.data && Comp.obj.isObj(options.data[0])) {
          x = options.data.map(function (row) { return obj2Array(row,features) });
          y = options.data.map(function (row) { return row[target] })
        } else if (options.data && Comp.obj.isMatrix(options.data)) {
          x = options.data,map(function (row) { return row.slice(0,row.length-1) });
          y = options.data,map(function (row) { return row[row.length-1] });
        } else if (options.x && options.y) {
          x = options.x;
          y = options.y;
        }
        model = KNN.create(
          x,
          y,
          {
            distance:options.distance,
            k:options.k
          });
        model.algorithm = options.algorithm
        model.features  = features
        model.target    = target
        model.time=Io.time()-t0;
        return model;
        break;

      case ML.KNN2:
        // typeof @options = {data: {}[]|[][], distance?:function|string,k?:number}
        // typeof @options = {x:number [][], y:number [], 
        //                    distance?:function|string,k?:number}
        if (options.features && options.target) target=options.target,features = options.features;
        else {
          features = [];
          if (options.data) {
            for(key in options.data[0]) features.push(key);
            target = features.pop()
          } else if (options.x) {
            for(key in options.x[0]) features.push('x'+key);
            target='y';
          }
        }
        if (options.data && Comp.obj.isObj(options.data[0])) {
          x = options.data.map(function (row) { return obj2Array(row,features) });
          y = options.data.map(function (row) { return row[target] })
        } else if (options.data && Comp.obj.isMatrix(options.data)) {
          x = options.data,map(function (row) { return row.slice(0,row.length-1) });
          y = options.data,map(function (row) { return row[row.length-1] });
        } else if (options.x && options.y) {
          x = options.x;
          y = options.y;
        }
        model = KNN.create2(
          {
            x : x,
            y : y,
            distance:options.distance,
            k:options.k
          });
        model.algorithm=options.algorithm
        model.features = features
        model.target = target
        model.time=Io.time()-t0;
        return model;
        break;
        
      case ML.KMN:
        if (options.data && Comp.obj.isMatrix(options.data)) {
          data=options.data;
        } 
        model = KMN.cluster({
          data:data,
          k:options.k,
          distance:options.distance,
          epochs:options.epochs,
        })
        model.algorithm=options.algorithm
        model.data = data
        model.time=Io.time()-t0;
        return model;
        break;
                
      // Function Regression
      case ML.REG:
        /* typeof @options = {
          alpha : number is paramter change rate,
          lambda,
          iterations,
          dynamic?: boolean,
          cost? number,  
          error?:number,
          order : number,
          trace?: boolean.
        }
        */
        model={}
        options.alpha   = options.alpha||0.001;
        options.lambda  = options.lambda||0;
        options.iterations = options.iterations||1000;
        options.order = options.order||1;
        options.algorithm2 = options.algorithm2||'LinearRegression';
        model.regression = new REG[options.algorithm2]({
            alpha               : options.alpha,
            lambda              : options.lambda,
            iterations          : options.iterations,
            cost                : options.cost,
            error               : options.error,
            trace               : options.verbose||options.trace,
            dynamic             : options.dynamic,
          });
        model.algorithm=options.algorithm;
        model.options=options;
        return model;
        break;

      case ML.RF:
        var model={};
        // Single Binary RF (y={-1,1}) or Multi-RF (y:string is in labels)
        // typeof options = {data: {}[], target:string, features: string []} |
        //                  {data: [][], target?:string, features?: string []} |
        //                  {x: number [][], y: {-1,1} []} |
        //                  {data: {x,y}[] }
        //                  {data: {x,y}[], labels: string [] }
        if (!options.x || !options.y) throw 'ML.learn.RF: Invalid options';
        // data=preprocess(data,'xmy',{features:features,target:target})
        data={x:options.x,y:options.y}; // TODO 
        if (options.labels) {
          // multi-RF
          model.labels = options.labels;
          model.rfs = model.labels.map (function (label) { return RF() });
          model.rfs.forEach (function (rf,i) {
            var y = data.y.map(function (label) { return label==model.labels[i]?1:-1} );
            RF.code.train(rf,options.x,y,{
              numTrees:options.numTrees,
              maxDepth:options.maxDepth,
              numTries:options.numTries,
              type:options.weakType,
            });
          });
        } else {
          model = RF();
          features=options.x[0].map(function (col,i) { return String(i) }); 
          target='y';
        
          RF.code.train(model,
            options.x,
            options.y,
            {
              numTrees:options.numTrees,
              maxDepth:options.maxDepth,
              numTries:options.numTries,
              type:options.weakType,
            });    
        }
        model.algorithm=options.algorithm
        model.time=Io.time()-t0;
        return model;
        break;

      case ML.RL:
        // Create learner instance
        model = {}
        if (!options.actions || !options.states) throw 'ML.learn.RL: Invalid options';
        options.environment=Io.checkOptions(options.environment,{});
        options.environment.getMaxNumActions=
          Io.checkOption(options.environment.getMaxNumActions,
                      function () { return options.actions.length })
        options.environment.getNumStates=
          Io.checkOption(options.environment.getNumStates,
                      function () { return options.states.length })
        var allowedActions=Io.checkOption(options.environment.allowedActions, function () { return options.actions });
        options.environment.allowedActions=
          // Ensure that allowedActions return number array!
          function (state) { 
            return allowedActions(state).map(function (a) {
              return options.actions.indexOf(a)
            })
          }  
        var nextState = options.environment.nextState;
        if (nextState) {
          options.environment.nextState = function (state,action) {
            return nextState(state,options.actions[action])
          }
        }
        switch (options.kind) {
          case ML.DQNAgent:                          
            model = RL.DQNAgent(
              options.environment,  
              {
                alpha:options.alpha,gamma:options.gamma,epsilon:options.epsilon,
                experience_add_every:options.experience_add_every,
                experience_size:options.experience_size,
                learning_steps_per_iteration:options.learning_steps_per_iteration,
                tderror_clamp:options.tderror_clamp,
                num_hidden_units:options.num_hidden_units,
                update:options.update,
               }
            )
            break;
          case ML.DPAgent:
            model = RL.DPAgent(
              options.environment,  
              {alpha:options.alpha,beta:options.beta,gamma:options.gamma,
               epsilon:options.epsilon,lambda:options.lambda}
            )
            break;
          case ML.TDAgent:
            model = RL.TDAgent(
              options.environment,  
              // specs
              {alpha:options.alpha,beta:options.beta,gamma:options.gamma,
               epsilon:options.epsilon,lambda:options.lambda,
               replacing_traces:options.replacing_traces,
               smooth_policy_update:options.smooth_policy_update,
               update:options.update,
               planN:options.planN}
            )
            break;
        }
        model.algorithm = options.algorithm;
        model.kind      = options.kind;
        if (options.actions)  model.actions   = options.actions;
        if (options.states)   model.states    = options.states;
        if (options.rewards)  model.rewards   = options.rewards;
        model.options   = options;
        return model;
        break;


      // typeof @options = { features : {name,categorical?:boolean,exclude?:boolean} [],
      //                     target   : {name,categorical?:boolean},
      //                     minPercentVarianceReduction?: number ?= 0.5,
      //                     minLeafNodeItems?: number ?= 10,
      //                     minSplitCandidateItems?: number ?= 30,
      //                     minAvgChildrenItems?: number ?= 2,
      //                     data?: {$attr:number|string} []
      case ML.RT:
        if (options.target && options.features) {
          if (!options.target.target) options.target.target=true;
          var columns = options.features.slice(),
              parameter = updateOptions({
                minPercentVarianceReduction:0.5,
                minLeafNodeItems:10,
                minSplitCandidateItems:30,
                minAvgChildrenItems:2,
              },options);
          model = RT();
          columns.push(options.target);
          model.defineConfig( columns, parameter );
          if (!options.featuresList) {
            options.featuresList=options.features.map(function (desc) { return desc.name });
          }
        } else throw 'ML.learn.RT: Invalid options';
        model.algorithm=options.algorithm;
        if (options.data) {
          // TODO
        }
        options.columns=columns;
        model.options=options;
        model.time=Io.time()-t0;
        return model;
        break;      

      case ML.SLP:
      case ML.MLP:
        // typeof options = {x?: number [][], 
        //                   y?: number number [][] | string [],
        //                   data?: number number [], features: number [], target: number [],
        //                   epochs?:number,
        //                   layers?:number [], 
        //                   hidden_layers?: number[],
        //                   verbose?:number,
        //                   labels?:string [], features?: string [], 
        //                   regression?,
        //                   normalize?, bipolar?, eps?:number | number [], verbose?}
        //
        // y and MLP(learn) require [[p1,p2,..],[p1,p2,..],..] with 0>=p>=1
        //                                                           p:label probability
        if (!options.x && !options.y && !options.data && options.layers){
          // create model only; layres must be defined!
          model = MLP({
            n_ins   : options.layers[0],
            n_outs  : options.layers[options.layers.length-1],
            hidden_layer_sizes  : options.layers.slice(1,options.layers.length-1),
            verbose : options.verbose||0,
          });
          model.algorithm = options.algorithm;
          return model;
        }
        if (options.data && options.features && options.target) {
          data=preprocess(options.data,'xmy',options);
          x=data.x;
          y=data.y;
        } else if (options.x && options.y) {
          x=options.x;
          y=options.y;
        } else if (options.data && options.data.x && options.data.y) {
          x=data.x;
          y=data.y;        
        } else throw 'ML.learn.MLP: invalid options';
        if (Comp.obj.isArray(options.x) && typeof options.x[0] == 'number') 
          x=wrap(options.x);   
        if (Comp.obj.isMatrix(options.y)) 
          y=options.y;
        else if (Comp.obj.isArray(options.y) && typeof options.y[0] == 'number') 
          y=wrap(options.y);        
        else if (Comp.obj.isArray(options.y) && options.labels) {
          y=options.y.map(function (l1) {
            return options.labels.map(function (l2) {
              return l1==l2?1:0;
            });
          });
        } else throw 'ML.learn.MLP: invalid options';
        if (options.normalize) {
          // normalize each variable independently!?
          var max=x[0].map(function (col) { return col}),
              min=x[0].map(function (col) { return col});
          x.forEach(function (row) { row.forEach(function (col,i) { 
            max[i]=Math.max(max[i],col);
            min[i]=Math.min(min[i],col) }) });
          xshift=options.bipolar?-1:0;
          xscale=max.map(function (x,i) { return (xshift?2:1)/((x-min[i])==0?1:x-min[i])});
          xoffset=min;
          x=x.map(function (row) { return row.map(function (col,i) { return xshift+(col-xoffset[i])*xscale[i] }) });
          if (options.regression) {
            // scale y, too, [0,1]
            max=y[0].map(function (col) { return col});
            min=y[0].map(function (col) { return col});
            y.forEach(function (row) { row.forEach(function (col,i) { 
              max[i]=Math.max(max[i],col);
              min[i]=Math.min(min[i],col) }) });
          
            yshift=options.bipolar?-1:0;
            yscale=max.map(function (x,i) { return (yshift?2:1)/((x-min[i])==0?1:x-min[i])});
            yoffset=min;
            y=y.map(function (row) { return row.map(function (col,i) { return yshift+(col-yoffset[i])*yscale[i] }) });
          }
        }
        model = MLP({
          input   : x,
          output  : y,
          n_ins   : x[0].length,
          n_outs  : y[0].length,
          hidden_layer_sizes:options.algorithm==ML.SLP?[]:(options.hidden_layers||[]),
          verbose:options.verbose||0,
        });
        model.algorithm=options.algorithm;
        model.labels=options.labels;
        model.features=options.features;
        model.xscale=options.normalize?{k:xscale,off:xoffset,shift:xshift}:undefined;
        model.yscale=options.normalize&&options.regression?{k:yscale,off:yoffset,shift:yshift}:undefined;
        model.nOutputs=y[0].length;
        
        MLP.code.train(model,{
          epochs : options.epochs||20000
        });
        model.time=Io.time()-t0;
        return model;
        break;


      // Simulated Annealing (final solution in model.state)
      case ML.SA:
        /* typeof @options = {
                coolingFactor: number =? 0.09,
		stabilizingFactor: number =? 1.005,
		freezingTemperature: number =? 0.001,
		initialTemperature: number =? 15,
		initialStabilizer: number =? 30,
                generateNewSolution : function () -> current:'a,
                generateNeighbor : function (current) -> current:'a,
                getCost : function (current:'a) -> cost:number
        }
        */
        var state = {
          final:null,
          current:null,
        }
        model = SA.SimulatedAnnealing({
            coolingFactor       : options.coolingFactor||0.09,
            stabilizingFactor   : options.stabilizingFactor||1.005,
            freezingTemperature : options.freezingTemperature||0.001,
            initialTemperature  : options.initialTemperature||15,
            initialStabilizer   : options.initialStabilizer||30,
          },
          /* */ function generateNewSolution () {
            state.current=state.final=options.generateNewSolution();
            return options.getCost(state.current)
          },
          /* */    function generateNeighbor () {
            state.current=options.generateNeighbor(state.final);
            return options.getCost(state.current)
          },
          /*  */     function acceptNeighbor () {
            state.final=state.current;
          }
        );
        model.current = null;
        model.state = state;
        model.algorithm=options.algorithm;
        return model;
        break;

      case ML.SOM:
        // typeof options = {x:nzumber,y:number,fields:{name:string,range:[]}[]..}
        model = {
         network : options.network?SOM.load(options.network):new SOM(options.x,options.y,options)
        }
        model.algorithm=options.algorithm;
        model.options=options;
        model.time=Io.time()-t0;
        return model;
        break;
        
      case ML.SVM:
        // typeof options = {x: number [][], 
        //                   y: ({-1,1}|string) [],
        //                   labels?:string|number [],
        //                   threshold?:number|false,
        //                   C?:numer,tol?:number,max_passes?:number,alpha_tol?:number,kernel?:{}}
        
        // If classes then multi-SVM (one for each class to be separated)!
        if (!options.labels) {
          model = SVM({
            x:options.x,
            y:options.y,
            threshold:options.threshold,
          });
          model.algorithm=options.algorithm
          SVM.code.train(model,{
            C:options.C||1.0,
            tol:options.tol||1e-4,
            max_passes:options.max_passes||20,
            alpha_tol:options.alpha_tol||1e-5,
            kernel:options.kernel
          });
        } else {
          model={};
          model.algorithm=options.algorithm;
          model._labels=options.labels;
          model.svms=options.labels.map(function (cl) {
            return SVM({
              x:options.x,
              y:options.y.map(function (y) { return y==cl?1:-1 }),
              threshold:options.threshold,
            });
          });
          
          model.svms.forEach(function (svm) {
            SVM.code.train(svm,{
              C:options.C||1.0,
              tol:options.tol||1e-4,
              max_passes:options.max_passes||20,
              alpha_tol:options.alpha_tol||1e-5,
              kernel:options.kernel
            });
          });
          // Create one SVM for each class
          // Transform y vector          
        }
        model.time=Io.time()-t0;
        return model;
        break;

      case ML.TXT:
        // typeof options = {data: string []}
        model = TXT.create(options.data,{
        });
        model.algorithm=options.algorithm
        return model;
        break;
    }
  },

  // add gaussian (!!) absolute or relative noise (0,1] to numerical data to create synthetic data
  // v + [-noise,+noise] | v + [-noise*v,noise*v]
  noise: function (data,noise,uniform,relative) {
    var rnd = uniform?
      function () {
        return Math.random()*2-1  
      }:function () {
        return STAT.utils.gaussian(-1,1)
      };
    function noisy(v,noise) {
      if (!relative) return v+rnd()*noise;
      else return v+rnd()*noise*v;
    }
    if (Comp.obj.isMatrix(data)) {
      return data.map(function (row) {
        return row.map(function (v,i) {
          if (typeof noise == 'number')
            return noisy(v,noise);
          else return noise[i]?noisy(v,noise[i]):v;
        })
      })
    } else if (Comp.obj.isArray(data) && Comp.obj.isObject(data[0])) {
      return data.map(function (row) {
        var o={};
        if (row.input && row.output) 
          return { input:row.input.map(function (col,index) { 
                      if (typeof noise.input == 'number') return noisy(col,noise.input);
                      else if (noise.input!=undefined) return noise.input[index]?noisy(col,noise.input[index]):col;
                      else return col;
                   }),
                   output:row.output.map(function (col,index) { 
                      if (typeof noise.output == 'number') return noisy(col,noise.output);
                      else if (noise.output!=undefined) return noise.output[index]?noisy(col,noise.output[index]):col;          
                      else return col;
                   })
                 };
        for (var p in row) {
          if (typeof noise == 'number')
            o[p] = noisy(row[p],noise);
          else o[p] = noise[p]?noisy(row[p],noise[p]):row[p];
        }
        return o;
      })      
    } else if (Comp.obj.isArray(data)) {
        return data.map(function (v,i) {
          if (typeof noise == 'number')
            return noisy(v,noise);
          else return noise[i]?noisy(v,noise[i]):v;
        })    
    } else if (typeof data == 'number') {
      return noisy(data,noise);
    }
  },

  /** Classification (prediction): Apply sample data to learned model.
   *  Returns prediction result.
   *
   */ 
  predict: function (model,samples,options) {
    var x,y,solutions,result,data;
    switch (model.algorithm) {
    
      case ML.ANN:
        if (Comp.obj.isMatrix(samples)) 
          return samples.map(function (sample) { 
            x=sample;          
            if (model.options.xscale) 
              x=x.map(function (row) { return scale(row,model.options.xscale) });
            y=model.network.activate(x);
            if (model.options.yscale)
              y=unscale(y,model.options.yscale);
            if (model.options.labels) // categorical classifier
            return y.map(function (v,i) { return { value:model.options.labels[i], prob:v } });
            return y;
          });
        else {
          x=samples;          
          if (model.options.xscale) 
            x=x.map(function (row) { return scale(row,model.options.xscale) });
          y=model.network.activate(x);
          if (model.options.labels) // categorical classifier
            return y.map(function (v,i) { return { value:model.options.labels[i], prob:v } });
          else 
            return y
        }
      case ML.CNN:
        if (Comp.obj.isMatrix(samples))
          return samples.map(function (sample) {
            return CNN.predict(model,sample);
          });
        else
          return CNN.predict(model,samples);
        break;

      case ML.C45:
        // Sample row format: [x1,x2,..,xn]
        if (Comp.obj.isMatrix(samples)) {
          return samples.map(function (sample) {
            return C45.classify(model,sample);
          });
        } else if (Comp.obj.isArray(samples) && !Comp.obj.isObj(samples[0])) {
          return C45.classify(model,samples);
        } else if (Comp.obj.isArray(samples) &&  Comp.obj.isObj(samples[0])) {
          return samples.map(function (sample) {
            return C45.classify(model,sample); 
          });
        } else if (Comp.obj.isObj(samples)) {
          return C45.classify(model,samples);
        }
        break;

      case ML.DT:
      case ML.ICE:
        if (Comp.obj.isMatrix(samples) ||
            Comp.obj.isArray(samples) && Comp.obj.isObj(samples[0])) 
          return samples.map(function (sample) { 
            return ICE.predict(model,sample) 
          });
        else 
          return ICE.predict(model,samples);

      case ML.DTI:
        if (Comp.obj.isMatrix(samples)) 
          return samples.map(function (sample) { 
            return DTI.predict(model,sample) 
          });
        else
          return DTI.predict(model,samples);

      case ML.ID3:
        if (Comp.obj.isArray(samples)) 
          return samples.map(function (sample) { 
            return ID3.predict(model,sample) 
          });
        else
          return ID3.predict(model,samples);

      case ML.KNN:
        if (Comp.obj.isMatrix(samples))
          return KNN.predict(model,samples);        
        else if (Comp.obj.isArray(samples) && Comp.obj.isObj(samples[0]))
          return KNN.predict(model,samples.map(function (sample) { 
            return obj2Array(sample,model.features)}));
        else if (Comp.obj.isObj(samples))
          return KNN.predict(model,obj2Array(samples,model.features));
        else
          return KNN.predict(model,samples);
        break;

      case ML.KNN2:
        if (Comp.obj.isMatrix(samples))
          return samples.map(function (sample) {
            return KNN.predict2(model,sample);
          });
        else if (Comp.obj.isArray(samples) && Comp.obj.isObj(samples[0]))
          return samples.map(function (sample) {
             return KNN.predict2(model,obj2Array(sample,model.features))
            })
        else if (Comp.obj.isObj(samples))
          return KNN.predict2(model,obj2Array(samples,model.features));
        else
          return KNN.predict2(model,samples);
        break;

      case ML.KMN:
        return model.clusters
        break;

      // Function Regression
      case ML.REG:
        // requires [x,x*x,x*x*x,..,y] [] data
        if (typeof samples == 'number') samples=[samples];
        if (model.options.order) {
          data=samples.map(function (xx) {
            if (typeof xx=='number') xx=[xx];
            var x=xx[0];
            for (var i=2;i<=model.options.order;i++)
              xx.push(Math.pow(x,i));
            return xx
          })
        }
          else data=samples;

        return model.regression.transform(data);
        break;

      case ML.RF:
        if (model.labels) {
          if (Comp.obj.isMatrix(samples)) {
            return samples.map(function (sample) {
              return model.rfs.map(function (rf) {
                return RF.code.predictOne(rf,sample);
              }).map(function (v,i) {
                return { value:model.labels[i], prob:v }
              })
            });
          } else if (Comp.obj.isArray(samples) && typeof samples[0] == 'number') {
            return model.rfs.map(function (rf) {
              return RF.code.predictOne(rf,samples);
            }).map(function (v,i) {
                return { value:model.labels[i], prob:v }
            })
          } // TODO
        } else {
          // Sample row format: [x1,x2,..,xn]
          if (Comp.obj.isMatrix(samples)) {
            return samples.map(function (sample) {
              return RF.code.predictOne(model,sample);
            });
          } else if (Comp.obj.isArray(samples) && typeof samples[0] == 'number') {
            return RF.predictOne(model,samples);
          } // TODO
        }
        // preprocess(samples,'m')
        break;
                
      case ML.RT:
        if (Comp.obj.isArray(samples)) {
          return samples.map(function (sample) { 
            if (!Comp.obj.isArray(sample))
              return model.predict(sample);
            else {
              // map to object
              data = array2Object(sample,model.options.featuresList);
              return model.predict(data);
            }
          });
        } else {
          if (!Comp.obj.isArray(samples))
            return model.predict(samples);
          else {
            // map to object
            data = array2Object(samples,model.options.featuresList);
            return model.predict(data);
          }
        }
        break;

      case ML.SOM:
          return model.network.predict(samples,options);
        break;
        
      case ML.SVM:
        if (!model._labels) {
          // Single SVM 
          if (Comp.obj.isMatrix(samples))
            return samples.map(function (sample) {
              return SVM.code.predict(model,sample);
            });
          else
            return SVM.code.predict(model,samples);
        } else {
          // Multi SVM
          if (Comp.obj.isMatrix(samples))
            return samples.map(function (sample) {
              solutions=model.svms.map(function (svm,index) { 
                if (svm.threshold==false)
                  return SVM.code.predict(svm,sample)
                else
                  return SVM.code.predict(svm,sample); 
              });
              return solutions.map(function (v,i) { return { value:model._labels[i], prob:v } });
            });
          else {
            solutions=model.svms.map(function (svm,index) { 
                if (svm.threshold==false)
                  return SVM.code.predict(svm,samples)
                else
                  return SVM.code.predict(svm,samples)==1; 
            })
            return solutions.map(function (v,i) { return { value:model._labels[i], prob:v } });
          }
        }
        break;
        
      case ML.SLP:
      case ML.MLP:
        // returns always [y1,y2,..][] w/o label coding and even if |y|=1
        if (Comp.obj.isMatrix(samples)) {
          x=samples;          
          if (model.xscale) 
            x=x.map(function (row) { return scale(row,model.xscale) });
          result = model.labels?MLP.code.predict(model,x).map(function (r) {
            var o={};
            r.forEach(function (v,i) { o[model.labels[i]]=v });
            return o;
          }):/*relax*/(MLP.code.predict(model,x));
        } else if (Comp.obj.isArray(samples)) {
          x=samples;
          if (model.xscale) 
            x=scale(x,model.xscale);
          result = model.labels?MLP.code.predict(model,[x]).map(function (r) {
            var o={};
            r.forEach(function (v,i) { o[model.labels[i]]=v });
            return o;
          })[0]:/*relax*/(MLP.code.predict(model,[x])[0]);
        } else if (Comp.obj.isObj(samples) && model.features) {
          x=model.features.map(function (f) { return samples[f] });
          if (model.xscale) 
            x=scale(x,model.xscale);
          result = model.labels?MLP.code.predict(model,[x]).map(function (r) {
            var o={};
            r.forEach(function (v,i) { o[model.labels[i]]=v });
            return o;
          })[0]:/*relax*/(MLP.code.predict(model,[x])[0]); 
        }
        if (Comp.obj.isArray(result)) {
          return model.yscale?result.map(function (y) { return unscale(y,model.yscale) }):result;
        } else {
          // TODO??
        }
        break;
        
       case ML.TXT:
        // typeof options = {data: string []}
        if (Comp.obj.isArray(samples))
          return samples.map(function (sample) { return TXT.classify(model,sample) });
        else
          return TXT.classify(model,samples);
        break;

   }
  },

  preprocess:preprocess,

  print: function (model,indent,compact) {
    switch (model.algorithm) {
      case ML.DTI:
        return DTI.print(model,indent,compact);
      case ML.DT:
      case ML.ICE:
        return ICE.print(model,indent);
      case ML.C45:
        return C45.print(model,indent);
      case ML.ID3:
        return ID3.print(model,indent);
    }
  },
  
  // Only text module
  similarity : TXT.similarity,
  
  stats : STAT,
  
  // Check model consistency with training or test data (input: x/y data table!)
  test: function (model,samples,options) {
    var x,y,data,res,p=0.0,error;
    switch (model.algorithm) {
    
      case ML.ANN:
        if (Comp.obj.isArray(samples)) {
          data=preprocess(samples,'xy',model.options); // data.x/data.y
          result=ml.predict(model,data.x);
          if (!options)
            return result.map(function (row,i) {
              return {y0:data.y[i],y:row};
            }); 
          else if (options.error) {
            
            error=result.map(function (row,i) {
              return options.error(data.y[i],row);
            }); 
            if (options.finally) return options.finally(error);
            else return error;
          }
        } else {
          data={x:samples.input,y:samples.output };
        }
        break;
        
      case ML.C45:
        // Sample row format: [x1,x2,..,y]
        if (Comp.obj.isMatrix(samples)) {
          samples.forEach(function (sample) {
            x=sample.slice(0,sample.length-1);
            y=sample[sample.length-1];
            res= C45.classify(model,x);
            if (res==y) p += 1;
          });
          return p/samples.length;
        } else if (Comp.obj.isArray(samples)  && !Comp.obj.isObject(samples[0])) {
          x=samples.slice(0,samples.length-1);
          y=samples[samples.length-1];
          res = C45.classify(model,x);
          return res==y?1.0:0.0
        } else if (Comp.obj.isObj(samples) && model.features) {
        }
        break;

      case ML.ICE:
        data=preprocess(samples,'xy',{features:model.features,target:model.target});
        data.x.forEach(function (sample,index) {
          res= ML.classify(model,sample);
          if (res==data.y[index]) p += 1;
        });
        return p/data.x.length;
        break;
        
      case ML.TXT:
        var model = model.string?{ data : [model.string] }:model;
        if (Comp.obj.isArray(samples))
          return samples.map(function (sample) { 
            return TXT.classify(model,sample).match
          });
        else
          return TXT.classify(model,samples).match;
        break;

        
    }
  },
  

  /** Update an already learned or train a new model
   *
   */
  train: function (model,options,more) {
    var data,t0;
    // if (!options) return ml.learn(options); // backward comp.
    switch (model.algorithm||options.algorithm) {
    
      case ML.ANN:
        Object.assign(model.options,more||{})
        data = preprocess(options,'io',model.options);
        if (!data) throw "ML.train.ANN: invalid data (not convertable to io format)";
        t0=Io.time();
        result=model.network.train(data,model.options);
        model.time=Io.time()-t0;
        return result;
        break;
        
      case ML.CNN:
        // typeof @options = { x,y,.. }
        return CNN.train(model,options);
        break;

      case ML.DTI:
        // typeof @options = {data: number [][], target:string, features: string [], eps?:number, maxdepth?:number} |
        //                   {x: number [][], y:[], eps?:number, maxdepth?:number}
        t0=Io.time();
        if (options.eps==_) options.eps=0;
        if (options.maxdepth==_) options.maxdepth=20;
        if (options.data && options.target && options.features)
          model = DTI.update(model,options);
        else if (options.x && options.y) {
          if (options.x.length != options.y.length) throw 'ML.update.DTI: X and Y vector have different length';
          data=options.x.slice();
          data=data.map(function (row,i) {row.push(options.y[i]); return row});
          features=Comp.array.init(data[0].length-1,function (i) { return String(i)});
          target=String(data[0].length-1);
          // console.log(data,features,target)
          model = DTI.update(model,{
            data:data,
            features:features,
            target:target,
            eps:options.eps,
            maxdepth:options.maxdepth
          });
        } else throw 'ML.update.DTI: Invalid options';
          
        model.time=Io.time()-t0;
        model.algorithm=options.algorithm;
        return model;

      // Function Regression
      case ML.REG:
        // requires [x,x*x,x*x*x,..,y] [] data
        if (model.options.order) {
          data=options.map(function (xy) {
            var x=xy[0],y=xy.pop();
            for (var i=2;i<=model.options.order;i++)
              xy.push(Math.pow(x,i));
            xy.push(y);
            return xy
          })
        }
          else data=options;
        return model.regression.fit(data);
        break;
            
      case ML.RL:
        switch (model.kind) {
          case ML.DQNAgent:
            return RL.DQNAgent.code.learn(model,options);
            break;
          case ML.DPAgent:  
            return RL.DPAgent.code.learn(model,options);
            break;
          case ML.TDAgent:
            return RL.TDAgent.code.learn(model,options);
            break;
        }
        break;

      case ML.RT:
        data=options;
        // data must be [][] with exact column order features@target!
        // if {}[], convert
        if (data[0] && !Comp.obj.isArray(data[0])) {
          data = data = ml.preprocess(data,'m',{
            features  : model.options.columns.pluck('name') 
          }).data;
        } 
        // console.log(data)
        for(var i in data) model.ingest(data[i]);
        
        return model.learn();
        break;
        
      case ML.SLP:
      case ML.MLP:
        // typoeof options = { x:[][],y:[][],data: number [][],features: number [], target:number [], epochs:number }
        // TODO scale/normalize/convert
        t0=Io.time();
        if (options.x && options.y) {
          MLP.code.train(model,{
            x      : options.x,
            y      : options.y,
            epochs : options.epochs||20000
          });
        } else if (options.data && options.features && options.target) {
          data = preprocess(options.data,'xmy',options);
          MLP.code.train(model,{
            x      : data.x,
            y      : data.y,
            epochs : options.epochs||20000
          });
        } else if (options.data && options.data.x && options.data.y) {
          data = preprocess(options.data,'xmy',options);
          MLP.code.train(model,{
            x      : data.x,
            y      : data.y,
            epochs : options.epochs||20000
          });
        } else throw "ML.MLP.train: Invalid options";
        model.time=Io.time()-t0;
        return { time:model.time, error:model.error, crossEntropy:model.crossEntropy };
        break;
        
        
      case ML.SA:
        var more=true,n=1E6,i=0;
        t0=Io.time();
        if (typeof options == 'number') n=options;
        while (more && i<n) {
          more = model.Do();
          if (!more) break;
          i++;
        }
        model.time=Io.time()-t0;
        return {
          temperature : model.GetCurrentTemperature(),
          energy      : model.GetCurrentEnergy(),   // last cost
          final       : model.state.final,
          more        : more,
          steps       : i,
          time        : model.time,
        }
        break;
        
      case ML.SOM:
        data=options;
        model.network.train(data,more);
        return model.network.getQuantizationError();
        break;
    }
  },
  // Returns an unified JSON-like representation of the core model, e.g., for graph drawing
  // Types: Node or graoh function structure, parametrised function, tables
  toGraph: function (model,options) {
    var j,nodes,connections,map;
    options=options||{};
    switch (model.algorithm||options.algorithm) {
      case ML.ANN:
        // nodes, connections, input, output
        var ir = model.network.toJSON();
        if (options.native) return ir;
        nodes = ir.nodes.map(function (node) {
          return {
            type    : node.type,
            index   : node.index,
            bias    : node.bias,
            eval    : ['SUM',node.squash],
            attributes : {
              layerid : node.layerid,
              groupid : node.groupid,
              mask    : node.mask,
            }
          }
        })
        //
        j = {
          type      : 'graph',
          attributes  : ['directed','ANN'],
          nodes       : nodes,
          connections : ir.connections, // TODO: unification
          parameter : {
            layers    : model.options.layers,
            algorithm : model.algorithm,
            functions : {
              SUM: 'function (node,connections) { return node.bias+connections.sum(function (c) { return c.from.y*c.weight })',
              LOGISTIC:'function (x) { return 1 / (1 + Math.exp(-x)) }',
            }
          }
        };   
        break;
      case ML.ID3:
        nodes=[];
        results=[];
        resultsMap=[];
        connections=[];
        map=[];
        function iter1(node) {
          if (node.type=='feature') {
            var index=nodes.length;
            var _node = {
              type  : 'feature',
              name  : node.name, 
              index : index
            }
            map[index]=node
            nodes.push(_node);
            node.vals.forEach(function (e) {
              iter1(e.child)
            })
          }
        }
        function iter2(node) {
          if (node.type=='feature') {
            node.vals.forEach(function (e) {
              iter2(e.child)
            })
          } else if (node.type=='result') {
            var index=nodes.length;
            if (results.indexOf(node.name)!=-1) return;
            var _node = {
              type  : 'result',
              name  : node.name,
              value : node.value, 
              index : index
            }
            map[index]=node;
            results.push(node.name);
            resultsMap.push(_node);
            nodes.push(_node);              
          }
        }
        function iter3(node) {
          if (node.type=='feature') {
            var from = map.indexOf(node);
            node.vals.forEach(function (e) {
              if (e.child.type=='feature') connections.push({
                from  : from,
                to    : map.indexOf(e.child),
                value : e.value
              }); else if (e.child.type=='result') connections.push({
                from  : from,
                to    : resultsMap[results.indexOf(e.child.name)].index,
                value : e.value
              })
            })
            node.vals.forEach(function (e) {
              iter3(e.child)
            })           
          } 
        }
        iter1(model)
        iter2(model)
        iter3(model)
        j = {
          type        : 'graph',
          attributes  : ['directed','DT'],
          nodes       : nodes,
          connections : connections,
        }
        break;
      case ML.MLP:
        map=[];
        nodes=[];
        connections=[];
        var input = model.sigmoidLayers[0].W;
        map[0]=[];
        input = input.map(function (v,i) {
          var index=nodes.length;
          var node = {
            type : 'input',
            eval : ['ID'],
            index : index,
            attributes : {
              layreid : 0,
            }
          };
          nodes.push(node);
          map[0].push(node);
          return node;
        });
        model.sigmoidLayers.forEach(function (layer,layerIndex) {
          map[layerIndex+1]=[];
          layer.b.forEach(function (b,bi) {
            var index=nodes.length;
            var node = {
              type : layerIndex==model.sigmoidLayers.length-1?'output':'hidden',
              bias : b,
              eval : ['SUM','SIGMOID'],
              index : index,
              attributes : {
                layreid : layerIndex+1
              }
            };
            nodes.push(node);
            map[layerIndex+1].push(node);
          });        
        });
        model.sigmoidLayers.forEach(function (layer,layerIndex) {  
          input = layer.b.map(function (b,bi) {
            layer.W.forEach(function (w,wi) {
              connections.push({
                from : input[wi].index,
                to   : map[layerIndex+1][bi].index,
                weight : w[bi]
              });
            })
            return map[layerIndex+1][bi]
          });        
        });
        j = {
          type        : 'graph',
          attributes  : ['directed','ANN'],
          nodes       : nodes,
          connections : connections,
          functions : {
            ID:'function (x) { return x }',
            SUM: 'function (node,connections) { return node.bias+connections.sum(function (c) { return c.from.y*c.weight })',
            SIGMOID:'function (x) { return 1 / (1 + Math.exp(-x)) }',
          }
        }
        break;
      case ML.RT:
        j=model.exportJSON();
        break;
    }  
    return j;
  },
  // Create a model JSON data object that can be saved and restored! Not supported by all algorithms!
  // !!! NEW unified JSON format: { algorith, network, options } // breaks old code!
  toJSON : function (model,options) {
    options=options||{};
    switch (model.algorithm||options.algorithm) {
      case ML.ANN:
        // nodes, connections, input, output
        return {
          algorithm : ML.ANN, 
          network   : model.network.toJSON(),
          options   : model.options,
        }
      case ML.CNN:
        return {
          algorithm : ML.CNN, 
          network   : model.network.toJSON(),
          options   : getOptions(model.options,['width','height','depth','layers','targets','normalize','trainer']),
        };
        break;
      case ML.SOM:
        return {
          algorithm : ML.SOM, 
          network   : model.network.export(),
          // TODO incomplete
          options   : getOptions(model.options,['x','y','fields','iterations','learningRate']),
        };
        break;
      case ML.MLP:
        return model; 
      default:
        // TODO
        return 'Not supported';
    }    
  },
  // restore a model from JSON
  fromJSON : function (model) {
    if (typeof model=='string') model=JSON.parse(model);
    switch (model.algorithm) {
      case ML.ANN:
        return ml.learner({
          algorithm : ML.ANN,
          network   : model.network
        })
      case ML.CNN:
        return ml.learner(Object.assign(model.options,{
          algorithm : ML.CNN,
          network   : model.network
        }))
        break;
      case ML.SOM:
        return ml.learner(Object.assign(model.options,{
          algorithm : ML.SOM,
          network   : model.network
        }))
        break;
      default:
        // TODO
        throw 'ML.fromJSON: Algorithm not supproted';
    }
  },
  
  utils : {
    scale:scale,
    toScale:toScale,
  },
  
  ML:ML,
};
  
ICE.ml=ml;
CNN.ml=ml;
ml.classify=ml.predict;
ml.update=ml.train;
ml.best=ml.stats.utils.best;
ml.learn=ml.learner;
// loaded on demand
ml.xgboost = null;

module.exports = {
  action:ml.action,
  best:STAT.utils.best,
  classify:ml.classify,
  column:ml.column,
  convert : function (data,format,options) {
    // simplified {}[] <-> [][] data table conversion
    options=options||{};
    if (Comp.obj.isObject(format)) options=format,format=undefined;
    if (!format) {
      if (Comp.obj.isArray(data) && !Comp.obj.isArray(data[0]) && Comp.obj.isObject(data[0])) format='m';
      if (Comp.obj.isArray(data) && Comp.obj.isArray(data[0])) format='r';
    }
    if (format.toLowerCase()=='record') format='r';
    if (format.toLowerCase()=='array') format='m';
    if (format.toLowerCase()=='matrix') format='m';
    var result = preprocess(data,format,options);
    if (result && result.data) return result.data;
    else return result;
  },
  compact:ml.compact,
  depth:ml.depth,
  entropy:STAT.entropy,
  entropyN:STAT.entropyN,
  entropyDep:STAT.entropyDep,
  evaluate:ml.evaluate,
  fromJSON:ml.fromJSON,
  help:ml.help,
  info:ml.info,
  learn:ml.learn,
  learner:ml.learner,
  noise:ml.noise,
  options:options,
  pca:PCA,
  predict:ml.predict,
  preprocess:preprocess,
  print:ml.print,
  scale:scale,
  scale0:scale0,
  split:split,
  statistics:STAT,
  test:ml.test,
  toScale:toScale,
  train:ml.train,
  toJSON:ml.toJSON,
  unique:ml.stats.unique,
  unscale:unscale,
  update:ml.update,
  ANN:ANN,
  CNN:CNN,
  // set logging function
  log:function (f) {
    MLP.code.log=f;
  },
  ML:ML,
  DBCLUST:DBCLUST,
  DR:DR,
  math:MATH,
  version : options.version
}

if (typeof window != 'undefined') console.log('ML '+options.version+' loaded.');

};
BundleModuleCode['com/compat']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Stefan Bosse
 **    $INITIAL:     (C) 2006-2021 bLAB
 **    $CREATED:     30-3-15 by sbosse.
 **    $VERSION:     1.23.6X
 **
 **    $INFO:
 **
 **  JavaScript-OCaML Compatibility Module
 **
 **    $ENDOFINFO
 */
var Io = Require('com/io');
var Path = Require('com/path');
var Sprintf = Require('com/sprintf');

/*******************************
** Some global special "values"
********************************/

/** A matching template pattern matching any value
 *
 * @type {undefined}
 */
var any = undefined;
/** A matching template pattern matching any value
 *
 * @type {undefined}
 */
var _ = undefined;

/**
 *
 * @type {null}
 */
var none = null;
/**
 *
 * @type {null}
 */
var empty = null;

var NL = '\n';

global.int = function (v) {return v|0};
global.div = function (a,b) {return a/b|0};

if (!Object.prototype.forEach) {
	Object.defineProperties(Object.prototype, {
		'forEach': {
			value: function (callback) {
				if (this == null) {
					throw new TypeError('Not an object');
				}
				var obj = this;
				for (var key in obj) {
					if (obj.hasOwnProperty(key)) {
						callback.call(obj, obj[key], key, obj);
					}
				}
			},
			writable: true
		}
	});
}
/** Just transfer parent prototypes to child
 *
 */
function inherit(child,parent) {
  for(var p in parent.prototype) {
    if (p == '__proto__') continue;
    child.prototype[p]=parent.prototype[p];
  }
}

/** Portable class inheritance and instanceOf polyfill
 *
 */
// SomeObject.prototype.__proto__=SomeObject2.prototype;
// Child class inherits prototype from parent using __proto__
function inheritPrototype(child,parent) {
  var __proto__=child.__proto__;
  child.prototype.__proto__=parent.prototype;
  if (!__proto__) for(var p in parent.prototype) {
    if (p == '__proto__') continue;
    child.prototype[p]=parent.prototype[p];
  }
}
// Polyfill fir o instanceof c with inheritance check (checking __proto__)
function instanceOf(obj,cla) {
  var p=obj.__proto__;
  if (obj instanceof cla) return true;
  while (p) {
    if (p === cla.prototype) return true;
    p=p.__proto__
  }
  return false;
}
// Polyfill for __defineGetter__ / __defineSetter__
function defineGetter(cla,prop,fun) {
  Object.defineProperty(cla.prototype,prop,{
    configurable:true,
    get:fun
  });
}
function defineSetter(cla,prop,fun) {
  Object.defineProperty(cla.prototype,prop,{
    configurable:true,
    set:fun
  });

}

var inherit = inherit;
var inheritPrototype = inheritPrototype;
var instanceOf = instanceOf;
var defineGetter = defineGetter;
var defineSetter = defineSetter;

/**
 *
 */
var assert = function(condmsg) {
    if (condmsg != true) {
        Io.out('** Assertion failed: '+condmsg+' **');
        Io.stacktrace();
        throw Error(condmsg);
    }
};
global.assert=assert;

function forof(obj,f) {
  var _iteratorNormalCompletion = true;
  var _didIteratorError = false;
  var _iteratorError = undefined;

  try {
    for (var _iterator = obj[Symbol.iterator](), _step; 
         !(_iteratorNormalCompletion = (_step = _iterator.next()).done); 
         _iteratorNormalCompletion = true) {
      element = _step.value;

      f(element);
    }
  } catch (err) {
    _didIteratorError = true;
    _iteratorError = err;
  } finally {
    try {
      if (!_iteratorNormalCompletion && _iterator.return) {
        _iterator.return();
      }
    } finally {
      if (_didIteratorError) {
        throw _iteratorError;
      }
    }
  }
}


global.forof=forof;

/** OBJ
 *
 */
var obj = {
    /** Compact an object:
     * [{a:b},[c:d},..] -> {a:b,c:d,..}
     * {a:[b]} -> {a:b}
     *
     */
    compact: function (o) {
      var a;
      if (obj.isArray(o)) {
        if (o.length==1 && obj.isObject(o[0])) return obj.compact(o[0]);
        else return o;
      } else if (obj.isObject(o)) for (a in o) {
          var elem=o[a];
          o[a]=obj.compact(elem);
      }
      return o;
    },
    copy: function (o) {
      if (o === null || typeof o !== 'object') {
        return o;
      }
 
      var temp = (o instanceof Array) ? [] : {};
      for (var key in o) {
        temp[key] = obj.copy(o[key]);
      }
 
      return temp;    
    },
    equal: function (o1,o2) {
      if (!o1 || !o2) return false;
      for(var i in o1) if (o1[i]!=o2[i]) return false;
      for(var i in o2) if (o1[i]!=o2[i]) return false;
      return true;
    },
    extend: function (o1,o2) {
      for(var i in o2) o1[i]=o2[i];
      return o1;
    },
    find: function(obj,fun) {
      var p;
      for(p in obj) {
          if (fun(obj[p],p)) return obj[p];
      }
    },

    hasProperty: function (o,p) {
      return o[p]!=undefined || (p in o);
    },
    head:function(o) {
      for (var p in o) return p;
      return undefined;
    },
    // transfer src attributes to dst recusively (no object overwrite)
    inherit: function (dst,src) {
      for(var i in src) {
        if (typeof dst[i] == 'object' && typeof src[i] == 'object')
          inherit(dst[i],src[i]);
        else if (typeof dst[i] == 'undefined')
          dst[i]=src[i];
      }
      return dst;
    },
    isArray:function (o) {
      if (o==_ || o ==null) return false;
      else return typeof o == "array" || (typeof o == "object" && o.constructor === Array);
    },
    isMatrix:function (o) {
      if (o==_ || o ==null) return false;
      else return obj.isArray(o) &&
                  obj.isArray(o[0]);
    },
    isEmpty: function (o) {
      for(var prop in o) {
         if (o[prop]!=undefined) return false;
      }
      return true;  
    },
    isFunction: function (o) {
        return typeof o == "function";
    },
    isObj:function (o) {
        return typeof o == "object";
    },
    isObject:function (o) {
        return typeof o == "object";
    },
    isRegex: function (o) {
        return o instanceof RegExp;
    },
    isString: function (o) {
        return typeof o == "string" || (typeof o == "object" && o.constructor === String);
    },
    isNumber: function (o) {
        return typeof o == "number" || (typeof o == "object" && o.constructor === Number);
    },


    iter: function(obj,fun) {
      var p;
      for(p in obj) {
        fun(obj[p],p)
      }
    }
};

/** ARRAY
 *
 */
var array = {
    /** Evaluate a function returning a boolean value for each member of the array and
     *  compute the boolean conjunction.
     *
     * @param {* []} array
     * @param {function(*,number)} fun
     */
    and: function(array,fun) {
        var res=true;
        var i=0;
        var len=array.length;
        for(i=0;i<len;i++) {
            var element=array[i];
            res=res&&fun(element,i)
        }
        return res;
    },
    /** Append one element at the end of the array.
     *
     * @param {* []} array
     * @param {*} element
     * @returns {* []}
     */
    append : function(array,element) {
        array.push(element);
        return array;
    },
    /**
     *
     * @param {* []} array
     * @param {function(*,number)} fun
     */
    call: function(array,args) {
        var i=0;
        var len=array.length;
        for(i=0;i<len;i++) {
            var element=array[i];
            element()
        }
    },
    /** Check for an elenment in the array by using a check function.
     *
     * @param array
     * @param fun
     * @returns {boolean}
     */
    check: function(array,fun) {
        var i,exist;
        exist=false;
        loop: for(i in array) {
            var element=array[i];
            if (fun(element,i)) {
                exist=true;
                break loop;
            }
        }
        return exist;
    },
    /** Append array2 at the end of array inplace. The extended array is returned.
     *  Source array (1) will be modified.
     *
     * @param {*[]} array
     * @param {*[]} array2
     * @returns {*[]}
     */
    concat : function(array,array2) {
        for(var i in array2) {
            array.push(array2[i]);
        }
        return array;
    },
    /** Create the conjunction set of two arrays
     *
     */
    conjunction :function (set1,set2,fun) {
      return array.union(set1,set2,fun);
    },
    /**
     *
     * @param {*[]} array
     * @param {number|string|*|*[]} elements
     * @param {function} [fun] Optional equality test function
     * @returns {boolean}
     */
    contains : function(array,elements,fun) {
        var i = array.length;
        if (!fun) fun=function(o1,o2) {return o1===o2};
        if (obj.isArray(elements)) {
          while (i--) {
            var j = elements.length;
            while (j--) {
              if (fun(array[i],elements[j])) {
                  return true;
              }          
            }
          }
        }
        else while (i--) {
            if (fun(array[i],elements)) {
                return true;
            }
        }
        return false;
    },
    /** Return a fresh copy of the source array or copy src array to dst.
     *
     * @param array
     * @returns {Array.<T>|string|Blob|ArrayBuffer}
     */
    copy: function(src,dst) {
        var i;
        if (dst) {
          for(i in src) dst[i]=src[i];  
        } else return src.slice();
    },
    /** Create a new array with initial element values.
     *
     * @param length
     * @param init
     * @returns {Array}
     */
    create : function(length,init) {
        var arr = [], i = length;
        while (i--) {
          arr[i] = init;
        }
        return arr;
    },
    /** Create a matrix (array of array) with initial element values.
     *
     */
    create_matrix : function(rows,cols,init) {
        var m = [];
        var r = [];
        var i,j;
        for (i = 0; i < rows; i++) {
            r=[];
            for(j=0;j<cols;j++) r.push(init);
            m.push(r);
        }
        return m;
    },
    /** Create the (inclusive) disjunction set of two arrays.
     *  Source arrays will not be modified.
     *
     */
    disjunction :function (set1,set2,fun) {
      return array.merge(set1,set2);
    },
    /**
     *
     * @param array
     * @returns {boolean}
     */
    empty : function (array) {
      return (array==undefined ||
              array.length==0)
    },
    
    /** Test for equality
    */
    equal: function (a1,a2) {
      if (a1.length != a2.length) return false;
      for(var i in a1) if (a1[i]!=a2[i]) return false;
      return true;
    },
    
    /** Create the (exclusive) disjunction set of two arrays. 
     *  Source arrays will not be modified.
     *
     */
    exclusive :function (set1,set2,fun) {
        var i,j,found,res = [];
        for (i in set1) {
          found=false;
          loop1: for (j in set2) {
            if (fun != undefined && fun(set1[i],set2[j])) {found=true; break loop1;}
            else if (fun == undefined && set1[i]==set2[j]) {found=true; break loop1;};
          }
          if (!found) res.push(set1[i]);
        }
        for (i in set2) {
          found=false;
          loop2: for (j in set1) {
            if (fun != undefined && fun(set2[i],set1[j])) {found=true; break loop2;}
            else if (fun == undefined && set2[i]==set1[j]) {found=true; break loop2;};
          }
          if (!found) res.push(set2[i]);
        }
        return res;
    },
    /** Find an element in an array and return it (or none);
     *
     * @param array
     * @param fun
     * @returns {undefined|*}
     */
    find: function(array,fun) {
        var i;
        for(i in array) {
          if (fun(array[i],i)) return array[i];
        }
        return none;
    },
    /** Search and map an element of an array using a test&map function.
     *
     * @param array
     * @param {function(*,number):*} fun
     * @returns {undefined|*}
     */
    findmap: function(array,fun) {
        var i,found;
        for(i in array) {
          found=fun(array[i],i);
          if (found) return found;
        }
        return none;
    },
    /** Filter out elements using a test function.
     *
     * @param {* []} array
     * @param {function(*,number):boolean} fun
     * @returns {* []}
     */
    filter: function(array,fun) {
      if (array.filter) return array.filter(fun);
      else {
        var res=[],
            len=array.length,
            element,i;
        for(i=0;i<len;i++) {
            element=array[i];
            if (fun(element,i)) res.push(element);
        }
        return res;
      }
    },
    /** Filter out and map elements using a test&map function.
     *
     * @param {* []} array
     * @param {function(*,number):*|undefined} fun
     * @returns {* []}
     */
    filtermap: function(array,fun) {
        var res=[],
            len=array.length,
            element,mapped,i;
        for(i=0;i<len;i++) {
            element=array[i];
            mapped=fun(element,i);
            if (mapped!=undefined) res.push(mapped);
        }
        return res;
    },
    /** Flattens an array consting of arrays (and elements)
     *
     * @param array
     * @returns {Array}
     */
    flatten: function (array) {
        var res=[];
        var len=array.length;
        var i;
        for(i=0;i<len;i++) {
            var element=array[i];
            if (!obj.isArray(element)) res.push(element);
            else {
                var j;
                var len2=element.length;
                for(j=0;j<len2;j++) {
                    var element2=element[j];
                    res.push(element2);
                }
            }
        }
        return res;

    },
    /**
     *
     * @param array
     * @returns {*}
     */
    head : function(array) {
        return array[0];
    },
    /**
     *
     * @param length
     * @param fun
     * @returns {Array}
     */
    init : function(length,fun) {
        var arr = [], i = length;
        while (i--) {
          arr[i] = fun(i);
        }
        return arr;
    },
    /**
     *
     * @param {* []} array
     * @param {function(*,number)} fun
     */
    iter: function(array,fun) {
      /*
        var i=0;
        var len=array.length;
        for(i=0;i<len;i++) {
            fun(array[i],i)
        }
      */
      array.forEach(fun);
    },
    /**
     *
     * @param {* []} array1
     * @param {* []} array2
     * @param {function(*,*,number)} fun
     */
    iter2: function(array1,array2,fun) {
        var i=0;
        assert((array1.length == array2.length)||('Array.iter2: arrays of different lengths'));
        /*
        var len=array1.length;
        for(i=0;i<len;i++) {
            fun(array1[i],array2[i],i)
        }
        */
        array1.forEach(function (e1,i) { fun(e1,array2[i],i) });
    },
    /**
     *
     * @param {* []} array
     * @param {function(*,number)} fun Returning a true value leaves iteration loop
     */
    iter_break: function(array,fun) {
        var i=0;
        var len=array.length;
        for(i=0;i<len;i++) {
            var element=array[i];
            if (fun(element,i)) return;
        }
    },
    /**
     *
     * @param {* []} array
     * @param {function(*,number)} fun
     */
    iter_rev: function(array,fun) {
        var i;
        var len=array.length;
        for(i=len-1;i>=0;i--) {
            fun(array[i],i)
        }
    },
    /** Return last element of array.
     *
     */
    last : function(array) {
      var len=array.length;
      if (len==0) return none;
      else return array[len-1];
    },
    
    length : function(array) {
        return array.length;
    },
    /**
     *
     * @param {* []} array1
     * @param {* []} array2
     * @param {function(*,*,number)} fun
     * @returns {* []}
     */
    map2: function(array1,array2,fun) {
        var i=0;
        assert((array1.length == array2.length)||('Array.map2: arrays of different lengths'));
        var len=array1.length;
        var res=[];
        for(i=0;i<len;i++) {
            res.push(fun(array1[i],array2[i],i));
        }
        return res;
    },
    /**
     *
     * @param {* []} array
     * @param {function(*,number)} fun
     * @returns {* []}
     */
    map: function(array,fun) {
        var i=0;
        var len=array.length;
        var res=[];
        for(i=0;i<len;i++) {
            var element=array[i];
            res.push(fun(element,i));
        }
        return res;
    },
    /**
     *
     * @param {* []} array
     * @param {Function} fun_hdtl  - function(hd,tl)
     * @param {Function} [fun_empty] - function()
     */
    match: function(array,fun_hdtl,fun_empty) {
        if (array.length == 0) {
            if (fun_empty) fun_empty();
        } else if (array.length>1) {
            var hd = this.head(array);
            var tl = this.tail(array);
            fun_hdtl(hd,tl);
        } else fun_hdtl(this.head(array),[]);
    },
    /**
     *
     * @param {* []} array
     * @param {Function} fun_hd1hd2  - function(hd1,hd2)
     * @param {Function} [fun_hdtl]  - function(hd,tl)
     * @param {Function} [fun_empty] - function()
     */
    match2: function(array,fun_hd1hd2,fun_hdtl,fun_empty) {
        if (array.length == 0 && fun_empty)
            fun_empty();
        else if (array.length == 2) {
            var hd1 = this.head(array);
            var hd2 = this.second(array);
            fun_hd1hd2(hd1,hd2);
        }
        else if (array.length>1 && fun_hdtl) {
            var hd = this.head(array);
            var tl = this.tail(array);
            fun_hdtl(hd,tl);
        } else if (fun_hdtl) fun_hdtl(this.head(array),[]);
    },
    /** Return the maximum element of an array applying
     *  an optional mapping function.
     *
     * @param {* []} array
     * @param [fun]
     * @returns {number|undefined}
     */
    max : function (array,fun) {        
        var res,max,num;
        for(var i in array) {
            if (fun) num=fun(array[i],i); else num=array[i];
            if (max==undefined) { max=num; res=array[i] } 
            else if (num > max) { max=num; res=array[i] }
        }
        return res;
    },
    /** Return the minimum element of an array applying
     *  an optional mapping function.
     *
     * @param {* []} array
     * @param [fun]
     * @returns {number|undefined}
     */
    min : function (array,fun) {        
        var res,min,num;
        for(var i in array) {
            if (fun) num=fun(array[i],i); else num=array[i];
            if (min==undefined) { min=num; res=array[i] }
            else if (num < min) { min=num; res=array[i] }
        }
        return res;
    },
    /** Check for an element in the array.
     *
     * @param {(number|string|boolean) []} array
     * @param {number|string|boolean} element
     * @returns {boolean}
     */
    member: function(array,element) {
        var i,exist;
        var len=array.length;
        exist=false;
        loop: for(i=0;i<len;i++) {
            var _element=array[i];
            if (_element==element) {
                exist=true;
                break loop;
            }
        }
        return exist;
    },
    /** Merge all arrays and return a new array.
     *
     * @param {Array} array1
     * @param {Array} array2
     * @param {Array} [array3]
     * @param {Array} [array4]
     * @returns {Array}
     */
    merge: function(array1,array2,array3,array4) {
        var arraynew=array1.slice();
        arraynew=arraynew.concat(array2);
        if (array3!=undefined) arraynew=arraynew.concat(array3);
        if (array4!=undefined) arraynew=arraynew.concat(array4);
        return arraynew;
    },
    /** Return the next element from array after val (next element after last is first!)
     * @param {Array} array
     * @param {number|string} val
     * @returns {number|string}
     */
    next: function(array,val) {
        var i;
        var len=array.length;
        if (obj.isString(val))
          for(i=0;i<len;i++) {
            if (string.equal(array[i],val)) {
              if (i==len-1) return array[0];
              else return array[i+1];
            }
          }
        else
          for(i=0;i<len;i++) {
            if (array[i]==val) {
              if (i==len-1) return array[0];
              else return array[i+1];
            }
          }
          
        return none;
    },
    /** Evaluate a function returning a boolean value for each member of the array and
     *  compute the boolean disjunction.
     *
     * @param {* []} array
     * @param {function(*,number)} fun
     */
    or: function(array,fun) {
        var res=false;
        var i=0;
        var len=array.length;
        for(i=0;i<len;i++) {
            var element=array[i];
            res=res||fun(element,i)
        }
        return res;
    },
    
   /**
     * Gets the property value of `key` from all elements in `collection`.
     *
     * var users = [
     *   { 'user': 'barney', 'age': 36 },
     *   { 'user': 'fred',   'age': 40 }
     * ];
     *
     * pluck(users, 'user');
     * // => ['barney', 'fred']
     */
    pluck: function(collection, key) {
      return collection.map(function(object) {
          return object == null ? undefined : object[key];
        });
    },
    /*
     ** Push/pop head elements (Stack behaviour)
     */
    /** Remove and return top element of array.
     *
     * @param array
     * @returns {*}
     */
    pop : function(array) {
        var element=array[0];
        array.shift();
        return element;
    },
    print: function(array) {
        var i;
        var len=array.length;
        var str='[';
        for(i=0;i<len;i++) {
            var cell=array[i];
            str=str+cell;
        }
        return str+']';
    },
    /** Add new element at top of array.
     *
     * @param array
     * @param element
     */
    push : function(array,element) {
        array.unshift(element);
    },
    /** Create an ordered array of numbers {a,a+1,..b}
     *
     * @param a
     * @param b
     * @returns {Array}
     */
    range : function(a,b) {
        var i;
        var array=[];
        for(i=a;i<=b;i++) array.push(i);
        return array;
    },
    /** Remove elements from an array.
     *  [1,2,3,4,5,6] (begin=2,end=4) => [1,2,6]
     * @param {* []} array
     * @returns {* []}
     */
    remove: function(array,begin,end) {
      var i,a;
      if (end==undefined) end=begin+1;
      if (begin<0 || end >= array.length) return [];
      a=array.slice(0,begin);
      for(i=end;i<array.length;i++) a.push(array[i]);
      return a;
    },
    
    second : function(array) {
        return array[1];
    },
    /**
     *
     * @param {* []} array
     * @param {function(*,*):number} fun   (1:a gt. b by the ordering criterion,-1: a lt. b, 0: a eq. b)
     * @returns {* []}
     */
    sort: function(array,fun) {
        var array2=array.slice();
        array2.sort(fun);
        return array2;
    },
    /** Split an array at position 'pos', i.e., remove 'len' (1) elements starting at 
     *  position 'pos'.
     *  ==> use remove!!! split should return two arrays!!
     *
     * @param array
     * @param pos
     * @param [len]
     * @param element
     */    
    split: function(array,pos,len) {
      if (pos==0) return array.slice((len||1));
      else {
        var a1=array.slice(0,pos);
        var a2=array.slice(pos+(len||1));
        return a1.concat(a2);
      }
    },
    /** Return the sum number of an array applying
     *  an optional mapping function.
     *
     * @param {* []} array
     * @param [fun]
     * @returns {number|undefined}
     */
    sum : function (array,fun) {        
        var res=0;
        for(var i in array) {
            var num=0;
            if (fun) num=fun(array[i]); else num=array[i];
            if (!obj.isNumber(num)) return undefined;
            res += num;
        }
        return res;
    },
    /** Return a new array w/o the head element (or optional 
     *  w/o the first top elements).
     *
     */
    tail : function(array,top) {
        var array2=array.slice();
        array2.shift();
        if (top) for(;top>1;top--) array2.shift();
        return array2;
    },
    /** Return union of two sets (== conjunction set)
     *
     * @param {* []} set1 
     * @param {* []} set2
     * @param {function} [fun]  Equality test
     * @returns {* []}
     */
    union : function(set1,set2,fun) {
        var i,j,res = [];
        for (i in set1) {
          for (j in set2) {
            if (fun != undefined && fun(set1[i],set2[j])) res.push(set1[i]);
            else if (fun == undefined && set1[i]==set2[j]) res.push(set1[i]);
          }
        }
        return res;
    },
    
    /**
     * Creates a duplicate-free version of an array
     */
    unique: function(array) {
      var length = array ? array.length : 0;
      function baseUniq(array) {
        var index = -1,
            length = array.length,
            seen,
            result = [];

        seen = result;
        outer:
        while (++index < length) {
          var value = array[index];
          var seenIndex = seen.length;
          while (seenIndex--) {
            if (seen[seenIndex] === value) {
              continue outer;
            }
          }
          result.push(value);
        }
        return result;
      }
      if (!length) {
        return [];
      }
      return baseUniq(array);
    },
    
    /**
     * Creates an array excluding all provided values
     * without([1, 2, 1, 3], 1, 2);
     * // => [3]
     */
    without: function () {
      var array,
          values=[];
      for(var i in arguments) {
        if (i==0) array=arguments[0];
        else values.push(arguments[i]);
      }
      return array.filter(function (e) {
        return values.indexOf(e) == -1;
      });
    },
    /** Test for zero elements {0, '', false, undefined, ..}
    */
    zero: function (array) {
      for(var i in array) if (!!array[i]) return false;
      return true;
    },
};

/** STRING
 *
 */
var string = {
    /** Is pattern conatined in template?
     *
     */
    contains: function (template,pattern) {
      return template.indexOf(pattern)>-1;
    },
    copy: function(src) {
        var i;
        var dst='';
        for(i=0;i<src.length;i++) dst=dst+src.charAt(i);
        return dst;
    },
    /**
     *
     * @param {number} size
     * @returns {string} filled with spaces
     */
    create: function(size)
    {
        var i;
        var s='';
        var init=' ';
        for(i=0;i<size;i++) s=s+init;
        return s;
    },
    endsWith : function (str,tail) {
        return str.indexOf(tail)==(str.length-tail.length);
    },
    empty: function (str) {
      return this.equal(str,'');
    },
    equal:  function(str1,str2) {
        var i;
        var eq=true;
        if (str1.length != str2.length) return false;
        for(i=0;i<str1.length;i++) { if (string.get(str1,i)!=string.get(str2,i)) eq=false;}
        return eq;
    },
    find: function (search,str) {
        return str.indexOf(search);
    },
    format_hex: function (n,len) {
        // format a hexadecimal number with 'len' figures.
        switch (len) {
            case 2: return (((n>>4) & 0xf).toString(16))+
                            ((n&0xf).toString(16));
            case 4: return (((n>>12) & 0xf).toString(16)+
                            ((n>>8) & 0xf).toString(16)+
                            ((n>>4) & 0xf).toString(16)+
                            (n&0xf).toString(16));
            case 6: return (((n>>20) & 0xf).toString(16)+
                            ((n>>16) & 0xf).toString(16)+
                            ((n>>12) & 0xf).toString(16)+
                            ((n>>8) & 0xf).toString(16)+
                            ((n>>4) & 0xf).toString(16)+
                            (n&0xf).toString(16));
            case 8: return (((n>>28) & 0xf).toString(16)+
                            ((n>>24) & 0xf).toString(16)+
                            ((n>>20) & 0xf).toString(16)+
                            ((n>>16) & 0xf).toString(16)+
                            ((n>>12) & 0xf).toString(16)+
                            ((n>>8) & 0xf).toString(16)+
                            ((n>>4) & 0xf).toString(16)+
                            (n&0xf).toString(16));
            default: return 'format_hex??';
        }
    },
    /**
     *
     * @param {string} str
     * @param {number} index
     * @returns {string}
     */
    get: function (str,index) {
        assert((str != undefined && index < str.length && index >= 0)||('string.get ('+str.length+')'));
        return str.charAt(index);
    },
    isBoolean: function (str) {
        return (str=='true' || str=='false')
    },
    isNumeric: function (str) {
        return !isNaN(parseFloat(str)) && isFinite(str);
    },
    isText: function (s) {
      var is_text=true;
      string.iter(s,function (ch,i) {
        string.match(ch,[
          ['a','z',function () {}],
          ['A','Z',function () {}],
          ['0','9',function () {if (i==0) is_text=false;}],
          function () {is_text=false;}
        ]);
      });
      return is_text;
    },
    /**
     *
     * @param {string} str
     * @param {function(string,number)} fun
     */
    iter: function(str,fun) {
        var i;
        var len=str.length;
        for (i = 0; i < len; i++)  {
            var c = str.charAt(i);
            fun(c,i);
        }
    },
    /**
     *
     * @param str
     * @returns {*}
     */
    length: function(str) {
        if (str!=undefined) return str.length;
        else return 0;
    },
    /**
     *
     * @param str
     * @returns {string}
     */
    lowercase : function (str) {
        return str.toLowerCase();
    },
    /**
     *
     * @param {number} size
     * @param {string} init
     * @returns {string}
     */
    make: function(size,init)
    {
        var i;
        var s='';
        for(i=0;i<size;i++) s=s+init;
        return s;
    },
    /** Map a string with a set of (test,reuslt) transformation rules.
     * 
     * @param {string} str
     * @param {* [] []} case - ([string,string] | fun) []
     */
    map: function(str,mapping) {
        var i;
        var map;
        for(i in mapping) {
            map=mapping[i];
            if (obj.isFunction(map)) return map(str);
            else if (this.equal(str,map[0])) return map[1];
        }          
    },
    /** Match a string with different patterns and apply a matching function.
     *
     * @param {string} str
     * @param {* [] []} cases - ([string,fun] | [string [<case1>,<case2>,..],fun] | [<range1>:string,<range2>:string,fun] | fun) []
     */
    match: function(str,cases) {
        var i,j;
        var cas,cex,cv;
        for(i in cases) {
            cas=cases[i];
            if (obj.isArray(cas)) {
              switch (cas.length) {
                case 2:
                  // Multi-value-case
                  cex=cas[0];
                  if (!obj.isArray(cex)) {
                      if (this.equal(str,cex)) {
                          cas[1]();
                          return;
                      }
                  } else {
                      for(j in cex) {
                          cv=cex[j];
                          if (this.equal(str,cv)) {
                              cas[1]();
                              return;
                          }
                      }
                  }
                  break;
                case 3:
                  // Character range check
                  try {
                    j=pervasives.int_of_char(str);
                    if (j>= pervasives.int_of_char(cas[0]) && j<=pervasives.int_of_char(cas[1])) {
                      cas[2](str);
                      return;
                    }
                  } catch(e) {
                    return
                  };
                  break;
                case 1:
                  cas[0](str); // Default case - obsolete
                  return;
                default: 
                  throw 'String.match #args';
              }
            } else if (obj.isFunction(cas)) {
                // Default case
                cas(str);
                return;
            }
        }
    },
    /** Pad a string on the left (pre-str.length) if pre>0,
     *  right (post-str.length) if post>0, or centered (pre>0&post>0).
     *
     */
     
    pad: function (str,pre,post,char) {
      var len = str.length;
      if (pre>0 && post==0) return string.make(len-pre,char||' ')+str;
      else if (post>0 && pre==0) return str+string.make(post-len,char||' ');
      else return string.make(len-pre/2,char||' ')+str+string.make(len-post/2,char||' ');
    },
    /**
     *
     * @param str
     * @param pos
     * @param len
     * @returns {Number}
     */
    parse_hex: function (str,pos,len) {
        // parse a hexadecimal number in string 'str' starting at position 'pos' with 'len' figures.
        return parseInt(this.sub(str,pos,len),16);
    },
    /** Return the sub-string after a point in the source string ('.' or optional point string).
     * If there is no splitting point, the original string is returned.
     *
     * @param str
     * @param [point]
     * @returns {string}
     */
    postfix: function (str,point) {
      var n = str.indexOf(point||'.');
        if (n <= 0) return str;
        else return str.substr(n+1);
    },
    /** Return the sub-string before a point in the source string ('.' or optional point string)
     * If there is no splitting point, the original string is returned.
     *
     * @param str
     * @param [point]
     * @returns {string}
     */
    prefix: function (str,point) {
        var n = str.indexOf(point||'.');
        if (n <= 0) return str;
        else return str.substr(0,n);
    },
    replace_first: function (pat,repl,str) {
        return str.replace(pat,repl);
    },
    replace_all: function (pat,repl,str) {
        return str.replace('/'+pat+'/g',repl);
    },
    /**
     *
     * @param str
     * @param index
     * @param char
     * @returns {string}
     */
    set: function (str,index,char) {
        assert((str != undefined && index < str.length && index >= 0)||'string.get');
        return str.substr(0, index) + char + str.substr(index+1)
    },
    /**
     *
     * @param delim
     * @param str
     * @returns {*|Array}
     */
    split: function (delim,str) {
        return str.split(delim);
    },
    startsWith : function (str,head) {
        return !str.indexOf(head);
    },
    /** Return a sub-string.
     * 
     * @param str
     * @param off
     * @param [len] If not give, return a sub-string from off to end
     * @returns {string}
     */
    sub: function (str,off,len) {
        if (len)
            return str.substr(off,len);
        else
            return str.substr(off);
    },
    /** Remove leading and trailing characters from string
     *
     * @param str
     * @param {number} pref number of head characters to remove
     * @param {number} post number of tail characters to remove
     * @returns {*}
     */
    trim: function (str,pref,post) {
        if (str.length==0 ||
            pref>str.length ||
            post>str.length ||
            pref < 0 || post < 0 ||
            (pref==0 && post==0)
        ) return str;
        return str.substr(pref,str.length-pref-post);
    },
    /** Return a string with all characters converted to uppercase letters.
     *
     * @param str
     * @returns {string}
     */
    uppercase : function (str) {
        return str.toUpperCase();
    },
    /** Return a string with first character converted to uppercase letter.
     *
     * @param str
     * @returns {string}
     */
    Uppercase : function (str) {
        var len = str.length;
        if (len > 1) {
            var head = str.substr(0,1);
            var tail = str.substr(1,len-1);
            return head.toUpperCase()+tail.toLowerCase()
        } if (len==1) return str.toUpperCase();
        else return '';
    }
};

/** RANDOM
 *
 */
var rnd = Math.random;
/* Antti Syk�ri's algorithm adapted from Wikipedia MWC
** Returns a random generator function [0.0,1.0| with seed initialization
*/
var seeder = function(s) {
    var m_w  = s;
    var m_z  = 987654321;
    var mask = 0xffffffff;

    return function() {
      m_z = (36969 * (m_z & 65535) + (m_z >> 16)) & mask;
      m_w = (18000 * (m_w & 65535) + (m_w >> 16)) & mask;

      var result = ((m_z << 16) + m_w) & mask;
      result /= 4294967296;

      return result + 0.5;
    }
}
 
var random = {
    float: function(max) {
        return rnd()*max
    }, 
    int: function(max) {
        return Math.floor(rnd()*max+0)
    },
    // integer
    interval: function(min,max) {
        return Math.round(min+rnd()*(max-min))
    },
    // float
    range: function(min,max) {
        return min+rnd()*(max-min)
    },
    seed: function (s) {
      // Create a new initialized random generator
      rnd=seeder(s);
    }
};

/** PRINTF
 *
 */
var printf = {
    /** Trim string(s).
     *
     * @param str
     * @param indent
     * @param [width]
     * @param {string} [tab]
     * @returns {string}
     */
    align: function (str,indent,width,tab) {
        var lines = string.split('\n',str);
        var form = '';
        var sp = printf.spaces(indent);
        var spbreak = sp;

        array.iter(lines,function(line){
            var rest;
            function breakit(spbreak,str) {
                if (width < (str.length + spbreak.length)) {
                    return spbreak+string.sub(str,0,width-spbreak.length)+'\n'+
                           breakit(spbreak,string.sub(str,width-spbreak.length,str.length-width+spbreak.length));
                } else return spbreak+str+'\n';
            }
            if (width && width < (line.length + indent)) {
                if (tab) {
                    var pos = string.find(tab,line);
                    if (pos > 0 && pos < width) spbreak=printf.spaces(pos+indent+1);
                    else spbreak=sp;
                }
                form=form+sp+string.sub(line,0,width-indent)+'\n';
                rest=string.sub(line,width-indent,line.length-width+indent);
                form=form+breakit(spbreak,rest);
            }
            else
                form=form+sp+line+'\n';
        });
        return form;
    },
    /** Format a list of array elements using the (optional) mapping
     *  function <fun> and the separator <sep> (optional, too, default is ',').
     * 
     */
    list: function (array,fun,sep) {
      var i, str='';
      if (sep==undefined) sep=',';
      if (fun==undefined) fun=function (s) {return s;};
      if (!obj.isArray(array)) array=[array];
      for (i in array) {
        if (str==='') str=fun(array[i]);
        else str=str+sep+fun(array[i]);
      }
      return str;
    },
    /**
     *
     * @param n
     * @returns {string}
     */
    spaces: function (n){
        return string.make(n,' ');
    },
    /** Formatted printer (simplified)
     *
     * @param {* []} args (['%format',arg]|string) []  format=%s,%d,%f,%c,%x,%#d,%#s,..
     * @returns {string}
     */
    sprintf2: function(args) {
        var str='';
        array.iter(args,function(fmtarg) {
            var len, n,fs;
            if (obj.isArray(fmtarg)) {
                if (fmtarg.length==2) {
                    var fmt=fmtarg[0];
                    var arg=fmtarg[1];
                    var fc='';
                    var fn=0;
                    string.iter(fmt,function(c) {
                        if (c=='s' || c=='d' || c=='f' || c=='x') {
                            fc=c;
                        } else if (c!='%') {
                            fn=fn*10;
                            n=parseInt(c);
                            if (!isNaN(n)) fn=fn+n;
                        }
                    });
                    if (fc=='s' && obj.isString(arg)) {
                        str=str+arg;
                        if (fn!=0) {
                            len=arg.length;
                            if (len<fn) str=str+string.create(fn-len);
                        }
                    } else if (fc=='d' && obj.isNumber(arg)) {
                        fs = pervasives.string_of_int(arg);
                        if (fn!=0) {
                            len = fs.length;
                            if (len < fn) {
                                str=str+string.create(fn-len);
                            }
                        }
                        str=str+fs;
                    } else if (fc=='x' && obj.isNumber(arg)) {
                        fs = string.format_hex(arg,fn||8);
                        str=str+fs;
                    }
                }
            } else if (obj.isString(fmtarg)) {
                str = str + fmtarg;
            }
        });
        return str;
    },
    sprintf:Sprintf.sprintf
};

/** FILENAME
 *
 */
var filename = {
    /**
     *
     * @param path
     * @returns {string}
     */
    basename : function (path) {
        return Path.basename(path);
    },
    /**
     *
     * @param path
     * @returns {string}
     */
    dirname : function (path) {
        return Path.dirname(path);
    },
    /**
     *
     * @param path
     * @returns {string}
     */
    extname : function (path) {
        return Path.extname(path)
    },
    /**
     *
     * @param path
     * @returns {boolean}
     */
    is_relative: function(path) {
        return !(path.length > 0 && path[0] == '/');
    },
    /**
     *
     * @param pathl
     * @param absolute
     * @returns {string}
     */
    join: function (pathl,absolute) {
        var path=(absolute?'/':'');
        array.iter(pathl,function (name,index) {
            if (index>0) {
                path=path+'/'+name;
            }
            else {
                path=path+name;
            }
        });
        return path;
    },
    /**
     *
     * @param path
     * @returns {string}
     */
    normalize : function (path) {
        return Path.normalize(path)
    },
    /**
     *
     * @param path
     * @returns {*}
     */
    path_absolute: function (path) {
        if (this.is_relative(path)) {
            var workdir = Io.workdir();
            return this.path_normalize(workdir + '/' + path);
        } else return this.path_normalize(path);
    },
    /** Duplicate of Path.normalize!?
     *
     * @param path
     * @returns {string}
     */
    path_normalize: function (path) {
        var i;
        if (string.equal(path, '')) path = '/';
        var relpath = !(string.get(path, 0) == '/');
        var pathlist = path.split('/');
        var pathlist2 = pathlist.filter(function (s) {
            return (!string.equal(s, '') && !string.equal(s, '.'))
        });
        var pathlist3 = [];
        array.iter(pathlist2, function (pe) {
            if (!string.equal(pe, '..')) {
                array.push(pathlist3, pe)
            } else {
                if (pathlist3.length == 0) return '';
                else
                    pathlist3 = array.tail(pathlist3);
            }
        });
        var path2 = '';
        i = 0;
        array.iter(pathlist3, function (pe) {
            var sep;
            if (i == 0) sep = ''; else sep = '/';
            path2 = pe + sep + path2;
            i++;
        });
        if (relpath) return path2; else return '/' + path2;
    },
    removeext: function (path) {
      return path.substr(0, path.lastIndexOf('.'));
    }
};

/** PERVASIVES
 *
 *
 */
var pervasives = {
    assert:assert,
    char_of_int: function (i) {return String.fromCharCode(i)},
    div: function(a,b) {return a/b|0;},
    failwith: function(msg) {Io.err(msg);},
    float_of_string: function(s) {var num=parseFloat(s); if (isNaN(num)) throw 'NaN'; else return num;},
    int_of_char: function(c) {return c.charCodeAt()},
    int_of_float: function(f) {return f|0;},
    int_of_string: function(s) {      
      var num=parseInt(s); if (isNaN(num)) throw 'NaN'; else return num;
    },

    /** Try to find a value in a search list and return a mapping value.
     *
     * @param {*} value
     * @param {* []} mapping [testval,mapval] []
     * @returns {*}
     */
    map: function(value,mapping) {
        function eq(v1,v2) {
            if (v1==v2) return true;
            if (obj.isString(v1) && obj.isString(v2)) return string.equal(v1,v2);
            return false;
        }
        if (!array.empty(mapping)) {
          var hd=array.head(mapping);
          var tl=array.tail(mapping);
          if (eq(hd[0],value)) return hd[1];
          else return pervasives.map(value,tl);
        }  else return undefined;
    },
    /** Apply a matcher function to a list of cases with case handler functions.
     * A case is matched if the matcher function returns a value/object.
     *
     * The result of the matcher function is passed as an argument ot the case handler function.
     * The return value of the case handler fucntion is finally returned by this match function
     * or undefined if there was no matching case.
     *
     * @param {function(*,*):*} matcher function(expr,pat)
     * @param {*} expr
     * @param {*[]} cases (pattern,handler function | handler function) []
     * @returns {*|undefined}
     */
    match: function (matcher,expr,cases) {
        var ret = undefined;
        array.iter_break(cases, function (match) {
            var quit, succ, pat, fun;

            if (match.length == 2) {
                /*
                 ** Pattern, Function
                 */
                pat = match[0];
                fun = match[1];
                succ = matcher(expr, pat);
                if (succ) ret = fun(succ);
                quit = succ!=undefined;
            } else if (match.length == 1) {
                /*
                 ** Default case, Function
                 */
                fun = match[0];
                ret = fun();
                quit= true;
            }
            return quit;
        });
        return ret;
    },
    mtime: function () {var time = new Date(); return time.getTime();},
    min: function(a,b) { return (a<b)?a:b},
    max: function(a,b) { return (a>b)?a:b},
    string_of_float: function(f) {return f.toString()},
    string_of_int: function(i) {return i.toString()},
    string_of_int64: function(i) {return i.toString()},
    time: function () {var time = new Date(); return (time.getTime()/1000)|0;}
};

/** BIT
 *
 */
var bit = {
    get: function (v,b) {return (v >> b) && 1;},
    isSet: function (v,b) {return ((v >> b) && 1)==1;},
    set: function (v,b) {return v & (1 << b);}
};

/** ARGS
 *
 */
var args = {
    /** Parse process or command line arguments (array argv). The first offset [1] arguments are
     ** ignored. The numarg pattern '*' consumes all remaining arguments.
     *
     * @param {string []} argv
     * @param {*[]} map  [<argname>,<numargs:0..3|'*'>,<handler(up to 3 arguments|[])>]|[<defhandler(val)>] []
     * @param {number} [offset]
     */
    parse: function(argv,map,offset) {
        var shift=undefined,
            in_shift=0,
            shift_args=[],
            names,
            mapfun,
            numarg,
            len=argv.length;

        if (offset==undefined) offset=1;

        argv.forEach(function (val, index) {
            var last=index==(len-1);
            if(index>=offset) {
                if (in_shift==0) {
                    array.check(map,function (onemap) {
                        assert(onemap!=undefined||'map');
                        if (onemap.length==3) {
                            names  = onemap[0];
                            numarg = onemap[1];
                            mapfun = onemap[2];
                            if (!obj.isArray(names)) names=[names];
                            var found = array.find(names,function (name) {
                                if (string.equal(val, name)) return name; else _;
                            });
                            if (found) {
                                if (numarg==0) mapfun(found);
                                else {
                                    in_shift=numarg;
                                    shift_args=[];
                                    shift=mapfun;
                                }
                                return true;
                            }
                        } else if (obj.isFunction(onemap)) {
                          onemap(val);
                          return true;                        
                        } else if (onemap.length==1) {
                            mapfun = onemap[0];
                            mapfun(val);
                            return true;
                        }
                        return false;
                    });
                } else {
                    shift_args.push(val);
                    if (in_shift!='*') in_shift--;
                    if (in_shift==0 && shift!=undefined) {
                        numarg=shift_args.length;
                        switch (numarg) {
                            case 0: shift(val);break;
                            case 1: shift(shift_args[0],val); break;
                            case 2: shift(shift_args[0],shift_args[1],val); break;
                            case 3: shift(shift_args[0],shift_args[1],shift_args[2],val); break;
                            default: break;
                        }
                        shift=undefined;
                    } else if (in_shift=='*' && last) shift(shift_args);
                }
            }
        });
    }

};

/** HASHTBL
 *
 */
var hashtbl = {
    add: function(hash,key,data) {
        hash[key]=data;
    },
    create: function(initial) {
        return [];
    },
    empty: function(hash) {
        for (var key in hash) return false;
        return true;
    },
    find: function(hash,key) {
        return hash[key];
    },
    invalidate: function(hash,key) {
        hash[key]=undefined;
    },
    iter: function(hash,fun) {
        for (var key in hash) {
            if (hash[key]!=undefined) fun(key,hash[key]);
        }
    },
    mem: function(hash,key) {
        return hash[key] != undefined;
    },
    remove: function(hash,key) {
        // TODO: check, its wrong!
        if (!hash.hasOwnProperty(key))
            return;
        if (isNaN(parseInt(key)) || !(hash instanceof Array))
            delete hash[key];
        else
            hash.splice(key, 1)
    }
};

var types = [];
/**
 * 
 * @param name
 * @returns {number}
 */
function register_type(name) {
    var typoff = 1000+types.length*1000;
    if (array.member(types,name)) throw('[COMP] register_type: type '+name+' exists already.');
    types.push(name);
    return typoff;
}

/**
 *
 * @typedef {{v1:*, v2:*, v3:*, v4:*, v5:*, v6:*, v7:*, v8:*, v9:*  }} tuple
 */
/**
 *
 * @typedef {{t:number, v1:*, v2:*, v3:*, v4:*, v5:*, v6:*, v7:*, v8:*, v9:*  }} tagged_tuple
 */

module.exports = {
    args:args,
    assert: assert,
    array:array,
    bit:bit,
    defineGetter : defineGetter,
    defineSetter : defineSetter,
    div:pervasives.div,
    filename:filename,
    hashtbl:hashtbl,
    inherit : inherit,
    inheritPrototype : inheritPrototype,
    instanceOf : instanceOf,
    isNodeJS: function () {
        return (typeof global !== "undefined" &&
                {}.toString.call(global) == '[object global]');
    },
    obj:obj,
    pervasives:pervasives,
    printf:printf,
    random:random,
    string:string,
    isArray: obj.isArray,
    isString: obj.isString,
    isNumber: obj.isNumber,

    register_type:register_type,
    /**
     *
     * @param tag
     * @param [val1]
     * @param [val2]
     * @param [val3]
     * @returns {(tagged_tuple)}
     */
    Tuple: function (tag,val1,val2,val3) {
        if(val3) return {t:tag,v1:val1,v2:val2,v3:val3};
        else if (val2) return {t:tag,v1:val1,v2:val2};
        else if (val1) return {t:tag,v1:val1};
        else return {t:tag};
    }
};
};
BundleModuleCode['plugins/ml/ice']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Ankit Kuwadekar, Stefan Bosse
 **    $INITIAL:     (C) 2014, Ankit Kuwadekar
 **    $MODIFIED:    (C) 2006-2018 bLAB by sbosse
 **    $VERSION:     1.3.2X
 **
 **    $INFO:
 **
 ** ICE: C45/ID3 Decision Tree Algorithm supporting feature variables with eps intervals
 **
 ** Portable model
 **
 ** New:
 **        typeof eps = number | [epsx1:number,epsx2:number,..]
 **
 **    $ENDOFINFO
 */
var Io = Require('com/io');
var Comp = Require('com/compat');
var current=none;
var Aios=none;
var that;
var _ = undefined;
var none = null;

/**
 * Map of valid tree node types
 * @constant
 * @static
 */
var NODE_TYPES = {
  RESULT: 'result',
  FEATURE: 'feature',
  FEATURE_VALUE: 'feature_value'
};

var NL ='\n'

/**
 * Creates a new tree
 */
function createTree(data, target, features, eps) {
  var ml = that.ml;

  var targets = ml.stats.unique(ml.stats.utils.column(data, target));
  if (targets.length == 1) {
    return {
      type: NODE_TYPES.RESULT,
      name: targets[0],
    };
  }

  if (features.length == 0) {
    var topTarget = ml.stats.mostCommon(targets);
    return {
      type: NODE_TYPES.RESULT,
      name: topTarget,
    };
  }

  
  var split = ml.stats.splitEps(data,features,target,targets,eps);
  var bestFeature = split.feature;
  var index = features.indexOf(bestFeature);
  var remainingFeatures = split.remainingFeatures;
  var remainingEps = 
    typeof eps == 'number'?eps:remainingFeatures.map(function (v) { return eps[features.indexOf(v)] });
  var possibleValues = split.possibleValues;

  var node = {
    type: NODE_TYPES.FEATURE,
    name: bestFeature,
    index: index,
    eps: that.ml.stats.utils.selectEps(eps,index)
  };

  node.vals = split.choices.map(function (c) {
    var child_node = {
      val : c.val,
      eps : that.ml.stats.utils.selectEps(eps,index),
      type: NODE_TYPES.FEATURE_VALUE
    };

    child_node.child = createTree(c.data, target, remainingFeatures, remainingEps);
    return child_node;
    
  })
  return node;
}


function depth(model) {
  switch (model.type) {
    case NODE_TYPES.RESULT: return 1;
    case NODE_TYPES.FEATURE: 
      return 1+Comp.array.max(model.vals.map(function (val) {
        return depth(val);
      }));
    case NODE_TYPES.FEATURE_VALUE: 
      return 1+depth(model.child);   
  }
  return 0;
}

function info(model) {
  var vl = vars(model);
  return {
    depth:depth(model),
    nodes:vl.length,
    vars:vl.unique(),
  }
}

function predictEps(model,sample,prob,eps) {
  var root = model;
  if (!prob) prob=1;
  while (root.type !== NODE_TYPES.RESULT) {
    var attr = root.name;
    var sampleVal = sample[attr];
    // kNN approximation
    var childNode = null;
    root.vals.forEach(function(node) {
      var fit=Math.abs(node.val-sampleVal);
      if (!childNode || fit < childNode.fit) childNode={fit:fit,node:node};
    });
    if (childNode){
      // with fit quality propagation
      prob = prob * (1-Math.abs(childNode.fit/that.ml.stats.utils.selectEps(eps,root.index))/4) 
      root = childNode.node.child;
    } else {
      root = root.vals[0].child;
    }
  }
  return {value:root.name,prob:prob};
};


function printModel(model,indent) {
  var line='',sep;
  if (indent==undefined) indent=0;
  if (!model) return '';
  var sp = function () {var s=''; for(var i=0;i<indent;i++) s+=' '; return s};
  switch (model.type) {
    case NODE_TYPES.RESULT: 
      return sp()+'-> '+model.name+NL;
    case NODE_TYPES.FEATURE:
      line=sp()+'$'+model.name+'?'+NL;
      model.vals.forEach(function (v) {
        line += printModel(v,indent+2);
      }); 
      return line;
    case NODE_TYPES.FEATURE_VALUE: 
      line=sp()+'=['+(model.val-model.eps)+','+(model.val+model.eps)+']'+NL;
      return line+printModel(model.child,indent+2); 
  }
  return 'model?';
}

function vars(model) {
  switch (model.type) {
    case NODE_TYPES.RESULT: return [];
    case NODE_TYPES.FEATURE: 
      return [model.name].concat(Comp.array.flatten(model.vals.map(vars)));
    case NODE_TYPES.FEATURE_VALUE: 
      return vars(model.child);   
  }
  return [];
}

that = module.exports = {
  create: function (options) {
    return createTree(options.data,
                      options.target,
                      options.features,
                      options.eps)
  },
  depth:depth,
  info:info,
  ml:{},
  predict:function (model,sample) {
    return predictEps(model,sample,1,model.eps)
  },
  print:printModel,
}
};
BundleModuleCode['plugins/ml/dti']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Stefan Bosse
 **    $INITIAL:     (C) 2006-2018 bLAB
 **    $CREATED:     03-03-16 by sbosse.
 **    $VERSION:     1.4.2X
 **
 **    $INFO:
 **
 ** Interval Decision Tree Learner
 **
 ** Modified ID3-based Decision Tree Algorithm that wraps all data with 2-eps intervals and uses
 ** interval instead single value arithmetic for entropy calculation and feature selection.
 ** The classification bases on a nearest-neighbourhood look-up of best matching results.
 **
 ** Two different algorithms are supported:
 **
 **   1. Static (using learn), the DTI learner using attribute selection based on entropy.
 **      The training data must be available in advance.
 **   2. Dynamic (using update), the DTI learrner using attribute selection based on significance.
 **      The training data is applied sequentielly (stream learning) updating the model.
 **
 **   Though in principle the both algrotihms can be mixed (first static, then dynamic updating), 
 **   the resulting model will have poor classification quality. Either use static or only dynamic
 **   (stream) learning.
 **   
 ** Portable model
 **
 **    $ENDOFINFO
 */
var Io = Require('com/io');
var Comp = Require('com/compat');
var current=none;
var Aios=none;
var min = Comp.pervasives.min;
var max = Comp.pervasives.max;
var _ = undefined;
var none = null;

/**
 * Map of valid tree node types
 * @constant
 * @static
 */
var NODE_TYPES = {
  RESULT: 'result',
  FEATURE: 'feature',
  FEATURE_VALUE: 'feature_value'
};


function Result(key) {
  return {
    type:NODE_TYPES.RESULT,
    name:key
  }
}

function Feature(name,vals) {
  return {
    type:NODE_TYPES.FEATURE,
    name:name,
    vals:vals
  }
}

// A value can be a scalar or a range {a,b} object
function Value(val,child) {
  return {
    type:NODE_TYPES.FEATURE_VALUE,
    val:val,
    child:child
  }
}

/** Add a new training set with optional data set merging and value interval expansion.
 * 
 */
function add_training_set(data,set,merge) {
  if (merge) {
    // Merge a data set with an existing for a specific key; create value ranges
  } else
    data.push(set);  
} 


/**
 * Computes Log with base-2
 * @private
 */
function log2(n) {
  return Math.log(n) / Math.log(2);
}




function results(model) {
  var line='',sep;
  if (!model) return '';
  switch (model.type) {
    case NODE_TYPES.RESULT: 
      return model.name;
    case NODE_TYPES.FEATURE:
      sep='';
      line='';
      Comp.array.iter(model.vals,function (v) {
        line += sep+results(v);
        sep=',';
      }); 
      return line;
    case NODE_TYPES.FEATURE_VALUE: 
      return results(model.child);   
  }
  return 'result?';
}


/**
 * Finds element with highest occurrence in a list
 * @private
 */
function mostCommon(list) {
  var elementFrequencyMap = {};
  var largestFrequency = -1;
  var mostCommonElement = null;

  list.forEach(function(element) {
    var elementFrequency = (elementFrequencyMap[element] || 0) + 1;
    elementFrequencyMap[element] = elementFrequency;

    if (largestFrequency < elementFrequency) {
      mostCommonElement = element;
      largestFrequency = elementFrequency;
    }
  });

  return mostCommonElement;
}

function addVal(v1,v2) {
  if (v1.a!=undefined) {
    if (v2.a!=undefined) return {a:v1.a+v2.a,b:v1.b+v2.b};
    else return {a:v1.a+v2,b:v2.b+v2};
  } else if (v2.a!=undefined) return {a:v2.a+v1,b:v2.b+v1};
  else return v1+v2;
}

function lowerBound(v) {
  if (v.a==undefined) return v; else return v.a;
}

function upperBound(v) {
  if (v.b==undefined) return v; else return v.b;
}

function equal(v1,v2) {
  return (v1==v2 ||
          (upperBound(v1) == upperBound(v2) &&
          (lowerBound(v1) == lowerBound(v2))))
}

function overlap(v1,v2) {
  return (upperBound(v1) >= lowerBound(v2) && upperBound(v1) <= upperBound(v2)) ||
         (upperBound(v2) >= lowerBound(v1) && upperBound(v2) <= upperBound(v1))
}

function containsVal(vl,v) {
  for (var i in vl) {
    var v2=vl[i];
    if (overlap(v,v2)) return true;
  }
  return false;
}

function centerVal(v) {
  if (v.a==undefined) return v; else return (v.a+v.b)/2;
}

function distanceVal (v1,v2) {
  return Math.abs(centerVal(v1)-centerVal(v2));
}

function Bounds(vl,v) {
  if (vl.length==0) return {a:v,b:v};
  else if (v==undefined) return {a:Min(vl),b:Max(vl)};
  else return {a:Min([Min(vl),v]),b:Max([Max(vl),v])};
}

function Min(vals) {
  var min=none;
  Comp.array.iter(vals, function (val) {
    if (min==none) min=(val.a==undefined?val:val.a);
    else min=val.a==undefined?(val<min?val:min):(val.a<min?val.a:min);
  });
  return min;
}

function Max(vals) {
  var max=none;
  Comp.array.iter(vals,function (val) {
    if (max==none) max=(val.b==undefined?val:val.b);
    else max=(val.b==undefined?(val>max?val:max):(val.b>max?val.a:max));
  });
  return max;
}

// Return interval of a value x with a<=x_center-eps, b>=x_center+eps
function epsVal(x,eps) {
  if (x.a == undefined) return {a:x-eps,b:x+eps};
  else if ((x.b-x.a) < 2*eps) return {a:centerVal(x)-eps,b:centerVal(x)+eps}; 
  else return x;
}
/** Filter out unique values that are spaced at least by eps
 *
 */
function uniqueEps(data,eps) {
  var results=[];
  Comp.array.iter(data,function (x) {
    var found;
    if (!results.length) results.push(x);
    else {
      Comp.array.iter(results,function (y,i) {
        if (found) return;
        found = Math.abs(centerVal(x)-centerVal(y))<eps;
        if (found) // create new overlapping value with +-eps extensions 
          results[i]={a:Min([x,y])-eps,b:Max([x,y])+eps}
      }); 
      if (!found) results.push(x);
    }
  });
  return results;
}

/** Compact tree, merge nodes and intervals.
 ** adjust=true: Adjust overlapping feature variable value intervals!!!
 */

function compactTree(model,adjust) {
  var i,j,vi,vj,_vals,merged;
  function target(model) {
    var line;
    switch (model.type) {
      case NODE_TYPES.RESULT: 
        return model.name;
      case NODE_TYPES.FEATURE:      
        line = model.name+'?'+target;
        Comp.array.iter(model.vals,function (v) {
          line += target(v);
        }); 
        return line;  
      case NODE_TYPES.FEATURE_VALUE: 
        line='='+(model.val.a==undefined?model.val:'['+model.val.a+','+model.val.b+']')+NL;
        return line+target(model.child); 
    }
  }
  if (!model) return model;
  switch (model.type) {
    case NODE_TYPES.RESULT: 
      return model;
      break;
    case NODE_TYPES.FEATURE:
      _vals=[];
      // 1. Merge
      for (i in model.vals) {
        vi=model.vals[i];
        assert((vi.type==NODE_TYPES.FEATURE_VALUE)||'vi.type==NODE_TYPES.FEATURE_VALUE');
        merged=false;
        loopj: for(j in _vals) {
          vj=_vals[j];
          if (target(vi.child)==target(vj.child)) {
            merged=true;
            vj.val={a:Min([vi.val,vj.val]),b:Max([vi.val,vj.val])}
            break loopj;
          }
        }
        if (!merged) {
          _vals.push(vi);
          vi.child=compactTree(vi.child);
        }
      }
      // 2. Adjust overlapping value intervals!
      if (adjust) {
        // TODO: approach too simple!!!! 
        for (i in _vals) {
          i=Comp.pervasives.int_of_string(i);
          if (_vals[i+1]) {
            if (upperBound(_vals[i].val) > lowerBound(_vals[i+1].val)) {
              if (_vals[i].val.b) _vals[i].val.b=lowerBound(_vals[i+1].val)-1;
              else _vals[i+1].val.a=upperBound(_vals[i].val)+1;
            }
          }
        }
      }
      
      model.vals=_vals;
      return model;
      break;
    case NODE_TYPES.FEATURE_VALUE:
      return model;
      break;
  }
}



/** Creates a new tree from training data (data)
 *
 *  data is {x1:v1,x2:v2,..,y:vn} []
 *  target is classification key name
 *  features is ['x1','x2,',..]  w/o target variable
 *  eps is interval applied to all data values
 *
 */
function createTree(data, target, features, options) {
  var _newS,child_node,bounds;
      
  var targets = Comp.array.unique(Comp.array.pluck(data, target));
  // console.log(targets)  
  if (options.maxdepth==undefined) options.maxdepth=1;
  if (options.maxdepth==0) return Result('-');
  // console.log(data);
  // console.log(features);

  //Aios.aios.log('createTree:'+targets.length);
  //try {Aios.aios.CP();} catch (e) {throw 'DTI.createTree: '+options.maxdepth };
  if (Aios) Aios.aios.CP();
  if (targets.length == 1) return Result(targets[0]);

  if (features.length == 0) {
    var topTarget = mostCommon(targets);
    return Result(topTarget)
  }
  var bestFeatures = getBestFeatures(data, target, features, options.eps);
  var bestFeature = bestFeatures[0];

  var remainingFeatures = Comp.array.filtermap(bestFeatures,function (feat) {
    if (feat.name!=bestFeature.name) return feat.name;
    else return none;
  });
/*  
  var possibleValues = Comp.array.sort(Comp.array.pluck(data, bestFeature.name), function (x,y) {
    if (upperBound(x) < lowerBound(y)) return -1; else return 1; // increasing value order
  });
*/
  var possibleValues = getPossibleVals(data,bestFeature.name);
  
  var vals=[];
  
  //console.log(bestFeatures);
  //console.log(possibleValues);
  var partitions=partitionVals(possibleValues,options.eps);
  // Aios.aios.log(partitions);
  //console.log(bestFeatures);
  //console.log(possibleValues);
  if (partitions.length==1) {
    // no further 2*eps separation possible, find best feature by largest distance
    // resort best feature list with respect to value deviation
    bestFeatures.sort(function (ef1,ef2) {
      if (ef1.d > ef2.d) return -1; else return 1;
    });
    bestFeature = bestFeatures[0];
    possibleValues = getPossibleVals(data,bestFeature.name);
    Comp.array.iter(mergeVals(possibleValues),function (val,i) {

      _newS = data.filter(function(x) {
        // console.log(x[bestFeature.name],val,overlap(val,x[bestFeature.name]))
        
        return overlap(val,x[bestFeature.name]);
      });
      child_node = Value(val);
      options.maxdepth--;
      child_node.child = createTree(_newS, target, remainingFeatures, options);
      //console.log(_newS);
      vals.push(child_node);
    })    
    
  } else Comp.array.iter(partitions,function (partition,i) {
    
    _newS = data.filter(function(x) {
      // console.log(x[bestFeature.name],v,overlap(x[bestFeature.name],v))
      return containsVal(partition,x[bestFeature.name]);
    });
    bounds = Bounds(partition);
    child_node = Value(options.eps==0?{a:bounds.a,b:bounds.b}:{a:bounds.a-options.eps,b:bounds.b+options.eps});
      options.maxdepth--;
    child_node.child = createTree(_newS, target, remainingFeatures, options);
    //console.log(_newS);
    vals.push(child_node);
  });
  
  return Feature(bestFeature.name,vals);
}

/** Return the depth of the tree
 *
 */
function depth(model) {
  switch (model.type) {
    case NODE_TYPES.RESULT: return 0;
    case NODE_TYPES.FEATURE: 
      return 1+Comp.array.max(model.vals,function (val) {
        return depth(val);
      });
    case NODE_TYPES.FEATURE_VALUE: 
      return depth(model.child);   
  }
  return 0;
}

/** Computes entropy of a list with 2-epsilon intervals
 *
 */

function entropyEps(vals,eps) {
  // TODO: overlapping value intervals
  var uniqueVals = Comp.array.unique(vals);
  var probs = uniqueVals.map(function(x) {
    return probEps(x, vals, eps)
  });

  var logVals = probs.map(function(p) {
    return -p * log2(p)
  });

  return logVals.reduce(function(a, b) {
    return a + b
  }, 0);
}

function entropyEps2(vals,eps) {
  // TODO: overlapping value intervals
  var uniqueVals = uniqueEps(vals,eps);
  var probs = uniqueVals.map(function(x) {
    return probEps2(x, vals, eps)
  });

  var logVals = probs.map(function(p) {
    return -p * log2(p)
  });

  return logVals.reduce(function(a, b) {
    return a + b
  }, 0);
}


function getBestFeatures(data,target,features,eps) {
  var bestfeatures=[];
  function deviation(vals) {
    var n = vals.length;
    var mu=Comp.array.sum(vals,function (val) {
      return (lowerBound(val)+upperBound(val))/2;
    })/n;
    var dev=Comp.array.sum(vals,function (val) {
      return Math.pow(((lowerBound(val)+upperBound(val))/2)-mu,2);
    })/n;
    return dev;
  }
  for (var feature in features) {
    if (features[feature]==undefined) throw 'DTI.getBestFeatures: invalid feature vector';
    var vals=Comp.array.pluck(data, features[feature]).map(function (val) {return val==undefined?0:val});
    var e = entropyEps(vals,eps);
    var d = deviation(vals);
    var min = Min(vals);
    var max = Max(vals);
    bestfeatures.push({e:e,d:d,range:{a:min,b:max},name:features[feature]});
  }
  bestfeatures.sort(function (ef1,ef2) {
    if (ef1.e > ef2.e) return -1; else return 1;
  });
  return bestfeatures;
}

/** Find in one data set the most significant feature variable (i.e., with highest value)
 */
function getSignificantFeature(data,features) {
  var f,sig;
  for (f in features) {
    if (sig==undefined || sig.val < data[features[f]]) sig={name:features[f],val:data[features[f]]};
  }
  return sig;
}

function getPossibleVals(data,feature) {
  return Comp.array.sort(Comp.array.pluck(data, feature), function (x,y) {
    if (upperBound(x) < lowerBound(y)) return -1; else return 1; // increasing value order
  });
}

/** Merge values and intervals
 */
function mergeVals(vals) {
  var _vals,
      merged,i,j;
  for (i in vals) {
    var vi = vals[i];
    if (!_vals) _vals=[vi];
    else {
      // Find overlapping values and merge
      merged=false;
      loopj: for (j in _vals) {
        var vj = _vals[j];
        if (equal(vi,vj)) {
          merged=true;
          break loopj;          
        }
        else if (overlap(vi,vj)) {
          merged=true;
          _vals[j]={a:Min([vi,vj]),b:Max([vi,vj])};
          break loopj;
        }
      }
      if (!merged) _vals.push(vi);
    }
  }
  //Aios.aios.log(_vals);
  return _vals||[];
}

/**
 * Predicts class for sample
 */
function nearestVal(vals,sample,fun) {
  var best=none;
  for (var v in vals) {
    var d=fun?distanceVal(fun(vals[v]),sample):distanceVal(vals[v],sample);
    if (best==none) 
      best={v:vals[v],d:d};
    else if (best.d > d)
      best={v:vals[v],d:d};    
  }
  if (best) return best.v;
  else return none;
}


/** Parttition an ordered set of values
 *  Each partition of values has at least 2*eps distance to the next partition.
 *
 */
function partitionVals(vals,eps) {
  var last=none;
  var partitions=[];
  var partition=[];
  for(var i in vals) {
    var val0=vals[i];
    var val1=vals[i-1];

    if (val1==undefined) partition.push(val0);
    else if ( upperBound(val0) < upperBound(addVal(val1,2*eps))) partition.push(val0);    
    else {
      partitions.push(partition);
      partition=[val0];
    }
  }
  if (partition.length>0) partitions.push(partition);
  return partitions;
}

/** Make a predicition with sample data
 *
 */
function predict(model,sample) {
  var root = model;
  while (root && root.type !== NODE_TYPES.RESULT) {
    var attr = root.name;
    var sampleVal = sample[attr];
    var childNode = nearestVal(root.vals,sampleVal,function (node) {
      return node.val;
    });

    if (childNode){
      root = childNode.child;
    } else {
      root = none;
    }
  }
  if (root) return root.name||root.val;
  else return none;
};

/** Print the tree
 *
 */
function print(model,indent, compact) {
  var line='',sep;
  if (compact) return results(model);
  if (indent==undefined) indent=0;
  if (!model) return '';
  var sp = function () {return Comp.string.create(indent);};
  switch (model.type) {
    case NODE_TYPES.RESULT: 
      return sp()+'-> '+model.name+NL;
    case NODE_TYPES.FEATURE:
      line=sp()+'$'+model.name+'?'+NL;
      Comp.array.iter(model.vals,function (v) {
        line += print(v,indent+2);
      }); 
      return line;
    case NODE_TYPES.FEATURE_VALUE: 
      line=sp()+'='+(model.val.a==undefined?model.val:'['+model.val.a+','+model.val.b+']')+NL;
      return line+print(model.child,indent+2); 
  }
  return 'model?';
}

/**
 * Computes probability of of a given value existing in a given list
 * with additional 2*epsilon interval, only applicable to numerical values.
 */
function probEps(value, list, eps) {
  // TODO: ranges
  var occurrences = Comp.array.filter(list, function(element) {
    return (element >= (value-eps)) && (element <= (value+eps));
  });

  var numOccurrences = occurrences.length;
  var numElements = list.length;
  return numOccurrences / numElements;
}

function probEps2(value, list, eps) {
  // TODO: ranges
  var occurrences = Comp.array.filter(list, function(element) {
    return overlap(epsVal(value), epsVal(element));
  });

  var numOccurrences = occurrences.length;
  var numElements = list.length;
  return numOccurrences / numElements;
}

/** Incremental update of the model with new training set(s). Can be executed with an empty model.
 *  The current tree can be week for a new training set (new target).
 *  This can result in a classification of the new target with insignificant variables.
 *  Therefore, the last tree node must be exapnded with an additional strong (most significant)
 *  variable of the new data set (but it is still a heuristic for future updates). 
 */
function updateTree(model,data, target, features, options) {
  var eps = options.eps,
      maxdepth = options.maxdepth,
      verbose = options.verbose;
  var featuresINm={},   // All current tree feature variables and their value interval
      results=[],       // All current tree result leafs
      set,i,v,feature,remainingFeatures,exists,sigFeature;
  // 1. Analysis of existing model
 
  var analyze = function (model,feature) {
    var feature2;
    if (!model) return;
    switch (model.type) {
      case NODE_TYPES.RESULT:
        if (!Comp.array.contains(results,model.name)) results.push(model.name); 
        break;
      case NODE_TYPES.FEATURE:
        feature2={name:model.name};
        if (!featuresINm[model.name]) featuresINm[model.name]=feature2;
        Comp.array.iter(model.vals,function (v) { analyze(v,featuresINm[model.name]) });
        break;
      case NODE_TYPES.FEATURE_VALUE:
        if (!feature.val) feature.val={
          a:(model.val.a==undefined?model.val:model.val.a),
          b:(model.val.a==undefined?model.val:model.val.b)
        }; else {
          feature.val.a=min(feature.val.a,
                            (model.val.a==undefined?model.val:model.val.a));
          feature.val.b=max(feature.val.b,
                            (model.val.a==undefined?model.val:model.val.b));
        }                  
        analyze(model.child);
        break; 
    }   
  }

  
  analyze(model);
  // console.log(featuresINm);
  // console.log(results);
  
  exists=Comp.array.contains(results,data[target]);

  
  // 2a. Empty model, add first training set with two significant feature variable nodes
  function init(set) {
    set=data[i];
      sigFeature1=getSignificantFeature(set,features);
      remainingFeatures=Comp.array.filter(features,function (feat) {
        return sigFeature1.name!=feat;
      });
      sigFeature2=getSignificantFeature(set,remainingFeatures);

      featuresINm[sigFeature1.name]={name:sigFeature1.name,
                                    val:{a:sigFeature1.val-eps,b:sigFeature1.val+eps}};
      featuresINm[sigFeature2.name]={name:sigFeature2.name,
                                    val:{a:sigFeature2.val-eps,b:sigFeature2.val+eps}};
      results.push(set[target]);
      model=Feature(sigFeature1.name,[
                    Value({a:set[sigFeature1.name]-eps,b:set[sigFeature1.name]+eps},
                          Feature(sigFeature2.name,[
                                 Value({a:sigFeature2.val-eps,b:sigFeature2.val+eps},
                                       Result(set[target])) 
                                  ]))]);
      return model;
  }
  
  remainingFeatures=Comp.array.filter(features,function (feat) {
    return !featuresINm[feat];
  });
  
  // 2b. Update the tree with the new training set
  var update = function (model,set,feature) {
    var feature2,p;
    if (!model) return;
    switch (model.type) {
    
      case NODE_TYPES.RESULT:
        if (model.name != set[target] && verbose)
          console.log('Cannot insert new training set '+set[target]+' in tree. No more separating variables!');
        break;
        
      case NODE_TYPES.FEATURE:
        // console.log(set[target]+': '+ model.name+'='+set[model.name]);
        if (set[model.name]<(featuresINm[model.name].val.a-eps) ||
            set[model.name]>(featuresINm[model.name].val.b+eps)) {
          // add new training set; done
          // the current decision tree can  be week, thus add another strong variable node, too! 
          sigFeature=getSignificantFeature(set,remainingFeatures);
          featuresINm[sigFeature.name]={name:sigFeature.name,
                                        val:{a:sigFeature.val-eps,b:sigFeature.val+eps}};
          featuresINm[model.name].val.a=min(featuresINm[model.name].val.a,set[model.name]-eps);
          featuresINm[model.name].val.b=max(featuresINm[model.name].val.b,set[model.name]+eps);
          if (!Comp.array.contains(results,set[target])) results.push(set[target]);

          model.vals.push(Value({a:set[model.name]-eps,b:set[model.name]+eps},
                          Feature(sigFeature.name,[
                            Value({a:sigFeature.val-eps,b:sigFeature.val+eps},
                                  Result(set[target]))
                          ])));
          model.vals=Comp.array.sort(model.vals,function (v1,v2) {return (lowerBound(v1.val)<lowerBound(v2.val))?-1:1});  
        } else {
          // go deeper, but extend the interval of the best matching child node with new data variable
          Comp.array.iter_break(model.vals,function (fv) {
            // console.log(model.name,fv.val,overlap(fv.val,{a:set[model.name]-eps,b:set[model.name]+eps})) 
            if (overlap(fv.val,{a:set[model.name]-eps,b:set[model.name]+eps})) {
              fv.val.a=min(lowerBound(fv.val),set[model.name]-eps);
              fv.val.b=max(upperBound(fv.val),set[model.name]+eps);
              update(fv,set,model.name);
              return true;
            } else return false;
          });
        }
        break;
        
      case NODE_TYPES.FEATURE_VALUE:
        update(model.child,set);
        break; 
    }   
  }

  for (i in data) {
    set=data[i];
    if (model==undefined || model.type==undefined)
      model=init(set);
    else
      update(model,set);
  }
  return model;
}

module.exports =  {
  NODE_TYPES:NODE_TYPES,
  compactTree:compactTree,
  create:function (options) {
    // type options = {data number [][], target:string, features: string [], eps;number, maxdepth}
    return createTree(options.data,options.target,options.features,options)
  },
  depth:depth,
  entropy:entropyEps,
  evaluate:function evaluate(model,target,samples){},
  predict:predict,
  print:print,
  results:results,
  update:function (model,options) {
    // type options = {data number [][], target:string, features: string [], eps:number, maxdepth}
    return updateTree(model,options.data,options.target,options.features,options)
  },
  current:function (module) { current=module.current; Aios=module;}
};


};
BundleModuleCode['plugins/ml/knn']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Ankit Kuwadekar, Stefan Bosse
 **    $INITIAL:     (C) 2014, Ankit Kuwadekar
 **    $MODIFIED:    (C) 2006-2019 bLAB by sbosse
 **    $VERSION:     1.2.1
 **
 **    $INFO:
 **
 ** KNN: k-nearest-neighbour Algorithm
 ** A General purpose k-nearest neighbor classifier algorithm based on the 
 ** k-d tree Javascript library develop by Ubilabs.
 **
 ** Portable models (KNN/KNN2)
 **
 **    $ENDOFINFO
 */
var options = {
  version:'1.2.1'
}
var Comp = Require('com/compat');
var math = Require('plugins/ml/math');
var euclideanDistance = math.euclidean;

/*
 * Original code from:
 *
 * k-d Tree JavaScript - V 1.01
 *
 * https://github.com/ubilabs/kd-tree-javascript
 *
 * @author Mircea Pricop <pricop@ubilabs.net>, 2012
 * @author Martin Kleppe <kleppe@ubilabs.net>, 2012
 * @author Ubilabs http://ubilabs.net, 2012
 * @license MIT License <http://www.opensource.org/licenses/mit-license.php>
 */

function Node(obj, dimension, parent) {
    var N = {}
    N.obj = obj;
    N.left = null;
    N.right = null;
    N.parent = parent;
    N.dimension = dimension;
    return N;
}

/* KDTree
 *
 */

function KDTree(points, metric) {
    // if (!(this instanceof KDTree)) return new KDTree(points, metric);
    // If points is not an array, assume we're loading a pre-built tree
    var K ={}
    if (!Array.isArray(points)) {
        K.dimensions = points.dimensions;
        K.root = points;
        restoreParent(K.root);
    } else {
        K.dimensions = new Array(points[0].length);
        for (var i = 0; i < K.dimensions.length; i++) {
            K.dimensions[i] = i;
        }
        K.root = buildTree(points, 0, null, K.dimensions);
    }
    K.metric = metric;
    return K;
}

// Convert to a JSON serializable structure; this just requires removing
// the `parent` property
KDTree.code = {
  nearest : function(K, point, maxNodes, maxDistance) {
    var metric = K.metric;
    var dimensions = K.dimensions;
    var i;

    var bestNodes = BinaryHeap(
        function (e) {
            return -e[1];
        }
    );

    function nearestSearch(node) {
        var dimension   = dimensions[node.dimension];
        var ownDistance = metric(point, node.obj);
        var linearPoint = {};
        var bestChild,
            linearDistance,
            otherChild,
            i;
        function saveNode(node, distance) {
            BinaryHeap.code.push(bestNodes,[node, distance]);
            if (BinaryHeap.code.size(bestNodes) > maxNodes) {
                BinaryHeap.code.pop(bestNodes);
            }
        }

        for (i = 0; i < dimensions.length; i += 1) {
            if (i === node.dimension) {
                linearPoint[dimensions[i]] = point[dimensions[i]];
            } else {
                linearPoint[dimensions[i]] = node.obj[dimensions[i]];
            }
        }

        linearDistance = metric(linearPoint, node.obj);
        if (node.right === null && node.left === null) {
            if (BinaryHeap.code.size(bestNodes) < maxNodes || ownDistance < BinaryHeap.code.peek(bestNodes)[1]) {
                saveNode(node, ownDistance);
            }
            return;
        }

        if (node.right === null) {
            bestChild = node.left;
        } else if (node.left === null) {
            bestChild = node.right;
        } else {
            if (point[dimension] < node.obj[dimension]) {
                bestChild = node.left;
            } else {
                bestChild = node.right;
            }
        }

        nearestSearch(bestChild);

        if (BinaryHeap.code.size(bestNodes) < maxNodes || ownDistance < BinaryHeap.code.peek(bestNodes)[1]) {
            saveNode(node, ownDistance);
        }

        if (BinaryHeap.code.size(bestNodes) < maxNodes || Math.abs(linearDistance) < BinaryHeap.code.peek(bestNodes)[1]) {
            if (bestChild === node.left) {
                otherChild = node.right;
            } else {
                otherChild = node.left;
            }
            if (otherChild !== null) {
                nearestSearch(otherChild);
            }
        }
    }

    if (maxDistance) {
        for (i = 0; i < maxNodes; i += 1) {
            BinaryHeap.code.push(bestNodes,[null, maxDistance]);
        }
    }

    if (K.root) {
        nearestSearch(K.root);
    }

    var result = [];
    for (i = 0; i < Math.min(maxNodes, bestNodes.content.length); i += 1) {
        if (bestNodes.content[i][0]) {
            result.push([bestNodes.content[i][0].obj, bestNodes.content[i][1]]);
        }
    }
    return result;
  }
}

function buildTree(points, depth, parent, dimensions) {
    var dim = depth % dimensions.length;

    if (points.length === 0) {
        return null;
    }
    if (points.length === 1) {
        return Node(points[0], dim, parent);
    }

    points.sort(function (a, b) { a[dimensions[dim]] - b[dimensions[dim]]});

    var median  = Math.floor(points.length / 2);
    var node    = Node(points[median], dim, parent);
    node.left   = buildTree(points.slice(0, median), depth + 1, node, dimensions);
    node.right  = buildTree(points.slice(median + 1), depth + 1, node, dimensions);

    return node;
}

function restoreParent(root) {
    if (root.left) {
        root.left.parent = root;
        restoreParent(root.left);
    }

    if (root.right) {
        root.right.parent = root;
        restoreParent(root.right);
    }
}
/** BinaryHeap
 *
 */
 
// Binary heap implementation from:
// http://eloquentjavascript.net/appendix2.html
function BinaryHeap (scoreFunction) {
  var B={}
    //if (!(this instanceof BinaryHeap)) return new BinaryHeap (scoreFunction);
  B.content = [];
  B.scoreFunction = scoreFunction;
  return B;
}


BinaryHeap.code = {
  push : function(B,element) {
    // Add the new element to the end of the array.
    B.content.push(element);
    // Allow it to bubble up.
    BinaryHeap.code.bubbleUp(B,B.content.length - 1);
  },
  pop : function(B) {
    // Store the first element so we can return it later.
    var result = B.content[0];
    // Get the element at the end of the array.
    var end = B.content.pop();
    // If there are any elements left, put the end element at the
    // start, and let it sink down.
    if (B.content.length > 0) {
        B.content[0] = end;
        BinaryHeap.code.sinkDown(B,0);
    }
    return result;
  },
  peek : function(B) {
    return B.content[0];
  },
  size : function(B) {
    return B.content.length;
  },
  bubbleUp : function(B,n) {
    // Fetch the element that has to be moved.
    var element = B.content[n];
    // When at 0, an element can not go up any further.
    while (n > 0) {
        // Compute the parent element's index, and fetch it.
        var parentN = Math.floor((n + 1) / 2) - 1;
        var parent = B.content[parentN];
        // Swap the elements if the parent is greater.
        if (B.scoreFunction(element) < B.scoreFunction(parent)) {
            B.content[parentN] = element;
            B.content[n] = parent;
            // Update 'n' to continue at the new position.
            n = parentN;
        } else { // Found a parent that is less, no need to move it further.
            break;
        }
    }
  },
  sinkDown : function(B,n) {
    // Look up the target element and its score.
    var length = B.content.length;
    var element = B.content[n];
    var elemScore = B.scoreFunction(element);

    while (true) {
        // Compute the indices of the child elements.
        var child2N = (n + 1) * 2;
        var child1N = child2N - 1;
        // This is used to store the new position of the element,
        // if any.
        var swap = null;
        // If the first child exists (is inside the array)...
        if (child1N < length) {
            // Look it up and compute its score.
            var child1 = B.content[child1N];
            var child1Score = B.scoreFunction(child1);
            // If the score is less than our element's, we need to swap.
            if (child1Score < elemScore) {
                swap = child1N;
            }
        }
        // Do the same checks for the other child.
        if (child2N < length) {
            var child2 = B.content[child2N];
            var child2Score = B.scoreFunction(child2);
            if (child2Score < (swap === null ? elemScore : child1Score)) {
                swap = child2N;
            }
        }

        // If the element needs to be moved, swap it, and continue.
        if (swap !== null) {
            B.content[n] = B.content[swap];
            B.content[swap] = element;
            n = swap;
        } else {
            // Otherwise, we are done.
            break;
        }
    }
  }
}

/** KNN
 *
 */

/**
 ** typeof @dataset = number [] []
 ** typeof @labels  = number []
 ** typeof @options = { distance?:function, k?:number }
 */
function KNN(dataset, labels, options) {
    var L = {}
    if (!options) options={};
    if (dataset === true) {
        var model = labels;
        L.kdTree = KDTree(model.kdTree, options);
        L.k = model.k;
        L.classes = new Set(model.classes);
        L.isEuclidean = model.isEuclidean;
        return L;
    }
    var classes = new Set(labels);

    var distance = getDistanceFunction(options.distance),
        k = options.k||classes.size + 1;

    var points = new Array(dataset.length);
    for (var i = 0; i < points.length; ++i) {
        points[i] = dataset[i].slice();
    }

    for (i = 0; i < labels.length; ++i) {
        points[i].push(labels[i]);
    }

    L.kdTree = KDTree(points, distance);
    L.k = k;
    L.distance = distance;
    L.classes = classes;
    L.isEuclidean = distance === euclideanDistance;
    return L;
}


/**
 * Predicts the output given the matrix to predict.
 * @param {Array} dataset
 * @return {Array} predictions
 */
KNN.code = {
  predict : function(L,dataset) {
    if (Array.isArray(dataset)) {
        if (typeof dataset[0] === 'number') {
            return getSinglePrediction(L, dataset);
        } else if (Array.isArray(dataset[0]) && typeof dataset[0][0] === 'number') {
            var predictions = new Array(dataset.length);
            for (var i = 0; i < dataset.length; i++) {
                predictions[i] = getSinglePrediction(L, dataset[i]);
            }
            return predictions;
        }
    }
    throw new TypeError('dataset to predict must be an array or a matrix');
  }
}

function getSinglePrediction(knn, currentCase) {
    var nearestPoints = KDTree.code.nearest(knn.kdTree, currentCase, knn.k);
    var pointsPerClass = {};
    var predictedClassMin = null;
    var predictedClassMax = null;
    var predictedClassDistance = 0;
    var maxPoints = -1;
    var minDistance = 1E30;
    
    var lastElement = nearestPoints[0][0].length - 1;
    //for (var element of knn.classes) {
    //    pointsPerClass[element] = 0;
    //}
    forof(knn.classes,function (element) {
      pointsPerClass[element] = 0;
    });
    for (var i = 0; i < nearestPoints.length; ++i) {
        var currentClass = nearestPoints[i][0][lastElement];
        var currentPoints = ++pointsPerClass[currentClass];
        // Either use majority of points matching a class or the nearest points
        if (currentPoints > maxPoints) {
            predictedClassMax = currentClass;
            predictedClassDistance = predictedClassDistance+nearestPoints[i][1];
            maxPoints = currentPoints;
        }
        if (nearestPoints[i][1] < minDistance) {
            predictedClassMin = currentClass;
            minDistance = nearestPoints[i][1];
        }
    }
    predictedClassDistance /= maxPoints;
    return maxPoints>2?predictedClassMax:predictedClassMin;
}



/** Create a simple KNN (2)
 *
 * typeof @options = {x:number [] [],y: number []}
 *
 */
var KNN2 = function (options) {
  var model={}
  // if (!(this instanceof KNN2)) return new KNN2(options);
  model.x       = options.x;
  model.y       = options.y;
  model.target  = options.y;
  model.k       = options.k || 3
  model.distance = getDistanceFunction(options.distance);
  model.weightf =  getWeightedFunction(options.weightf);
  return model
}

/** Make a prediction
 *  
 */
KNN2.code = {
  predict : function (model,data) {
    var x = data;
    var k = model.k;
    var weightf = model.weightf;
    var distance = model.distance;
    var distanceList = [];
    var i;
    for(i=0; i<model.x.length; i++)
        distanceList.push([distance(x,model.x[i]),i]);
    distanceList.sort(function(a,b) {return a[0]-b[0];});
    var avg = 0.0;
    var totalWeight = 0, weight;
    for(i=0; i<k; i++) {
        var dist = distanceList[i][0];
        var idx = distanceList[i][1];
        weight = weightf(dist);
        avg += weight * model.y[idx];
        totalWeight += weight;
    }

    avg /= totalWeight;
    return avg;
  }
}

function getWeightedFunction(options) {
    if(typeof options === 'undefined') {
        return function(x) {
            var sigma = 10.0;
            return Math.exp(-1.*x*x/(2*sigma*sigma));
        }
    } else if(typeof options === 'function') {
        return options;
    } else if(options === 'gaussian') {
        return function(x) {
            var sigma = options.sigma;
            return Math.exp(-1.*x*x/(2*sigma*sigma));
        }
    } else if(options === 'none') {
        return function(dist) {
            return 1.0;
        }
    }
}

function getDistanceFunction(options) {
    if(typeof options === 'undefined') {
        return math.euclidean;
    } else if (typeof options === 'function') {
        return options;
    } else if (options === 'euclidean') {
        return math.euclidean;
    } else if (options === 'pearson') {
        return math.pearson;
    } else 
        throw new TypeError('distance opions invalid: '+options);;      
}

module.exports={
  create    : KNN,
  predict   : KNN.code.predict,
  create2   : KNN2,
  predict2  : KNN2.code.predict,
}
};
BundleModuleCode['plugins/ml/math']=function (module,exports,global,process){
/**
 * Created by joonkukang on 2014. 1. 12..
 */
var m = module.exports;

m.randn = function() {
    // generate random guassian distribution number. (mean : 0, standard deviation : 1)
    var v1, v2, s;

    do {
        v1 = 2 * Math.random() - 1;   // -1.0 ~ 1.0 까지의 값
        v2 = 2 * Math.random() - 1;   // -1.0 ~ 1.0 까지의 값
        s = v1 * v1 + v2 * v2;
    } while (s >= 1 || s == 0);

    s = Math.sqrt( (-2 * Math.log(s)) / s );
    return v1 * s;
}

m.shape = function(mat) {
    var row = mat.length;
    var col = mat[0].length;
    return [row,col];
};

m.addVec = function(vec1, vec2) {
    if(vec1.length === vec2.length) {
        var result = [];
        var i;
        for(i=0;i<vec1.length;i++)
            result.push(vec1[i]+vec2[i]);
        return result;
    } else {
        throw new Error("Length Error : not same.")
    }
}

m.minusVec = function(vec1,vec2) {
    if(vec1.length === vec2.length) {
        var result = [];
        var i;
        for(i=0;i<vec1.length;i++)
            result.push(vec1[i]-vec2[i]);
        return result;
    } else {
        throw new Error("Length Error : not same.")
    }
};

m.addMatScalar = function(mat,scalar) {
    var row = m.shape(mat)[0];
    var col = m.shape(mat)[1];
    var i , j,result = [];
    for(i=0 ; i<row ; i++) {
        var rowVec = [];
        for(j=0 ; j<col ; j++) {
            rowVec.push(mat[i][j] + scalar);
        }
        result.push(rowVec);
    }
    return result;
}

m.addMatVec = function(mat,vec) {
    if(mat[0].length === vec.length) {
        var result = [];
        var i;
        for(i=0;i<mat.length;i++)
            result.push(m.addVec(mat[i],vec));
        return result;
    } else {
        throw new Error("Length Error : not same.")
    }
}

m.minusMatVec = function(mat,vec) {
    if(mat[0].length === vec.length) {
        var result = [];
        var i;
        for(i=0;i<mat.length;i++)
            result.push(m.minusVec(mat[i],vec));
        return result;
    } else {
        throw new Error("Length Error : not same.")
    }
}

m.addMat = function (mat1, mat2) {
    if ((mat1.length === mat2.length) && (mat1[0].length === mat2[0].length)) {
        var result = new Array(mat1.length);
        for (var i = 0; i < mat1.length; i++) {
            result[i] = new Array(mat1[i].length);
            for (var j = 0; j < mat1[i].length; j++) {
                result[i][j] = mat1[i][j] + mat2[i][j];
            }
        }
        return result;
    } else {
        throw new Error('Matrix mismatch.');
    }
};

m.minusMat = function(mat1, mat2) {
    if ((mat1.length === mat2.length) && (mat1[0].length === mat2[0].length)) {
        var result = new Array(mat1.length);
        for (var i = 0; i < mat1.length; i++) {
            result[i] = new Array(mat1[i].length);
            for (var j = 0; j < mat1[i].length; j++) {
                result[i][j] = mat1[i][j] - mat2[i][j];
            }
        }
        return result;
    } else {
        throw new Error('Matrix mismatch.');
    }
}

m.transpose = function (mat) {
    var result = new Array(mat[0].length);
    for (var i = 0; i < mat[0].length; i++) {
        result[i] = new Array(mat.length);
        for (var j = 0; j < mat.length; j++) {
            result[i][j] = mat[j][i];
        }
    }
    return result;
};

m.dotVec = function (vec1, vec2) {
    if (vec1.length === vec2.length) {
        var result = 0;
        for (var i = 0; i < vec1.length; i++) {
            result += vec1[i] * vec2[i];
        }
        return result;
    } else {
        throw new Error("Vector mismatch");
    }
};

m.outerVec = function (vec1,vec2) {
    var mat1 = m.transpose([vec1]);
    var mat2 = [vec2];
    return m.mulMat(mat1,mat2);
};

m.mulVecScalar = function(vec,scalar) {
    var i, result = [];
    for(i=0;i<vec.length;i++)
        result.push(vec[i]*scalar);
    return result;
};

m.mulMatScalar = function(mat,scalar) {
    var row = m.shape(mat)[0];
    var col = m.shape(mat)[1];
    var i , j,result = [];
    for(i=0 ; i<row ; i++) {
        var rowVec = [];
        for(j=0 ; j<col ; j++) {
            rowVec.push(mat[i][j] * scalar);
        }
        result.push(rowVec);
    }
    return result;
};

m.mulMatElementWise = function(mat1, mat2) {
    if (mat1.length === mat2.length && mat1[0].length === mat2[0].length) {
        var result = new Array(mat1.length);

        for (var x = 0; x < mat1.length; x++) {
            result[x] = new Array(mat1[0].length);
        }

        for (var i = 0; i < result.length; i++) {
            for (var j = 0; j < result[i].length; j++) {
                result[i][j] = mat1[i][j] * mat2[i][j]
            }
        }
        return result;
    } else {
        throw new Error("Matrix shape error : not same");
    }
};

m.mulMat = function (mat1, mat2) {
    if (mat1[0].length === mat2.length) {
        var result = new Array(mat1.length);

        for (var x = 0; x < mat1.length; x++) {
            result[x] = new Array(mat2[0].length);
        }


        var mat2_T = m.transpose(mat2);
        for (var i = 0; i < result.length; i++) {
            for (var j = 0; j < result[i].length; j++) {
                result[i][j] = m.dotVec(mat1[i],mat2_T[j]);
            }
        }
        return result;
    } else {
        throw new Error("Array mismatch");
    }
};

m.sumVec = function(vec) {
    var sum = 0;
    var i = vec.length;
    while (i--) {
        sum += vec[i];
    }
    return sum;
};

m.sumMat = function(mat) {
    var sum = 0;
    var i = mat.length;
    while (i--) {
        for(var j=0;j<mat[0].length;j++)
          sum += mat[i][j];
    }
    return sum;
};

m.sumMatAxis = function(mat,axis) {
    // default axis 0;
    // axis 0 : mean of col vector . axis 1 : mean of row vector
    if(axis === 1) {
        var row = m.shape(mat)[0];
        var i ;
        var result = [];
        for(i=0 ; i<row; i++)
            result.push(m.sumVec(mat[i]));
        return result;
    } else {
        mat_T = m.transpose(mat);
        return m.sumMatAxis(mat_T,1);
    }
};

m.meanVec = function(vec) {
    return 1. * m.sumVec(vec) / vec.length;
};

m.meanMat = function(mat) {
    var row = mat.length;
    var col = mat[0].length;
    return 1. * m.sumMat(mat) / (row * col);
};

m.meanMatAxis = function(mat,axis) {
    // default axis 0;
    // axis 0 : mean of col vector . axis 1 : mean of row vector
    if(axis === 1) {
        var row = m.shape(mat)[0];
        var i ;
        var result = [];
        for(i=0 ; i<row; i++)
            result.push(m.meanVec(mat[i]));
        return result;
    } else {
        mat_T = m.transpose(mat);
        return m.meanMatAxis(mat_T,1);
    }
};

m.squareVec = function(vec) {
    var squareVec = [];
    var i;
    for(i=0;i<vec.length;i++) {
        squareVec.push(vec[i]*vec[i]);
    }
    return squareVec;
};

m.squareMat = function(mat) {
    var squareMat = [];
    var i;
    for(i=0;i<mat.length;i++) {
        squareMat.push(m.squareVec(mat[i]));
    }
    return squareMat;
};

m.minVec = function(vec) {
    var min = vec[0];
    var i = vec.length;
    while (i--) {
        if (vec[i] < min)
            min = vec[i];
    }
    return min;
};

m.maxVec = function(vec) {
    var max = vec[0];
    var i = vec.length;
    while (i--) {
        if (vec[i] > max)
            max = vec[i];
    }
    return max;
}

m.minMat = function(mat) {
    var min = mat[0][0];
    var i = mat.length;
    while (i--) {
        for(var j=0;j<mat[0].length;j++) {
            if(mat[i][j] < min)
                min = mat[i][j];
        }
    }
    return min;
};

m.maxMat = function(mat) {
    var max = mat[0][0];
    var i = mat.length;
    while (i--) {
        for(var j=0;j<mat[0].length;j++) {
            if(mat[i][j] < max)
                max = mat[i][j];
        }
    }
    return max;
};

m.zeroVec = function(n) {
    var vec = [];
    while(vec.length < n)
        vec.push(0);
    return vec;
};

m.zeroMat = function(row,col) {
    var mat = [];
    while(mat.length < row)
        mat.push(m.zeroVec(col));
    return mat;
};

m.oneVec = function(n) {
    var vec = [];
    while(vec.length < n)
        vec.push(1);
    return vec;
};

m.oneMat = function(row,col) {
    var mat = [];
    while(mat.length < row)
        mat.push(m.oneVec(col));
    return mat;
};

m.randVec = function(n,lower,upper) {
    lower = (typeof lower !== 'undefined') ? lower : 0;
    upper = (typeof upper !== 'undefined') ? upper : 1;
    var vec = [];
    while(vec.length < n)
        vec.push(lower + (upper-lower) * Math.random());
    return vec;
};

m.randMat = function(row,col,lower,upper) {
    lower = (typeof lower !== 'undefined') ? lower : 0;
    upper = (typeof upper !== 'undefined') ? upper : 1;
    var mat = [];
    while(mat.length < row)
        mat.push(m.randVec(col,lower,upper));
    return mat;
};

m.randnVec = function(n,mean,sigma) {
    var vec = [];
    while(vec.length < n)
        vec.push(mean+sigma* m.randn());
    return vec;
};

m.randnMat = function(row,col,mean,sigma) {
    var mat = [];
    while(mat.length < row)
        mat.push(m.randnVec(col,mean,sigma));
    return mat;
};

m.identity = function (n) {
    var result = new Array(n);

    for (var i = 0; i < n ; i++) {
        result[i] = new Array(n);
        for (var j = 0; j < n; j++) {
            result[i][j] = (i === j) ? 1 : 0;
        }
    }

    return result;
};

m.sigmoid = function(x) {
    var sigmoid = (1. / (1 + Math.exp(-x)))
    if(sigmoid ==1) {
     //   console.warn("Something Wrong!! Sigmoid Function returns 1. Probably javascript float precision problem?\nSlightly Controlled value to 1 - 1e-14")
        sigmoid = 0.99999999999999; // Javascript Float Precision Problem.. This is a limit of javascript.
    } else if(sigmoid ==0) {
      //  console.warn("Something Wrong!! Sigmoid Function returns 0. Probably javascript float precision problem?\nSlightly Controlled value to 1e-14")
        sigmoid = 1e-14;
    }
    return sigmoid; // sigmoid cannot be 0 or 1;;
};

m.dSigmoid = function(x){
    a = m.sigmoid(x);
    return a * (1. - a);
};

m.probToBinaryMat = function(mat) {
    var row = m.shape(mat)[0];
    var col = m.shape(mat)[1];
    var i,j;
    var result = [];

    for(i=0;i<row;i++) {
        var rowVec = [];
        for(j=0;j<col;j++) {
            if(Math.random() < mat[i][j])
                rowVec.push(1);
            else
                rowVec.push(0);
        }
        result.push(rowVec);
    }
    return result;
};

m.activateVec = function(vec,activation) {
    var i, result = [];
    for(i=0;i<vec.length;i++)
        result.push(activation(vec[i]));
    return result;
};

m.activateMat = function(mat,activation) {
    var row = m.shape(mat)[0];
    var col = m.shape(mat)[1];
    var i, j,result = [];
    for(i=0;i<row;i++) {
        var rowVec = [];
        for(j=0;j<col;j++)
            rowVec.push(activation(mat[i][j]));
        result.push(rowVec);
    }
    return result;
};

m.activateTwoVec = function(vec1, vec2,activation) {
    if (vec1.length === vec2.length) {
        var result = new Array(vec1.length);
        for (var i = 0; i < result.length; i++) {
            result[i] = activation(vec1[i],vec2[i]);
        }
        return result;
    } else {
        throw new Error("Matrix shape error : not same");
    }
};

m.activateTwoMat = function(mat1, mat2,activation) {
    if (mat1.length === mat2.length && mat1[0].length === mat2[0].length) {
        var result = new Array(mat1.length);

        for (var x = 0; x < mat1.length; x++) {
            result[x] = new Array(mat1[0].length);
        }

        for (var i = 0; i < result.length; i++) {
            for (var j = 0; j < result[i].length; j++) {
                result[i][j] = activation(mat1[i][j],mat2[i][j]);
            }
        }
        return result;
    } else {
        throw new Error("Matrix shape error : not same");
    }
};

m.fillVec = function(n,value) {
    var vec = [];
    while(vec.length < n)
        vec.push(value);
    return vec;
};

m.fillMat = function(row,col,value) {
    var mat = [];
    while(mat.length < row) {
        var rowVec = [];
        while(rowVec.length < col)
            rowVec.push(value);
        mat.push(rowVec);
    }
    return mat;
};

m.softmaxVec = function(vec) {
    var max = m.maxVec(vec);
    var preSoftmaxVec = m.activateVec(vec,function(x) {return Math.exp(x - max);})
    return m.activateVec(preSoftmaxVec,function(x) {return x/ m.sumVec(preSoftmaxVec)})
};

m.softmaxMat = function(mat) {
    var result=[], i;
    for(i=0 ; i<mat.length ; i++)
        result.push(m.softmaxVec(mat[i]));
    return result;
};

m.randInt = function(min,max) {
  var rand = Math.random() * (max - min + 0.9999) + min
  return Math.floor(rand);
}

m.normalizeVec = function(vec) {
    var i;
    var newVec = [],tot = 0;
    for(i=0; i<vec.length; i++)
        tot += vec[i];
    for(i=0; i<vec.length;i++)
        newVec.push(1.*vec[i]/tot);
    return newVec;
};

m.euclidean = function(x1,x2) {
    var i;
    var distance = 0;
    for(i=0 ; i<x1.length; i++) {
        var dx = x1[i] - x2[i];
        distance += dx * dx;
    }
    return Math.sqrt(distance);
};

m.pearson = function(x, y)
{
    var xy = [];
    var x2 = [];
    var y2 = [];

    for(var i=0; i<x.length; i++)
    {
        xy.push(x[i] * y[i]);
        x2.push(x[i] * x[i]);
        y2.push(y[i] * y[i]);
    }

    var sum_x = 0;
    var sum_y = 0;
    var sum_xy = 0;
    var sum_x2 = 0;
    var sum_y2 = 0;

    for(var i=0; i<x.length; i++)
    {
        sum_x += x[i];
        sum_y += y[i];
        sum_xy += xy[i];
        sum_x2 += x2[i];
        sum_y2 += y2[i];
    }

    var step1 = (x.length * sum_xy) - (sum_x * sum_y);
    var step2 = (x.length * sum_x2) - (sum_x * sum_x);
    var step3 = (x.length * sum_y2) - (sum_y * sum_y);
    var step4 = Math.sqrt(step2 * step3);
    var answer = step1 / step4;

    return answer;
};

m.getNormVec = function(vec) {
    var i;
    var sqsum = 0;
    for(i=0; i<vec.length; i++)
        sqsum += vec[i] * vec[i];
    return Math.sqrt(sqsum);
}

m.gaussian = function(x, sigma) {
    sigma = sigma || 10.0;
    return Math.exp(-1.*x*x/(2*sigma*sigma));
}

m.meanVecs = function(vecs) {
    var sum = m.zeroVec(vecs[0].length);
    var i;
    for(i=0; i<vecs.length; i++)
        sum = m.addVec(sum,vecs[i]);
    return m.activateVec(sum,function(x) {return 1.*x/vecs.length;});
};

m.covarianceVecs = function(vecs) {
    var mat = m.zeroMat(vecs[0].length,vecs[0].length);
    var meanVec = m.meanVecs(vecs);
    var i;
    for(i=0; i<vecs.length; i++) {
        var a = m.minusVec(vecs[i],meanVec);
        mat = m.addMat(mat, m.mulMat(m.transpose([a]),[a]));
    }
    return m.activateMat(mat,function(x) { return 1.*x/(vecs.length-1);});
};

m.shuffle = function(arr){
    var o = [];
    for(var i=0;i<arr.length;i++)
        o.push(arr[i]); // deep copy
    for(var j, x, i = o.length; i; j = parseInt(Math.random() * i), x = o[--i], o[i] = o[j], o[j] = x);
    return o;
};

m.range = function(start, end, step) {
    var ret = [];
    if(typeof step === "undefined")
        step = 1;
    if(typeof end === "undefined") {
        end = start;
        start = 0;
    }
    for(var i=start;i<end;i+=step)
        ret.push(i);
    return ret;
};

m.vec2Mat = function (vec) {
  return vec.map(function (v) { return [v] });
}
// For CRBM
/*
m.phi = function(mat,vec,low,high) {
    var i;
    var result = [];
    for(i=0;i<mat.length;i++) {
        result.push(m.activateTwoVec(mat[i],vec,function(x,y){return low+(high-low)* m.sigmoid(x*y);}))
    }
    return result;
}
*/
};
BundleModuleCode['plugins/ml/kmeans']=function (module,exports,global,process){
/**
 * Created by joonkukang on 2014. 1. 16..
 */
var math = Require('plugins/ml/math')
var Kmeans = module.exports;

Kmeans.cluster = function(options) {
    var data = options['data'];
    var k = options['k'];
    var distance = getDistanceFunction(options['distance']);
    var epochs = options['epochs'];
    var init_using_data = options['init_using_data'];
    if(typeof init_using_data === "undefined");
        init_using_data = true;
    var means = getRandomMeans(data,k, init_using_data);

    var epoch, i, j, l;
    var clusters = [];
    for(i=0 ; i<k ; i++)
        clusters.push([]);

    for(epoch=0 ; epoch<epochs ; epoch++) {
        clusters = [];
        for(i=0 ; i<k ; i++)
            clusters.push([]);

        // Find which centroid is the closest for each row
        for(i=0 ; i<data.length ; i++) {
            var bestmatch = 0;
            for(j=0 ; j<k ; j++) {
                if(distance(means[j],data[i]) < distance(means[bestmatch],data[i])) bestmatch = j;
            }
            clusters[bestmatch].push(i);
        }

        // Move the centroids to the average of their members
        for(i=0 ; i<k ; i++) {
            var avgs = [];
            for(j=0 ; j<data[0].length ; j++)
                avgs.push(0.0);
            if(clusters[i].length > 0) {
                for(j=0 ; j<clusters[i].length ; j++) {
                    for(l=0 ; l<data[0].length ; l++) {
                        avgs[l] += data[clusters[i][j]][l];
                    }
                }
                for(j=0 ; j<data[0].length ; j++) {
                    avgs[j] /= clusters[i].length;
                }
                means[i] = avgs;
            }
        }
    }
    return {
        clusters : clusters,
        means : means
    };
}

var getRandomMeans = function(data,k, init_using_data) {
    var clusters = [];
    if(init_using_data) {
        var cluster_index = math.range(data.length);
        cluster_index = math.shuffle(cluster_index);
        for(i=0 ; i<k ; i++) {
            clusters.push(data[cluster_index[i]]);
        }
    } else {
        var i,j;
        var ranges = [];
        for(i=0 ; i<data[0].length ; i++) {
            var min = data[0][i] , max = data[0][i];
            for(j=0 ; j<data.length ; j++) {
                if(data[j][i] < min) min = data[j][i];
                if(data[j][i] > max) max = data[j][i];
            }
            ranges.push([min,max]);
        }
        for(i=0 ; i<k ; i++) {
            var cluster = [];
            for(j=0 ; j<data[0].length;j++) {
                cluster.push(Math.random() * (ranges[j][1] - ranges[j][0]) + ranges[j][0]);
            }
            clusters.push(cluster);
        }
    }
    return clusters;
}


function getDistanceFunction(options) {
    if(typeof options === 'undefined') {
        return math.euclidean;
    } else if (typeof options === 'function') {
        return options;
    } else if (options['type'] === 'euclidean') {
        return math.euclidean;
    } else if (options['type'] === 'pearson') {
        return math.pearson;
    }
}
};
BundleModuleCode['plugins/ml/svm']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     joonkukang, Stefan Bosse
 **    $INITIAL:     (C) 2014, joonkukang
 **    $MODIFIED:    (C) 2006-2018 bLAB by sbosse
 **    $VERSION:     1.1.3
 **
 **    $INFO:
 **
 ** Support Vector Machine Algrotihm
 **
 ** 1. References : http://cs229.stanford.edu/materials/smo.pdf . simplified smo algorithm 
 ** 2. https://github.com/karpathy/svmjs
 ** 
 ** Portable model
 **
 **    $ENDOFINFO
 */

var math = Require('plugins/ml/math');
var Io = Require('com/io');

/**
 * type options = {x: number [] [], y: number []}
 */
var SVM = function (options) {
    var L = {};
    L.x = options.x;
    L.y = options.y;
    return L
};

SVM.code = {
  train : function (L,options) {
    var self = L;
    var C = options.C || 1.0;
    var tol = options.tol || 1e-4;
    var maxPasses = options.max_passes || 20;
    var alphatol = options.alpha_tol || 1e-5;

    L.options={kernel:options.kernel,iterations:maxPasses,alpha_tol:alphatol, C:C, tol:tol };
    self.kernel = getKernel(options.kernel);
    self.alphas = math.zeroVec(self.x.length);
    self.b = 0;
    var passes = 0, i;
    var count=0;
    while(passes < maxPasses) {
        var numChangedAlphas = 0;

        for(i=0; i<self.x.length; i++) {

            var E_i = SVM.code.f(self,self.x[i]) - self.y[i];

            if((self.y[i] * E_i < -tol && self.alphas[i] < C) || (self.y[i] * E_i > tol && self.alphas[i] >0)) {

                // Randomly selects j (i != j)
                var j = math.randInt(0,self.x.length-1);
                if(i==j) j = (j+1) % self.x.length;

                var E_j = SVM.code.f(self,self.x[j]) - self.y[j];
                var alpha_i_old = self.alphas[i], alpha_j_old = self.alphas[j];

                // Compute L,H
                var L,H;
                if(self.y[i] !== self.y[j]) {
                    L = Math.max(0, self.alphas[j] - self.alphas[i]);
                    H = Math.min(C, C + self.alphas[j] - self.alphas[i]);
                } else {
                    L = Math.max(0, self.alphas[j] + self.alphas[i] - C);
                    H = Math.min(C, self.alphas[j] + self.alphas[i]);
                }

                if(L === H)
                    continue;

                // Compute ETA
                var ETA = 2 * self.kernel(self.x[i],self.x[j]) - self.kernel(self.x[i],self.x[i]) - self.kernel(self.x[j],self.x[j]);
                if(ETA >= 0)
                    continue;

                // Clip new value to alpha_j
                self.alphas[j] -= 1.*self.y[j] * (E_i - E_j) / ETA;
                if(self.alphas[j] > H)
                    self.alphas[j] = H;
                else if(self.alphas[j] < L)
                    self.alphas[j] = L;

                if(Math.abs(self.alphas[j] - alpha_j_old) < alphatol)
                    continue;

                // Clip new value to alpha_i
                self.alphas[i] += self.y[i] * self.y[j] * (alpha_j_old - self.alphas[j]);

                // update b
                var b1 = self.b - E_i - self.y[i] * (self.alphas[i] - alpha_i_old) * self.kernel(self.x[i],self.x[i])
                                - self.y[j] * (self.alphas[j] - alpha_j_old) * self.kernel(self.x[i],self.x[j]);
                var b2 = self.b - E_j - self.y[i] * (self.alphas[i] - alpha_i_old) * self.kernel(self.x[i],self.x[j])
                                - self.y[j] * (self.alphas[j] - alpha_j_old) * self.kernel(self.x[j],self.x[j]);

                if(0 < self.alphas[i] && self.alphas[i] < C)
                    self.b = b1;
                else if(0 < self.alphas[j] && self.alphas[j] < C)
                    self.b = b2;
                else
                    self.b = (b1+b2)/2.0;

                numChangedAlphas ++ ;
            } // end-if
        } // end-for
        if(numChangedAlphas == 0)
            passes++;
        else
            passes = 0;
    }
  },
  
  predict : function(L,x) {
    var self = L;
    this.kernel = getKernel(L.options.kernel); // update kernel
    if(SVM.code.f(L,x) >= 0)
        return 1;
    else
        return -1;
  },

  f : function(L,x) {
    var self = L;
    var f = 0, j;
    for(j=0; j<self.x.length; j++)
        f += self.alphas[j] * self.y[j] * self.kernel(self.x[j],x);
    f += self.b;
    return f;
  }
}

function getKernel (options) {
    if(typeof options === 'undefined') {
        return function(x,y) {
            var sigma = 1.0;
            return Math.exp(-1.*Math.pow(math.getNormVec(math.minusVec(x,y)),2)/(2*sigma*sigma));
        }
    } else if (typeof options === 'function') {
        return options;
    } else if (options['type'] === 'gaussian') {
        return function(x,y) {
            var sigma = options['sigma'];
            return Math.exp(-1.*Math.pow(math.getNormVec(math.minusVec(x,y)),2)/(2*sigma*sigma));
        }
    } else if (options['type'] === 'linear') {
        return function(x,y) {
            return math.dotVec(x,y);
        }
    } else if (options['type'] === 'polynomial') {
        return function(x,y) {
            var c = options['c'];
            var d = options['d'];
            return Math.pow(math.dotVec(x,y) + c, d);
        }
    } else if (options['type'] === 'rbf') {
        return function(v1, v2) {
          var s=0;
          var sigma = options.sigma||options.rbfsigma || 0.5;
          for(var q=0;q<v1.length;q++) { s += (v1[q] - v2[q])*(v1[q] - v2[q]); } 
          return Math.exp(-s/(2.0*sigma*sigma));
        }
    }
}


var SVM2 = function (options) {
    var L = {};
    L.data = options.x;
    L.labels = options.y;
    L.threshold=Io.checkOption(options.threshold,0);
    return L
};

SVM2.code = {

  // data is NxD array of floats. labels are 1 or -1.
  train: function(L, options) {
    var data = L.data,labels=L.labels;

    // parameters
    options = options || {};
    var C = options.C || 1.0; // C value. Decrease for more regularization
    var tol = options.tol || 1e-4; // numerical tolerance. Don't touch unless you're pro
    var alphatol = options.alphatol || options.alpha_tol || 1e-7; // non-support vectors for space and time efficiency are truncated. To guarantee correct result set this to 0 to do no truncating. If you want to increase efficiency, experiment with setting this little higher, up to maybe 1e-4 or so.
    var maxiter = options.maxiter || 10000; // max number of iterations
    var numpasses = options.numpasses || options.max_passes || 10; // how many passes over data with no change before we halt? Increase for more precision.

    // instantiate kernel according to options. kernel can be given as string or as a custom function
    var kernel = linearKernel;
    L.kernelType = "linear";
    L.options={kernel:options.kernel};
    if("kernel" in options) {
      if  (typeof options.kernel == 'object') {
        kernel = getKernel(options.kernel);
        L.kernelType=options.kernel.type;
        L.rbfSigma = options.kernel.sigma || options.kernel.rbfsigma;
      } else if (typeof options.kernel == 'function') {
        // assume kernel was specified as a function. Let's just use it
        L.kernelType = "custom";
        kernel = options.kernel;
      }
    }
    L.options.C=C;
    L.options.tol=tol;
    L.options.alphatol=alphatol;
    L.options.iterations=numpasses;
    
    // initializations
    L.kernel = kernel;
    L.N = data.length; var N = L.N;
    L.D = data[0].length; var D = L.D;
    L.alpha = zeros(N);
    L.b = 0.0;
    L.usew_ = false; // internal efficiency flag

    // Cache kernel computations to avoid expensive recomputation.
    // This could use too much memory if N is large.
    if (options.memoize) {
      L.kernelResults = new Array(N);
      for (var i=0;i<N;i++) {
        L.kernelResults[i] = new Array(N);
        for (var j=0;j<N;j++) {
          L.kernelResults[i][j] = kernel(data[i],data[j]);
        }
      }
    }

    // run SMO algorithm
    var iter = 0;
    var passes = 0;
    while(passes < numpasses && iter < maxiter) {

      var alphaChanged = 0;
      for(var i=0;i<N;i++) {

        var Ei= SVM2.code.marginOne(L, data[i]) - labels[i];
        if( (labels[i]*Ei < -tol && L.alpha[i] < C)
         || (labels[i]*Ei > tol && L.alpha[i] > 0) ){

          // alpha_i needs updating! Pick a j to update it with
          var j = i;
          while(j === i) j= randi(0, L.N);
          var Ej= SVM2.code.marginOne(L, data[j]) - labels[j];

          // calculate L and H bounds for j to ensure we're in [0 C]x[0 C] box
          ai= L.alpha[i];
          aj= L.alpha[j];
          var Lb = 0; var Hb = C;
          if(labels[i] === labels[j]) {
            Lb = Math.max(0, ai+aj-C);
            Hb = Math.min(C, ai+aj);
          } else {
            Lb = Math.max(0, aj-ai);
            Hb = Math.min(C, C+aj-ai);
          }

          if(Math.abs(Lb - Hb) < 1e-4) continue;

          var eta = 2*SVM2.code.kernelResult(L, i,j) - SVM2.code.kernelResult(L, i,i) - SVM2.code.kernelResult(L, j,j);
          if(eta >= 0) continue;

          // compute new alpha_j and clip it inside [0 C]x[0 C] box
          // then compute alpha_i based on it.
          var newaj = aj - labels[j]*(Ei-Ej) / eta;
          if(newaj>Hb) newaj = Hb;
          if(newaj<Lb) newaj = Lb;
          if(Math.abs(aj - newaj) < 1e-4) continue; 
          L.alpha[j] = newaj;
          var newai = ai + labels[i]*labels[j]*(aj - newaj);
          L.alpha[i] = newai;

          // update the bias term
          var b1 = L.b - Ei - labels[i]*(newai-ai)*SVM2.code.kernelResult(L, i,i)
                   - labels[j]*(newaj-aj)*SVM2.code.kernelResult(L, i,j);
          var b2 = L.b - Ej - labels[i]*(newai-ai)*SVM2.code.kernelResult(L, i,j)
                   - labels[j]*(newaj-aj)*SVM2.code.kernelResult(L, j,j);
          L.b = 0.5*(b1+b2);
          if(newai > 0 && newai < C) L.b= b1;
          if(newaj > 0 && newaj < C) L.b= b2;

          alphaChanged++;

        } // end alpha_i needed updating
      } // end for i=1..N

      iter++;
      //console.log("iter number %d, alphaChanged = %d", iter, alphaChanged);
      if(alphaChanged == 0) passes++;
      else passes= 0;

    } // end outer loop

    // if the user was using a linear kernel, lets also compute and store the
    // weights. This will speed up evaluations during testing time
    if(L.kernelType === "linear") {

      // compute weights and store them
      L.w = new Array(L.D);
      for(var j=0;j<L.D;j++) {
        var s= 0.0;
        for(var i=0;i<L.N;i++) {
          s+= L.alpha[i] * labels[i] * data[i][j];
        }
        L.w[j] = s;
        L.usew_ = true;
      }
    } else {

      // okay, we need to retain all the support vectors in the training data,
      // we can't just get away with computing the weights and throwing it out

      // But! We only need to store the support vectors for evaluation of testing
      // instances. So filter here based on L.alpha[i]. The training data
      // for which L.alpha[i] = 0 is irrelevant for future. 
      var newdata = [];
      var newlabels = [];
      var newalpha = [];
      for(var i=0;i<L.N;i++) {
        //console.log("alpha=%f", L.alpha[i]);
        if(L.alpha[i] > alphatol) {
          newdata.push(L.data[i]);
          newlabels.push(L.labels[i]);
          newalpha.push(L.alpha[i]);
        }
      }

      // store data and labels
      L.data = newdata;
      L.labels = newlabels;
      L.alpha = newalpha;
      L.N = L.data.length;
      // console.log("filtered training data from %d to %d support vectors.", data.length, L.data.length);
    }

    var trainstats = {};
    trainstats.iters= iter;
    trainstats.passes= passes;
    return trainstats;
  }, 

  // inst is an array of length D. Returns margin of given example
  // this is the core prediction function. All others are for convenience mostly
  // and end up calling this one somehow.
  marginOne: function(L,inst) {

    var f = L.b;
    // if the linear kernel was used and w was computed and stored,
    // (i.e. the svm has fully finished training)
    // the internal class variable usew_ will be set to true.
    if(L.usew_) {

      // we can speed this up a lot by using the computed weights
      // we computed these during train(). This is significantly faster
      // than the version below
      for(var j=0;j<L.D;j++) {
        f += inst[j] * L.w[j];
      }

    } else {

      for(var i=0;i<L.N;i++) {
        f += L.alpha[i] * L.labels[i] * L.kernel(inst, L.data[i]);
      }
    }
    return f;
  },

  predict: function(L,inst) { 
    L.kernel=getKernel(L.options.kernel); // update kernel
    var result = SVM2.code.marginOne(L,inst);
    if (L.threshold===false) return result;
    else return  result > L.threshold ? 1 : -1; 
  },

  // data is an NxD array. Returns array of margins.
  margins: function(L,data) {

    // go over support vectors and accumulate the prediction. 
    var N = data.length;
    var margins = new Array(N);
    for(var i=0;i<N;i++) {
      margins[i] = SVM2.code.marginOne(L,data[i]);
    }
    return margins;

  },

  kernelResult: function(L, i, j) {
    if (L.kernelResults) {
      return L.kernelResults[i][j];
    }
    return L.kernel(L.data[i], L.data[j]);
  },

  // data is NxD array. Returns array of 1 or -1, predictions
  predictN: function(L,data) {
    L.kernel=getKernel(L.options.kernel); // update kernel
    var margs = SVM2.code.margins(L, data);
    for(var i=0;i<margs.length;i++) {
      if (L.threshold!=false)
        margs[i] = margs[i] > L.threshold ? 1 : -1;
    }
    return margs;
  },

  // THIS FUNCTION IS NOW DEPRECATED. WORKS FINE BUT NO NEED TO USE ANYMORE. 
  // LEAVING IT HERE JUST FOR BACKWARDS COMPATIBILITY FOR A WHILE.
  // if we trained a linear svm, it is possible to calculate just the weights and the offset
  // prediction is then yhat = sign(X * w + b)
  getWeights: function(L) {

    // DEPRECATED
    var w= new Array(L.D);
    for(var j=0;j<L.D;j++) {
      var s= 0.0;
      for(var i=0;i<L.N;i++) {
        s+= L.alpha[i] * L.labels[i] * L.data[i][j];
      }
      w[j]= s;
    }
    return {w: w, b: L.b};
  },

  toJSON: function(L) {

    if(L.kernelType === "custom") {
      console.log("Can't save this SVM because it's using custom, unsupported kernel...");
      return {};
    }

    json = {}
    json.N = L.N;
    json.D = L.D;
    json.b = L.b;

    json.kernelType = L.kernelType;
    if(L.kernelType === "linear") { 
      // just back up the weights
      json.w = L.w; 
    }
    if(L.kernelType === "rbf") { 
      // we need to store the support vectors and the sigma
      json.rbfSigma = L.rbfSigma; 
      json.data = L.data;
      json.labels = L.labels;
      json.alpha = L.alpha;
    }

    return json;
  },

  fromJSON: function(L,json) {

    this.N = json.N;
    this.D = json.D;
    this.b = json.b;

    this.kernelType = json.kernelType;
    if(this.kernelType === "linear") { 

      // load the weights! 
      this.w = json.w; 
      this.usew_ = true; 
      this.kernel = linearKernel; // this shouldn't be necessary
    }
    else if(this.kernelType == "rbf") {

      // initialize the kernel
      this.rbfSigma = json.rbfSigma; 
      this.kernel = makeRbfKernel(this.rbfSigma);

      // load the support vectors
      this.data = json.data;
      this.labels = json.labels;
      this.alpha = json.alpha;
    } else {
      console.log("ERROR! unrecognized kernel type." + this.kernelType);
    }
  }
}

// Kernels
function makeRbfKernel(sigma) {
  return function(v1, v2) {
    var s=0;
    for(var q=0;q<v1.length;q++) { s += (v1[q] - v2[q])*(v1[q] - v2[q]); } 
    return Math.exp(-s/(2.0*sigma*sigma));
  }
}

function linearKernel(v1, v2) {
  var s=0; 
  for(var q=0;q<v1.length;q++) { s += v1[q] * v2[q]; } 
  return s;
}

// Misc utility functions
// generate random floating point number between a and b
function randf(a, b) {
  return Math.random()*(b-a)+a;
}

// generate random integer between a and b (b excluded)
function randi(a, b) {
   return Math.floor(Math.random()*(b-a)+a);
}

// create vector of zeros of length n
function zeros(n) {
  var arr= new Array(n);
  for(var i=0;i<n;i++) { arr[i]= 0; }
  return arr;
}

module.exports = SVM2
};
BundleModuleCode['plugins/ml/mlp']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     joonkukang, Stefan Bosse
 **    $INITIAL:     (C) 2014, joonkukang
 **    $MODIFIED:    (C) 2006-2021 bLAB by sbosse
 **    $VERSION:     1.3.5
 **
 **    $INFO:
 **
 ** Multilayer Perceptron Artificial Neural Network
 **
 ** References : http://cs229.stanford.edu/materials/smo.pdf . simplified smo algorithm 
 **
 ** Portable model
 **
 **    $ENDOFINFO
 */
/**
 */
var math = Require('plugins/ml/math');
var HiddenLayer = Require('plugins/ml/HiddenLayer');

var MLP = function (settings) {
    var L = {}
    var self = L;
    self.x = settings.input||settings.x;
    self.y = settings.output||settings.y;
    self.sigmoidLayers = [];
    self.nLayers = settings.hidden_layer_sizes.length;
    self.settings = {
        verbose : settings.verbose || 0, // 0 : nothing, 1 : info, 2: warn
        hidden_layers : settings.hidden_layer_sizes
    };
    var i;
    for(i=0 ; i<self.nLayers+1 ; i++) {
        var inputSize, layerInput;
        if(i == 0)
            inputSize = settings.n_ins;
        else
            inputSize = settings.hidden_layer_sizes[i-1];

        if(i == 0)
            layerInput = self.x||math.oneMat(1,inputSize);
        else
            layerInput = HiddenLayer.code.sampleHgivenV(self.sigmoidLayers[self.sigmoidLayers.length-1]);

        var sigmoidLayer;
        if(i == self.nLayers) {
            sigmoidLayer = HiddenLayer({
                'input' : layerInput,
                'n_in' : inputSize,
                'n_out' : settings.n_outs,
                'activation' : math.sigmoid,
                'W' : (typeof settings.w_array === 'undefined')? undefined : settings.w_array[i],
                'b' : (typeof settings.b_array === 'undefined')? undefined : settings.b_array[i]
            });
        } else {
            sigmoidLayer = HiddenLayer({
                'input' : layerInput,
                'n_in' : inputSize,
                'n_out' : settings.hidden_layer_sizes[i],
                'activation' : math.sigmoid,
                'W' : (typeof settings.w_array === 'undefined')? undefined : settings.w_array[i],
                'b' : (typeof settings.b_array === 'undefined')? undefined : settings.b_array[i]
            });
        }
        self.sigmoidLayers.push(sigmoidLayer);
    }
    return L
};

MLP.code = {
  train : function(L,settings,data) {
    var self = L;
    var epochs = 1000;
    if(typeof settings.epochs !== 'undefined')
        epochs = settings.epochs;
    if (typeof data != 'undefined') {
      self.x=data.x;
      self.y=data.y;
    }
    if (typeof settings.x != 'undefined') {
      self.x=settings.x;
      self.y=settings.y;
    }
    self.settings.iterations=epochs;
    
    // calculate mean square error
    function error(output,target) {
      var e=0;
      for(var i=0;i<output.length;i++) {
        for(var j=0;j<output[i].length;j++) {
          e+=Math.pow(output[i][j]-target[i][j],2);
        }
      }
      return e/target.length;
    }
    var epoch;
    var currentProgress = 1;
    for(epoch=0 ; epoch < epochs ; epoch++) {

        // Feed Forward
        var i;
        var layerInput = [];
        layerInput.push(self.x);
        for(i=0; i<self.nLayers+1 ; i++) {
            layerInput.push(HiddenLayer.code.output(self.sigmoidLayers[i],layerInput[i]));
        }
        var output = layerInput[self.nLayers+1];
        // Back Propagation
        var delta = new Array(self.nLayers + 1);
        delta[self.nLayers] = math.mulMatElementWise(math.minusMat(self.y, output),
            math.activateMat(HiddenLayer.code.linearOutput(self.sigmoidLayers[self.nLayers],layerInput[self.nLayers]), math.dSigmoid));
        if (L.settings.verbose > 2) MLP.code.log('MLP',epoch,'delta[output]: ',math.shape(delta[self.nLayers]),'=',delta[self.nLayers],error(output,self.y));
        /*
         self.nLayers = 3 (3 hidden layers)
         delta[3] : ouput layer
         delta[2] : 3rd hidden layer, delta[0] : 1st hidden layer
         */
        for(i = self.nLayers - 1; i>=0 ; i--) {
            delta[i] = math.mulMatElementWise(HiddenLayer.code.backPropagate(self.sigmoidLayers[i+1],delta[i+1]),
                math.activateMat(HiddenLayer.code.linearOutput(self.sigmoidLayers[i],layerInput[i]), math.dSigmoid));
        }
        // Update Weight, Bias
        for(var i=0; i<self.nLayers+1 ; i++) {
            var deltaW = math.activateMat(math.mulMat(math.transpose(layerInput[i]),delta[i]),function(x){return 1. * x / self.x.length;})
            if (L.settings.verbose > 2) 
              MLP.code.log(i,math.shape(delta[i]),math.shape(deltaW),math.shape(layerInput[i]),math.shape(math.mulMat(math.transpose(layerInput[i]),delta[i])));
            var deltaB = math.meanMatAxis(delta[i],0);
            self.sigmoidLayers[i].W = math.addMat(self.sigmoidLayers[i].W,deltaW);
            self.sigmoidLayers[i].b = math.addVec(self.sigmoidLayers[i].b,deltaB);
        }

        if(self.settings.verbose > 0) {
            var progress = (1.*epoch/epochs)*100;
            if(progress > currentProgress) {
                MLP.code.log("MLP "+progress.toFixed(0)+"% Completed ("+epoch+" epochs). Mean Squared Error="+error(output,self.y));
                currentProgress+=8;
            }
        }
    }
    var ce = MLP.code.getReconstructionCrossEntropy(L);
    if(self.settings.verbose > 0)
        MLP.code.log("MLP Final Cross Entropy : ",ce);
    L.error=error(output,self.y);
    L.crossEntropy=ce;
    return {crossEntropy:ce, Error:L.error}
  },
  getReconstructionCrossEntropy : function(L) {
    var self = L;
    var reconstructedOutput = MLP.code.predict(L, self.x);
    var a = math.activateTwoMat(self.y,reconstructedOutput,function(x,y){
        return x*Math.log(Math.max(1E-6,y));
    });
    var b = math.activateTwoMat(self.y,reconstructedOutput,function(x,y){
        return (1-x)*Math.log(1-Math.min(0.9999999999,y));
    });

    var crossEntropy = -math.meanVec(math.sumMatAxis(math.addMat(a,b),1));
    return crossEntropy
  },
  predict : function(L,x) {
    var self = L;
    var output = x;
    for(i=0; i<self.nLayers+1 ; i++) {
        output = HiddenLayer.code.output(self.sigmoidLayers[i],output);
    }
    return output;
  },
  set : function(L,property,value) {
    var self = L;
    self.settings[property] = value;
  },
  log : function () {
    console.log.bind(console).apply(this,arguments)
  },
  version : '1.3.5',
}
module.exports = MLP
};
BundleModuleCode['plugins/ml/HiddenLayer']=function (module,exports,global,process){
/**
 * Created by joonkukang on 2014. 1. 12..
 */
var math = Require('plugins/ml/math');
var HiddenLayer = module.exports = function (settings) {
    var L = {}
    var self = L;
    self.input = settings['input'];

    if(typeof settings['W'] === 'undefined') {
        var a = 1. / settings['n_in'];
        settings['W'] = math.randMat(settings['n_in'],settings['n_out'],-a,a);
    }
    if(typeof settings['b'] === 'undefined')
        settings['b'] = math.zeroVec(settings['n_out']);
    if(typeof settings['activation'] === 'undefined')
        settings['activation'] = math.sigmoid;

    self.W = settings['W'];
    self.b = settings['b'];
    self.activation = settings['activation'];
    return L;
}

HiddenLayer.code = {
  output : function(L,input) {
    var self = L;
    if(typeof input !== 'undefined')
        self.input = input;

    var linearOutput = math.addMatVec(math.mulMat(self.input,self.W),self.b);
    return math.activateMat(linearOutput,self.activation);
  },
  linearOutput : function(L,input) { // returns the value before activation.
    var self = L;
    if(typeof input !== 'undefined')
        self.input = input;

    var linearOutput = math.addMatVec(math.mulMat(self.input,self.W),self.b);
    return linearOutput;
  },
  backPropagate : function (L,input) { // example+num * n_out matrix
    var self = L;
    if(typeof input === 'undefined')
        throw new Error("No BackPropagation Input.")

    var linearOutput = math.mulMat(input, math.transpose(self.W));
    return linearOutput;
  },
  sampleHgivenV : function(L,input) {
    var self = L;
    if(typeof input !== 'undefined')
        self.input = input;

    var hMean = HiddenLayer.code.output(self);
    var hSample = math.probToBinaryMat(hMean);
    return hSample;
  }
}
};
BundleModuleCode['plugins/ml/id3']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Ankit Kuwadekar, Stefan Bosse
 **    $INITIAL:     (C) 2014, Ankit Kuwadekar
 **    $MODIFIED:    (C) 2006-2018 bLAB by sbosse
 **    $VERSION:     1.3.1X
 **
 **    $INFO:
 **
 ** ID3 Decision Tree Algorithm supporting categorical values only
 ** Portable model
 **
 ** New
 **   predict with nn selection
 **
 **    $ENDOFINFO
 */
var Io = Require('com/io');
var Comp = Require('com/compat');
var current=none;
var Aios=none;
var _ = undefined;
var none = null;


/**
 * Map of valid tree node types
 * @constant
 * @static
 */
var NODE_TYPES = {
  RESULT: 'result',
  FEATURE: 'feature',
  FEATURE_VALUE: 'feature_value'
};

function isEqual(a,b) { return a==b }

/**
 * Predicts class for sample
 */
function predict(model,sample) {
  var root = model;
  while (root.type !== NODE_TYPES.RESULT) {
    var attr = root.name;
    var sampleVal = sample[attr];
    var childNode = Comp.array.min(root.vals, function(node) {
      if (typeof node.value == 'number' && typeof sampleVal == 'number')  
        return Math.pow(node.value - sampleVal,2);
      else
        return node.value == sampleVal? 0:1;
    });
    if (childNode){
      root = childNode.child;
    } else {
      root = root.vals[0].child;
    }
  }
  return root.value;
};

/**
 * Evalutes prediction accuracy on samples
 */
function evaluate(model,target,samples) {
   var total = 0;
   var correct = 0;

   Comp.array.iter(samples, function(s) {
     total++;
     var pred = predict(model,s);
     var actual = s[target];
     if (isEqual(pred,actual)) {
       correct++;
     }
   });
   return correct / total;
};

/**
 * Creates a new tree
 */
function createTree(data, target, features) {
  var targets = Comp.array.unique(Comp.array.pluck(data, target));
  
  if (targets.length == 1) {
    return {
      type:   NODE_TYPES.RESULT,
      value:  targets[0],
      name:   targets[0],
      // alias: targets[0] + randomUUID()
    };
  }

  if (features.length == 0) {
    var topTarget = mostCommon(targets);
    return {
      type:   NODE_TYPES.RESULT,
      value:  topTarget,
      name:   topTarget,
      // alias: topTarget + randomUUID()
    };
  }

  var bestFeature = maxGain(data, target, features);
  var remainingFeatures = Comp.array.without(features, bestFeature);
  var possibleValues = Comp.array.unique(Comp.array.pluck(data, bestFeature));

  var node = {
    name: bestFeature,
    // alias: bestFeature + randomUUID()
  };

  node.type = NODE_TYPES.FEATURE;
  node.vals = Comp.array.map(possibleValues, function(v) {
    var _newS = data.filter(function(x) {
      return x[bestFeature] == v
    });

    var child_node = {
      value: v,
      // alias: v + randomUUID(),
      type: NODE_TYPES.FEATURE_VALUE
    };

    child_node.child = createTree(_newS, target, remainingFeatures);
    return child_node;
  });

  return node;
}

/**
 * Computes Max gain across features to determine best split
 * @private
 */
function maxGain(data, target, features) {
  var gains=[];
  var maxgain= Comp.array.max(features, function(element) {
    var g = gain(data, target, element);
    gains.push(element+':'+g);
    return g;
  });
  return maxgain;
}

/**
 * Computes entropy of a list
 * @private
 */
function entropy(vals) {
  var uniqueVals = Comp.array.unique(vals);
  var probs = uniqueVals.map(function(x) {
    return prob(x, vals)
  });

  var logVals = probs.map(function(p) {
    return -p * log2(p)
  });

  return logVals.reduce(function(a, b) {
    return a + b
  }, 0);
}

/**
 * Computes gain
 * @private
 */
function gain(data, target, feature) {
  var attrVals = Comp.array.unique(Comp.array.pluck(data, feature));
  var setEntropy = entropy(Comp.array.pluck(data, target));
  var setSize = data.length;

  var entropies = attrVals.map(function(n) {
    var subset = data.filter(function(x) {
      return x[feature] === n
    });

    return (subset.length / setSize) * entropy(Comp.array.pluck(subset, target));
  });

  // var entropyData = entropyV(Comp.array.pluck(data, feature),eps);
  // console.log('Feat '+feature+':'+entropyData);
  var sumOfEntropies = entropies.reduce(function(a, b) {
    return a + b
  }, 0);
  return setEntropy - sumOfEntropies;
}

/**
 * Computes probability of of a given value existing in a given list
 * @private
 */
function prob(value, list) {
  var occurrences = Comp.array.filter(list, function(element) {
    return element === value
  });

  var numOccurrences = occurrences.length;
  var numElements = list.length;
  return numOccurrences / numElements;
}

/**
 * Computes Log with base-2
 * @private
 */
function log2(n) {
  return Math.log(n) / Math.log(2);
}

/**
 * Finds element with highest occurrence in a list
 * @private
 */
function mostCommon(list) {
  var elementFrequencyMap = {};
  var largestFrequency = -1;
  var mostCommonElement = null;

  list.forEach(function(element) {
    var elementFrequency = (elementFrequencyMap[element] || 0) + 1;
    elementFrequencyMap[element] = elementFrequency;

    if (largestFrequency < elementFrequency) {
      mostCommonElement = element;
      largestFrequency = elementFrequency;
    }
  });

  return mostCommonElement;
}

/**
 * Generates random UUID
 * @private
 */
function randomUUID() {
  return "_r" + Math.random().toString(32).slice(2);
}

function depth(model) {
  switch (model.type) {
    case NODE_TYPES.RESULT: return 1;
    case NODE_TYPES.FEATURE: 
      return 1+Comp.array.max(model.vals.map(function (val) {
        return depth(val);
      }));
    case NODE_TYPES.FEATURE_VALUE: 
      return 1+depth(model.child);   
  }
  return 0;
}


function info(model) {
  var vl = vars(model);
  return {
    depth:depth(model),
    nodes:vl.length,
    vars:vl.unique(),
  }
}


function print(model,indent) {
  var NL = '\n',
      line='',sep,
      sp = function () {return Comp.string.create(indent);};
  if (indent==undefined) indent=0;
  switch (model.type) {
    case NODE_TYPES.RESULT: 
      return ' -> '+model.name;
    case NODE_TYPES.FEATURE:
      line=NL+sp()+'($'+model.name+'?'+NL;
      sep='';
      Comp.array.iter(model.vals,function (v) {
        line += sep+print(v,indent+2)+NL;
        sep='';
      }); 
      return line+sp()+')';
    case NODE_TYPES.FEATURE_VALUE: 
      return sp()+model.value+':'+print(model.child,indent+2);   
  }
  return 0;
}

function vars(model) {
  switch (model.type) {
    case NODE_TYPES.RESULT: return [];
    case NODE_TYPES.FEATURE: 
      return [model.name].concat(Comp.array.flatten(model.vals.map(vars)));
    case NODE_TYPES.FEATURE_VALUE: 
      return vars(model.child);   
  }
  return [];
}

module.exports =  {
  NODE_TYPES:NODE_TYPES,
  createTree:createTree,
  depth:depth,
  entropy:entropy,
  evaluate:evaluate,
  info:info,
  predict:predict,
  print:print,
  current:function (module) { current=module.current; Aios=module;}
};

};
BundleModuleCode['plugins/ml/C45']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     ?, Stefan Bosse
 **    $INITIAL:     (C) ?
 **    $MODIFIED:    (C) 2006-2020 bLAB by sbosse
 **    $VERSION:     1.1.8X
 **
 **    $INFO:
 **
 ** C45 Decision Tree ML Algorithm
 **
 ** Portable model
 **
 **    $ENDOFINFO
 */
'use strict';
var Io = Require('com/io');
var Comp = Require('com/compat');
var current=none;
var Aios=none;
var _ = undefined;
var none = null;

var NODE_TYPES = {
  RESULT: 'result',
  FEATURE_NUMBER: 'feature_number',     // Number value node (cut split)
  FEATURE_VALUE: 'feature_value',       // Category value
  FEATURE_CATEGORY: 'feature_category'  // Symbolic variable node (split)
};

function unique(col) {
  var u = {}, a = [];
  for(var i = 0, l = col.length; i < l; ++i){
    if(u.hasOwnProperty(col[i])) {
      continue;
    }
    a.push(col[i]);
    u[col[i]] = 1;
  }
  return a;
}

function find(col, pred) {
  var value;
  col.forEach(function(item) {
    var result = pred(item);
    if (result) {
      value = item;
    }
  });
  return value;
}

function max(array, fn) {
  var max = -Infinity;
  var index;
  for (var i = 0; i < array.length; i++) {
    var result = fn(array[i]);
    if (result >= max) {
      max = result;
      index = i;
    }
  }
  return typeof index !== 'undefined' ? array[index] : max;
}

function sortBy(col, fn) {
 col = [].slice.call(col);
 return col.sort(fn);
}

var C45 = {
  create: function () {
    return {
      features : [],
      targets: [],
      model: null
    }
  },
  /**
   * train
   *
   * @param {object} options
   * @param {array} options.data - training data
   * @param {string} options.target - class label
   * @param {array} options.features - features names
   * @param {array} options.featureTypes - features type (ie 'category', 'number')
   */
  train: function(model,options) {
    var data = options.data,
        target = options.target,
        features = options.features,
        featureTypes = options.featureTypes;
    featureTypes.forEach(function(f) {
      if (['number','category'].indexOf(f) === -1) {
        throw new Error('C4.5: Unrecognized option!');
      }
    });

    var targets = unique(data.map(function(d) {
      return d[d.length-1];
    }));
    
    model.features = features;
    model.targets = targets;
    // model is the generated tree structure
    model.model = C45._c45(model, data, target, features, featureTypes, 0);
  },

  _c45: function(model, data, target, features, featureTypes, depth) {
    var targets = unique(data.map(function(d) {
      return d[d.length-1];
    }));

    if (!targets.length) {
      // console.log(data,features,featureTypes,depth);
      return {
        type: 'result',
        value: '?',
        name: '?'
      };
    }

    if (targets.length === 1) {
      return {
        type: 'result',
        value: targets[0],
        name: targets[0]
      };
    }

    if (!features.length) {
      var topTarget = C45.mostCommon(targets);
      return {
        type: 'result',
        value: topTarget,
        name: topTarget
      };
    }

    var bestFeatureData = C45.maxGain(model, data, target, features, featureTypes);
    var bestFeature = bestFeatureData.feature;

    var remainingFeatures = features.slice(0);
    remainingFeatures.splice(features.indexOf(bestFeature), 1);

    if (featureTypes[model.features.indexOf(bestFeature)] === 'category') {
      var possibleValues = unique(data.map(function(d) {
        return d[model.features.indexOf(bestFeature)];
      }));
      var node = {
        name: bestFeature,
        type: 'feature_category',
        values: possibleValues.map(function(v) {
          var newData = data.filter(function(x) {
            return x[model.features.indexOf(bestFeature)] === v;
          });
          var childNode = {
            name: v,
            type: 'feature_value',
            child: C45._c45(model, newData, target, remainingFeatures, featureTypes, depth+1)
          };
          return childNode;
        })
      };
    } else if (featureTypes[model.features.indexOf(bestFeature)] === 'number') {
      var possibleValues = unique(data.map(function(d) {
        return d[model.features.indexOf(bestFeature)];
      }));
      var node = {
        name: bestFeature,
        type: 'feature_number',
        cut: bestFeatureData.cut,
        values: []
      };

      var newDataRight = data.filter(function(x) {
        return parseFloat(x[model.features.indexOf(bestFeature)]) > bestFeatureData.cut;
      });
      var childNodeRight = {
        name: bestFeatureData.cut.toString(),
        type: 'feature_value',
        child: C45._c45(model, newDataRight, target, remainingFeatures, featureTypes, depth+1)
      };
      node.values.push(childNodeRight);

      var newDataLeft = data.filter(function(x) {
        return parseFloat(x[model.features.indexOf(bestFeature)]) <= bestFeatureData.cut;
      });
      var childNodeLeft = {
        name: bestFeatureData.cut.toString(),
        type: 'feature_value',
        child: C45._c45(model, newDataLeft, target, remainingFeatures, featureTypes, depth+1),
      };
      node.values.push(childNodeLeft);
    }
    return node;
  },


  classify: function (model,sample) {
    // root is feature (attribute) containing all sub values
    var childNode, featureName, sampleVal;
    var root = model.model;

    if (typeof root === 'undefined') {
      callback(new Error('model is undefined'));
    }

    while (root.type != NODE_TYPES.RESULT) {

      if (root.type == NODE_TYPES.FEATURE_NUMBER) {
        // feature number attribute
        featureName = root.name;
        sampleVal = parseFloat(sample[featureName]);
        if (sampleVal <= root.cut) {
          childNode = root.values[1];
        } else {
          childNode = root.values[0];
        }
      } else if (root.type == NODE_TYPES.FEATURE_CATEGORY) {
        // feature category attribute
        featureName = root.name;
        sampleVal = sample[featureName];

        // sub value , containing n childs
        childNode = find(root.values, function(x) {
          return x.name === sampleVal;
        });
      }

      // non trained feature
      if (typeof childNode === 'undefined') {
        return 'unknown';
      }
      root = childNode.child;
    }
    return root.value;
  },

  conditionalEntropy: function(model, data, feature, cut, target) {
    var subset1 = data.filter(function(x) {
      return parseFloat(x[model.features.indexOf(feature)]) <= cut;
    });
    var subset2 = data.filter(function(x) {
      return parseFloat(x[model.features.indexOf(feature)]) > cut;
    });
    var setSize = data.length;
    return subset1.length/setSize * C45.entropy(model,
      subset1.map(function(d) {
        return d[d.length-1];
      })
    ) + subset2.length/setSize*C45.entropy(model,
      subset2.map(function(d) {
        return d[d.length-1];
      })
    );
  },

  count: function(target, targets) {
    return targets.filter(function(t) {
      return t === target;
    }).length;
  },

  depth : function (model) {
    switch (model.type) {
      case NODE_TYPES.RESULT: 
        return 1;
      case NODE_TYPES.FEATURE_NUMBER:
      case NODE_TYPES.FEATURE_CATEGORY:
        return 1+Comp.array.max(model.values.map(function (v) {
          return C45.depth(v)
        })); 
      case NODE_TYPES.FEATURE_VALUE:
        return 1+C45.depth(model.child);
    }
    return 0; 
  },
  
  entropy: function(model, vals) {
    var uniqueVals = unique(vals);
    var probs = uniqueVals.map(function(x) {
      return C45.prob(x, vals);
    });
    var logVals = probs.map(function(p) {
      return -p * C45.log2(p);
    });
    return logVals.reduce(function(a, b) {
      return a + b;
    }, 0);
  },

  gain: function(model, data, target, features, feature, featureTypes) {
    var setEntropy = C45.entropy(model, data.map(function(d) {
      return d[d.length-1];
    }));
    if (featureTypes[model.features.indexOf(feature)] === 'category') {
      var attrVals = unique(data.map(function(d) {
        return d[model.features.indexOf(feature)];
      }));
      var setSize = data.length;
      var entropies = attrVals.map(function(n) {
        var subset = data.filter(function(x) {
          return x[feature] === n;
        });
        return (subset.length/setSize) * C45.entropy(model,
          subset.map(function(d) {
            return d[d.length-1];
          })
        );
      });
      var sumOfEntropies = entropies.reduce(function(a, b) {
        return a + b;
      }, 0);
      return {
        feature: feature,
        gain: setEntropy - sumOfEntropies,
        cut: 0
      };
    } else if (featureTypes[model.features.indexOf(feature)] === 'number') {
      var attrVals = unique(data.map(function(d) {
        return d[model.features.indexOf(feature)];
      }));
      var gainVals = attrVals.map(function(cut) {
        var cutf = parseFloat(cut);
        var gain = setEntropy - C45.conditionalEntropy(model, data, feature, cutf, target);
        return {
            feature: feature,
            gain: gain,
            cut: cutf
        };
      });
      var maxgain = max(gainVals, function(e) {
        return e.gain;
      });
      return maxgain;
    }
  },
  
  info : function (model) {
    var vl = C45.vars(model);
    return {
      depth:C45.depth(model),
      nodes:vl.length,
      vars:vl.unique(),
    }
  },

  
  log2: function(n) {
    return Math.log(n) / Math.log(2);
  },
  
  maxGain: function(model, data, target, features, featureTypes) {
    var g45 = features.map(function(feature) {
      return C45.gain(model, data, target, features, feature, featureTypes);
    });
    return max(g45, function(e) {
      return e.gain;
    });
  },


  mostCommon: function(targets) {
    return sortBy(targets, function(target) {
      return C45.count(target, targets);
    }).reverse()[0];
  },

  /** Print the tree
  *
  */
  print: function (model,indent) {
    var NL = '\n',
        line='',sep;
    if (indent==undefined) indent=0;
    if (!model) return '';
    var sp = function () {return Comp.string.create(indent);};
    switch (model.type) {
      case NODE_TYPES.RESULT: 
        return sp()+'-> '+model.name+NL;
      case NODE_TYPES.FEATURE_CATEGORY:
        line=sp()+'$'+model.name+'?'+NL;
        Comp.array.iter(model.values,function (v) {
          line += C45.print(v,indent+2);
        }); 
        return line;
      case NODE_TYPES.FEATURE_NUMBER:
        line = sp()+'$'+model.name+'>'+model.cut+'?'+NL;
        if (model.values[0].type==NODE_TYPES.FEATURE_VALUE)
          line = line+C45.print(model.values[0].child,indent+2);
        else
          line = line+C45.print(model.values[0],indent+2);
        line = line+sp()+'$'+model.name+'<='+model.cut+'?'+NL;
        if (model.values[0].type==NODE_TYPES.FEATURE_VALUE)
          line = line+C45.print(model.values[1].child,indent+2);
        else
          line = line+C45.print(model.values[1],indent+2);
        return line;
      case NODE_TYPES.FEATURE_VALUE:
        line=sp()+''+model.name+NL;
        line += C45.print(model.child,indent+2);
        return line;
    }
    return 'model?';
  },

  prob: function(target, targets) {
    return C45.count(target,targets)/targets.length;
  },

  vars : function (model) {
    switch (model.type) {
      case NODE_TYPES.RESULT: return [];
      case NODE_TYPES.FEATURE_NUMBER: 
      case NODE_TYPES.FEATURE_CATEGORY: 
        return [model.name].concat(Comp.array.flatten(model.values.map(C45.vars)));
      case NODE_TYPES.FEATURE_VALUE: 
        return C45.vars(model.child);   
    }
    return [];
  },

};

module.exports = {
  classify: C45.classify,
  create:   C45.create,
  depth:    function (model) { return C45.depth(model.model) },
  entropy:  C45.entropy,
  info:     function (model) { return C45.info(model.model) },
  log2:     C45.log2,
  print:    function (model,indent) { return C45.print(model.model,indent) },
  unique:   unique,
  train:    C45.train,
  current:  function (module) { current=module.current; Aios=module;}  
}
};
BundleModuleCode['plugins/ml/text']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Stefan Bosse
 **    $INITIAL:     (C) 2006-2019 BSSLAB
 **    $CREATED:     5-3-19 by sbosse.
 **    $VERSION:     1.1.1X
 **
 **    $INFO:
 **
 **  JavaScript AIOS Machine Learning API: Text analysis
 **
 ** Portable model
 **
 **    $ENDOFINFO
 */
'use strict';
var Io = Require('com/io');
var Comp = Require('com/compat');
var current=none;
var Aios=none;
var _ = undefined;
var none = null;

function similarity(s1, s2) {
  var longer = s1;
  var shorter = s2;
  if (s1.length < s2.length) {
    longer = s2;
    shorter = s1;
  }
  var longerLength = longer.length;
  if (longerLength == 0) {
    return 1.0;
  }
  return (longerLength - editDistance(longer, shorter)) / parseFloat(longerLength);
}
function editDistance(s1, s2) {
  s1 = s1.toLowerCase();
  s2 = s2.toLowerCase();

  var costs = new Array();
  for (var i = 0; i <= s1.length; i++) {
    var lastValue = i;
    for (var j = 0; j <= s2.length; j++) {
      if (i == 0)
        costs[j] = j;
      else {
        if (j > 0) {
          var newValue = costs[j - 1];
          if (s1.charAt(i - 1) != s2.charAt(j - 1))
            newValue = Math.min(Math.min(newValue, lastValue),
              costs[j]) + 1;
          costs[j - 1] = lastValue;
          lastValue = newValue;
        }
      }
    }
    if (i > 0)
      costs[s2.length] = lastValue;
  }
  return costs[s2.length];
}


// Create a model
function create(strings,options) {
  return {
    data:strings
  }
}

// Classify one sample; return best matching string
function classify(model,sample) {
  var matches = model.data.map(function (h) {
    return {
      match:similarity(h,sample),
      string:h
    }
  }).sort(function (a,b) {
    if (a.match < b.match) return 1; else return -1;
  });
  return matches[0];
}

module.exports = {
  classify:classify,
  create:create,
  similarity:similarity,
  current:function (module) { current=module.current; Aios=module;}  
}
};
BundleModuleCode['plugins/ml/rf']=function (module,exports,global,process){
// MIT License
// Random Forest Trees (only binary classifier)
// Andrej Karpathy
// @blab+ 
// https://github.com/karpathy/forestjs


var RandomForest = function(options) {
  var L = {};
  return L
}

RandomForest.code = {

  /*
  data is 2D array of size N x D of examples
  labels is a 1D array of labels (only -1 or 1 for now). In future will support multiclass or maybe even regression
  options.numTrees can be used to customize number of trees to train (default = 100)
  options.maxDepth is the maximum depth of each tree in the forest (default = 4)
  options.numTries is the number of random hypotheses generated at each node during training (default = 10)
  options.trainFun is a function with signature "function myWeakTrain(data, labels, ix, options)". Here, ix is a list of 
                   indeces into data of the instances that should be payed attention to. Everything not in the list 
                   should be ignored. This is done for efficiency. The function should return a model where you store 
                   variables. (i.e. model = {}; model.myvar = 5;) This will be passed to testFun.
  options.testFun is a function with signature "funtion myWeakTest(inst, model)" where inst is 1D array specifying an example,
                   and model will be the same model that you return in options.trainFun. For example, model.myvar will be 5.
                   see decisionStumpTrain() and decisionStumpTest() downstairs for example.
  */
  train: function(L, data, labels, options) {
    options = options || {};
    L.options = options;
    
    L.numTrees = options.numTrees || 100;

    // initialize many trees and train them all independently
    L.trees= new Array(L.numTrees);
    for(var i=0;i<L.numTrees;i++) {
      L.trees[i] = DecisionTree();
      DecisionTree.code.train(L.trees[i],data, labels, options);
    }
  },

  /*
  inst is a 1D array of length D of an example. 
  returns the probability of label 1, i.e. a number in range [0, 1]
  */
  predictOne: function(L, inst) {

    // have each tree predict and average out all votes
    var dec=0;
    for(var i=0;i<L.numTrees;i++) {
      dec += DecisionTree.code.predictOne(L.trees[i],inst);
    }
    dec /= L.numTrees;
    return dec;
  },

  // convenience function. Here, data is NxD array. 
  // returns probabilities of being 1 for all data in an array.
  predict: function(L, data) {

    var probabilities= new Array(data.length);
    for(var i=0;i<data.length;i++) {
      probabilities[i]= RandomForest.code.predictOne(L,data[i]);
    }
    return probabilities;

  }

}

// represents a single decision tree
var DecisionTree = function(options) {
  var L = {};
  return L
}

DecisionTree.code = {

  train: function(L, data, labels, options) {

    options = options || {};
    var maxDepth = options.maxDepth || 4;
    var weakType = options.type || 0;

    
    var trainFun= decisionStumpTrain;
    var testFun= decisionStumpTest;

    if(options.trainFun) trainFun = options.trainFun;
    if(options.testFun) testFun = options.testFun;

    if(weakType == 0) {
      // Default
      trainFun  = decisionStumpTrain;
      testFun   = decisionStumpTest;
    }
    if(weakType) {
      trainFun  = decision2DStumpTrain;
      L.testFun = testFun = decision2DStumpTest;
    }

    // initialize various helper variables
    var numInternals= Math.pow(2, maxDepth)-1;
    var numNodes= Math.pow(2, maxDepth + 1)-1;
    var ixs= new Array(numNodes);
    for(var i=1;i<ixs.length;i++) ixs[i]=[];
    ixs[0]= new Array(labels.length);
    for(var i=0;i<labels.length;i++) ixs[0][i]= i; // root node starts out with all nodes as relevant
    var models = new Array(numInternals);

    // train
    for(var n=0; n < numInternals; n++) {

      // few base cases
      var ixhere= ixs[n];
      if(ixhere.length == 0) { continue; }
      if(ixhere.length == 1) { ixs[n*2+1] = [ixhere[0]]; continue; } // arbitrary send it down left

      // learn a weak model on relevant data for this node
      var model= trainFun(data, labels, ixhere);
      models[n]= model; // back it up model

      // split the data according to the learned model
      var ixleft=[];
      var ixright=[];
      for(var i=0; i<ixhere.length;i++) {
          var label= testFun(data[ixhere[i]], model);
          if(label === 1) ixleft.push(ixhere[i]);
          else ixright.push(ixhere[i]);
      }
      ixs[n*2+1]= ixleft;
      ixs[n*2+2]= ixright;
    }

    // compute data distributions at the leafs
    var leafPositives = new Array(numNodes);
    var leafNegatives = new Array(numNodes);
    for(var n=numInternals; n < numNodes; n++) {
      var numones= 0;
      for(var i=0;i<ixs[n].length;i++) {
          if(labels[ixs[n][i]] === 1) numones+=1;
      }
      leafPositives[n]= numones;
      leafNegatives[n]= ixs[n].length-numones;
    }

    // back up important prediction variables for predicting later
    L.models= models;
    L.leafPositives = leafPositives;
    L.leafNegatives = leafNegatives;
    L.maxDepth= maxDepth;
    // L.trainFun= trainFun;
    // L.testFun= testFun;
  }, 

  // returns probability that example inst is 1.
  predictOne: function(L, inst) { 
      var testFun = L.testFun||decisionStumpTest;
      var n=0;
      for(var i=0;i<L.maxDepth;i++) {
          var dir= testFun(inst, L.models[n]);
          if(dir === 1) n= n*2+1; // descend left
          else n= n*2+2; // descend right
      }

      return (L.leafPositives[n] + 0.5) / (L.leafNegatives[n] + 1.0); // bayesian smoothing!
  }
}

// returns model
function decisionStumpTrain(data, labels, ix, options) {

  options = options || {};
  var numtries = options.numTries || 10;

  // choose a dimension at random and pick a best split
  var ri= randi(0, data[0].length);
  var N= ix.length;

  // evaluate class entropy of incoming data
  var H= entropy(labels, ix);
  var bestGain=0; 
  var bestThr= 0;
  for(var i=0;i<numtries;i++) {

      // pick a random splitting threshold
      var ix1= ix[randi(0, N)];
      var ix2= ix[randi(0, N)];
      while(ix2==ix1) ix2= ix[randi(0, N)]; // enforce distinctness of ix2

      var a= Math.random();
      var thr= data[ix1][ri]*a + data[ix2][ri]*(1-a);

      // measure information gain we'd get from split with thr
      var l1=1, r1=1, lm1=1, rm1=1; //counts for Left and label 1, right and label 1, left and minus 1, right and minus 1
      for(var j=0;j<ix.length;j++) {
          if(data[ix[j]][ri] < thr) {
            if(labels[ix[j]]==1) l1++;
            else lm1++;
          } else {
            if(labels[ix[j]]==1) r1++;
            else rm1++;
          }
      }
      var t= l1+lm1;  // normalize the counts to obtain probability estimates
      l1=l1/t;
      lm1=lm1/t;
      t= r1+rm1;
      r1=r1/t;
      rm1= rm1/t;

      var LH= -l1*Math.log(l1) -lm1*Math.log(lm1); // left and right entropy
      var RH= -r1*Math.log(r1) -rm1*Math.log(rm1);

      var informationGain= H - LH - RH;
      //console.log("Considering split %f, entropy %f -> %f, %f. Gain %f", thr, H, LH, RH, informationGain);
      if(informationGain > bestGain || i === 0) {
          bestGain= informationGain;
          bestThr= thr;
      }
  }

  model= {};
  model.thr= bestThr;
  model.ri= ri;
  return model;
}

// returns a decision for a single data instance
function decisionStumpTest(inst, model) {
  if(!model) {
      // this is a leaf that never received any data... 
      return 1;
  }
  return inst[model.ri] < model.thr ? 1 : -1;

}

// returns model. Code duplication with decisionStumpTrain :(
function decision2DStumpTrain(data, labels, ix, options) {

  options = options || {};
  var numtries = options.numTries || 10;

  // choose a dimension at random and pick a best split
  var N= ix.length;

  var ri1= 0;
  var ri2= 1;
  if(data[0].length > 2) {
    // more than 2D data. Pick 2 random dimensions
    ri1= randi(0, data[0].length);
    ri2= randi(0, data[0].length);
    while(ri2 == ri1) ri2= randi(0, data[0].length); // must be distinct!
  }

  // evaluate class entropy of incoming data
  var H= entropy(labels, ix);
  var bestGain=0; 
  var bestw1, bestw2, bestthr;
  var dots= new Array(ix.length);
  for(var i=0;i<numtries;i++) {

      // pick random line parameters
      var alpha= randf(0, 2*Math.PI);
      var w1= Math.cos(alpha);
      var w2= Math.sin(alpha);

      // project data on this line and get the dot products
      for(var j=0;j<ix.length;j++) {
        dots[j]= w1*data[ix[j]][ri1] + w2*data[ix[j]][ri2];
      }

      // we are in a tricky situation because data dot product distribution
      // can be skewed. So we don't want to select just randomly between
      // min and max. But we also don't want to sort as that is too expensive
      // let's pick two random points and make the threshold be somewhere between them.
      // for skewed datasets, the selected points will with relatively high likelihood
      // be in the high-desnity regions, so the thresholds will make sense
      var ix1= ix[randi(0, N)];
      var ix2= ix[randi(0, N)];
      while(ix2==ix1) ix2= ix[randi(0, N)]; // enforce distinctness of ix2
      var a= Math.random();
      var dotthr= dots[ix1]*a + dots[ix2]*(1-a);

      // measure information gain we'd get from split with thr
      var l1=1, r1=1, lm1=1, rm1=1; //counts for Left and label 1, right and label 1, left and minus 1, right and minus 1
      for(var j=0;j<ix.length;j++) {
          if(dots[j] < dotthr) {
            if(labels[ix[j]]==1) l1++;
            else lm1++;
          } else {
            if(labels[ix[j]]==1) r1++;
            else rm1++;
          }
      }
      var t= l1+lm1; 
      l1=l1/t;
      lm1=lm1/t;
      t= r1+rm1;
      r1=r1/t;
      rm1= rm1/t;

      var LH= -l1*Math.log(l1) -lm1*Math.log(lm1); // left and right entropy
      var RH= -r1*Math.log(r1) -rm1*Math.log(rm1);

      var informationGain= H - LH - RH;
      //console.log("Considering split %f, entropy %f -> %f, %f. Gain %f", thr, H, LH, RH, informationGain);
      if(informationGain > bestGain || i === 0) {
          bestGain= informationGain;
          bestw1= w1;
          bestw2= w2;
          bestthr= dotthr;
      }
  }

  model= {};
  model.w1= bestw1;
  model.w2= bestw2;
  model.dotthr= bestthr;
  return model;
}

// returns label for a single data instance
function decision2DStumpTest(inst, model) {
  if(!model) {
      // this is a leaf that never received any data... 
      return 1;
  }
  return inst[0]*model.w1 + inst[1]*model.w2 < model.dotthr ? 1 : -1;

}

// Misc utility functions
function entropy(labels, ix) {
  var N= ix.length;
  var p=0.0;
  for(var i=0;i<N;i++) {
      if(labels[ix[i]]==1) p+=1;
  }
  p=(1+p)/(N+2); // let's be bayesian about this
  q=(1+N-p)/(N+2);
  return (-p*Math.log(p) -q*Math.log(q));
}

// generate random floating point number between a and b
function randf(a, b) {
  return Math.random()*(b-a)+a;
}

// generate random integer between a and b (b excluded)
function randi(a, b) {
   return Math.floor(Math.random()*(b-a)+a);
}

module.exports = RandomForest
};
BundleModuleCode['plugins/ml/rl']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Ankit Kuwadekar, Stefan Bosse
 **    $INITIAL:     (C) 2015, Andrej Karpathy
 **    $MODIFIED:    (C) 2006-2019 bLAB by sbosse
 **    $VERSION:     1.1.2
 **
 **    $INFO:
 **
 ** Reinforcement Learning module that implements several common RL algorithms.
 ** Portable models (TDAgent/DPAgent/DQNAgent)
 **
 **    $ENDOFINFO
 */
"use strict";

var options = {
  version:'1.1.2'
}
var Io = Require('com/io')
var R = module.exports; // the Recurrent library


// Utility fun
function assert(condition, message) {
  // from http://stackoverflow.com/questions/15313418/javascript-assert
  if (!condition) {
    message = message || "Assertion failed";
    if (typeof Error !== "undefined") {
      throw new Error(message);
    }
    throw message; // Fallback
  }
}

// Random numbers utils
var return_v = false;
var v_val = 0.0;
var gaussRandom = function() {
  if(return_v) { 
    return_v = false;
    return v_val; 
  }
  var u = 2*Math.random()-1;
  var v = 2*Math.random()-1;
  var r = u*u + v*v;
  if(r == 0 || r > 1) return gaussRandom();
  var c = Math.sqrt(-2*Math.log(r)/r);
  v_val = v*c; // cache this
  return_v = true;
  return u*c;
}
var randf = function(a, b) { return Math.random()*(b-a)+a; }
var randi = function(a, b) { return Math.floor(Math.random()*(b-a)+a); }
var randn = function(mu, std){ return mu+gaussRandom()*std; }

// helper function returns array of zeros of length n
// and uses typed arrays if available
var zeros = function(n) {
  if(typeof(n)==='undefined' || isNaN(n)) { return []; }
  if(typeof ArrayBuffer === 'undefined') {
    // lacking browser support
    var arr = new Array(n);
    for(var i=0;i<n;i++) { arr[i] = 0; }
    return arr;
  } else {
    return new Float64Array(n);
  }
}

// Mat holds a matrix
var Mat = function(n,d) {
  var M = {}
  // n is number of rows d is number of columns
  M.n = n;
  M.d = d;
  M.w = zeros(n * d);
  M.dw = zeros(n * d);
  return M;
}

Mat.code = {
  get: function(M,row, col) { 
    // slow but careful accessor function
    // we want row-major order
    var ix = (M.d * row) + col;
    assert(ix >= 0 && ix < M.w.length);
    return M.w[ix];
  },
  set: function(M, row, col, v) {
    // slow but careful accessor function
    var ix = (M.d * row) + col;
    assert(ix >= 0 && ix < M.w.length);
    M.w[ix] = v; 
  },
  setFrom: function(M, arr) {
    for(var i=0,n=arr.length;i<n;i++) {
      M.w[i] = arr[i]; 
    }
  },
  setColumn: function(M, m, i) {
    for(var q=0,n=m.w.length;q<n;q++) {
      M.w[(M.d * q) + i] = m.w[q];
    }
  },
  toJSON: function(M) {
    var json = {};
    json['n'] = M.n;
    json['d'] = M.d;
    json['w'] = M.w;
    return json;
  },
  fromJSON: function(M, json) {
    M.n = json.n;
    M.d = json.d;
    M.w = zeros(M.n * M.d);
    M.dw = zeros(M.n * M.d);
    for(var i=0,n=M.n * M.d;i<n;i++) {
      M.w[i] = json.w[i]; // copy over weights
    }
  }
}

var copyMat = function(b) {
  var a = Mat(b.n, b.d);
  Mat.code.setFrom(a, b.w);
  return a;
}

var copyNet = function(net) {
  // nets are (k,v) pairs with k = string key, v = Mat()
  var new_net = {};
  for(var p in net) {
    if(net.hasOwnProperty(p)){
      new_net[p] = copyMat(net[p]);
    }
  }
  return new_net;
}

var updateMat = function(m, alpha) {
  // updates in place
  for(var i=0,n=m.n*m.d;i<n;i++) {
    if(m.dw[i] !== 0) {
      m.w[i] += - alpha * m.dw[i];
      m.dw[i] = 0;
    }
  }
}

var updateNet = function(net, alpha) {
  for(var p in net) {
    if(net.hasOwnProperty(p)){
      updateMat(net[p], alpha);
    }
  }
}

var netToJSON = function(net) {
  var j = {};
  for(var p in net) {
    if(net.hasOwnProperty(p)){
      j[p] = Mat.code.toJSON(net[p]);
    }
  }
  return j;
}
var netFromJSON = function(j) {
  var net = {};
  for(var p in j) {
    if(j.hasOwnProperty(p)){
      net[p] = Mat(1,1); // not proud of this
      Mat.code.fromJSON(net[p],j[p]);
    }
  }
  return net;
}
var netZeroGrads = function(net) {
  for(var p in net) {
    if(net.hasOwnProperty(p)){
      var mat = net[p];
      gradFillConst(mat, 0);
    }
  }
}
var netFlattenGrads = function(net) {
  var n = 0;
  for(var p in net) { 
   if(net.hasOwnProperty(p)) { 
    var mat = net[p]; n += mat.dw.length; 
  }}
  var g = Mat(n, 1);
  var ix = 0;
  for(var p in net) {
    if(net.hasOwnProperty(p)){
      var mat = net[p];
      for(var i=0,m=mat.dw.length;i<m;i++) {
        g.w[ix] = mat.dw[i];
        ix++;
      }
    }
  }
  return g;
}

// return Mat but filled with random numbers from gaussian
var RandMat = function(n,d,mu,std) {
  var m = Mat(n, d);
  fillRandn(m,mu,std);
  //fillRand(m,-std,std); // kind of :P
  return m;
}

// Mat utils
// fill matrix with random gaussian numbers
var fillRandn = function(m, mu, std) { for(var i=0,n=m.w.length;i<n;i++) { m.w[i] = randn(mu, std); } }
var fillRand = function(m, lo, hi) { for(var i=0,n=m.w.length;i<n;i++) { m.w[i] = randf(lo, hi); } }
var gradFillConst = function(m, c) { for(var i=0,n=m.dw.length;i<n;i++) { m.dw[i] = c } }



// Transformer definitions
var Graph = function(needs_backprop) {
  var G = {}
  if(typeof needs_backprop === 'undefined') { needs_backprop = true; }
  G.needs_backprop = needs_backprop;

  // this will store a list of functions that perform backprop,
  // in their forward pass order. So in backprop we will go
  // backwards and evoke each one
  G.backprop = [];
  return G
}
Graph.code = {
  backward: function(G) {
    for(var i=G.backprop.length-1;i>=0;i--) {
      G.backprop[i](); // tick!
    }
  },
  rowPluck: function(G, m, ix) {
    // pluck a row of m with index ix and return it as col vector
    assert(ix >= 0 && ix < m.n);
    var d = m.d;
    var out = Mat(d, 1);
    for(var i=0,n=d;i<n;i++){ out.w[i] = m.w[d * ix + i]; } // copy over the data

    if(G.needs_backprop) {
      var backward = function() {
        for(var i=0,n=d;i<n;i++){ m.dw[d * ix + i] += out.dw[i]; }
      }
      G.backprop.push(backward);
    }
    return out;
  },
  tanh: function(G, m) {
    // tanh nonlinearity
    var out = Mat(m.n, m.d);
    var n = m.w.length;
    for(var i=0;i<n;i++) { 
      out.w[i] = Math.tanh(m.w[i]);
    }

    if(G.needs_backprop) {
      var backward = function() {
        for(var i=0;i<n;i++) {
          // grad for z = tanh(x) is (1 - z^2)
          var mwi = out.w[i];
          m.dw[i] += (1.0 - mwi * mwi) * out.dw[i];
        }
      }
      G.backprop.push(backward);
    }
    return out;
  },
  sigmoid: function(G, m) {
    // sigmoid nonlinearity
    var out = Mat(m.n, m.d);
    var n = m.w.length;
    for(var i=0;i<n;i++) { 
      out.w[i] = sig(m.w[i]);
    }

    if(G.needs_backprop) {
      var backward = function() {
        for(var i=0;i<n;i++) {
          // grad for z = tanh(x) is (1 - z^2)
          var mwi = out.w[i];
          m.dw[i] += mwi * (1.0 - mwi) * out.dw[i];
        }
      }
      G.backprop.push(backward);
    }
    return out;
  },
  relu: function(G, m) {
    var out = Mat(m.n, m.d);
    var n = m.w.length;
    for(var i=0;i<n;i++) { 
      out.w[i] = Math.max(0, m.w[i]); // relu
    }
    if(G.needs_backprop) {
      var backward = function() {
        for(var i=0;i<n;i++) {
          m.dw[i] += m.w[i] > 0 ? out.dw[i] : 0.0;
        }
      }
      G.backprop.push(backward);
    }
    return out;
  },
  mul: function(G, m1, m2) {
    // multiply matrices m1 * m2
    assert(m1.d === m2.n, 'matmul dimensions misaligned');

    var n = m1.n;
    var d = m2.d;
    var out = Mat(n,d);
    for(var i=0;i<m1.n;i++) { // loop over rows of m1
      for(var j=0;j<m2.d;j++) { // loop over cols of m2
        var dot = 0.0;
        for(var k=0;k<m1.d;k++) { // dot product loop
          dot += m1.w[m1.d*i+k] * m2.w[m2.d*k+j];
        }
        out.w[d*i+j] = dot;
      }
    }

    if(G.needs_backprop) {
      var backward = function() {
        for(var i=0;i<m1.n;i++) { // loop over rows of m1
          for(var j=0;j<m2.d;j++) { // loop over cols of m2
            for(var k=0;k<m1.d;k++) { // dot product loop
              var b = out.dw[d*i+j];
              m1.dw[m1.d*i+k] += m2.w[m2.d*k+j] * b;
              m2.dw[m2.d*k+j] += m1.w[m1.d*i+k] * b;
            }
          }
        }
      }
      G.backprop.push(backward);
    }
    return out;
  },
  add: function(G, m1, m2) {
    assert(m1.w.length === m2.w.length);

    var out = Mat(m1.n, m1.d);
    for(var i=0,n=m1.w.length;i<n;i++) {
      out.w[i] = m1.w[i] + m2.w[i];
    }
    if(G.needs_backprop) {
      var backward = function() {
        for(var i=0,n=m1.w.length;i<n;i++) {
          m1.dw[i] += out.dw[i];
          m2.dw[i] += out.dw[i];
        }
      }
      G.backprop.push(backward);
    }
    return out;
  },
  dot: function(G, m1, m2) {
    // m1 m2 are both column vectors
    assert(m1.w.length === m2.w.length);
    var out = Mat(1,1);
    var dot = 0.0;
    for(var i=0,n=m1.w.length;i<n;i++) {
      dot += m1.w[i] * m2.w[i];
    }
    out.w[0] = dot;
    if(G.needs_backprop) {
      var backward = function() {
        for(var i=0,n=m1.w.length;i<n;i++) {
          m1.dw[i] += m2.w[i] * out.dw[0];
          m2.dw[i] += m1.w[i] * out.dw[0];
        }
      }
      G.backprop.push(backward);
    }
    return out;
  },
  eltmul: function(G, m1, m2) {
    assert(m1.w.length === m2.w.length);

    var out = Mat(m1.n, m1.d);
    for(var i=0,n=m1.w.length;i<n;i++) {
      out.w[i] = m1.w[i] * m2.w[i];
    }
    if(G.needs_backprop) {
      var backward = function() {
        for(var i=0,n=m1.w.length;i<n;i++) {
          m1.dw[i] += m2.w[i] * out.dw[i];
          m2.dw[i] += m1.w[i] * out.dw[i];
        }
      }
      G.backprop.push(backward);
    }
    return out;
  },
}


var softmax = function(m) {
    var out = Mat(m.n, m.d); // probability volume
    var maxval = -999999;
    for(var i=0,n=m.w.length;i<n;i++) { if(m.w[i] > maxval) maxval = m.w[i]; }

    var s = 0.0;
    for(var i=0,n=m.w.length;i<n;i++) { 
      out.w[i] = Math.exp(m.w[i] - maxval);
      s += out.w[i];
    }
    for(var i=0,n=m.w.length;i<n;i++) { out.w[i] /= s; }

    // no backward pass here needed
    // since we will use the computed probabilities outside
    // to set gradients directly on m
    return out;
  }


var Solver = function() {
  var S = {}
  S.decay_rate = 0.999;
  S.smooth_eps = 1e-8;
  S.step_cache = {};
  return S
}
Solver.code = {
  step: function(S, model, step_size, regc, clipval) {
    // perform parameter update
    var solver_stats = {};
    var num_clipped = 0;
    var num_tot = 0;
    for(var k in model) {
      if(model.hasOwnProperty(k)) {
        var m = model[k]; // mat ref
        if(!(k in S.step_cache)) { S.step_cache[k] = Mat(m.n, m.d); }
        var s = S.step_cache[k];
        for(var i=0,n=m.w.length;i<n;i++) {

          // rmsprop adaptive learning rate
          var mdwi = m.dw[i];
          s.w[i] = s.w[i] * S.decay_rate + (1.0 - S.decay_rate) * mdwi * mdwi;

          // gradient clip
          if(mdwi > clipval) {
            mdwi = clipval;
            num_clipped++;
          }
          if(mdwi < -clipval) {
            mdwi = -clipval;
            num_clipped++;
          }
          num_tot++;

          // update (and regularize)
          m.w[i] += - step_size * mdwi / Math.sqrt(s.w[i] + S.smooth_eps) - regc * m.w[i];
          m.dw[i] = 0; // reset gradients for next iteration
        }
      }
    }
    solver_stats['ratio_clipped'] = num_clipped*1.0/num_tot;
    return solver_stats;
  }
}

var initLSTM = function(input_size, hidden_sizes, output_size) {
  // hidden size should be a list

  var model = {};
  for(var d=0;d<hidden_sizes.length;d++) { // loop over depths
    var prev_size = d === 0 ? input_size : hidden_sizes[d - 1];
    var hidden_size = hidden_sizes[d];

    // gates parameters
    model['Wix'+d]  = RandMat(hidden_size, prev_size , 0, 0.08);  
    model['Wih'+d]  = RandMat(hidden_size, hidden_size , 0, 0.08);
    model['bi'+d]   = Mat(hidden_size, 1);
    model['Wfx'+d]  = RandMat(hidden_size, prev_size , 0, 0.08);  
    model['Wfh'+d]  = RandMat(hidden_size, hidden_size , 0, 0.08);
    model['bf'+d]   = Mat(hidden_size, 1);
    model['Wox'+d]  = RandMat(hidden_size, prev_size , 0, 0.08);  
    model['Woh'+d]  = RandMat(hidden_size, hidden_size , 0, 0.08);
    model['bo'+d]   = Mat(hidden_size, 1);
    // cell write params
    model['Wcx'+d]  = RandMat(hidden_size, prev_size , 0, 0.08);  
    model['Wch'+d]  = RandMat(hidden_size, hidden_size , 0, 0.08);
    model['bc'+d]   = Mat(hidden_size, 1);
  }
  // decoder params
  model['Whd']  = RandMat(output_size, hidden_size, 0, 0.08);
  model['bd']   = Mat(output_size, 1);
  return model;
}

var forwardLSTM = function(G, model, hidden_sizes, x, prev) {
  // forward prop for a single tick of LSTM
  // G is graph to append ops to
  // model contains LSTM parameters
  // x is 1D column vector with observation
  // prev is a struct containing hidden and cell
  // from previous iteration

  if(prev == null || typeof prev.h === 'undefined') {
    var hidden_prevs = [];
    var cell_prevs = [];
    for(var d=0;d<hidden_sizes.length;d++) {
      hidden_prevs.push(R.Mat(hidden_sizes[d],1)); 
      cell_prevs.push(R.Mat(hidden_sizes[d],1)); 
    }
  } else {
    var hidden_prevs = prev.h;
    var cell_prevs = prev.c;
  }

  var hidden = [];
  var cell = [];
  for(var d=0;d<hidden_sizes.length;d++) {

    var input_vector = d === 0 ? x : hidden[d-1];
    var hidden_prev = hidden_prevs[d];
    var cell_prev = cell_prevs[d];

    // input gate
    var h0 = Graph.code.mul(G,model['Wix'+d], input_vector);
    var h1 = Graph.code.mul(G,model['Wih'+d], hidden_prev);
    var input_gate = Graph.code.sigmoid(G,Graph.code.add(G,Graph.code.add(G,h0,h1),
                                        model['bi'+d]));

    // forget gate
    var h2 = Graph.code.mul(G,model['Wfx'+d], input_vector);
    var h3 = Graph.code.mul(G,model['Wfh'+d], hidden_prev);
    var forget_gate = Graph.code.sigmoid(
                        G,Graph.code.add(G,Graph.code.add(G,h2, h3),
                        model['bf'+d]));

    // output gate
    var h4 = Graph.code.mul(G,model['Wox'+d], input_vector);
    var h5 = Graph.code.mul(G,model['Woh'+d], hidden_prev);
    var output_gate = Graph.code.sigmoid(G,Graph.code.add(G,Graph.code.add(G,h4, h5),
                                                          model['bo'+d]));

    // write operation on cells
    var h6 = Graph.code.mul(G,model['Wcx'+d], input_vector);
    var h7 = Graph.code.mul(G,model['Wch'+d], hidden_prev);
    var cell_write = Graph.code.tanh(G,Graph.code.add(
                                         G,Graph.code.add(G,h6, h7),
                                         model['bc'+d]));

    // compute new cell activation
    var retain_cell = Graph.code.eltmul(G,forget_gate, cell_prev); // what do we keep from cell
    var write_cell = Graph.code.eltmul(G,input_gate, cell_write); // what do we write to cell
    var cell_d = Graph.code.add(G,retain_cell, write_cell); // new cell contents

    // compute hidden state as gated, saturated cell activations
    var hidden_d = Graph.code.eltmul(G, output_gate, Graph.code.tanh(G,cell_d));

    hidden.push(hidden_d);
    cell.push(cell_d);
  }

  // one decoder to outputs at end
  var output = Graph.code.add(G,Graph.code.mul(G,model['Whd'], hidden[hidden.length - 1]),model['bd']);

  // return cell memory, hidden representation and output
  return {'h':hidden, 'c':cell, 'o' : output};
}

var sig = function(x) {
  // helper function for computing sigmoid
  return 1.0/(1+Math.exp(-x));
}

var maxi = function(w) {
  // argmax of array w
  var maxv = w[0];
  var maxix = 0;
  for(var i=1,n=w.length;i<n;i++) {
    var v = w[i];
    if(v > maxv) {
      maxix = i;
      maxv = v;
    }
  }
  return maxix;
}

var samplei = function(w) {
  // sample argmax from w, assuming w are 
  // probabilities that sum to one
  var r = randf(0,1);
  var x = 0.0;
  var i = 0;
  while(true) {
    x += w[i];
    if(x > r) { return i; }
    i++;
  }
  return w.length - 1; // pretty sure we should never get here?
}

// various utils
module.exports.assert = assert;
module.exports.zeros = zeros;
module.exports.maxi = maxi;
module.exports.samplei = samplei;
module.exports.randi = randi;
module.exports.randn = randn;
module.exports.softmax = softmax;
// classes
module.exports.Mat = Mat;
module.exports.RandMat = RandMat;
module.exports.forwardLSTM = forwardLSTM;
module.exports.initLSTM = initLSTM;
// more utils
module.exports.updateMat = updateMat;
module.exports.updateNet = updateNet;
module.exports.copyMat = copyMat;
module.exports.copyNet = copyNet;
module.exports.netToJSON = netToJSON;
module.exports.netFromJSON = netFromJSON;
module.exports.netZeroGrads = netZeroGrads;
module.exports.netFlattenGrads = netFlattenGrads;
// optimization
module.exports.Solver = Solver;
module.exports.Graph = Graph;

// END OF RECURRENTJS

var RL = module.exports;

// syntactic sugar function for getting default parameter values
var getopt = function(opt, field_name, default_value) {
  if(typeof opt === 'undefined') { return default_value; }
  return (typeof opt[field_name] !== 'undefined') ? opt[field_name] : default_value;
}

var zeros = R.zeros; // inherit these
var assert = R.assert;
var randi = R.randi;
var randf = R.randf;

var setConst = function(arr, c) {
  for(var i=0,n=arr.length;i<n;i++) {
    arr[i] = c;
  }
}

var sampleWeighted = function(p) {
  var r = Math.random();
  var c = 0.0;
  for(var i=0,n=p.length;i<n;i++) {
    c += p[i];
    if(c >= r) { return i; }
  }
  // assert(false, 'sampleWeighted: Invalid samples '+Io.inspect(p));
  return 0
}

// ------
// AGENTS
// ------

// DPAgent performs Value Iteration
// - can also be used for Policy Iteration if you really wanted to
// - requires model of the environment :(
// - does not learn from experience :(
// - assumes finite MDP :(
var DPAgent = function(env, opt) {
  var L={};
  L.V = null; // state value function
  L.P = null; // policy distribution \pi(s,a)
  L.env = env; // store pointer to environment
  L.gamma = getopt(opt, 'gamma', 0.75); // future reward discount factor
  DPAgent.code.reset(L);
  return L;
}
DPAgent.code = {
  reset: function(L) {
    // reset the agent's policy and value function
    L.ns = L.env.getNumStates();
    L.na = L.env.getMaxNumActions();
    L.V = zeros(L.ns);
    L.P = zeros(L.ns * L.na);
    // initialize uniform random policy
    for(var s=0;s<L.ns;s++) {
      var poss = L.env.allowedActions(s);
      for(var i=0,n=poss.length;i<n;i++) {
        L.P[poss[i]*L.ns+s] = 1.0 / poss.length;
      }
    }
  },
  act: function(L,s) {
    // behave according to the learned policy
    var poss = L.env.allowedActions(s);
    var ps = [];
    for(var i=0,n=poss.length;i<n;i++) {
      var a = poss[i];
      var prob = L.P[a*L.ns+s];
      ps.push(prob);
    }
    var maxi = sampleWeighted(ps);
    return poss[maxi];
  },
  learn: function(L) {
    // perform a single round of value iteration
    DPAgent.code.evaluatePolicy(L); // writes this.V
    DPAgent.code.updatePolicy(L); // writes this.P
  },
  evaluatePolicy: function(L) {
    // perform a synchronous update of the value function
    var Vnew = zeros(L.ns);
    for(var s=0;s<L.ns;s++) {
      // integrate over actions in a stochastic policy
      // note that we assume that policy probability mass over allowed actions sums to one
      var v = 0.0;
      var poss = L.env.allowedActions(s);
      for(var i=0,n=poss.length;i<n;i++) {
        var a = poss[i];
        var prob = L.P[a*L.ns+s]; // probability of taking action under policy
        if(prob === 0) { continue; } // no contribution, skip for speed
        var ns = L.env.nextState(s,a);
        var rs = L.env.reward(s,a,ns); // reward for s->a->ns transition
        v += prob * (rs + L.gamma * L.V[ns]);
      }
      Vnew[s] = v;
    }
    L.V = Vnew; // swap
  },
  updatePolicy: function(L) {
    // update policy to be greedy w.r.t. learned Value function
    for(var s=0;s<L.ns;s++) {
      var poss = L.env.allowedActions(s);
      // compute value of taking each allowed action
      var vmax, nmax;
      var vs = [];
      for(var i=0,n=poss.length;i<n;i++) {
        var a = poss[i];
        var ns = L.env.nextState(s,a);
        var rs = L.env.reward(s,a,ns);
        var v = rs + L.gamma * L.V[ns];
        vs.push(v);
        if(i === 0 || v > vmax) { vmax = v; nmax = 1; }
        else if(v === vmax) { nmax += 1; }
      }
      // update policy smoothly across all argmaxy actions
      for(var i=0,n=poss.length;i<n;i++) {
        var a = poss[i];
        L.P[a*L.ns+s] = (vs[i] === vmax) ? 1.0/nmax : 0.0;
      }
    }
  },
}

// QAgent uses TD (Q-Learning, SARSA)
// - does not require environment model :)
// - learns from experience :)
var TDAgent = function(env, opt) {
  var L={}
  L.update = getopt(opt, 'update', 'qlearn'); // qlearn | sarsa
  L.gamma = getopt(opt, 'gamma', 0.75); // future reward discount factor
  L.epsilon = getopt(opt, 'epsilon', 0.1); // for epsilon-greedy policy
  L.alpha = getopt(opt, 'alpha', 0.01); // value function learning rate

  // class allows non-deterministic policy, and smoothly regressing towards the optimal policy based on Q
  L.smooth_policy_update = getopt(opt, 'smooth_policy_update', false);
  L.beta = getopt(opt, 'beta', 0.01); // learning rate for policy, if smooth updates are on

  // eligibility traces
  L.lambda = getopt(opt, 'lambda', 0); // eligibility trace decay. 0 = no eligibility traces used
  L.replacing_traces = getopt(opt, 'replacing_traces', true);

  // optional optimistic initial values
  L.q_init_val = getopt(opt, 'q_init_val', 0);

  L.planN = getopt(opt, 'planN', 0); // number of planning steps per learning iteration (0 = no planning)

  L.Q = null; // state action value function
  L.P = null; // policy distribution \pi(s,a)
  L.e = null; // eligibility trace
  L.env_model_s = null;; // environment model (s,a) -> (s',r)
  L.env_model_r = null;; // environment model (s,a) -> (s',r)
  L.env = env; // store pointer to environment
  TDAgent.code.reset(L);
  return L;
}
TDAgent.code = {
  reset: function(L){
    // reset the agent's policy and value function
    L.ns = L.env.getNumStates();
    L.na = L.env.getMaxNumActions();
    L.Q = zeros(L.ns * L.na);
    if(L.q_init_val !== 0) { setConst(L.Q, L.q_init_val); }
    L.P = zeros(L.ns * L.na);
    L.e = zeros(L.ns * L.na);

    // model/planning vars
    L.env_model_s = zeros(L.ns * L.na);
    setConst(L.env_model_s, -1); // init to -1 so we can test if we saw the state before
    L.env_model_r = zeros(L.ns * L.na);
    L.sa_seen = [];
    L.pq = zeros(L.ns * L.na);

    // initialize uniform random policy
    for(var s=0;s<L.ns;s++) {
      var poss = L.env.allowedActions(s);
      for(var i=0,n=poss.length;i<n;i++) {
        L.P[poss[i]*L.ns+s] = 1.0 / poss.length;
      }
    }
    // agent memory, needed for streaming updates
    // (s0,a0,r0,s1,a1,r1,...)
    L.r0 = null;
    L.s0 = null;
    L.s1 = null;
    L.a0 = null;
    L.a1 = null;
  },
  resetEpisode: function(L) {
    // an episode finished
  },
  act: function(L,s){
    // act according to epsilon greedy policy
    var poss = L.env.allowedActions(s);
    var probs = [];
    for(var i=0,n=poss.length;i<n;i++) {
      probs.push(L.P[poss[i]*L.ns+s]);
    }
    // epsilon greedy policy
    if(Math.random() < L.epsilon) {
      var a = poss[randi(0,poss.length)]; // random available action
      L.explored = true;
    } else {
      var a = poss[sampleWeighted(probs)];
      L.explored = false;
    }
    // shift state memory
    L.s0 = L.s1;
    L.a0 = L.a1;
    L.s1 = s;
    L.a1 = a;
    return a;
  },
  learn: function(L,r1){
    // takes reward for previous action, which came from a call to act()
    if(!(L.r0 == null)) {
      TDAgent.code.learnFromTuple(L, L.s0, L.a0, L.r0, L.s1, L.a1, L.lambda);
      if(L.planN > 0) {
        TDAgent.code.updateModel(L, L.s0, L.a0, L.r0, L.s1);
        TDAgent.code.plan(L);
      }
    }
    L.r0 = r1; // store this for next update
  },
  updateModel: function(L, s0, a0, r0, s1) {
    // transition (s0,a0) -> (r0,s1) was observed. Update environment model
    var sa = a0 * L.ns + s0;
    if(L.env_model_s[sa] === -1) {
      // first time we see this state action
      L.sa_seen.push(a0 * L.ns + s0); // add as seen state
    }
    L.env_model_s[sa] = s1;
    L.env_model_r[sa] = r0;
  },
  plan: function(L) {

    // order the states based on current priority queue information
    var spq = [];
    for(var i=0,n=L.sa_seen.length;i<n;i++) {
      var sa = L.sa_seen[i];
      var sap = L.pq[sa];
      if(sap > 1e-5) { // gain a bit of efficiency
        spq.push({sa:sa, p:sap});
      }
    }
    spq.sort(function(a,b){ return a.p < b.p ? 1 : -1});

    // perform the updates
    var nsteps = Math.min(L.planN, spq.length);
    for(var k=0;k<nsteps;k++) {
      // random exploration
      //var i = randi(0, this.sa_seen.length); // pick random prev seen state action
      //var s0a0 = this.sa_seen[i];
      var s0a0 = spq[k].sa;
      L.pq[s0a0] = 0; // erase priority, since we're backing up this state
      var s0 = s0a0 % L.ns;
      var a0 = Math.floor(s0a0 / L.ns);
      var r0 = L.env_model_r[s0a0];
      var s1 = L.env_model_s[s0a0];
      var a1 = -1; // not used for Q learning
      if(L.update === 'sarsa') {
        // generate random action?...
        var poss = L.env.allowedActions(s1);
        var a1 = poss[randi(0,poss.length)];
      }
      TDAgent.code.learnFromTuple(L, s0, a0, r0, s1, a1, 0); // note lambda = 0 - shouldnt use eligibility trace here
    }
  },
  learnFromTuple: function(L, s0, a0, r0, s1, a1, lambda) {
    var sa = a0 * L.ns + s0;

    // calculate the target for Q(s,a)
    if(L.update === 'qlearn') {
      // Q learning target is Q(s0,a0) = r0 + gamma * max_a Q[s1,a]
      var poss = L.env.allowedActions(s1);
      var qmax = 0;
      for(var i=0,n=poss.length;i<n;i++) {
        var s1a = poss[i] * L.ns + s1;
        var qval = L.Q[s1a];
        if(i === 0 || qval > qmax) { qmax = qval; }
      }
      var target = r0 + L.gamma * qmax;
    } else if(L.update === 'sarsa') {
      // SARSA target is Q(s0,a0) = r0 + gamma * Q[s1,a1]
      var s1a1 = a1 * L.ns + s1;
      var target = r0 + L.gamma * L.Q[s1a1];
    }

    if(lambda > 0) {
      // perform an eligibility trace update
      if(L.replacing_traces) {
        L.e[sa] = 1;
      } else {
        L.e[sa] += 1;
      }
      var edecay = lambda * L.gamma;
      var state_update = zeros(L.ns);
      for(var s=0;s<L.ns;s++) {
        var poss = L.env.allowedActions(s);
        for(var i=0;i<poss.length;i++) {
          var a = poss[i];
          var saloop = a * L.ns + s;
          var esa = L.e[saloop];
          var update = L.alpha * esa * (target - L.Q[saloop]);
          L.Q[saloop] += update;
          L.updatePriority(s, a, update);
          L.e[saloop] *= edecay;
          var u = Math.abs(update);
          if(u > state_update[s]) { state_update[s] = u; }
        }
      }
      for(var s=0;s<L.ns;s++) {
        if(state_update[s] > 1e-5) { // save efficiency here
          TDAgent.code.updatePolicy(L,s);
        }
      }
      if(L.explored && L.update === 'qlearn') {
        // have to wipe the trace since q learning is off-policy :(
        L.e = zeros(L.ns * L.na);
      }
    } else {
      // simpler and faster update without eligibility trace
      // update Q[sa] towards it with some step size
      var update = L.alpha * (target - L.Q[sa]);
      L.Q[sa] += update;
      TDAgent.code.updatePriority(L,s0, a0, update);
      // update the policy to reflect the change (if appropriate)
      TDAgent.code.updatePolicy(L,s0);
    }
  },
  updatePriority: function(L,s,a,u) {
    // used in planning. Invoked when Q[sa] += update
    // we should find all states that lead to (s,a) and upgrade their priority
    // of being update in the next planning step
    u = Math.abs(u);
    if(u < 1e-5) { return; } // for efficiency skip small updates
    if(L.planN === 0) { return; } // there is no planning to be done, skip.
    for(var si=0;si<L.ns;si++) {
      // note we are also iterating over impossible actions at all states,
      // but this should be okay because their env_model_s should simply be -1
      // as initialized, so they will never be predicted to point to any state
      // because they will never be observed, and hence never be added to the model
      for(var ai=0;ai<L.na;ai++) {
        var siai = ai * L.ns + si;
        if(L.env_model_s[siai] === s) {
          // this state leads to s, add it to priority queue
          L.pq[siai] += u;
        }
      }
    }
  },
  updatePolicy: function(L,s) {
    var poss = L.env.allowedActions(s);
    // set policy at s to be the action that achieves max_a Q(s,a)
    // first find the maxy Q values
    var qmax, nmax;
    var qs = [];
    for(var i=0,n=poss.length;i<n;i++) {
      var a = poss[i];
      var qval = L.Q[a*L.ns+s];
      qs.push(qval);
      if(i === 0 || qval > qmax) { qmax = qval; nmax = 1; }
      else if(qval === qmax) { nmax += 1; }
    }
    // now update the policy smoothly towards the argmaxy actions
    var psum = 0.0;
    for(var i=0,n=poss.length;i<n;i++) {
      var a = poss[i];
      var target = (qs[i] === qmax) ? 1.0/nmax : 0.0;
      var ix = a*L.ns+s;
      if(L.smooth_policy_update) {
        // slightly hacky :p
        L.P[ix] += L.beta * (target - L.P[ix]);
        psum += L.P[ix];
      } else {
        // set hard target
        L.P[ix] = target;
      }
    }
    if(L.smooth_policy_update) {
      // renomalize P if we're using smooth policy updates
      for(var i=0,n=poss.length;i<n;i++) {
        var a = poss[i];
        L.P[a*L.ns+s] /= psum;
      }
    }
  }
}


var DQNAgent = function(env, opt) {
  var L = {}
  L.gamma = getopt(opt, 'gamma', 0.75); // future reward discount factor
  L.epsilon = getopt(opt, 'epsilon', 0.1); // for epsilon-greedy policy
  L.alpha = getopt(opt, 'alpha', 0.01); // value function learning rate

  L.experience_add_every = getopt(opt, 'experience_add_every', 25); // number of time steps before we add another experience to replay memory
  L.experience_size = getopt(opt, 'experience_size', 5000); // size of experience replay
  L.learning_steps_per_iteration = getopt(opt, 'learning_steps_per_iteration', 10);
  L.tderror_clamp = getopt(opt, 'tderror_clamp', 1.0); 

  L.num_hidden_units =  getopt(opt, 'num_hidden_units', 100); 

  L.env = env;
  DQNAgent.code.reset(L);
  return L
}
DQNAgent.code = {
  reset: function(L) {
    L.nh = L.num_hidden_units; // number of hidden units
    L.ns = L.env.getNumStates();
    L.na = L.env.getMaxNumActions();

    // nets are hardcoded for now as key (str) -> Mat
    // not proud of this. better solution is to have a whole Net object
    // on top of Mats, but for now sticking with this
    L.net = {};
    L.net.W1 = R.RandMat(L.nh, L.ns, 0, 0.01);
    L.net.b1 = R.Mat(L.nh, 1, 0, 0.01);
    L.net.W2 = R.RandMat(L.na, L.nh, 0, 0.01);
    L.net.b2 = R.Mat(L.na, 1, 0, 0.01);

    L.exp = []; // experience
    L.expi = 0; // where to insert

    L.t = 0;

    L.r0 = null;
    L.s0 = null;
    L.s1 = null;
    L.a0 = null;
    L.a1 = null;

    L.tderror = 0; // for visualization only...
  },
  toJSON: function(L) {
    // save function
    var j = {};
    j.nh = L.nh;
    j.ns = L.ns;
    j.na = L.na;
    j.net = R.netToJSON(L.net);
    return j;
  },
  fromJSON: function(L,j) {
    // load function
    L.nh = j.nh;
    L.ns = j.ns;
    L.na = j.na;
    L.net = R.netFromJSON(j.net);
  },
  forwardQ: function(L, net, s, needs_backprop) {
    var G = R.Graph(needs_backprop);
    var a1mat = Graph.code.add(G,Graph.code.mul(G,net.W1, s), net.b1);
    var h1mat = Graph.code.tanh(G,a1mat);
    var a2mat = Graph.code.add(G,Graph.code.mul(G,net.W2, h1mat), net.b2);
    L.lastG = G; // back this up. Kind of hacky isn't it
    return a2mat;
  },
  act: function(L,slist) {
    // convert to a Mat column vector
    var s = R.Mat(L.ns, 1);
    Mat.code.setFrom(s,slist);

    // epsilon greedy policy
    if(Math.random() < L.epsilon) {
      var a = randi(0, L.na);
    } else {
      // greedy wrt Q function
      var amat = DQNAgent.code.forwardQ(L,L.net, s, false);
      var a = R.maxi(amat.w); // returns index of argmax action
    }

    // shift state memory
    L.s0 = L.s1;
    L.a0 = L.a1;
    L.s1 = s;
    L.a1 = a;

    return a;
  },
  learn: function(L,r1) {
    // perform an update on Q function
    if(!(L.r0 == null) && L.alpha > 0) {

      // learn from this tuple to get a sense of how "surprising" it is to the agent
      var tderror = DQNAgent.code.learnFromTuple(L, L.s0, L.a0, L.r0, L.s1, L.a1);
      L.tderror = tderror; // a measure of surprise
      // decide if we should keep this experience in the replay
      if(L.t % L.experience_add_every === 0) {
        L.exp[L.expi] = [L.s0, L.a0, L.r0, L.s1, L.a1];
        L.expi += 1;
        if(L.expi > L.experience_size) { L.expi = 0; } // roll over when we run out
      }
      L.t += 1;

      // sample some additional experience from replay memory and learn from it
      for(var k=0;k<L.learning_steps_per_iteration;k++) {
        var ri = randi(0, L.exp.length); // todo: priority sweeps?
        var e = L.exp[ri];
        DQNAgent.code.learnFromTuple(L, e[0], e[1], e[2], e[3], e[4])
      }
    }
    L.r0 = r1; // store for next update
  },
  learnFromTuple: function(L, s0, a0, r0, s1, a1) {
    // want: Q(s,a) = r + gamma * max_a' Q(s',a')

    // compute the target Q value
    var tmat = DQNAgent.code.forwardQ(L, L.net, s1, false);
    var qmax = r0 + L.gamma * tmat.w[R.maxi(tmat.w)];

    // now predict
    var pred = DQNAgent.code.forwardQ(L, L.net, s0, true);

    var tderror = pred.w[a0] - qmax;
    var clamp = L.tderror_clamp;
    if(Math.abs(tderror) > clamp) {  // huber loss to robustify
      if(tderror > clamp) tderror = clamp;
      if(tderror < -clamp) tderror = -clamp;
    }
    pred.dw[a0] = tderror;

    Graph.code.backward( L.lastG); // compute gradients on net params

    // update net
    R.updateNet(L.net, L.alpha);
    return tderror;
  }
}



// exports
module.exports.DPAgent = DPAgent;
module.exports.TDAgent = TDAgent;
module.exports.DQNAgent = DQNAgent;
//module.exports.SimpleReinforceAgent = SimpleReinforceAgent;
//module.exports.RecurrentReinforceAgent = RecurrentReinforceAgent;
//module.exports.DeterministPG = DeterministPG;


};
BundleModuleCode['plugins/ml/rt']=function (module,exports,global,process){
//     wink-regression-tree
//     Decision Tree to predict the value of a continuous
//     target variable
//
//     https://github.com/winkjs/wink-regression-tree
//
//     Copyright (C) 2017-18  GRAYPE Systems Private Limited
//
//     This file is part of “wink-regression-tree”.
//
//     Permission is hereby granted, free of charge, to any person obtaining a
//     copy of this software and associated documentation files (the "Software"),
//     to deal in the Software without restriction, including without limitation
//     and/or sell copies of the Software, and to permit persons to whom the
//     Software is furnished to do so, subject to the following conditions:
//
//     The above copyright notice and this permission notice shall be included
//     in all copies or substantial portions of the Software.
//
//     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
//     DEALINGS IN THE SOFTWARE.

/* eslint no-continue: 0 */

var helpers = Require( 'ml/helpers' );
var stdevEPSILON = Math.pow( 2, -48 );

// ### regressionTree
/**
 *
 * Creates an instance of a {@link RegressionTree}.
 *
 * @return {RegressionTree} object conatining set of API methods for tasks like configuration,
 * data ingestion, learning, and prediction etc.
 * @example
 * // Load wink regression tree.
 * var regressionTree = require( 'wink-regression-tree' );
 * // Create your instance of regression tree.
 * var myRT = regressionTree();
*/
var regressionTree = function () {
  // Columns configuration supplied to the `defineConfig()` function.
  var columnsConfig;
  // Columns definition created from the `columnsConfig` supplied to the `defineConfig()`
  // method.
  var columnsDefn;
  // Create configuration object.
  var config = Object.create( null );
  // The **w**ink **r**egression tree.
  var wrTree = Object.create( null );
  // Xformed Column id to input column id map.
  var xc2cMap = [];
  // Xformed data, where categorical variables are encoded by a numeric code. Useful
  // in reduction of memory load.
  var xdata = [];
  // Parameters used for evaluation.
  var evalParams = Object.create( null );
  // Remember the target column name in this.
  var target;
  // Current rules tree object version.
  var winkRulesTreeVersion = 'WRT 1.0.0';

  /**
   * @classdesc Regression tree class
   * @class RegressionTree
   * @hideconstructor
   */
  var methods = Object.create( null );

  // ### initEvalParams
  /**
   *
   * Initializes all the properties of `evalParams`.
   *
   * @return {undefined} nothing!
   * @private
  */
  var initEvalParams = function () {
    // Setup evaluation parameters.
    evalParams.size = 0;
    evalParams.mean = 0;
    evalParams.prevMean = 0;
    // Grand Sum of Squared Deviations from the Mean, prior to prediction.
    evalParams.gssdm = 0;
    // Sum of Squared Deviations from the Mean, post prediction
    evalParams.ssdm = 0;
  }; // initEvalParams()

  // ### initColsDefn
  /**
   *
   * Initializes the columns' definition by cloning the input `cols` and by adding
   * a struncture containing `map` and `nextCode` (next unique value's code)
   * for every categorical column that is not excluded fom processing.
   *
   * @param {object[]} cols — each object specifies 4 properties viz. (a) `name`;
   * (b) type in terms of `categorical` as `true or false`, where `false` indicates a
   * continuous variable; (c) `exclude`, which is set to true if the column
   * has to be excluded from training; and (d) `target`, which is set to true for
   * the column whose value is to be predicted.
   * @return {object[]} cloned `cols`, where each element gets 2 addtitional
   * properties viz. `map` and the `nextCode` that is initialized to **0**.
   * @private
  */
  var initColsDefn = function ( cols ) {
    // Clone the incoming `cols`
    var cc = JSON.parse( JSON.stringify( cols ) );
    // Intialize the included categorical columns with empty `map` object
    // and `nextCode` that will be assigned to the next unique value encountered.
    for ( var i = 0, imax = cc.length; i < imax; i += 1 ) {
      if ( cc[ i ].categorical && !cc[ i ].exclude ) {
        cc[ i ].nextCode = 0;
        cc[ i ].map = Object.create( null );
        cc[ i ].invertedMap = [];
      }
      // Remember the target column name.
      if ( cc[ i ].target ) {
        target = cc[ i ].name;
      }
    }
    // Return the cloned & initialized collumns — `cc`.
    return cc;
  }; // initColsDefn()

  // ### transformRow
  /**
   *
   * It transforms the **included categorical** column's data of `row` into coded
   * values using `colsDefn`. This encoding reduces the memory space requirements.
   * If a new unique value is encountered, the `colsDefn.map` & `colsDefn.nextCode`
   *  values are accordingly updated.
   *
   * @param {array} row — contains data i.e. column values for a single row.
   * @param {object} colsDefn — columns' definition data structure.
   * @return {array} transformed row with encoded categorical column values.
   * @private
  */
  var transformRow = function ( row, colsDefn ) {
    // Transformed row builds up in this variable.
    var xRow = [ ];
    // Map, inverted Map and target value.
    var invertedMap, map, tv;

    for ( var i = 0, imax = row.length; i < imax; i += 1 ) {
      // Categorical and Included?
      if ( colsDefn[ i ].categorical && !colsDefn[ i ].exclude ) {
        map = colsDefn[ i ].map;
        invertedMap = colsDefn[ i ].invertedMap;
        // Map defined for row's element in question?
        if ( map[ row[ i ] ] === undefined ) {
          // Not! Update the `map` & the `invertedMap`.
          map[ row[ i ] ] = colsDefn[ i ].nextCode;
          invertedMap.push( row[ i ] );
          colsDefn[ i ].nextCode += 1;
        }
      }
      // Transform value.
      if ( colsDefn[ i ].target ) {
        // Remember target's transformed value, it will be pushed as the last
        // element in the `xRow`.
        tv = ( colsDefn[ i ].categorical ) ? map[ row[ i ] ] : row[ i ];
      } else if ( !colsDefn[ i ].exclude ) {
        // Ensure exclusion.
        if (map)
          xRow.push( map[ row[ i ] ] );
        else // @blab+ non-catergorical variables
          xRow.push( row[ i ] );
      }
    }
    // Target's value is always the last element in `xRow`.
    xRow.push( tv );
    return xRow;
  }; // transformRow()

  // ### createCandidates
  /**
   *
   * It creates empty data structure for each potential candidate column.
   *
   * @param {array} cols2p — array of indexes of columns to be processed.
   * @return {object} containing further empty objects indexed by each columns
   * specified in the `cols2p` array.
   * @private
  */
  var createCandidates = function ( cols2p ) {
    // Create `candidates` object.
    var candidates = Object.create( null );
    var ci;
    // Each Column specific data structure pertaining to every unique value goes here.
    candidates.columns = Object.create( null );
    // List of indexes of columns, to avoid calls to `Object.keys()` on candidate columns.
    candidates.list = [];
    for ( var i = 0, imax = cols2p.length; i < imax; i += 1 ) {
      ci = cols2p[ i ];
      // Push this index in to the list.
      candidates.list.push( ci );
      // Create an empty structure for this column by its index.
      candidates.columns[ ci ] = Object.create( null );
    }
    return candidates;
  }; // createCandidates()

  // ### computeMeanDelta
  /**
   *
   * Computes the delta mean value from the next `data`; this delta may be used to
   * update mean by additing it to the current mean.
   *
   * @param {number} data — data used to compute the delta.
   * @param {number} currMean — current value of mean from which delta is computed
   * using the `data`.
   * @param {number} size — the number of `data` items encountered so far.
   * @return {number} the delta mean.
   * @private
  */
  var computeMeanDelta = function ( data, currMean, size ) {
    return ( data - currMean ) / ( size );
  }; // computeMeanDelta()

  // ### computeVarianceXnDelta
  /**
   *
   * Computes the delta varianceXn value from the next `data`; this delta may be
   * used to update varianceXn by additing it to the current varianceXn. Note,
   * varianceXn is nothing but *sum of squared devaitions from the mean*.
   *
   * @param {number} data — data used to compute the delta.
   * @param {number} currMean — current value of mean and
   * @param {number} prevMean — the previous value of mean; using these delta is
   * computed using the `data`.
   * @return {number} the delta varianceXn.
   * @private
  */
  var computeVarianceXnDelta = function ( data, currMean, prevMean ) {
    return ( data - prevMean ) * ( data - currMean );
  }; // computeVarianceXnDelta()

  // ### computeStdev
  /**
   *
   * Computes the standard deviation from `varianceXn` and `size` after applying
   * Bessel's correction.
   *
   * @param {number} varianceXn — the sum of squared devaitions from the mean.
   * @param {number} size — the number of items.
   * @return {number} the standard deviation.
   * @private
  */
  var computeStdev = function ( varianceXn, size ) {
    // Apply Bessel's correction for a better estimate of population standard
    // deviation.
    return ( size > 1 ) ? Math.sqrt( varianceXn / ( size - 1 ) ) : 0;
  }; // computeStdev()

  // ### computePercentageVarianceReduction
  /**
   *
   * Computes percentage reduction in variance in split children from the parent.
   *
   * @param {number} varianceXn — the sum of squared devaitions from the mean.
   * @param {number} size — the number of items.
   * @param {number} weightedSumOfVar — weighted sum of variance of every child node.
   * @return {number} the percentage reduction in variance.
   * @private
  */
  var computePercentageVarianceReduction = function ( varianceXn, size, weightedSumOfVar ) {
    return ( ( ( varianceXn / size ) - weightedSumOfVar ) * 100 / ( varianceXn / size ) );
  }; // computePercentageVarianceReduction()

  // ### updateVarianceXn
  /**
   *
   * Incrementally updates the varianceXn of `targetsValue`  for the `c2psValue` of column to
   * process — `c2p` in `candidates` for the row pointed by `rowsIndex`.
   *
   * @param {object} candidates — data structure containing varianceXn for every
   * column's applicable unique values.
   * @param {number} c2p — the column to be processed.
   * @param {string} c2psValue — the column to be processed's value.
   * @param {number} rowsIndex — index of the data row to be used.
   * @param {number} targetsValue — target's value to be used for updating varianceXn.
   * @return {boolean} always true.
   * @private
  */
  var updateVarianceXn = function ( candidates, c2p, c2psValue, rowsIndex, targetsValue ) {
    // The candidates' colums where varianceXn will be updated.
    var cc2p = candidates.columns[ c2p ];
    // Create a place holder for `c2psValue`, provided it is being encountered
    // for the first time.
    if ( cc2p[ c2psValue ] === undefined ) {
      cc2p[ c2psValue ] = Object.create( null );
      // Mean of `targetsValue` encountered so far.
      cc2p[ c2psValue ].mean = 0;
      // The variance multiplied by `n or size`.
      cc2p[ c2psValue ].varianceXn = 0;
      // The count or size of values processed so far; will match with `index`
      // array size.
      cc2p[ c2psValue ].size = 0;
      // INdex of rows containing this specific value i.e. `c2psValue`.
      cc2p[ c2psValue ].index = [];
    }
    // Update varianceXn, etc.
    var prevMean = cc2p[ c2psValue ].mean;
    cc2p[ c2psValue ].size += 1;
    cc2p[ c2psValue ].mean += computeMeanDelta( targetsValue, cc2p[ c2psValue ].mean, cc2p[ c2psValue ].size );
    // ( targetsValue - cc2p[ c2psValue ].mean ) / ( cc2p[ c2psValue ].size );
    cc2p[ c2psValue ].varianceXn += computeVarianceXnDelta( targetsValue, cc2p[ c2psValue ].mean, prevMean );
    // ( targetsValue - prevMean ) * ( targetsValue - cc2p[ c2psValue ].mean );
    cc2p[ c2psValue ].index.push( rowsIndex );
    return true;
  }; // updateVarianceXn()

  // ### processRow
  /**
   *
   * It requires a `row` of data, columns to be processed —`c2p`, the `colsDefn`,
   * and a `node` that captures the column-wise varianceXn & mean for every unique
   * of the a column.
   *
   * @param {array} row — single row of transformed data that needs to be processed.
   * @param {number} rowsIndex — index of the row being passed.
   * @param {object} candidates — for split, contains all the statistic.
   * @param {function} updateFn — updates the statistic in `candidates`.
   * @return {object[]} ???
   * @private
  */
  var processRow = function ( row, rowsIndex, candidates, updateFn ) {
    // Single column to process from the array `cols2p`.
    var c2p;
    var indexOfTarget = row.length - 1;
    for ( var i = 0, imax = candidates.list.length; i < imax; i += 1 ) {
      c2p = candidates.list[ i ];
      updateFn( candidates, c2p, row[ c2p ], rowsIndex, row[ indexOfTarget ] );
    }
  }; // processRow()

  // ### selectBestSplit
  /**
   *
   * Finds the best candidate column for split on the basis of maximum reduction
   * in variance (impurity or maximum gain).
   *
   * @param {object} candidates — columns from where the best candidate for split
   * is selected.
   * @return {object} containing the best `col` and the corresponding wieghted
   * `sum` of squared deviation from mean for each unique value.
   * @private
  */
  var selectBestSplit = function ( candidates ) {
    // Used in for-in loop: unique values (`uvs`) in a `col`.
    var col, uvs;
    // Sum of `varianceXn * size` for each `uvs` in a `col`; and its size.
    var size, sum;
    // Used to compute average children item for minAvgChildrenItems config.
    var counter, meanSize;
    // Minimum Sum and the Best Column.
    var bestCol, minSum;

    minSum = Infinity;
    bestCol = -1;
    for ( col in candidates.columns ) { // eslint-disable-line guard-for-in
      // Initialize `sum` and `size` for this `col`.
      sum = 0;
      size = 0;
      // And also counter & meanSize.
      counter = 0;
      meanSize = 0;
      for ( uvs in candidates.columns[ col ] ) { // eslint-disable-line guard-for-in
        size += candidates.columns[ col ][ uvs ].size;
        // Compute average (mean) children items.
        counter += 1;
        meanSize += computeMeanDelta( candidates.columns[ col ][ uvs ].size, meanSize, counter );
        // Compute weighted sum; will divide by sum after the loop finishes to normalize.
        // Recall, `varianceXn` is variance multiplied by items.
        sum += ( candidates.columns[ col ][ uvs ].varianceXn /* candidates.columns[ col ][ uvs ].size */ );
      }
      // Normalize - this will yield weighted sum of variances.
      sum /= size;
      // Update minumum only if `meanSize` is above the defined threshold.
      if ( ( sum < minSum ) && ( meanSize > config.minAvgChildrenItems ) ) {
        minSum = sum;
        bestCol = col;
      }
    }
    // If the best column is not found, return `undefined`.
    return ( bestCol === -1 ) ? undefined : { col: +bestCol, sum: minSum };
  }; // selectBestSplit()

  // ### reducer
  /**
   *
   * Helper function for `JS array reduce`; used to merge two arrays.
   *
   * @param {object} acc — accumulator i.e. the array containing the merged values.
   * @param {object} cv — current value i.e. one array element to be pushed.
   * @return {object} collapsed column.
   * @private
  */
  var reducer = function ( acc, cv ) {
    acc.push( cv );
    return ( acc );
  }; // reducer();

  // ### collapseNodesInCol
  /**
   *
   * Iterates through every candidate column in `cc`. For each candidate column,
   * it collapses all nodes with `size < config.minLeafNodeItems` into a single
   * node referred to as `$$other_values`.
   *
   * @param {object} col — candidate columns that are iterated through for a
   * possible collapse.
   * @return {object} collapsed column.
   * @private
  */
  var collapseNodesInCol = function ( col ) {
    // Collapsed column
    var collapsedCol = Object.create( null );
    // All `nodes < config.minLeafNodeItems` will be collapsed into this.
    var others = Object.create( null );
    // Unique Value in `col`
    var uv;
    // Helpers!
    var collapsedOccurred = false;
    // Combined mean, temp object holder.
    var meanc, obj;

    others.size = 0;
    others.mean = 0;
    others.varianceXn = 0;
    others.index = [];
    others.collapsedNodes = 0;
    // Iterate through every unique value in the `col` object.
    for ( uv in col ) { // eslint-disable-line guard-for-in
      obj = col[ uv ];
      if ( obj.size < config.minLeafNodeItems ) {
        collapsedOccurred = true;
        others.collapsedNodes += 1;
        // Combine means and remember it for a while before updating.
        meanc = ( ( others.mean * others.size ) + ( obj.mean * obj.size ) ) / ( others.size + obj.size );
        // Combine `variances * size` i.e. `varianceXn`.
        others.varianceXn = others.varianceXn +
                            obj.varianceXn +
                            ( others.size * ( others.mean - meanc ) * ( others.mean - meanc ) ) +
                            ( obj.size * ( obj.mean - meanc ) * ( obj.mean - meanc ) );
        // Now update combined means!
        others.mean = meanc;
        // Update size.
        others.size += obj.size;
        // Finally merge both indexes.
        others.index = obj.index.reduce( reducer, others.index );
      } else {
        collapsedCol[ uv ] = col[ uv ];
      }
    }
    // If collapse has occurred then include `$$other_values` in `collapsedCol`.
    if ( collapsedOccurred ) collapsedCol.$$other_values = others; // eslint-disable-line camelcase
    return collapsedCol;
  }; // collapseNodesInCol()

  // ### collapseNodesInCC
  /**
   *
   * Iterates through every candidate column in `cc`. For each candidate column,
   * it collapses all nodes with `size < config.minLeafNodeItems` into a single
   * node referred to as `$$other_values`.
   *
   * @param {object} cc — candidate columns that are iterated through for a
   * possible collapse.
   * @return {undefined} the void!
   * @private
  */
  var collapseNodesInCC = function ( cc ) {
    // Column Id in Candidate Columns (cc).
    var cid;
    for ( cid in cc ) { // eslint-disable-line guard-for-in
      cc[ cid ] = collapseNodesInCol( cc[ cid ] );
    }
  }; // collapseNodesInCC()


  // ### growTree
  /**
   *
   * Builds the tree recursively by maximaizing the variance reduction on each
   * split.
   *
   * @param {object} cc — candidate columns to consider for further growing the
   * tree.
   * @param {number} splitData — columns on which split occurred.
   * @param {number} colUsed4Split — column used for creating the `splitData`.
   * @param {object} node — node of the tree, from where tree may be grown further.
   * @param {number} depth — of the tree so far.
   * @return {object} the tree!
   * @private
  */
  var growTree = function ( cc, splitData, colUsed4Split, node, depth ) {
    // Maximum defined depth reached?
    if ( depth > config.maxDepth ) {
      // Yes, return.
      return;
    }

    var cCols;
    var colsLeft;
    var bs, uniqVal;
    var varianceReduction;
    var child;
    // Helper variables
    var actualValue, index, j, k, kmax;
    node.branches = Object.create( null );
    for ( uniqVal in splitData ) { // eslint-disable-line guard-for-in
      // Node always has enough items as collapse would have already occurred.
      // @blab+ address non-categorical values, too
      var candidate = columnsDefn[ xc2cMap[ colUsed4Split ] ];
      if (uniqVal === '$$other_values' || !candidate.invertedMap) actualValue = uniqVal;
      else actualValue =  candidate.invertedMap[ +uniqVal ];
      // actualValue = ( uniqVal === '$$other_values' ) ? uniqVal : columnsDefn[ xc2cMap[ colUsed4Split ] ].invertedMap[ +uniqVal ];
      child = node.branches[ actualValue ] = Object.create( null );
      child.size = splitData[ uniqVal ].size;
      child.mean = splitData[ uniqVal ].mean;
      child.stdev = computeStdev( splitData[ uniqVal ].varianceXn, splitData[ uniqVal ].size );
      // Add collapsed node count, if collapsed had occurred: more for reference only.
      // It has no predictionn value.
      if ( splitData[ uniqVal ].collapsedNodes !== undefined ) child.collapsedNodes = splitData[ uniqVal ].collapsedNodes;
      // Create candidate colums for this node. These will be used to obtain bestCol
      // split as per the `config`.
      cCols = createCandidates( cc );
      index = splitData[ uniqVal ].index;
      // Does it have enough items to proceed with split?
      if ( index.length <= config.minSplitCandidateItems || child.stdev < stdevEPSILON ) {
        // No! continue with the iteration with the next `uniqVal`.
        continue;
      }
      // Attempt split.
      for ( k = 0, kmax = index.length; k < kmax; k += 1 ) {
        processRow( xdata[ index[ k ] ], index[ k ], cCols, updateVarianceXn );
      }
      // Node that contain less than `config.minLeafNodeItems` are collapsed here.
      collapseNodesInCC(cCols.columns);
      bs = selectBestSplit( cCols );
      if ( bs === undefined ) {
        // No best column found, coninue with the next one!
        continue;
      }
      varianceReduction = computePercentageVarianceReduction( splitData[ uniqVal ].varianceXn, splitData[ uniqVal ].size, bs.sum );
      // Reasonable variance reduction?
      if ( varianceReduction < config.minPercentVarianceReduction ) {
        // No! continue with the iteration with the next `uniqVal`.
        continue;
      }
      // Yes, split possible! Make a list of left columns by removing the columns
      // found for splitting.
      colsLeft = [];
      for ( j = 0; j < cc.length; j += 1 ) {
        if ( cc[ j ] !== bs.col ) colsLeft.push( cc[ j ] );
      }
      // Recurse!
      child.colUsed4Split = columnsDefn[xc2cMap[bs.col]].name;
      child.varianceReduction = varianceReduction;
      growTree( colsLeft, cCols.columns[ bs.col ], bs.col, child, ( depth + 1 ) );
    }
  }; // growTree()

  // ### countRules
  /**
   *
   * Counts the number of rules generated from a rules tree and updates the final
   * number in the root node of the tree.
   *
   * @param {object} tree — the rules tree.
   * @return {undefined} or void!
   * @private
  */
  var countRules = function ( tree ) {
    var subTree = tree.branches;
    for ( var node in subTree ) {
      if ( subTree[ node ].branches !== undefined && Object.keys( subTree[ node ].branches ).length > 0 ) {
        countRules( subTree[ node ] );
      } else wrTree.rulesLearned += 1;
    }
  }; // countRules()

  // ### defineConfig
  /**
   *
   * Defines the configuration required to read the input data and to generates
   * the regression tree.
   *
   * @method RegressionTree#defineConfig
   * @param {object[]} inputDataCols each object in this array defines a column of input
   * data in the same sequence in which data will be supplied to `ingest().` It is
   * defined in terms of the following details:
   * @param {string} inputDataCols[].name of the column.
   * @param {boolean} inputDataCols[].categorical defines column's data type — `true` indicating categorical
   * **or** `false` indicating numeric; currently numeric data type is not supported.
   * @param {boolean} [inputDataCols[].exclude=false] used to exclude a column during tree building.
   * @param {boolean} [inputDataCols[].target=false] is set to `true` only for the target column, whose
   * value needs to be predicted. Note this column must be a numeric column.
   * @param {object} tree contains key value pairs of the following regression
   * tree's parameters:
   * @param {number} [tree.maxDepth=20] is the maximum depth of the tree after which
   * learning stops.
   * @param {number} [tree.minPercentVarianceReduction=10] is the minmum variance reduction
   * required for a split to occur.
   * @param {number} [tree.minSplitCandidateItems=50] the minimum items that must be present
   * at a node for it to be split further, even after the `minPercentVarianceReduction`
   * target has been achieved.
   * @param {number} [tree.minLeafNodeItems=10] is the minimum number of items that
   * must be present at a leaf node to be retained as an independent node. Nodes with
   * less than this value size are merged together.
   * @param {number} [tree.minAvgChildrenItems=2] the average number of items
   * across children must be greater than this number, for a column to become a candidate
   * for split. A higher number will discourage splits that creates many branches
   * with each child node containing fewer items.
   * @return {number} number of columns defined.
   * @example
   * // Define each column.
   * var columns = [
   *   { name: 'model', categorical: true, exclude: true },
   *   { name: 'mpg', categorical: false, target: true },
   *   { name: 'cylinders', categorical: true },
   *   { name: 'displacement', categorical: true, exclude: false },
   *   { name: 'horsepower', categorical: true, exclude: false },
   *   { name: 'weight', categorical: true, exclude: false },
   *   { name: 'acceleration', categorical: true, exclude: false },
   *   { name: 'year', categorical: true, exclude: true },
   *   { name: 'origin', categorical: true, exclude: false  }
   * ];
   * // Define parameters to grow the tree.
   * var treeParams = {
   *   minPercentVarianceReduction: 2.5,
   *   minLeafNodeItems: 10,
   *   minSplitCandidateItems: 30,
   *   minAvgChildrenItems: 3
   * };
   * // Define the configuration using above 2 variables.
   * myRT.defineConfig( columns, treeParams );
   * // -> 8
  */
  var defineConfig = function ( inputDataCols, tree ) {
    config.maxDepth = tree.maxDepth || config.maxDepth;
    config.minPercentVarianceReduction = tree.minPercentVarianceReduction || config.minPercentVarianceReduction;
    config.minSplitCandidateItems = tree.minSplitCandidateItems || config.minSplitCandidateItems;
    config.minLeafNodeItems = tree.minLeafNodeItems || config.minLeafNodeItems;
    config.minAvgChildrenItems = tree.minAvgChildrenItems || config.minAvgChildrenItems;
    columnsConfig = inputDataCols;
    columnsDefn = initColsDefn( columnsConfig );
    return inputDataCols.length;
  }; // defineConfig();

  // ### ingest
  /**
   *
   * Ingests one row of the data at a time. It is specially useful for reading
   * data in an asynchronus manner, where this may be used as a call back function
   * on every row read event.
   *
   * @method RegressionTree#ingest
   * @param {array} row one row of the data to be ingested; column values
   * should be in the same sequence in which they are defined in data configuration
   * via `defineConfig()`.
   * @return {boolean} always `true`.
   * @throws {error} if number of elements in `row` don't match with the
   * number of columns defined.
   * @example
   * // Load cars training data set.
   * var cars = require( 'wink-regression-tree/sample-data/cars.json' );
   * // Ingest the data.
   * cars.forEach( function ( row ) {
   *   myRT.ingest( row );
   * } );
  */
  var ingest = function ( row ) {
    if ( row.length === columnsConfig.length ) {
      xdata.push( transformRow( row, columnsDefn ) );
    } else {
      throw Error( 'winkRT: ingest is expecting ' + columnsConfig.length + ' elements instead found: ' + row.length );
    }

    return true;
  }; // ingest()

  // ### learn
  /**
   *
   * Learns from the ingested data and generates the rule tree that is used to
   * `predict()` the value of target variable from the input. It requires at least
   * 60 data rows to initiate meaningful learning.
   *
   * @method RegressionTree#learn
   * @return {number} number of rules learned from the input data.
   * @throws {error} if number of rows in the ingested data are <60.
   * @example
   * myRT.learn();
   * // -> Number of rules learned
  */
  var learn = function ( ) {
    if ( xdata.length < 60 ) {
      throw Error( 'winkRT: learn is expecting at least 60 rows of data, instead found: ' + xdata.length );
    }
    // Candidate columns list
    var candidateCols = [];
    // Candidate columns created using above list.
    var cndts;
    // Required for the root node.
    var rootsMean = 0;
    var rootsVarianceXn = 0;
    var prevRootsMean;
    // Index of the target variable (Y).
    var indexOfTarget;
    // Object containing best split info in terms of the column and the
    // weighted `sum` of variance.
    var bestSplit;
    // Updated candidate columns list after split.
    var updatedCandidateCols = [];
    // Helper variables
    var i, imax;
    var k = 0;

    // Create candidate columns list & `xc2cMap`.
    for ( i = 0, imax = columnsConfig.length; i < imax; i += 1 ) {
      if ( !columnsConfig[ i ].exclude ) {
        if ( !columnsConfig[ i ].target ) {
          xc2cMap.push( i );
          candidateCols.push( k );
          k += 1;
        }
      }
    }

    cndts = createCandidates( candidateCols );

    indexOfTarget = xdata[ 0 ].length - 1;
    // Process every row as this is the root level.
    for ( i = 0; i < xdata.length; i += 1 ) {
      processRow( xdata[ i ], i, cndts, updateVarianceXn );
      prevRootsMean = rootsMean;
      rootsMean += computeMeanDelta( xdata[ i ][ indexOfTarget ], rootsMean, ( i + 1 ) );
      rootsVarianceXn += computeVarianceXnDelta( xdata[ i ][ indexOfTarget ], rootsMean, prevRootsMean );
    }
    // Node that contain less than `config.minLeafNodeItems` are collapsed here.
    collapseNodesInCC(cndts.columns);
    // Define minimal root node stuff here itself.
    wrTree.version = winkRulesTreeVersion;
    wrTree.size = xdata.length;
    wrTree.mean = rootsMean;
    wrTree.stdev = computeStdev( rootsVarianceXn, wrTree.size );
    // Attempt to grow tree if standard deviation is large enough!
    if ( wrTree.stdev > stdevEPSILON ) {
      bestSplit = selectBestSplit( cndts );
      if ( bestSplit === undefined ) {
        // Opps, no worthy column available - return the root!
        wrTree.rulesLearned = 0;
        countRules( wrTree );
        return wrTree.rulesLearned;
      }
      // Find the updated list of candidate columsn after the split.
      for ( i = 0; i < candidateCols.length; i += 1 ) {
        if ( candidateCols[ i ] !== bestSplit.col ) updatedCandidateCols.push( candidateCols[ i ] );
      }
      // Define the balance stuff as a split has been found!
      wrTree.colUsed4Split = columnsDefn[xc2cMap[bestSplit.col]].name;
      wrTree.varianceReduction = computePercentageVarianceReduction( rootsVarianceXn, wrTree.size, bestSplit.sum );
      // Call recursive function, `growTree()`.
      growTree( updatedCandidateCols, cndts.columns[ bestSplit.col ], bestSplit.col, wrTree, 1 );
    }
    wrTree.rulesLearned = 0;
    countRules( wrTree );
    return wrTree.rulesLearned;
  }; // learn()

  // ### navigateRules
  /**
   *
   * Recursively navigaes the rule tree to arrive at a prediction for the
   * `input` data. If the value of a columm in the input data, required during
   * the prediction is missing, it throws an error provided the function
   * `f` is not defined. Otherwise the name of column is passed to this function;
   * and the function is expected to handle the same.
   *
   * @param {object} input — data containing column name/value pairs; the column
   * names must the same as defined via `defineConfig()`.
   * @param {object} rules — the rules tree generated during `learn()`; on every
   * recursion a branch of tree is passed.
   * @param {function} [f=undefined] — is called once
   * a leaf node is reached during prediction with the following 4 parameters: **size,**
   * **mean** and **stdev** values at the node; an **array** of column names
   * navigated to reach the leaf and **column name** for which value is missing
   * in the input (if found). The value returned from this function becomes  the prediction.
   * @param {array} colsUsed4Prediction — columns used for prediction are pushed into this array; if
   * this is empty then it means no rules matched and prediction occurred using
   * the root node.
   * @return {number} `mean` value or whatever is returned by the `fn` function, if defined.
   * @private
  */
  var navigateRules = function ( input, rules, f, colsUsed4Prediction ) {
    // Sub-tree is present if # of branches > 0.
    var hasSubTree = helpers.object.isObject( rules.branches ) &&
                        ( ( Object.keys( rules.branches ) ).length > 0 );


    var inputHasReqdValue = false;
    var stopNavigation = true;
    var column;
    var reqdValue;

    if ( !hasSubTree ) {
      // No subTree, return!
      return (
        ( typeof f === 'function' ) ?
          f( rules.size, rules.mean, rules.stdev, colsUsed4Prediction ) :
          rules.mean
      );
    }
    // Sub-tree is present, check if the input has a value for `colUsed4Split`.
    column = rules.colUsed4Split;

    inputHasReqdValue = ( ( input[ column ] !== undefined ) &&
      ( input[ column ] !== null ) );

    if ( inputHasReqdValue ) {
      // Lookup `reqdValue` from the input.
      reqdValue = input[ column ];
      // If there is no branch corresponding to the `reqdValue` then instead of stopping
      // navigation and returning the parent's node stuff, also check if there exist
      // `$$other_values`. If such a node exist, **assume** that this `reqdValue` belongs
      // to the `$$other_values` set. The intuition is that typically other values are
      // those that have very few instances (i.e. frequency of occurrance) and
      // therefore this `reqdValue` will share characterstics with `$$other_values`.
      // However, if there is no `$$other_values` set at this level then simply return
      // parent's node stuff.
      stopNavigation = !helpers.object.isObject( rules.branches[ reqdValue ] || rules.branches.$$other_values );
    } else {
      // Input does not have the value for column.
      if ( typeof f !== 'function' ) {
        // No `f` defined, throw error.
        throw Error( 'winkRT: missing column value for the column found during prediction: ' + JSON.stringify( column ) );
      }
      // The `f` is defined, let it handle.
      return f( rules.size, rules.mean, rules.stdev, colsUsed4Prediction, column );
    }

    if ( stopNavigation ) {
      return (
        ( typeof f === 'function' ) ?
          f( rules.size, rules.mean, rules.stdev, colsUsed4Prediction, column ) :
          rules.mean
      );
    }
    // Continue navigation!
    colsUsed4Prediction.push( rules.colUsed4Split );
    return navigateRules( input, rules.branches[ reqdValue ] || rules.branches.$$other_values, f, colsUsed4Prediction );
  }; // navigateRules()

  // ### predict
  /**
   *
   * Predicts the value of target variable from the `input` using the rules tree generated by
   * `learn()`. If the value of a columm in the input data, required for
   * the prediction is missing, by defualt it throws an error. If the function
   * `fn` is defined then no error is thrown, instead the name of missing column is passed
   * to this function; and the function is expected to handle the same.
   *
   * @method RegressionTree#predict
   * @param {object} input data containing column name/value pairs; the column
   * names must the same as defined via `defineConfig()`.
   * @param {function} [modifier=undefined] is called once
   * a leaf node is reached during prediction with the following 5 parameters: **size,**
   * **mean** and **stdev** values at the node; an **array** of column names
   * navigated to reach the leaf and **column name** for which value is missing
   * in the input (`default=undefined`). The value returned from this function becomes  the prediction.
   * @return {number} `mean` value or whatever is returned by the `modifier` function, if defined.
   * @throws {error} if the `input` is not a javascript object.
   * @throws {error} if a value of a column required for prediction is missing in `input`,
   * provided `modifier` has not been defined.
   * @example
   * // Populate sample input
   * var input = {
   *   model: 'Ford Gran Torino',
   *   weight: 'very high weight',
   *   displacement: 'very large displacement',
   *   horsepower: 'extremely high power',
   *   origin: 'US',
   *   acceleration: 'slow'
   * };
   * // Attempt prediction.
   * myRT.predict( input );
   * // -> 14.3
  */
  var predict = function ( input, modifier ) {
    if ( !helpers.object.isObject( input ) ) {
      throw Error( 'winkRT: input for prediction must be an object, instead found: ' + ( typeof input ) );
    }
    var colsUsed4Prediction = [];
    return navigateRules( input, wrTree, modifier, colsUsed4Prediction );
  }; // predict()

  // ### navigateRules4Stats
  /**
   *
   * Recursively navigaes the rule tree to generate the summary by extracting the
   * level wise column hierarchy, nodes that were split on this hierarchy, min &
   * max variance reduction, etc.
   *
   * @param {object} subTree — the rules tree generated during `learn()`; on every
   * recursion a branch of tree is passed.
   * @param {object} stats — summary of min/max means and their corresponding stdevs
   * along with the overall `minSD` — minimum stdev.
   * @param {stats} colImp — contains depth wise column hierarchy, number of nodesSplit
   * and the min/max varaiance reduction at that level.
   * @param {number} depth — the current depth of the tree.
   * @param {string} ch — column's hierarchy in the unix file/folder naming style.
   * @return {undefined} nothing!
   * @private
  */
  var navigateRules4Stats = function ( subTree, stats, colImp, depth, ch ) {
    var chVal = ch;
    if ( subTree.branches && ( Object.keys( subTree.branches ) ).length > 0 ) {
      // Update column's hierarchy in unix styled path names.
      chVal += '/' + subTree.colUsed4Split;
      // Initialize stats at the current `depth` and `ch` level.
      colImp[ depth ] = colImp[ depth ] || Object.create( null );
      if ( colImp[ depth ][ chVal ] === undefined ) {
        colImp[ depth ][ chVal ] = Object.create( null );
        colImp[ depth ][ chVal ].nodesSplit = 0;
        colImp[ depth ][ chVal ].minVR = Infinity;
        colImp[ depth ][ chVal ].maxVR = -Infinity;
      }
      // Update stats.
      colImp[ depth ][ chVal ].nodesSplit += 1;
      // Update min/max varaiance reductions.
      colImp[ depth ][ chVal ].minVR = Math.min( colImp[ depth ][ chVal ].minVR, +subTree.varianceReduction.toFixed( 4 ) );
      colImp[ depth ][ chVal ].maxVR = Math.max( colImp[ depth ][ chVal ].maxVR, +subTree.varianceReduction.toFixed( 4 ) );

      for ( var key in subTree.branches ) { // eslint-disable-line guard-for-in
        // Update summary!
        if ( stats.min.mean > subTree.branches[ key ].mean ) {
          stats.min.mean = subTree.branches[ key ].mean;
          stats.min.itsSD = subTree.branches[ key ].stdev;
        }
        if ( stats.max.mean < subTree.branches[ key ].mean ) {
          stats.max.mean = subTree.branches[ key ].mean;
          stats.max.itsSD = subTree.branches[ key ].stdev;
        }
        stats.minSD = Math.min( stats.minSD, subTree.branches[ key ].stdev );
        // Time to dig deeper!!
        navigateRules4Stats( subTree.branches[ key ], stats, colImp, ( depth + 1 ), chVal );
      }
    }
  }; // navigateRules4Stats()

  // ### summary
  /**
   *
   * Generates summary of the learnings in terms of the following:<ol>
   * <li>Relative importance of columns along with the corresponding min/max
   * variance reductions (VR).</li>
   * <li>The min/max mean values along with the corresponding standard
   * deviations (SD).</li>
   * <li>The minumum standard deviation (SD) discovered during the learning.</li></ol>
   *
   * @method RegressionTree#summary
   * @return {object} containing the following:<ol>
   * <li><code>table</code> — array of objects, where each object defines <code>level</code>, <code>columnHierarchy</code>,
   * <code>nodesSplit</code>, <code>minVR</code> and <code>maxVR</code>. A lower value of <code>level</code>
   * indicates higher importance; similarly more nodes at a level split on a columnHierarchy
   * is an indication of importance. Therefore, it is sorted in ascending order of <code>level</code>
   * followed by in descending order of <code>nodesSplit</code>.</li>
   * <li><code>stats</code> — object containing <code>min.mean</code>, <code>min.itsSD</code>, <code>max.mean</code>, <code>max.itsSD</code>,
   * and <code>minSD</code>.</li></ol>
   * @example
   * myRT.summary();
   * // -> returns the summary object.
  */
  var summary = function () {
    // Column imporatnce is captured first in an object to ease hashing and later
    // converted to a table.
    var columnsImportance = Object.create( null );
    var table = [];
    // Current depth of the tree.
    var depth = 1;
    // In unix style file paths.
    var columnHierarchy = '';
    // To capture min/max means and their stdevs, etc.
    var stats = Object.create( null );
    // Helper variables.
    var ch, level;

    // Initialize.
    stats.min = Object.create( null );
    stats.max = Object.create( null );
    stats.minSD = Infinity;
    stats.min.mean = Infinity;
    stats.min.itsSD = 0;
    stats.max.mean = -Infinity;
    stats.max.itsSD = 0;
    // Buld summary recursively.
    navigateRules4Stats( wrTree, stats, columnsImportance, depth, columnHierarchy );
    // Convert to `table`.
    for ( level in columnsImportance ) { // eslint-disable-line guard-for-in
      for ( ch in columnsImportance[ level ] ) { // eslint-disable-line guard-for-in
        table.push( {
          level: +level,
          columnHierarchy: ch,
          nodesSplit: columnsImportance[ level ][ ch ].nodesSplit,
          minVR: columnsImportance[ level ][ ch ].minVR,
          maxVR: columnsImportance[ level ][ ch ].maxVR,
        } );
      }
    }
    // Sort on level (asc) and then on nodesSplit(dsc).
    table.sort( function ( a, b ) {
      return (
        ( a.level > b.level ) ? 1 :
          ( a.level < b.level ) ? -1 :
            ( a.nodesSplit < b.nodesSplit ) ? 1 : -1
      );
    } );
    // Return summary!
    return { columnsImportance: table, stats: stats };
  }; // summary()

  // ### evaluate
  /**
   *
   * Incrementally evalutes variance reduction for one data row at a time.
   *
   * @method RegressionTree#evaluate
   * @param {object} rowObject contains column name/value pairs including the target column
   * name/value pair as well, which is used in evaluating the variance reduction.
   * @return {boolean} always `true`.
   * @example
   * myRT.evaluate( input );
  */
  var evaluate = function ( rowObject ) {
    var pv = predict( rowObject );
    evalParams.prevMean = evalParams.mean;
    evalParams.size += 1;
    evalParams.mean += computeMeanDelta( rowObject[ target ], evalParams.mean, evalParams.size );
    evalParams.gssdm += computeVarianceXnDelta( rowObject[ target ], evalParams.mean, evalParams.prevMean );
    evalParams.ssdm += ( ( rowObject[ target ] - pv ) * ( rowObject[ target ] - pv ) );
    return true;
  }; // evaluate()

  // ### metrics
  /**
   *
   * Computes the variance reduction observed in the validation data passed to
   * `evaluate()`.
   *
   * @method RegressionTree#metrics
   * @return {object} containing the `varianceReduction` in percentage and data `size`.
   * @example
   * myRT.metrics();
   * // -> object containing varianceReduction and data size.
  */
  var metrics = function ( ) {
    return (
      {
        size: evalParams.size,
        varianceReduction: +( ( evalParams.gssdm - evalParams.ssdm ) * 100 / evalParams.gssdm ).toFixed( 4 ),
      }
    );
  }; // metrics()

  // ### exportJSON
  /**
   *
   * Exports the JSON of the rule tree generated by `learn()`, which may be
   * saved in a file for later predictions.
   *
   * @method RegressionTree#exportJSON
   * @return {json} of the rule tree.
   * @example
   * var rules = myRT.exportJSON();
  */
  var exportJSON = function () {
    return JSON.stringify( wrTree );
  }; // exportJSON()

  // ### importJSON
  /**
   *
   * Imports the rule tree from the input `rulesTree` for subsequent use by `predict()`.
   * Note after a successful import, this can be used ONLY for prediction purpose
   * and not for further ingestion and/or learning.
   *
   * @method RegressionTree#importJSON
   * @param {json} rulesTree containg an earlier exported rule tree in JSON format.
   * @return {boolean} always `true`.
   * @throws {error} if `rulesTree` is `null`.
   * @throws {error} if `rulesTree` can not be parsed as a valid JSON.
   * @throws {error} if `rulesTree` is of incorrect version or incorrect format.
   * @example
   * var anRT = regressionTree();
   * // Assuming that json has a valid rule tree.
   * anRT.importJSON( rules );
  */
  var importJSON = function ( rulesTree ) {
    if ( !rulesTree ) {
      throw Error( 'winkRT: undefined or null JSON encountered, import failed!' );
    }
    try {
      wrTree = JSON.parse( rulesTree );
    } catch ( ex ) {
      throw Error( 'winkRT: JSON parsing error during import:\n\t' + ex.message );
    }
    if ( wrTree.version !== winkRulesTreeVersion ) {
      throw Error( 'winkRT: incorrect json format or tree version, import failed!' );
    }
    return true;
  }; // importJSON()

  // ### reset
  /**
   *
   * It completely resets the tree by re-initializing all the learning
   * related variables, except it's configuration. It is useful during
   * cross fold-validation.
   *
   * @method RegressionTree#reset
   * @return {undefined} nothing!
   * @example
   * var myRT.reset();
  */
  var reset = function () {
    // Do not reset variables pertaining to *configuration*:<br/>
    // 1. `columnsConfig`
    // 2. `columnsDefn`
    // 3. `config`
    // 4. `target`

    // All other variables are reset/re-initialized.

    // Re-initialize the **w**ink **r**egression tree.
    wrTree = Object.create( null );
    // Re-initialize Xformed Column id to input column id map.
    xc2cMap = [];
    // Re-initialize Xformed data, where categorical variables are encoded by a numeric code. Useful
    // in reduction of memory load.
    xdata = [];
    // Re-initialize parameters used for evaluation.
    evalParams = Object.create( null );
    initEvalParams();
  }; // reset();

  // Set default configuration;
  config.maxDepth = 20;
  config.minPercentVarianceReduction = 10;
  config.minSplitCandidateItems = 50;
  config.minLeafNodeItems = 10;
  // This will ensure that split will never occurr on uniq id like columns!
  config.minAvgChildrenItems = 2;
  // Initialize the number of rules learned.
  wrTree.rulesLearned = 0;

  // Initialize evaluation parameters.
  initEvalParams();

  methods.defineConfig = defineConfig;
  methods.ingest = ingest;
  methods.learn = learn;
  methods.predict = predict;
  methods.evaluate = evaluate;
  methods.metrics = metrics;
  // Setup an alias `stats()` to maintain similarity with other ML packages
  // such as naive bayes, etc.
  methods.stats = methods.summary = summary;
  methods.exportJSON = exportJSON;
  methods.importJSON = importJSON;
  methods.reset = reset;

  methods.info = function () {
    return {
      columnsConfig : columnsConfig,
      columnsDefn : columnsDefn,
    }
  }
  return methods;
}; // regressionTree()

// Export
module.exports = regressionTree;
};
BundleModuleCode['ml/helpers']=function (module,exports,global,process){
//     wink-helpers
//     Functions for cross validation, shuffle, cartesian product and more
//
//     https://github.com/winkjs/wink-helpers
//
//     Copyright (C) 2017-18  GRAYPE Systems Private Limited
//
//     This file is part of “wink-helpers”.
//
//     Permission is hereby granted, free of charge, to any person obtaining a
//     copy of this software and associated documentation files (the "Software"),
//     to deal in the Software without restriction, including without limitation
//     the rights to use, copy, modify, merge, publish, distribute, sublicense,
//     and/or sell copies of the Software, and to permit persons to whom the
//     Software is furnished to do so, subject to the following conditions:
//
//     The above copyright notice and this permission notice shall be included
//     in all copies or substantial portions of the Software.
//
//     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
//     DEALINGS IN THE SOFTWARE.

//
var helpers = Object.create( null );

// ### Private Functions

// #### Product Reducer (Callback)

// Callback function used by `reduce` inside the `product()` function.
// Follows the standard guidelines of `reduce()` callback function.
var productReducer = function ( prev, curr ) {
  var c,
      cmax = curr.length;
  var p,
      pmax = prev.length;
  var result = [];

  for ( p = 0; p < pmax; p += 1 ) {
    for ( c = 0; c < cmax; c += 1 ) {
      result.push( prev[ p ].concat( curr[ c ] ) );
    }
  }
  return ( result );
}; // productReducer()

// ### Public Function

// ### Array Helpers

helpers.array = Object.create( null);

// #### is Array

// Tests if argument `v` is a JS array; returns `true` if it is, otherwise returns `false`.
helpers.array.isArray = function ( v ) {
  return ( ( v !== undefined ) && ( v !== null ) && ( Object.prototype.toString.call( v ) === '[object Array]' ) );
}; // isArray()


// #### sorting helpers

// Set of helpers to sort either numbers or strings. For key/value pairs,
// the format for each element must be `[ key, value ]`.
// Sort helper to sort an array in ascending order.
helpers.array.ascending = function ( a, b ) {
  return ( a > b ) ? 1 :
            ( a === b ) ? 0 : -1;
}; // ascending()

// Sort helper to sort an array in descending order.
helpers.array.descending = function ( a, b ) {
  return ( b > a ) ? 1 :
            ( b === a ) ? 0 : -1;
}; // descending()

// Sort helper to sort an array of `[ key, value ]` in ascending order by **key**.
helpers.array.ascendingOnKey = function ( a, b ) {
  return ( a[ 0 ] > b[ 0 ] ) ? 1 :
            ( a[ 0 ] === b[ 0 ] ) ? 0 : -1;
}; // ascendingOnKey()

// Sort helper to sort an array of `[ key, value ]` in descending order by **key**.
helpers.array.descendingOnKey = function ( a, b ) {
  return ( b[ 0 ] > a[ 0 ] ) ? 1 :
            ( b[ 0 ] === a[ 0 ] ) ? 0 : -1;
}; // descendingOnKey()

// Sort helper to sort an array of `[ key, value ]` in ascending order by **value**.
helpers.array.ascendingOnValue = function ( a, b ) {
  return ( a[ 1 ] > b[ 1 ] ) ? 1 :
            ( a[ 1 ] === b[ 1 ] ) ? 0 : -1;
}; // ascendingOnValue()

// Sort helper to sort an array of `[ key, value ]` in descending order by **value**.
helpers.array.descendingOnValue = function ( a, b ) {
  return ( b[ 1 ] > a[ 1 ] ) ? 1 :
            ( b[ 1 ] === a[ 1 ] ) ? 0 : -1;
}; // descendingOnValue()

// The following two functions generate a suitable function for sorting on a single
// key or on a composite keys (max 2 only). Just a remider, the generated function
// does not sort on two keys; instead it will sort on a key composed of the two
// accessors.
// Sorts in ascending order on `accessor1` & `accessor2` (optional).
helpers.array.ascendingOn = function ( accessor1, accessor2 ) {
  if ( accessor2 ) {
    return ( function ( a, b ) {
      return ( a[ accessor1 ][ accessor2 ] > b[ accessor1 ][ accessor2 ] ) ? 1 :
              ( a[ accessor1 ][ accessor2 ] === b[ accessor1 ][ accessor2 ] ) ? 0 : -1;
    } );
  }
  return ( function ( a, b ) {
    return ( a[ accessor1 ] > b[ accessor1 ] ) ? 1 :
            ( a[ accessor1 ] === b[ accessor1 ] ) ? 0 : -1;
  } );
}; // ascendingOn()

// Sorts in descending order on `accessor1` & `accessor2` (optional).
helpers.array.descendingOn = function ( accessor1, accessor2 ) {
  if ( accessor2 ) {
    return ( function ( a, b ) {
      return ( b[ accessor1 ][ accessor2 ] > a[ accessor1 ][ accessor2 ] ) ? 1 :
              ( b[ accessor1 ][ accessor2 ] === a[ accessor1 ][ accessor2 ] ) ? 0 : -1;
    } );
  }
  return ( function ( a, b ) {
    return ( b[ accessor1 ] > a[ accessor1 ] ) ? 1 :
            ( b[ accessor1 ] === a[ accessor1 ] ) ? 0 : -1;
  } );
}; // descendingOn()

// #### pluck

// Plucks specified element from each element of an **array of array**, and
// returns the resultant array. The element is specified by `i` (default `0`) and
// number of elements to pluck are defined by `limit` (default `a.length`).
helpers.array.pluck = function ( a, key, limit ) {
  var k, plucked;
  k = a.length;
  var i = key || 0;
  var lim = limit || k;
  if ( lim > k ) lim = k;
  plucked = new Array( lim );
  for ( k = 0; k < lim; k += 1 ) plucked[ k ] = a[ k ][ i ];
  return plucked;
}; // pluck()

// #### product

// Finds the Cartesian Product of arrays present inside the array `a`. Therefore
// the array `a` must be an array of 1-dimensional arrays. For example,
// `product( [ [ 9, 8 ], [ 1, 2 ] ] )`
// will produce `[ [ 9, 1 ], [ 9, 2 ], [ 8, 1 ], [ 8, 2 ] ]`.
helpers.array.product = function ( a ) {
  return (
    a.reduce( productReducer, [ [] ] )
  );
};

// #### shuffle

// Randomly shuffles the elements of an array and returns the same.
// Reference: Chapter on Random Numbers/Shuffling in Seminumerical algorithms.
// The Art of Computer Programming Volume II by Donald E Kunth
helpers.array.shuffle = function ( array ) {
  var a = array;
  var balance = a.length;
  var candidate;
  var temp;

  while ( balance ) {
    candidate = Math.floor( Math.random() * balance );
    balance -= 1;

    temp = a[ balance ];
    a[ balance ] = a[ candidate ];
    a[ candidate ] = temp;
  }

  return ( a );
};


// ### Object Helpers

var objectKeys = Object.keys;
var objectCreate = Object.create;

helpers.object = Object.create( null );

// #### is Object

// Tests if argument `v` is a JS object; returns `true` if it is, otherwise returns `false`.
helpers.object.isObject = function ( v ) {
  return ( v && ( Object.prototype.toString.call( v ) === '[object Object]' ) ) ? true : false; // eslint-disable-line no-unneeded-ternary

}; // isObject()

// #### keys

// Returns keys of the `obj` in an array.
helpers.object.keys = function ( obj ) {
  return ( objectKeys( obj ) );
}; // keys()

// #### size

// Returns the number of keys of the `obj`.
helpers.object.size = function ( obj ) {
  return ( ( objectKeys( obj ) ).length );
}; // size()

// #### values

// Returns all values from each key/value pair of the `obj` in an array.
helpers.object.values = function ( obj ) {
  var keys = helpers.object.keys( obj );
  var length = keys.length;
  var values = new Array( length );
  for ( var i = 0; i < length; i += 1 ) {
    values[ i ] = obj[ keys[ i ] ];
  }
  return values;
}; // values()

// #### value Freq

// Returns the frequency of each unique value present in the `obj`, where the
// **key** is the *value* and **value** is the *frequency*.
helpers.object.valueFreq = function ( obj ) {
  var keys = helpers.object.keys( obj );
  var length = keys.length;
  var val;
  var vf = objectCreate( null );
  for ( var i = 0; i < length; i += 1 ) {
    val = obj[ keys[ i ] ];
    vf[ val ] = 1 + ( vf[ val ] || 0 );
  }
  return vf;
}; // valueFreq()

// #### table

// Converts the `obj` in to an array of `[ key, value ]` pairs in form of a table.
// Second argument - `f` is optional and it is a function, which is called with
// each `value`.
helpers.object.table = function ( obj, f ) {
  var keys = helpers.object.keys( obj );
  var length = keys.length;
  var pairs = new Array( length );
  var ak, av;
  for ( var i = 0; i < length; i += 1 ) {
    ak = keys[ i ];
    av = obj[ ak ];
    if ( typeof f === 'function' ) f( av );
    pairs[ i ] = [ ak, av ];
  }
  return pairs;
}; // table()

// ### Validation Helpers

helpers.validate = Object.create( null );

// Create aliases for isObject and isArray.
helpers.validate.isObject = helpers.object.isObject;
helpers.validate.isArray = helpers.array.isArray;

// #### isFiniteInteger

// Validates if `n` is a finite integer.
helpers.validate.isFiniteInteger = function ( n ) {
  return (
    ( typeof n === 'number' ) &&
    !isNaN( n ) &&
    isFinite( n ) &&
    ( n === Math.round( n ) )
  );
}; // isFiniteInteger()

// #### isFiniteNumber

// Validates if `n` is a valid number.
helpers.validate.isFiniteNumber = function ( n ) {
  return (
    ( typeof n === 'number' ) &&
    !isNaN( n ) &&
    isFinite( n )
  );
}; // isFiniteNumber()

// ### cross validation
/**
 *
 * Creates an instance of cross validator useful for machine learning tasks.
 *
 * @param {string[]} classLabels - array containing all the class labels.
 * @return {methods} object conatining set of API methods for tasks like evalutaion,
 * reset and metrics generation.
*/
helpers.validate.cross = function ( classLabels ) {
  // wink's const for unknown predictions!
  const unknown = 'unknown';
  // To ensure that metrics is not computed prior to evaluation.
  var evaluated = false;
  // The confusion matrix.
  var cm;
  var precision;
  var recall;
  var fmeasure;

  // The class labels is assigned to this variable.
  var labels;
  // The length of `labels` array.
  var labelCount;
  var labelsObj = Object.create( null );

  // Returned!
  var methods = Object.create( null );


  /**
   *
   * Resets the current instance for another round of evaluation; the class
   * labels defined at instance creation time are not touched.
   *
   * @return {undefined} nothing!
  */
  var reset = function ( ) {
    evaluated = false;
    cm = Object.create( null );
    precision = Object.create( null );
    recall = Object.create( null );
    fmeasure = Object.create( null );

    // Initialize confusion matrix and metrics.
    for ( var i = 0; i < labelCount; i += 1 ) {
      const row = labels[ i ];
      labelsObj[ row ] = true;
      cm[ row ] = Object.create( null );
      precision[ row ] = 0;
      recall[ row ] = 0;
      fmeasure[ row ] = 0;
      for ( var j = 0; j < labelCount; j += 1 ) {
        const col = labels[ j ];
        cm[ row ][ col ] = 0;
      }
    }
  }; // reset()

  /**
   *
   * Creates an instance of cross validator useful for machine learning tasks.
   *
   * @param {string} truth - the actual class label.
   * @param {string} guess - the predicted class label.
   * @return {boolean} returns true if the evaluation is successful. The evaluation
   * may fail if `truth` or `guess` is not in the array `classLabels` provided at
   * instance creation time; or if guess is equal to `unknown`.
  */
  var evaluate = function ( truth, guess ) {
    // If prediction failed then return false!
    if ( guess === unknown || !labelsObj[ truth ] || !labelsObj[ guess ] ) return false;
    // Update confusion matrix.
    if ( guess === truth ) {
      cm[ truth ][ guess ] += 1;
    } else {
      cm[ guess ][ truth ] += 1;
    }
    evaluated = true;
    return true;
  }; // evaluate()

  /**
   *
   * It computes a detailed metrics consisting of macro-averaged precision,
   * recall and f-measure along with their label-wise values and the confusion
   * matrix.
   *
   * @return {object} object containing macro-averaged `avgPrecision`, `avgRecall`,
   * `avgFMeasure` values along with other details such as label-wise values
   * and the confusion matrix. A value of `null` is returned if no evaluate()
   * has been called before.
  */
  var metrics = function ( ) {
    if ( !evaluated ) return null;
    // Numerators for every label; they are same for precision & recall both.
    var n = Object.create( null );
    // Only denominators differs for precision & recall
    var pd = Object.create( null );
    var rd = Object.create( null );
    // `row` and `col` of confusion matrix.
    var col, row;
    var i, j;
    // Macro average values for metrics.
    var avgPrecision = 0;
    var avgRecall = 0;
    var avgFMeasure = 0;

    // Compute label-wise numerators & denominators!
    for ( i = 0; i < labelCount; i += 1 ) {
      row = labels[ i ];
      for ( j = 0; j < labelCount; j += 1 ) {
        col = labels[ j ];
        if ( row === col ) {
          n[ row ] = cm[ row ][ col ];
        }
        pd[ row ] = cm[ row ][ col ] + ( pd[ row ] || 0 );
        rd[ row ] = cm[ col ][ row ] + ( rd[ row ] || 0 );
      }
    }
    // Ready to compute metrics.
    for ( i = 0; i < labelCount; i += 1 ) {
      row = labels[ i ];
      precision[ row ] = +( n[ row ] / pd[ row ] ).toFixed( 4 );
      // NaN can occur if a label has not been encountered.
      if ( isNaN( precision[ row ] ) ) precision[ row ] = 0;

      recall[ row ] = +( n[ row ] / rd[ row ] ).toFixed( 4 );
      if ( isNaN( recall[ row ] ) ) recall[ row ] = 0;

      fmeasure[ row ] = +( 2 * precision[ row ] * recall[ row ] / ( precision[ row ] + recall[ row ] ) ).toFixed( 4 );
      if ( isNaN( fmeasure[ row ] ) ) fmeasure[ row ] = 0;
    }
    // Compute thier averages, note they will be macro avegages.
    for ( i = 0; i < labelCount; i += 1 ) {
      avgPrecision += ( precision[ labels[ i ] ] / labelCount );
      avgRecall += ( recall[ labels[ i ] ] / labelCount );
      avgFMeasure += ( fmeasure[ labels[ i ] ] / labelCount );
    }
    // Return metrics.
    return (
      {
        // Macro-averaged metrics.
        avgPrecision: +avgPrecision.toFixed( 4 ),
        avgRecall: +avgRecall.toFixed( 4 ),
        avgFMeasure: +avgFMeasure.toFixed( 4 ),
        details: {
          // Confusion Matrix.
          confusionMatrix: cm,
          // Label wise metrics details, from those averages were computed.
          precision: precision,
          recall: recall,
          fmeasure: fmeasure
        }
      }
    );
  }; // metrics()

  if ( !helpers.validate.isArray( classLabels ) ) {
    throw Error( 'cross validate: class labels must be an array.' );
  }
  if ( classLabels.length < 2 ) {
    throw Error( 'cross validate: at least 2 class labels are required.' );
  }
  labels = classLabels;
  labelCount = labels.length;

  reset();

  methods.reset = reset;
  methods.evaluate = evaluate;
  methods.metrics = metrics;

  return methods;
}; // cross()

// ### Object Helpers

helpers.string = Object.create( null );

// Regex for [diacritical marks](https://en.wikipedia.org/wiki/Combining_Diacritical_Marks) removal.
var rgxDiacritical = /[\u0300-\u036f]/g;

/**
 *
 * Normalizes the token's value by converting it to lower case and stripping
 * the diacritical marks (if any).
 *
 * @param {string} str — that needs to be normalized.
 * @return {string} the normalized value.
 * @example
 * normalize( 'Nestlé' );
 * // -> nestle
*/
helpers.string.normalize = function ( str ) {
  return (
    str.toLowerCase().normalize( 'NFD' ).replace( rgxDiacritical, '' )
  );
}; // normalize()

helpers.getOptions = function (options,selected) {
  var options2 = {}
  selected.forEach(function (opt) { options2[opt]=options[opt] })
  return options2;
}
helpers.updateOptions = function (options,update) {
  for(var p in options) if (update[p]!=undefined) options[p]=update[p];
  return options;
}
module.exports = helpers;
};
BundleModuleCode['plugins/ml/stats']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Stefan Bosse
 **    $CREATED:     (C) 2006-2021 bLAB by sbosse
 **    $VERSION:     1.3.1X
 **
 **    $INFO:
 **
 **  ML Data Statistics and Utils 
 **
 **  New:
 **    type eps = number | number []
 **
 **    $ENDOFINFO
 */
var Io = Require('com/io');
var Comp = Require('com/compat');
var math = Require('plugins/ml/math');

///////// UTILS ////////////
var stat = {
	max: function(array) {
		return Math.max.apply(null, array);
	},
	
	min: function(array) {
		return Math.min.apply(null, array);
	},
	
	range: function(array) {
		return stat.max(array) - stat.min(array);
	},
	
	midrange: function(array) {
		return stat.range(array) / 2;
	},

	sum: function(array) {
		var num = 0;
		for (var i = 0, l = array.length; i < l; i++) num += array[i];
		return num;
	},
	
	mean: function(array) {
		return stat.sum(array) / array.length;
	},
	
	median: function(array) {
		array.sort(function(a, b) {
			return a - b;
		});
		var mid = array.length / 2;
		return mid % 1 ? array[mid - 0.5] : (array[mid - 1] + array[mid]) / 2;
	},
	
	modes: function(array) {
		if (!array.length) return [];
		var modeMap = {},
			maxCount = 0,
			modes = [];

		array.forEach(function(val) {
			if (!modeMap[val]) modeMap[val] = 1;
			else modeMap[val]++;

			if (modeMap[val] > maxCount) {
				modes = [val];
				maxCount = modeMap[val];
			}
			else if (modeMap[val] === maxCount) {
				modes.push(val);
				maxCount = modeMap[val];
			}
		});
		return modes;
	},
	
	variance: function(array) {
		var mean = stat.mean(array);
		return stat.mean(array.map(function(num) {
			return Math.pow(num - mean, 2);
		}));
	},
	
	standardDeviation: function(array) {
		return Math.sqrt(stat.variance(array));
	},
	
	meanAbsoluteDeviation: function(array) {
		var mean = stat.mean(array);
		return stat.mean(array.map(function(num) {
			return Math.abs(num - mean);
		}));
	},
  
  nans: function nans(vector) {
    var n=0; for(var i in vector) if (isNaN(vector[i])) n++;
    return n
  },

  zeros : function zeros(vector) {
    var n=0; for(var i in vector) if (vector[i]==0) n++;
    return n
  },
	
	zScores: function(array) {
		var mean = stat.mean(array);
		var standardDeviation = stat.standardDeviation(array);
		return array.map(function(num) {
			return (num - mean) / standardDeviation;
		});
	}
};

// Function aliases:
stat.average = stat.mean;

// generate gaussian noise (Standard Normal variate using Box-Muller transform)
function gaussian(min,max,skew) {
    min=min||0;
    max=max||1;
    skew=skew||1;
    var u = 0, v = 0;
    while(u === 0) u = Math.random(); //Converting [0,1) to (0,1)
    while(v === 0) v = Math.random();
    var num = Math.sqrt( -2.0 * Math.log( u ) ) * Math.cos( 2.0 * Math.PI * v );

    num = num / 10.0 + 0.5; // Translate to 0 -> 1
    if (num > 1 || num < 0) num = gaussian(min, max, skew); // resample between 0 and 1 if out of range
    num = Math.pow(num, skew); // Skew
    num *= max - min; // Stretch to fill range
    num += min; // offset to min
    return num;
}

// function ({$x:number}|{value:*,prob;number}[]|number [],boolean) 
// -> {value:*,prob:number}|{index:number, prob:number}
// normalize=1: scale output max=[0,1]
// normalize=2: scale and weight output max*[0,1]

function best(o,normalize) {
  var p,max,pos=0,sum=0,res;
  if (Comp.obj.isArray(o) && typeof o[0]=='number')  {
    max=-Infinity;
    for(p in o) {
      sum += o[p];       
      if (o[p] > max) max=o[p],pos=p;
    }  
    res = {index:pos,prob:max}   
  } else if (Comp.obj.isArray(o) && typeof o[0]=='object')  {
    for(p in o) {
      sum += o[p].prob; 
      if (!max || o[p].prob>max.prob) max=o[p];
    }
    res = {value:max.value,prob:max.prob}
  } else if (Comp.obj.isObj(o)) {
    max=-Infinity;
    for(p in o) {
      sum += o[p];
      if (o[p]>max) max=o[p],pos=p;
    }
    res = {value:pos,prob:max}      
  }
  if (!res) return;
  switch (normalize) {
    case 1: res.prob=res.prob/sum; break;
    case 2: res.prob=res.prob*(res.prob/sum); break;
    default: 
  }
  return res;
}
function bestNormalize(o) { return best(o,1) }


function log2(n) {
  return Math.log(n) / Math.log(2);
}

// Select maximal value of an array by values 
// retuned by optional function applied to array values
function max(array,fun) {        
    var res,max,num;
    for(var i in array) {
        if (fun) num=fun(array[i],i); else num=array[i];
        if (max==undefined) { max=num; res=array[i] } 
        else if (num > max) { max=num; res=array[i] }
    }
    return res;
}

/**
 * Finds element with highest occurrence in a list
 * @private
 */
function mostCommon(list) {
  var elementFrequencyMap = {};
  var largestFrequency = -1;
  var mostCommonElement = null;
  list.forEach(function(element) {
    var elementFrequency = (elementFrequencyMap[element] || 0) + 1;
    elementFrequencyMap[element] = elementFrequency;

    if (largestFrequency < elementFrequency) {
      mostCommonElement = element;
      largestFrequency = elementFrequency;
    }
  });

  return mostCommonElement;
}


function pluck(collection, key) {
  return collection.map(function(object) {
    return object == null ? undefined : object[key];
  });
}

function prob(value, list) {
  var occurrences = list.filter(function(element) {
    return element === value
  });

  var numOccurrences = occurrences.length;
  var numElements = list.length;
  return numOccurrences / numElements;
}


function sort(array) {
  return array.sort(function (a,b) { return a<b?-1:1 });
}

function sum (a,b) { return a+b }

function unique(array) {
  var length = array ? array.length : 0;
  function baseUniq(array) {
    var index = -1,
        length = array.length,
        seen,
        result = [];

    seen = result;
    outer:
    while (++index < length) {
      var value = array[index];
      var seenIndex = seen.length;
      while (seenIndex--) {
        if (seen[seenIndex] === value) {
          continue outer;
        }
      }
      result.push(value);
    }
    return result;
  }
  if (!length) {
    return [];
  }
  return baseUniq(array);
}

function without () {
  var array,
      values=[];
  for(var i in arguments) {
    if (i==0) array=arguments[0];
    else values.push(arguments[i]);
  }
  return array.filter(function (e) {
    return values.indexOf(e) == -1;
  });
}


////////////////////////////////////////

// Entropy of data vectors
function entropy(vals) {
  var uniqueVals = unique(vals);
  var probs = uniqueVals.map(function(x) {
    return prob(x, vals)
  });

  var logVals = probs.map(function(p) {
    return -p * log2(p)
  });

  return logVals.reduce(sum,0);
}

function entropyN(dist,N) {
  var p, probs=[];
  for(p in dist) probs.push(dist[p]/N);
  var logVals = probs.map(function(p) {
    return p==0?0:-p * log2(p)
  });
  return logVals.reduce(sum, 0);
  
}

function entropyEps(vals,eps) {
  var uniqueVals = uniqueEps(vals,eps);
  var probs = uniqueVals.map(function(x) {
    return probEps(x, vals, eps)
  });

  var logVals = probs.map(function(p) {
    return -p * log2(p)
  });

  return logVals.reduce(sum, 0);
}
// Binray Crossentropy! y0: labelled output, y1: predicted output in [0,1]
function crossEntropy (y0,y1) {
    var reconstructedOutput = y1;
    var a = math.activateTwoMat(y0,reconstructedOutput,function(x,y){
        return x*Math.log(Math.max(1E-6,y));
    });
    var b = math.activateTwoMat(y0,reconstructedOutput,function(x,y){
        return (1-x)*Math.log(1-Math.min(0.9999999999,y));
    });

    var crossEntropy = -math.meanVec(math.sumMatAxis(math.addMat(a,b),1));
    return crossEntropy
}

/**
 * Computes probability of of a given value existing in a given list
 * with additional 2*epsilon interval, only applicable to numerical values.
 */
function probEps(value, list, eps) {
  // TODO: ranges
  var occurrences = list.filter(function(element) {
    return (element >= (value-eps)) && (element <= (value+eps));
  });

  var numOccurrences = occurrences.length;
  var numElements = list.length;
  return numOccurrences / numElements;
}

function probEps2(value, list, eps) {
  // TODO: ranges
  var occurrences = list.filter( function(element) {
    return overlap(epsVal(value), epsVal(element));
  });

  var numOccurrences = occurrences.length;
  var numElements = list.length;
  return numOccurrences / numElements;
}

// Entropy of target variable partitioned feature vector
function entropyT(data,featureIndex,targetIndex,targets) {
  var en = 0;
  var col =  pluck(data,featureIndex);
  var uniqueVals = unique(col);
  uniqueVals.forEach(function (v) {
    var frac = targets.map(function () { return 0 }),
        cn=0;
    col.forEach (function (v2,row) {
      if (v2==v) cn++,frac[targets.indexOf(data[row][targetIndex])]++;
    })
    var p = cn/data.length;
    en += (p*entropyN(frac,frac.reduce(sum)))
    // print(frac,p,frac.reduce(sum))
  })
  return en;
}

function entropyTEps(data,feature,target,targets,eps) {
  var en = 0;
  var col =  pluck(data,feature);
  var uniqueVals = uniqueEps(col,eps);
  uniqueVals.forEach(function (v) {
    var frac = targets.map(function () { return 0 }),
        cn=0;
    col.forEach (function (v2,row) {
      if (v2>=v-eps && v2<=v+eps) cn++,frac[targets.indexOf(data[row][target])]++;
    })
    var p = cn/data.length;
    en += (p*entropyN(frac,frac.reduce(sum)))
    // print(frac,p,frac.reduce(sum))
  })
  return en;
}

function features (data,target) {
  var f;
  if (Comp.obj.isObj(data[0])) 
    f=Object.keys(data[0]);
  else if (Comp.obj.isArray(data[0]))
    f=data[0].map(function (x,i) { return String(i) });
  if (f && target != undefined) {
    if (typeof target == 'string')
      f=f.filter(function (a) { return a!=target  });
    else 
      f=f.filter(function (a,i) { return i!=target  });
  }
  return f;
}

// Commonly used formula= et-etn
function gain (data,feature,target,targets) {
  var et = entropy(pluck(data,target));
  return et-entropyT(data,feature,target,targets)
}

function gainEps(data,feature,target,targets,eps) {
  var et = entropy(pluck(data,target));
  return et/entropyTEps(data,feature,target,targets,eps)
}


function maxGainEps(data,features,target,targets,eps) {
  var maxgain=max(features, function(feature,index) {
    var g = gainEps(data,feature,target,targets,selectEps(eps,index));
    return g;
  });
  return maxgain;
}

function partition(data,feature,target,targets) {
  var parts={};
  targets.forEach(function (t) {parts[t]=[]});
  data.forEach(function (row) {
    parts[row[target]].push(row[feature]);
  })
  return parts
}

function partitionEps(data,feature,target,targets,eps) {
  var p,parts={}
  targets.forEach(function (t) {parts[t]={range:[Number.MAX_VALUE,-Number.MAX_VALUE],values:[]}});
  data.forEach(function (row) {
    parts[row[target]].values.push(row[feature]);
    parts[row[target]].range[0]=Math.min(parts[row[target]].range[0],row[feature]);
    parts[row[target]].range[1]=Math.max(parts[row[target]].range[1],row[feature]);
  })
  for(p in parts) {
    parts[p].unique=uniqueEps(parts[p].values,eps)
    parts[p].noise=2*stat.standardDeviation(parts[p].values);
  }
  return parts
}

// Return only eps-not-overlapping parititions - the most significant are selected 
// (with the lowest unique column values) 
function partitionUniqueEps(data,feature,target,targets,eps) {
  var p, q, parts={}
  // 1. Create all partitions 
  targets.forEach(function (t) {parts[t]={range:[Number.MAX_VALUE,-Number.MAX_VALUE],values:[]}});
  data.forEach(function (row) {
    parts[row[target]].values.push(row[feature]);
    parts[row[target]].range[0]=Math.min(parts[row[target]].range[0],row[feature]);
    parts[row[target]].range[1]=Math.max(parts[row[target]].range[1],row[feature]);
  })
  for(p in parts) {
    parts[p].unique=uniqueEps(parts[p].values,eps)
  }
  // 2. Remove overlapping partitions
  for(p in parts) {
    if (!parts[p]) continue;
    for (q in parts) {
      if (!parts[p]) break;
      if (p==q || !parts[q]) continue;
      if ((parts[p].range[0]-eps)<parts[q].range[1] ||
          (parts[p].range[1]+eps)>parts[q].range[0]) {
        // overlapping, select the part with best unique column values
        if ((parts[p].unique.length/parts[p].values.length)<
            (parts[q].unique.length/parts[q].values.length)) {
          //print('delete '+q)
          delete parts[q];
        } else {
          //print('delete '+p)
          delete parts[p];
        }
      }
    }
  }  
  return parts
}

function select (data,what) {
  if (Comp.obj.isArray(what) && what.length==2) {
    var c0=what[0],c1=what[1];
    return data.map(function (row) {
      return row.slice(c0,c1+1);
    })
  } 
}

function selectEps (eps,index) {
  if (typeof eps == 'number') return eps;
  else return eps[index]
}

/** Split a data set by finding the best feature (column) 
 *  based on maximal gain/entropy calculation of columns. 
 *  type eps = number | number []
 */

function splitEps (data,features,target,targets,eps) {
  var bestFeature = maxGainEps(data,features,target,targets,eps);
  var index = features.indexOf(bestFeature);
  eps = selectEps(eps,index);
  var remainingFeatures = without(features, bestFeature);
  var possibleValues = sort(uniqueEps(pluck(data, bestFeature),eps));
  var choices = possibleValues.map( function(v) {
    var dataS = data.filter(function(x) {
      return Math.abs(x[bestFeature] - v) <= eps
    });
    return {
      val:v,
      data:dataS,
    }
  });
  return {
    feature:bestFeature,
    choices:choices,
    possibleValues:possibleValues,
    remainingFeatures:remainingFeatures
  };
}

function uniqueEps(array,eps) {
  var result=[];
  array.forEach(function (x) {
    var found;
    if (!result.length) result.push(x);
    else {
      result.forEach(function (y) {
        if (found) return;
        found = Math.abs(x-y)<=eps;
      }); 
      if (!found) result.push(x);
    }
  });
  return result;
}



module.exports =  {
  analyze : function (data,features,target,eps) {
    var noise=[];
    if (!eps) eps=0;
    var targets = unique(pluck(data,target));
    var parts = {}, partsUnique = {},diversity={}
    features.forEach(function (feature) {
      partsUnique[feature]=partitionUniqueEps(data,feature,target,targets,eps);
      parts[feature]=partitionEps(data,feature,target,targets,eps);
      for(var p in parts[feature]) noise.push(parts[feature][p].noise);
    })
    features.forEach(function (feature) {
      diversity[feature]=Object.keys(partsUnique[feature]).length;
    })
   
    return {
      features:features,
      partitions:parts, // for each data column
      diversity:diversity,
      noise:stat.mean(noise)
    }
  },
  crossEntropy: crossEntropy,
  entropy:entropy,
  entropyN:entropyN,
  entropyEps:entropyEps,
  entropyTEps:entropyTEps,
  entropyT:entropyT,
  features:features,
  gain:gain,
  gainEps:gainEps,
  maxGainEps:maxGainEps,
  mostCommon:mostCommon,
  partition:partition,
  partitionEps:partitionEps,
  partitionUniqueEps:partitionUniqueEps,
  splitEps:splitEps,
  unique:unique,
  uniqueEps:uniqueEps,
  utils : {
    // return column by key of a matrix (array array|record array) 
    best:best,
    bestNormalize:bestNormalize,
    column:pluck,
    gaussian:gaussian,
    log2:log2,
    prob:prob,
    // transform [v][] -> v[]
    relax: function (mat) {
      if (Comp.obj.isMatrix(mat) && mat[0].length==1) return mat.map(function (row) { return row[0]})
      else return mat;
    },
    select:select,
    selectEps:selectEps,
    sort:sort,
    stat:stat,
    without:without,
    // transform v[] -> [v][]
    wrap: function (mat) {
      if (!Comp.obj.isMatrix(mat)) return mat.map(function (v) { return [v]})
      else return mat
    },
  },
  version:'1.2.4X',
};

};
BundleModuleCode['plugins/ml/cnn']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Stefan Bosse
 **    $CREATED:     (C) 2006-2022 bLAB by sbosse
 **    $VERSION:     1.3.2X
 **
 **    $INFO:
 **
 ** Convolutional neural network ML Algorithm Wrapper
 **
 ** Incremental learner using ml.update! Initial training data via ml.learn (or empty data set, just using ml.learner) 
 **
 ** Not portable!
 ** 
 **    $ENDOFINFO
 */
'use strict';
var Io = Require('com/io');
var Comp = Require('com/compat');
var current=none;
var Aios=none;
var _ = undefined;
var none = null;

var convnetjs = Require('plugins/ml/convnet')
var that;

function isTypedArray(o) {
  return typeof o == 'object' && o.buffer && Utils.isBufferArray(o.buffer)
}
function isLinearArray (row0) {
  if (row0.data) row0=row0.data;
  return Utils.isBufferArray(row0) || 
         isTypedArray(row0) ||
         (row0 instanceof Array && typeof row0[0]=='number')
}
that = module.exports =  {
  stats : {
    convFloat : 0,
    scale : 0,
    volRef : 0,
    volCopy : 0,
  },
  // typeof options = {x:[][],y:[],width,height,depth,normalize?:[a,b],layers:{}[]..}
  // format x = [ [row1=[col1=[z1,z2,..],col2,..],row2,..] ]
  create : function (options) {
    if (options.datatype) convnetjs.datatype=options.datatype;
    var net = new convnetjs.Net();
    if (options.network)
      // restore network from JSON model
      net.fromJSON(options.network);
    else if (options.layers)
      net.makeLayers(options.layers);
    options.trainer=options.trainer||
    {
      method: 'adadelta', 
      l2_decay: 0.001, 
      batch_size: 1
    }
    var trainer = new convnetjs.SGDTrainer(net, 
                                           options.trainer);
    trainer.options= {
      width     : options.width,
      height    : options.height,
      depth     : options.depth,
      targets   : options.targets,
      normalize : options.normalize,
      layers    : options.layers,
      trainer   : options.trainer,
    };
    return { trainer:trainer, network:net, options:trainer.options };
  },
  
  // convert data to volumes
  convert : function (x,options) {
    function toFloat32(o) {
      if (o.__constructor__=='Math.VectorTA') return Math.VectorTA(o,{datatype:'Float32'});
      if (o.__constructor__=='Math.MatrixTA') return Math.MatrixTA(o,{datatype:'Float32'});
      if (isTypedArray(o)) return new Float32Array(o);
    }
    if (options.depth==undefined) throw ('ML.CNN: no data vol depth specified!');
    switch (options.depth) {
      case 1: // GREY8 []/ number [][]
        var row0=x[0];
        if (isLinearArray(row0)) {
          if ((options.scale || options.normalize) && !Math.isFloat(row0)) {
            // need to convert to Float32
            x=x.map(function (row) { return toFloat32(row) })
            that.stats.convFloat += x.length;
          }
          if (options.scale) {
            x=x.map(function (row) {
              return that.ml.utils.scale(row,options.scale);
            })
            that.stats.scale += x.length;
          } else if (options.normalize) {
            var a,b,
                c=options.normalize[0],
                d=options.normalize[1];
            x.forEach(function (row) {
              var min=Math.min.apply(null,row),
                  max=Math.max.apply(null,row);
              if (a==undefined) a=min; else a=Math.min(a,min);
              if (b==undefined) b=max; else b=Math.max(b,max);        
            })
            options.scale = that.ml.utils.toScale(a,b,c,d);
            x=x.map(function (row) {
              return that.ml.utils.scale(row,options.scale);
            })
            that.stats.scale += x.length;
          }
          x=x.map(function (row) {
            var vol = new convnetjs.Vol(options.width, options.height, options.depth, row.data?row.data:row); //input volume (image)
            // console.log(vol)
            return vol;
          });
          that.stats.volRef += x.length;
        } else if (row0 instanceof Array && row0[0] instanceof Array) {
            // assuming image number [][][] layout
            var vol = new convnetjs.Vol(options.width, options.height, options.depth, 0.0); //input volume (image)
            var i=0;
            for (var yc=0;yc<options.height;yc++) {
              for (var xc=0;xc<options.width;xx++) {
                var v = row[yc][xc];
                if (options.scale) v=that.ml.utils.scale(v,options.scale);
                vol.set(xc,yc,zc,v);
              }
            }
            that.stats.volCopy += (options.height*options.width);
            return vol;        
        };
        break;
      case 3:   // RGB []/RGBA [] /number [][][] image data
        // options.scale should be provided
        var row0=x[0];
        if (isLinearArray(row0)) {
          if ((options.scale || options.normalize) && !Math.isFloat(row0)) {
            // need to convert to Float32
            x=x.map(function (row) { return toFloat32(row) })
            that.stats.convFloat += x.length;
          }
          var channels = (row0.data||row0).length/(options.width*options.height);
          if (channels==options.depth) {
            // TODO scale, normalize?
            if (options.scale || options.normalize) throw "ML.CNN: scale or normalize not supported for this data";
            x=x.map(function (row) {
              var vol = new convnetjs.Vol(options.width, options.height, options.depth, row.data?row.data:row); //input volume (image)
              return vol;            
            })
            that.stats.volRef += x.length;
          } else {
            x=x.map(function (row) {
              // assuming image RGB/RGBA layout
              var vol = new convnetjs.Vol(options.width, options.height, options.depth, 0.0); //input volume (image)
              var i=0;
              for (var yc=0;yc<options.height;yc++) {
                for (var xc=0;xc<options.width;xc++) {
                  for (var zc=0;zc<options.depth;zc++) {
                    var v = row[i * channels + zc]; // alpha channel is ignored!?
                    if (options.scale) v=that.ml.utils.scale(v,options.scale);
                    vol.set(xc,yc,zc,v);
                  }
                  i++;
                }
              }
              that.stats.volCopy += (options.height*options.width*options.depth);
              return vol;
            })
          }
        } else if (row0 instanceof Array && row0[0] instanceof Array) {
            // assuming image number [][][] layout
            var vol = new convnetjs.Vol(options.width, options.height, options.depth, 0.0); //input volume (image)
            var i=0;
            for (var yc=0;yc<options.height;yc++) {
              for (var xc=0;xc<options.width;cx++) {
                for (var zc=0;zc<options.depth;zc++) {
                  var v = row[yc][xc][zc];
                  if (options.scale) v=that.ml.utils.scale(v,options.scale);
                  vol.set(xc,yc,zc,v);
                }
                i++;
              }
            }
            that.stats.volCopy += (options.height*options.width*options.depth);
            return vol;        
        };      
        break;
      default:
        var row0=x[0];
        if (isLinearArray(row0)) {
          if ((options.scale || options.normalize) && !Math.isFloat(row0)) {
            // need to convert to Float32
            x=x.map(function (row) { return toFloat32(row) })
            that.stats.convFloat += x.length;
          }
          var channels = (row0.data||row0).length/(options.width*options.height);
          if (channels==options.depth) {
            // TODO scale, normalize?
            if (options.scale || options.normalize) throw "ML.CNN: scale or normalize not supported for this data";
            x=x.map(function (row) {
              var vol = new convnetjs.Vol(options.width, options.height, options.depth, row.data?row.data:row); //input volume (image)
              return vol;            
            })
            that.stats.volRef += x.length;
          } else {
            x=x.map(function (row) {
              // assuming image RGB/RGBA layout
              var vol = new convnetjs.Vol(options.width, options.height, options.depth, 0.0); //input volume (image)
              var i=0;
              for (var yc=0;yc<options.height;yc++) {
                for (var xc=0;xc<options.width;xc++) {
                  for (var zc=0;zc<options.depth;zc++) {
                    var v = row[i * channels + zc]; 
                    if (options.scale) v=that.ml.utils.scale(v,options.scale);
                    vol.set(xc,yc,zc,v);
                  }
                  i++;
                }
              }
              that.stats.volCopy += (options.height*options.width*options.depth);
              return vol;
            })
          }
        } else throw "ML.CNN: no way to convert non-linear data";
        break;
    }
    return x;
  },

  // ML module back reference
  ml:{},
  
  predict: function (model,sample) {
    var trainer = model.trainer, options = trainer.options;
    if (Utils.isArray(sample[0])) {
      var vols = that.convert(sample,options);
      return vols.map(function (vol) {
        return trainer.net.forward(vol);      
      })
    } else {
      var vol = that.convert([sample],options)[0];
      return trainer.net.forward(vol);
    }
  },
  
  print: function () {
  },
  
  // !!! updates model parameters (depth, width, height) if not already set on model creation
  train : function (model, options) {
    var trainer = model.trainer, result,
        row0 = options.x && options.x[0];
    if (!options.iterations)  options.iterations=10;
    // Inherit from model.trainer instance
    if (trainer.options.width) options.width=trainer.options.width;
    if (trainer.options.height) options.height=trainer.options.height;
    if (trainer.options.depth) options.depth=trainer.options.depth;
    if (trainer.options.targets) options.targets=trainer.options.targets;
    if (!options.width) {
      if (isLinearArray(row0)) {
        options.width=row0.length;
        options.height=1;
      } else if (row0[0] instanceof Array) {
        options.height=row0.length;
        options.width=row0[0].length;
      }
    }
    if (!options.depth) {
      if (isLinearArray(row0)) {
        options.depth=1;
      } else if (row0[0] instanceof Array) {
        if (row0[0][0] instanceof Array) 
          options.depth=row0[0][0].length;
        else options.depth=1;
      }
    }
    // convert matrix (2dim/3dim) to volume elements
    var x = options.x;
    var y = options.y;
    delete options.x;
    delete options.y;
    x = that.convert(x,options);

    if (!options.targets && !Utils.isArray(y[0]) && typeof y[0] != 'number') {
      // classification: get class label array
      options.targets=that.ml.stats.unique(y).sort(function (a,b) { return a<b?-1:1 });;
    }
    Object.assign(trainer.options,options);
    var stop=false;
    function train (iterations,run) {
      for(var iters=0;iters<iterations;iters++) {
        var t1,t0,lossAvg=0;
        t0=Date.now();
        if (options.targets) {
          // classification
          var stats = options.targets.slice().map(function() { return 0 });
          y.forEach(function (v,i) {
            stats[options.targets.indexOf(v)]++;
            // provide index of class in targets array
            result=trainer.train(x[i],options.targets.indexOf(v));
            lossAvg+=result.loss;
          })
        } else {
          // regression or generic network
          y.forEach(function (v,i) {
            result=trainer.train(x[i],v);
            lossAvg+=result.loss;
          })
        }
        t1=Date.now();
        result.time=trainer.time=(t1-t0);
        result.iteration=run+iters;
        if (options.targets) result.ydist=stats;
        result.lossAvg=lossAvg/y.length;
        trainer.result=result;
        if (options.verbose) Code.print('Iteration #'+result.iteration+' '+inspect(result));
        if (options.callback) {
          var more=options.callback(result,run);
          if (more===false) stop=true;
        }
      }
    }
    if (!options.async) train(options.iterations,0);
    else {
      var runs = 0;
      return Code.loop(function () {
        train(1,runs);
        runs++;
        return !stop && runs < options.iterations;
      },true);
    }
    return result;  
  },
  
  update: function (data) {
  },
  
  current:function (module) { current=module.current; Aios=module;},
  
  version : '1.4.2X',
};
};
BundleModuleCode['plugins/ml/convnet']=function (module,exports,global,process){

/*** https://github.com/karpathy/convnetjs ***/
/*** @blab+ Ver. 1.2.1 ***/

var convnet={
  REVISION: 'ALPHA',
  datatype:'Float64'    // @blab+
}
module.exports=convnet;
"use strict";

/*** convnet_util ***/
// Random number utilities
var return_v = false;
var v_val = 0.0;
var gaussRandom = function() {
  if(return_v) { 
    return_v = false;
    return v_val; 
  }
  var u = 2*Math.random()-1;
  var v = 2*Math.random()-1;
  var r = u*u + v*v;
  if(r == 0 || r > 1) return gaussRandom();
  var c = Math.sqrt(-2*Math.log(r)/r);
  v_val = v*c; // cache this
  return_v = true;
  return u*c;
}
var randf = function(a, b) { return Math.random()*(b-a)+a; }
var randi = function(a, b) { return Math.floor(Math.random()*(b-a)+a); }
var randn = function(mu, std){ return mu+gaussRandom()*std; }

// Array utilities
var zeros = function(n) {
  if(typeof(n)==='undefined' || isNaN(n)) { return []; }
  if(typeof ArrayBuffer === 'undefined') {
    // lacking browser support
    var arr = new Array(n);
    for(var i=0;i<n;i++) { arr[i]= 0; }
    return arr;
  } else {
    return new (convnet.datatype=='Float32'?Float32Array:Float64Array)(n);
  }
}

var arrContains = function(arr, elt) {
  for(var i=0,n=arr.length;i<n;i++) {
    if(arr[i]===elt) return true;
  }
  return false;
}

var arrUnique = function(arr) {
  var b = [];
  for(var i=0,n=arr.length;i<n;i++) {
    if(!arrContains(b, arr[i])) {
      b.push(arr[i]);
    }
  }
  return b;
}

// return max and min of a given non-empty array.
var maxmin = function(w) {
  if(w.length === 0) { return {}; } // ... ;s
  var maxv = w[0];
  var minv = w[0];
  var maxi = 0;
  var mini = 0;
  var n = w.length;
  for(var i=1;i<n;i++) {
    if(w[i] > maxv) { maxv = w[i]; maxi = i; } 
    if(w[i] < minv) { minv = w[i]; mini = i; } 
  }
  return {maxi: maxi, maxv: maxv, mini: mini, minv: minv, dv:maxv-minv};
}

// create random permutation of numbers, in range [0...n-1]
var randperm = function(n) {
  var i = n,
      j = 0,
      temp;
  var array = [];
  for(var q=0;q<n;q++)array[q]=q;
  while (i--) {
      j = Math.floor(Math.random() * (i+1));
      temp = array[i];
      array[i] = array[j];
      array[j] = temp;
  }
  return array;
}

// sample from list lst according to probabilities in list probs
// the two lists are of same size, and probs adds up to 1
var weightedSample = function(lst, probs) {
  var p = randf(0, 1.0);
  var cumprob = 0.0;
  for(var k=0,n=lst.length;k<n;k++) {
    cumprob += probs[k];
    if(p < cumprob) { return lst[k]; }
  }
}

// syntactic sugar function for getting default parameter values
var getopt = function(opt, field_name, default_value) {
  if(typeof field_name === 'string') {
    // case of single string
    return (typeof opt[field_name] !== 'undefined') ? opt[field_name] : default_value;
  } else {
    // assume we are given a list of string instead
    var ret = default_value;
    for(var i=0;i<field_name.length;i++) {
      var f = field_name[i];
      if (typeof opt[f] !== 'undefined') {
        ret = opt[f]; // overwrite return value
      }
    }
    return ret;
  }
}

function assert(condition, message) {
  if (!condition) {
    message = message || "Assertion failed";
    if (typeof Error !== "undefined") {
      throw new Error(message);
    }
    throw message; // Fallback
  }
}
// @blab+
function isArray(o) {
  return (typeof o == 'object') && (o.buffer instanceof ArrayBuffer || o instanceof Array)
}
function isTypedArray(o) {
  return o && o.buffer instanceof ArrayBuffer
}

convnet.randf = randf;
convnet.randi = randi;
convnet.randn = randn;
convnet.zeros = zeros;
convnet.maxmin = maxmin;
convnet.randperm = randperm;
convnet.weightedSample = weightedSample;
convnet.arrUnique = arrUnique;
convnet.arrContains = arrContains;
convnet.getopt = getopt;
convnet.assert = assert;

/*** convnet_vol ***/
// Vol is the basic building block of all data in a net.
// it is essentially just a 3D volume of numbers, with a
// width (sx), height (sy), and depth (depth).
// it is used to hold data for all filters, all volumes,
// all weights, and also stores all gradients w.r.t. 
// the data. c is optionally a value to initialize the volume
// with. If c is missing, fills the Vol with random numbers.
var Vol = function(sx, sy, depth, c) {
  // this is how you check if a variable is an array. Oh, Javascript :)
  // if(Object.prototype.toString.call(sx) === '[object Array]') {
  if (isArray(sx)) {
    // we were given a list in sx, assume 1D volume and fill it up
    this.sx = 1;
    this.sy = 1;
    this.depth = sx.length;
    // we have to do the following copy because we want to use
    // fast typed arrays, not an ordinary javascript array
    this.w = convnet.zeros(this.depth);
    this.dw = convnet.zeros(this.depth);
    for(var i=0;i<this.depth;i++) {
      this.w[i] = sx[i];
    }
  } else {
    // we were given dimensions of the vol
    this.sx = sx;
    this.sy = sy;
    this.depth = depth;
    var n = sx*sy*depth;
    // @blab+
    if (isArray(c)) {
      this.w  = c;
      this.dw = convnet.zeros(n);
      return;
    } else {
      this.w  = convnet.zeros(n);
      this.dw = convnet.zeros(n);
    }
    if(typeof c === 'undefined') {
      // weight normalization is done to equalize the output
      // variance of every neuron, otherwise neurons with a lot
      // of incoming connections have outputs of larger variance
      var scale = Math.sqrt(1.0/(sx*sy*depth));
      for(var i=0;i<n;i++) { 
        this.w[i] = convnet.randn(0.0, scale);
      }
    } else if (c!=0) {
      for(var i=0;i<n;i++) { 
        this.w[i] = c;
      }
    }
  }
}

Vol.prototype = {
  get: function(x, y, d) { 
    var ix=((this.sx * y)+x)*this.depth+d;
    return this.w[ix];
  },
  set: function(x, y, d, v) { 
    var ix=((this.sx * y)+x)*this.depth+d;
    this.w[ix] = v; 
  },
  add: function(x, y, d, v) { 
    var ix=((this.sx * y)+x)*this.depth+d;
    this.w[ix] += v; 
  },
  get_grad: function(x, y, d) { 
    var ix = ((this.sx * y)+x)*this.depth+d;
    return this.dw[ix]; 
  },
  set_grad: function(x, y, d, v) { 
    var ix = ((this.sx * y)+x)*this.depth+d;
    this.dw[ix] = v; 
  },
  add_grad: function(x, y, d, v) { 
    var ix = ((this.sx * y)+x)*this.depth+d;
    this.dw[ix] += v; 
  },
  cloneAndZero: function() { return new Vol(this.sx, this.sy, this.depth, 0.0)},
  clone: function() {
    var V = new Vol(this.sx, this.sy, this.depth, 0.0);
    var n = this.w.length;
    for(var i=0;i<n;i++) { V.w[i] = this.w[i]; }
    return V;
  },
  addFrom: function(V) { for(var k=0;k<this.w.length;k++) { this.w[k] += V.w[k]; }},
  addFromScaled: function(V, a) { for(var k=0;k<this.w.length;k++) { this.w[k] += a*V.w[k]; }},
  setConst: function(a) { for(var k=0;k<this.w.length;k++) { this.w[k] = a; }},

  toJSON: function() {
    // todo: we may want to only save d most significant digits to save space
    var json = {}
    json.sx = this.sx; 
    json.sy = this.sy;
    json.depth = this.depth;
    json.w = this.w;
    return json;
    // we wont back up gradients to save space
  },
  fromJSON: function(json) {
    this.sx = json.sx;
    this.sy = json.sy;
    this.depth = json.depth;

    var n = this.sx*this.sy*this.depth;
    this.w = convnet.zeros(n);
    this.dw = convnet.zeros(n);
    // copy over the elements.
    for(var i=0;i<n;i++) {
      this.w[i] = json.w[i];
    }
  }
}

convnet.Vol = Vol;

/*** convnet_vol_util ***/
var Vol = convnet.Vol; // convenience

// Volume utilities
// intended for use with data augmentation
// crop is the size of output
// dx,dy are offset wrt incoming volume, of the shift
// fliplr is boolean on whether we also want to flip left<->right
var augment = function(V, crop, dx, dy, fliplr) {
  // note assumes square outputs of size crop x crop
  if(typeof(fliplr)==='undefined') var fliplr = false;
  if(typeof(dx)==='undefined') var dx = convnet.randi(0, V.sx - crop);
  if(typeof(dy)==='undefined') var dy = convnet.randi(0, V.sy - crop);
  
  // randomly sample a crop in the input volume
  var W;
  if(crop !== V.sx || dx!==0 || dy!==0) {
    W = new Vol(crop, crop, V.depth, 0.0);
    for(var x=0;x<crop;x++) {
      for(var y=0;y<crop;y++) {
        if(x+dx<0 || x+dx>=V.sx || y+dy<0 || y+dy>=V.sy) continue; // oob
        for(var d=0;d<V.depth;d++) {
         W.set(x,y,d,V.get(x+dx,y+dy,d)); // copy data over
        }
      }
    }
  } else {
    W = V;
  }

  if(fliplr) {
    // flip volume horziontally
    var W2 = W.cloneAndZero();
    for(var x=0;x<W.sx;x++) {
      for(var y=0;y<W.sy;y++) {
        for(var d=0;d<W.depth;d++) {
         W2.set(x,y,d,W.get(W.sx - x - 1,y,d)); // copy data over
        }
      }
    }
    W = W2; //swap
  }
  return W;
}

// img is a DOM element that contains a loaded image
// returns a Vol of size (W, H, 4). 4 is for RGBA
var img_to_vol = function(img, convert_grayscale) {

  if(typeof(convert_grayscale)==='undefined') var convert_grayscale = false;

  var canvas = document.createElement('canvas');
  canvas.width = img.width;
  canvas.height = img.height;
  var ctx = canvas.getContext("2d");

  // due to a Firefox bug
  try {
    ctx.drawImage(img, 0, 0);
  } catch (e) {
    if (e.name === "NS_ERROR_NOT_AVAILABLE") {
      // sometimes happens, lets just abort
      return false;
    } else {
      throw e;
    }
  }

  try {
    var img_data = ctx.getImageData(0, 0, canvas.width, canvas.height);
  } catch (e) {
    if(e.name === 'IndexSizeError') {
      return false; // not sure what causes this sometimes but okay abort
    } else {
      throw e;
    }
  }

  // prepare the input: get pixels and normalize them
  var p = img_data.data;
  var W = img.width;
  var H = img.height;
  var pv = []
  for(var i=0;i<p.length;i++) {
    pv.push(p[i]/255.0-0.5); // normalize image pixels to [-0.5, 0.5]
  }
  var x = new Vol(W, H, 4, 0.0); //input volume (image)
  x.w = pv;

  if(convert_grayscale) {
    // flatten into depth=1 array
    var x1 = new Vol(W, H, 1, 0.0);
    for(var i=0;i<W;i++) {
      for(var j=0;j<H;j++) {
        x1.set(i,j,0,x.get(i,j,0));
      }
    }
    x = x1;
  }

  return x;
}

convnet.augment = augment;
convnet.img_to_vol = img_to_vol;


/*** convnet_layers_dotproducts ***/
// This file contains all layers that do dot products with input,
// but usually in a different connectivity pattern and weight sharing
// schemes: 
// - FullyConn is fully connected dot products 
// - ConvLayer does convolutions (so weight sharing spatially)
// putting them together in one file because they are very similar
var ConvLayer = function(opt) {
  var opt = opt || {};

  // required
  this.out_depth = opt.filters;
  this.sx = opt.sx; // filter size. Should be odd if possible, it's cleaner.
  this.in_depth = opt.in_depth;
  this.in_sx = opt.in_sx;
  this.in_sy = opt.in_sy;
  
  // optional
  this.sy = typeof opt.sy !== 'undefined' ? opt.sy : this.sx;
  this.stride = typeof opt.stride !== 'undefined' ? opt.stride : 1; // stride at which we apply filters to input volume
  this.pad = typeof opt.pad !== 'undefined' ? opt.pad : 0; // amount of 0 padding to add around borders of input volume
  this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;
  this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;

  // computed
  // note we are doing floor, so if the strided convolution of the filter doesnt fit into the input
  // volume exactly, the output volume will be trimmed and not contain the (incomplete) computed
  // final application.
  this.out_sx = Math.floor((this.in_sx + this.pad * 2 - this.sx) / this.stride + 1);
  this.out_sy = Math.floor((this.in_sy + this.pad * 2 - this.sy) / this.stride + 1);
  this.layer_type = 'conv';

  // initializations
  var bias = typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0;
  this.filters = [];
  for(var i=0;i<this.out_depth;i++) { this.filters.push(new Vol(this.sx, this.sy, this.in_depth)); }
  this.biases = new Vol(1, 1, this.out_depth, bias);
}
ConvLayer.prototype = {
  forward: function(V, is_training) {
    // optimized code by @mdda that achieves 2x speedup over previous version

    this.in_act = V;
    var A = new Vol(this.out_sx |0, this.out_sy |0, this.out_depth |0, 0.0);
    
    var V_sx = V.sx |0;
    var V_sy = V.sy |0;
    var xy_stride = this.stride |0;

    for(var d=0;d<this.out_depth;d++) {
      var f = this.filters[d];
      var x = -this.pad |0;
      var y = -this.pad |0;
      for(var ay=0; ay<this.out_sy; y+=xy_stride,ay++) {  // xy_stride
        x = -this.pad |0;
        for(var ax=0; ax<this.out_sx; x+=xy_stride,ax++) {  // xy_stride

          // convolve centered at this particular location
          var a = 0.0;
          for(var fy=0;fy<f.sy;fy++) {
            var oy = y+fy; // coordinates in the original input array coordinates
            for(var fx=0;fx<f.sx;fx++) {
              var ox = x+fx;
              if(oy>=0 && oy<V_sy && ox>=0 && ox<V_sx) {
                for(var fd=0;fd<f.depth;fd++) {
                  // avoid function call overhead (x2) for efficiency, compromise modularity :(
                  a += f.w[((f.sx * fy)+fx)*f.depth+fd] * V.w[((V_sx * oy)+ox)*V.depth+fd];
                }
              }
            }
          }
          a += this.biases.w[d];
          A.set(ax, ay, d, a);
        }
      }
    }
    this.out_act = A;
    return this.out_act;
  },
  backward: function() {

    var V = this.in_act;
    V.dw = convnet.zeros(V.w.length); // zero out gradient wrt bottom data, we're about to fill it

    var V_sx = V.sx |0;
    var V_sy = V.sy |0;
    var xy_stride = this.stride |0;

    for(var d=0;d<this.out_depth;d++) {
      var f = this.filters[d];
      var x = -this.pad |0;
      var y = -this.pad |0;
      for(var ay=0; ay<this.out_sy; y+=xy_stride,ay++) {  // xy_stride
        x = -this.pad |0;
        for(var ax=0; ax<this.out_sx; x+=xy_stride,ax++) {  // xy_stride

          // convolve centered at this particular location
          var chain_grad = this.out_act.get_grad(ax,ay,d); // gradient from above, from chain rule
          for(var fy=0;fy<f.sy;fy++) {
            var oy = y+fy; // coordinates in the original input array coordinates
            for(var fx=0;fx<f.sx;fx++) {
              var ox = x+fx;
              if(oy>=0 && oy<V_sy && ox>=0 && ox<V_sx) {
                for(var fd=0;fd<f.depth;fd++) {
                  // avoid function call overhead (x2) for efficiency, compromise modularity :(
                  var ix1 = ((V_sx * oy)+ox)*V.depth+fd;
                  var ix2 = ((f.sx * fy)+fx)*f.depth+fd;
                  f.dw[ix2] += V.w[ix1]*chain_grad;
                  V.dw[ix1] += f.w[ix2]*chain_grad;
                }
              }
            }
          }
          this.biases.dw[d] += chain_grad;
        }
      }
    }
  },
  getParamsAndGrads: function() {
    var response = [];
    for(var i=0;i<this.out_depth;i++) {
      response.push({params: this.filters[i].w, grads: this.filters[i].dw, l2_decay_mul: this.l2_decay_mul, l1_decay_mul: this.l1_decay_mul});
    }
    response.push({params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0});
    return response;
  },
  toJSON: function() {
    var json = {};
    json.sx = this.sx; // filter size in x, y dims
    json.sy = this.sy;
    json.stride = this.stride;
    json.in_depth = this.in_depth;
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    json.l1_decay_mul = this.l1_decay_mul;
    json.l2_decay_mul = this.l2_decay_mul;
    json.pad = this.pad;
    json.filters = [];
    for(var i=0;i<this.filters.length;i++) {
      json.filters.push(this.filters[i].toJSON());
    }
    json.biases = this.biases.toJSON();
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type;
    this.sx = json.sx; // filter size in x, y dims
    this.sy = json.sy;
    this.stride = json.stride;
    this.in_depth = json.in_depth; // depth of input volume
    this.filters = [];
    this.l1_decay_mul = typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0;
    this.l2_decay_mul = typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0;
    this.pad = typeof json.pad !== 'undefined' ? json.pad : 0;
    for(var i=0;i<json.filters.length;i++) {
      var v = new Vol(0,0,0,0);
      v.fromJSON(json.filters[i]);
      this.filters.push(v);
    }
    this.biases = new Vol(0,0,0,0);
    this.biases.fromJSON(json.biases);
  }
}

var FullyConnLayer = function(opt) {
  var opt = opt || {};

  // required
  // ok fine we will allow 'filters' as the word as well
  this.out_depth = typeof opt.num_neurons !== 'undefined' ? opt.num_neurons : opt.filters;

  // optional 
  this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;
  this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;

  // computed
  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;
  this.out_sx = 1;
  this.out_sy = 1;
  this.layer_type = 'fc';

  // initializations
  var bias = typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0;
  this.filters = [];
  for(var i=0;i<this.out_depth ;i++) { this.filters.push(new Vol(1, 1, this.num_inputs)); }
  this.biases = new Vol(1, 1, this.out_depth, bias);
}

FullyConnLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    var A = new Vol(1, 1, this.out_depth, 0.0);
    var Vw = V.w;
    for(var i=0;i<this.out_depth;i++) {
      var a = 0.0;
      var wi = this.filters[i].w;
      for(var d=0;d<this.num_inputs;d++) {
        a += Vw[d] * wi[d]; // for efficiency use Vols directly for now
      }
      a += this.biases.w[i];
      A.w[i] = a;
    }
    this.out_act = A;
    return this.out_act;
  },
  backward: function() {
    var V = this.in_act;
    V.dw = convnet.zeros(V.w.length); // zero out the gradient in input Vol
    
    // compute gradient wrt weights and data
    for(var i=0;i<this.out_depth;i++) {
      var tfi = this.filters[i];
      var chain_grad = this.out_act.dw[i];
      for(var d=0;d<this.num_inputs;d++) {
        V.dw[d] += tfi.w[d]*chain_grad; // grad wrt input data
        tfi.dw[d] += V.w[d]*chain_grad; // grad wrt params
      }
      this.biases.dw[i] += chain_grad;
    }
  },
  getParamsAndGrads: function() {
    var response = [];
    for(var i=0;i<this.out_depth;i++) {
      response.push({params: this.filters[i].w, grads: this.filters[i].dw, l1_decay_mul: this.l1_decay_mul, l2_decay_mul: this.l2_decay_mul});
    }
    response.push({params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0});
    return response;
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    json.num_inputs = this.num_inputs;
    json.l1_decay_mul = this.l1_decay_mul;
    json.l2_decay_mul = this.l2_decay_mul;
    json.filters = [];
    for(var i=0;i<this.filters.length;i++) {
      json.filters.push(this.filters[i].toJSON());
    }
    json.biases = this.biases.toJSON();
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type;
    this.num_inputs = json.num_inputs;
    this.l1_decay_mul = typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0;
    this.l2_decay_mul = typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0;
    this.filters = [];
    for(var i=0;i<json.filters.length;i++) {
      var v = new Vol(0,0,0,0);
      v.fromJSON(json.filters[i]);
      this.filters.push(v);
    }
    this.biases = new Vol(0,0,0,0);
    this.biases.fromJSON(json.biases);
  }
}

convnet.ConvLayer = ConvLayer;
convnet.FullyConnLayer = FullyConnLayer;


/*** convnet_layers_pool ***/
var PoolLayer = function(opt) {

  var opt = opt || {};

  // required
  this.sx = opt.sx; // filter size
  this.in_depth = opt.in_depth;
  this.in_sx = opt.in_sx;
  this.in_sy = opt.in_sy;

  // optional
  this.sy = typeof opt.sy !== 'undefined' ? opt.sy : this.sx;
  this.stride = typeof opt.stride !== 'undefined' ? opt.stride : 2;
  this.pad = typeof opt.pad !== 'undefined' ? opt.pad : 0; // amount of 0 padding to add around borders of input volume

  // computed
  this.out_depth = this.in_depth;
  this.out_sx = Math.floor((this.in_sx + this.pad * 2 - this.sx) / this.stride + 1);
  this.out_sy = Math.floor((this.in_sy + this.pad * 2 - this.sy) / this.stride + 1);
  this.layer_type = 'pool';
  // store switches for x,y coordinates for where the max comes from, for each output neuron
  this.switchx = convnet.zeros(this.out_sx*this.out_sy*this.out_depth);
  this.switchy = convnet.zeros(this.out_sx*this.out_sy*this.out_depth);
}

PoolLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;

    var A = new Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);
    
    var n=0; // a counter for switches
    for(var d=0;d<this.out_depth;d++) {
      var x = -this.pad;
      var y = -this.pad;
      for(var ax=0; ax<this.out_sx; x+=this.stride,ax++) {
        y = -this.pad;
        for(var ay=0; ay<this.out_sy; y+=this.stride,ay++) {

          // convolve centered at this particular location
          var a = -99999; // hopefully small enough ;\
          var winx=-1,winy=-1;
          for(var fx=0;fx<this.sx;fx++) {
            for(var fy=0;fy<this.sy;fy++) {
              var oy = y+fy;
              var ox = x+fx;
              if(oy>=0 && oy<V.sy && ox>=0 && ox<V.sx) {
                var v = V.get(ox, oy, d);
                // perform max pooling and store pointers to where
                // the max came from. This will speed up backprop 
                // and can help make nice visualizations in future
                if(v > a) { a = v; winx=ox; winy=oy;}
              }
            }
          }
          this.switchx[n] = winx;
          this.switchy[n] = winy;
          n++;
          A.set(ax, ay, d, a);
        }
      }
    }
    this.out_act = A;
    return this.out_act;
  },
  backward: function() { 
    // pooling layers have no parameters, so simply compute 
    // gradient wrt data here
    var V = this.in_act;
    V.dw = convnet.zeros(V.w.length); // zero out gradient wrt data
    var A = this.out_act; // computed in forward pass 

    var n = 0;
    for(var d=0;d<this.out_depth;d++) {
      var x = -this.pad;
      var y = -this.pad;
      for(var ax=0; ax<this.out_sx; x+=this.stride,ax++) {
        y = -this.pad;
        for(var ay=0; ay<this.out_sy; y+=this.stride,ay++) {

          var chain_grad = this.out_act.get_grad(ax,ay,d);
          V.add_grad(this.switchx[n], this.switchy[n], d, chain_grad);
          n++;

        }
      }
    }
  },
  getParamsAndGrads: function() {
    return [];
  },
  toJSON: function() {
    var json = {};
    json.sx = this.sx;
    json.sy = this.sy;
    json.stride = this.stride;
    json.in_depth = this.in_depth;
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    json.pad = this.pad;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type;
    this.sx = json.sx;
    this.sy = json.sy;
    this.stride = json.stride;
    this.in_depth = json.in_depth;
    this.pad = typeof json.pad !== 'undefined' ? json.pad : 0; // backwards compatibility
    this.switchx = convnet.zeros(this.out_sx*this.out_sy*this.out_depth); // need to re-init these appropriately
    this.switchy = convnet.zeros(this.out_sx*this.out_sy*this.out_depth);
  }
}

convnet.PoolLayer = PoolLayer;


/*** convnet_layers_input ***/
var getopt = convnet.getopt;

var InputLayer = function(opt) {
  var opt = opt || {};

  // required: depth
  this.out_depth = getopt(opt, ['out_depth', 'depth'], 0);

  // optional: default these dimensions to 1
  this.out_sx = getopt(opt, ['out_sx', 'sx', 'width'], 1);
  this.out_sy = getopt(opt, ['out_sy', 'sy', 'height'], 1);
  
  // computed
  this.layer_type = 'input';
}
InputLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    this.out_act = V;
    return this.out_act; // simply identity function for now
  },
  backward: function() { },
  getParamsAndGrads: function() {
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type; 
  }
}

convnet.InputLayer = InputLayer;


/*** convnet_layers_loss ***/
// Layers that implement a loss. Currently these are the layers that 
// can initiate a backward() pass. In future we probably want a more 
// flexible system that can accomodate multiple losses to do multi-task
// learning, and stuff like that. But for now, one of the layers in this
// file must be the final layer in a Net.

// This is a classifier, with N discrete classes from 0 to N-1
// it gets a stream of N incoming numbers and computes the softmax
// function (exponentiate and normalize to sum to 1 as probabilities should)
var SoftmaxLayer = function(opt) {
  var opt = opt || {};

  // computed
  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;
  this.out_depth = this.num_inputs;
  this.out_sx = 1;
  this.out_sy = 1;
  this.layer_type = 'softmax';
}

SoftmaxLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;

    var A = new Vol(1, 1, this.out_depth, 0.0);

    // compute max activation
    var as = V.w;
    var amax = V.w[0];
    for(var i=1;i<this.out_depth;i++) {
      if(as[i] > amax) amax = as[i];
    }

    // compute exponentials (carefully to not blow up)
    var es = convnet.zeros(this.out_depth);
    var esum = 0.0;
    for(var i=0;i<this.out_depth;i++) {
      var e = Math.exp(as[i] - amax);
      esum += e;
      es[i] = e;
    }

    // normalize and output to sum to one
    for(var i=0;i<this.out_depth;i++) {
      es[i] /= esum;
      A.w[i] = es[i];
    }

    this.es = es; // save these for backprop
    this.out_act = A;
    return this.out_act;
  },
  backward: function(y) {

    // compute and accumulate gradient wrt weights and bias of this layer
    var x = this.in_act;
    x.dw = convnet.zeros(x.w.length); // zero out the gradient of input Vol

    for(var i=0;i<this.out_depth;i++) {
      var indicator = i === y ? 1.0 : 0.0;
      var mul = -(indicator - this.es[i]);
      x.dw[i] = mul;
    }

    // loss is the class negative log likelihood
    return -Math.log(this.es[y]);
  },
  getParamsAndGrads: function() { 
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    json.num_inputs = this.num_inputs;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type;
    this.num_inputs = json.num_inputs;
  }
}

// implements an L2 regression cost layer,
// so penalizes \sum_i(||x_i - y_i||^2), where x is its input
// and y is the user-provided array of "correct" values.
var RegressionLayer = function(opt) {
  var opt = opt || {};

  // computed
  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;
  this.out_depth = this.num_inputs;
  this.out_sx = 1;
  this.out_sy = 1;
  this.layer_type = 'regression';
}

RegressionLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    this.out_act = V;
    return V; // identity function
  },
  // y is a list here of size num_inputs
  // or it can be a number if only one value is regressed
  // or it can be a struct {dim: i, val: x} where we only want to 
  // regress on dimension i and asking it to have value x
  backward: function(y) { 

    // compute and accumulate gradient wrt weights and bias of this layer
    var x = this.in_act;
    x.dw = convnet.zeros(x.w.length); // zero out the gradient of input Vol
    var loss = 0.0;
    if(y instanceof Array || y instanceof Float64Array || y instanceof Float32Array) {
      for(var i=0;i<this.out_depth;i++) {
        var dy = x.w[i] - y[i];
        x.dw[i] = dy;
        loss += 0.5*dy*dy;
      }
    } else if(typeof y === 'number') {
      // lets hope that only one number is being regressed
      var dy = x.w[0] - y;
      x.dw[0] = dy;
      loss += 0.5*dy*dy;
    } else {
      // assume it is a struct with entries .dim and .val
      // and we pass gradient only along dimension dim to be equal to val
      var i = y.dim;
      var yi = y.val;
      var dy = x.w[i] - yi;
      x.dw[i] = dy;
      loss += 0.5*dy*dy;
    }
    return loss;
  },
  getParamsAndGrads: function() { 
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    json.num_inputs = this.num_inputs;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type;
    this.num_inputs = json.num_inputs;
  }
}

var SVMLayer = function(opt) {
  var opt = opt || {};

  // computed
  this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;
  this.out_depth = this.num_inputs;
  this.out_sx = 1;
  this.out_sy = 1;
  this.layer_type = 'svm';
}

SVMLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    this.out_act = V; // nothing to do, output raw scores
    return V;
  },
  backward: function(y) {

    // compute and accumulate gradient wrt weights and bias of this layer
    var x = this.in_act;
    x.dw = convnet.zeros(x.w.length); // zero out the gradient of input Vol

    // we're using structured loss here, which means that the score
    // of the ground truth should be higher than the score of any other 
    // class, by a margin
    var yscore = x.w[y]; // score of ground truth
    var margin = 1.0;
    var loss = 0.0;
    for(var i=0;i<this.out_depth;i++) {
      if(y === i) { continue; }
      var ydiff = -yscore + x.w[i] + margin;
      if(ydiff > 0) {
        // violating dimension, apply loss
        x.dw[i] += 1;
        x.dw[y] -= 1;
        loss += ydiff;
      }
    }

    return loss;
  },
  getParamsAndGrads: function() { 
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    json.num_inputs = this.num_inputs;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type;
    this.num_inputs = json.num_inputs;
  }
}

convnet.RegressionLayer = RegressionLayer;
convnet.SoftmaxLayer = SoftmaxLayer;
convnet.SVMLayer = SVMLayer;


/*** convnet_layers_nonlinearities ***/
// Implements ReLU nonlinearity elementwise
// x -> max(0, x)
// the output is in [0, inf)
var ReluLayer = function(opt) {
  var opt = opt || {};

  // computed
  this.out_sx = opt.in_sx;
  this.out_sy = opt.in_sy;
  this.out_depth = opt.in_depth;
  this.layer_type = 'relu';
}
ReluLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    var V2 = V.clone();
    var N = V.w.length;
    var V2w = V2.w;
    for(var i=0;i<N;i++) { 
      if(V2w[i] < 0) V2w[i] = 0; // threshold at 0
    }
    this.out_act = V2;
    return this.out_act;
  },
  backward: function() {
    var V = this.in_act; // we need to set dw of this
    var V2 = this.out_act;
    var N = V.w.length;
    V.dw = convnet.zeros(N); // zero out gradient wrt data
    for(var i=0;i<N;i++) {
      if(V2.w[i] <= 0) V.dw[i] = 0; // threshold
      else V.dw[i] = V2.dw[i];
    }
  },
  getParamsAndGrads: function() {
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type; 
  }
}

// Implements Sigmoid nnonlinearity elementwise
// x -> 1/(1+e^(-x))
// so the output is between 0 and 1.
var SigmoidLayer = function(opt) {
  var opt = opt || {};

  // computed
  this.out_sx = opt.in_sx;
  this.out_sy = opt.in_sy;
  this.out_depth = opt.in_depth;
  this.layer_type = 'sigmoid';
}
SigmoidLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    var V2 = V.cloneAndZero();
    var N = V.w.length;
    var V2w = V2.w;
    var Vw = V.w;
    for(var i=0;i<N;i++) { 
      V2w[i] = 1.0/(1.0+Math.exp(-Vw[i]));
    }
    this.out_act = V2;
    return this.out_act;
  },
  backward: function() {
    var V = this.in_act; // we need to set dw of this
    var V2 = this.out_act;
    var N = V.w.length;
    V.dw = convnet.zeros(N); // zero out gradient wrt data
    for(var i=0;i<N;i++) {
      var v2wi = V2.w[i];
      V.dw[i] =  v2wi * (1.0 - v2wi) * V2.dw[i];
    }
  },
  getParamsAndGrads: function() {
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type; 
  }
}

// Implements Maxout nnonlinearity that computes
// x -> max(x)
// where x is a vector of size group_size. Ideally of course,
// the input size should be exactly divisible by group_size
var MaxoutLayer = function(opt) {
  var opt = opt || {};

  // required
  this.group_size = typeof opt.group_size !== 'undefined' ? opt.group_size : 2;

  // computed
  this.out_sx = opt.in_sx;
  this.out_sy = opt.in_sy;
  this.out_depth = Math.floor(opt.in_depth / this.group_size);
  this.layer_type = 'maxout';

  this.switches = convnet.zeros(this.out_sx*this.out_sy*this.out_depth); // useful for backprop
}
MaxoutLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    var N = this.out_depth; 
    var V2 = new Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);

    // optimization branch. If we're operating on 1D arrays we dont have
    // to worry about keeping track of x,y,d coordinates inside
    // input volumes. In convnets we do :(
    if(this.out_sx === 1 && this.out_sy === 1) {
      for(var i=0;i<N;i++) {
        var ix = i * this.group_size; // base index offset
        var a = V.w[ix];
        var ai = 0;
        for(var j=1;j<this.group_size;j++) {
          var a2 = V.w[ix+j];
          if(a2 > a) {
            a = a2;
            ai = j;
          }
        }
        V2.w[i] = a;
        this.switches[i] = ix + ai;
      }
    } else {
      var n=0; // counter for switches
      for(var x=0;x<V.sx;x++) {
        for(var y=0;y<V.sy;y++) {
          for(var i=0;i<N;i++) {
            var ix = i * this.group_size;
            var a = V.get(x, y, ix);
            var ai = 0;
            for(var j=1;j<this.group_size;j++) {
              var a2 = V.get(x, y, ix+j);
              if(a2 > a) {
                a = a2;
                ai = j;
              }
            }
            V2.set(x,y,i,a);
            this.switches[n] = ix + ai;
            n++;
          }
        }
      }

    }
    this.out_act = V2;
    return this.out_act;
  },
  backward: function() {
    var V = this.in_act; // we need to set dw of this
    var V2 = this.out_act;
    var N = this.out_depth;
    V.dw = convnet.zeros(V.w.length); // zero out gradient wrt data

    // pass the gradient through the appropriate switch
    if(this.out_sx === 1 && this.out_sy === 1) {
      for(var i=0;i<N;i++) {
        var chain_grad = V2.dw[i];
        V.dw[this.switches[i]] = chain_grad;
      }
    } else {
      // bleh okay, lets do this the hard way
      var n=0; // counter for switches
      for(var x=0;x<V2.sx;x++) {
        for(var y=0;y<V2.sy;y++) {
          for(var i=0;i<N;i++) {
            var chain_grad = V2.get_grad(x,y,i);
            V.set_grad(x,y,this.switches[n],chain_grad);
            n++;
          }
        }
      }
    }
  },
  getParamsAndGrads: function() {
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    json.group_size = this.group_size;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type; 
    this.group_size = json.group_size;
    this.switches = convnet.zeros(this.group_size);
  }
}

// a helper function, since tanh is not yet part of ECMAScript. Will be in v6.
function tanh(x) {
  var y = Math.exp(2 * x);
  return (y - 1) / (y + 1);
}
// Implements Tanh nnonlinearity elementwise
// x -> tanh(x) 
// so the output is between -1 and 1.
var TanhLayer = function(opt) {
  var opt = opt || {};

  // computed
  this.out_sx = opt.in_sx;
  this.out_sy = opt.in_sy;
  this.out_depth = opt.in_depth;
  this.layer_type = 'tanh';
}
TanhLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    var V2 = V.cloneAndZero();
    var N = V.w.length;
    for(var i=0;i<N;i++) { 
      V2.w[i] = tanh(V.w[i]);
    }
    this.out_act = V2;
    return this.out_act;
  },
  backward: function() {
    var V = this.in_act; // we need to set dw of this
    var V2 = this.out_act;
    var N = V.w.length;
    V.dw = convnet.zeros(N); // zero out gradient wrt data
    for(var i=0;i<N;i++) {
      var v2wi = V2.w[i];
      V.dw[i] = (1.0 - v2wi * v2wi) * V2.dw[i];
    }
  },
  getParamsAndGrads: function() {
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type; 
  }
}

convnet.TanhLayer = TanhLayer;
convnet.MaxoutLayer = MaxoutLayer;
convnet.ReluLayer = ReluLayer;
convnet.SigmoidLayer = SigmoidLayer;




/*** convnet_layers_dropout ***/
// An inefficient dropout layer
// Note this is not most efficient implementation since the layer before
// computed all these activations and now we're just going to drop them :(
// same goes for backward pass. Also, if we wanted to be efficient at test time
// we could equivalently be clever and upscale during train and copy pointers during test
// todo: make more efficient.
var DropoutLayer = function(opt) {
  var opt = opt || {};

  // computed
  this.out_sx = opt.in_sx;
  this.out_sy = opt.in_sy;
  this.out_depth = opt.in_depth;
  this.layer_type = 'dropout';
  this.drop_prob = typeof opt.drop_prob !== 'undefined' ? opt.drop_prob : 0.5;
  this.dropped = convnet.zeros(this.out_sx*this.out_sy*this.out_depth);
}
DropoutLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;
    if(typeof(is_training)==='undefined') { is_training = false; } // default is prediction mode
    var V2 = V.clone();
    var N = V.w.length;
    if(is_training) {
      // do dropout
      for(var i=0;i<N;i++) {
        if(Math.random()<this.drop_prob) { V2.w[i]=0; this.dropped[i] = true; } // drop!
        else {this.dropped[i] = false;}
      }
    } else {
      // scale the activations during prediction
      for(var i=0;i<N;i++) { V2.w[i]*=this.drop_prob; }
    }
    this.out_act = V2;
    return this.out_act; // dummy identity function for now
  },
  backward: function() {
    var V = this.in_act; // we need to set dw of this
    var chain_grad = this.out_act;
    var N = V.w.length;
    V.dw = convnet.zeros(N); // zero out gradient wrt data
    for(var i=0;i<N;i++) {
      if(!(this.dropped[i])) { 
        V.dw[i] = chain_grad.dw[i]; // copy over the gradient
      }
    }
  },
  getParamsAndGrads: function() {
    return [];
  },
  toJSON: function() {
    var json = {};
    json.out_depth = this.out_depth;
    json.out_sx = this.out_sx;
    json.out_sy = this.out_sy;
    json.layer_type = this.layer_type;
    json.drop_prob = this.drop_prob;
    return json;
  },
  fromJSON: function(json) {
    this.out_depth = json.out_depth;
    this.out_sx = json.out_sx;
    this.out_sy = json.out_sy;
    this.layer_type = json.layer_type; 
    this.drop_prob = json.drop_prob;
  }
}

convnet.DropoutLayer = DropoutLayer;

/*** convnet_layers_normailzation ***/
// a bit experimental layer for now. I think it works but I'm not 100%
// the gradient check is a bit funky. I'll look into this a bit later.
// Local Response Normalization in window, along depths of volumes
var LocalResponseNormalizationLayer = function(opt) {
  var opt = opt || {};

  // required
  this.k = opt.k;
  this.n = opt.n;
  this.alpha = opt.alpha;
  this.beta = opt.beta;

  // computed
  this.out_sx = opt.in_sx;
  this.out_sy = opt.in_sy;
  this.out_depth = opt.in_depth;
  this.layer_type = 'lrn';

  // checks
  if(this.n%2 === 0) { console.log('WARNING n should be odd for LRN layer'); }
}
LocalResponseNormalizationLayer.prototype = {
  forward: function(V, is_training) {
    this.in_act = V;

    var A = V.cloneAndZero();
    this.S_cache_ = V.cloneAndZero();
    var n2 = Math.floor(this.n/2);
    for(var x=0;x<V.sx;x++) {
      for(var y=0;y<V.sy;y++) {
        for(var i=0;i<V.depth;i++) {

          var ai = V.get(x,y,i);

          // normalize in a window of size n
          var den = 0.0;
          for(var j=Math.max(0,i-n2);j<=Math.min(i+n2,V.depth-1);j++) {
            var aa = V.get(x,y,j);
            den += aa*aa;
          }
          den *= this.alpha / this.n;
          den += this.k;
          this.S_cache_.set(x,y,i,den); // will be useful for backprop
          den = Math.pow(den, this.beta);
          A.set(x,y,i,ai/den);
        }
      }
    }

    this.out_act = A;
    return this.out_act; // dummy identity function for now
  },
  backward: function() { 
    // evaluate gradient wrt data
    var V = this.in_act; // we need to set dw of this
    V.dw = convnet.zeros(V.w.length); // zero out gradient wrt data
    var A = this.out_act; // computed in forward pass 

    var n2 = Math.floor(this.n/2);
    for(var x=0;x<V.sx;x++) {
      for(var y=0;y<V.sy;y++) {
        for(var i=0;i<V.depth;i++) {

          var chain_grad = this.out_act.get_grad(x,y,i);
          var S = this.S_cache_.get(x,y,i);
          var SB = Math.pow(S, this.beta);
          var SB2 = SB*SB;

          // normalize in a window of size n
          for(var j=Math.max(0,i-n2);j<=Math.min(i+n2,V.depth-1);j++) {              
            var aj = V.get(x,y,j); 
            var g = -aj*this.beta*Math.pow(S,this.beta-1)*this.alpha/this.n*2*aj;
            if(j===i) g+= SB;
            g /= SB2;
            g *= chain_grad;
            V.add_grad(x,y,j,g);
          }

        }
      }
    }
  },
  getParamsAndGrads: function() { return []; },
  toJSON: function() {
    var json = {};
    json.k = this.k;
    json.n = this.n;
    json.alpha = this.alpha; // normalize by size
    json.beta = this.beta;
    json.out_sx = this.out_sx; 
    json.out_sy = this.out_sy;
    json.out_depth = this.out_depth;
    json.layer_type = this.layer_type;
    return json;
  },
  fromJSON: function(json) {
    this.k = json.k;
    this.n = json.n;
    this.alpha = json.alpha; // normalize by size
    this.beta = json.beta;
    this.out_sx = json.out_sx; 
    this.out_sy = json.out_sy;
    this.out_depth = json.out_depth;
    this.layer_type = json.layer_type;
  }
}

convnet.LocalResponseNormalizationLayer = LocalResponseNormalizationLayer;



/*** convnet_net ***/
var assert = convnet.assert;

// Net manages a set of layers
// For now constraints: Simple linear order of layers, first layer input last layer a cost layer
var Net = function(options) {
  this.layers = [];
}

Net.prototype = {
  
  // takes a list of layer definitions and creates the network layer objects
  makeLayers: function(defs) {

    // few checks
    assert(defs.length >= 2, 'Error! At least one input layer and one loss layer are required.');
    assert(defs[0].type === 'input', 'Error! First layer must be the input layer, to declare size of inputs');

    // desugar layer_defs for adding activation, dropout layers etc
    var desugar = function() {
      var new_defs = [];
      for(var i=0;i<defs.length;i++) {
        var def = defs[i];
        
        if(def.type==='softmax' || def.type==='svm') {
          // add an fc layer here, there is no reason the user should
          // have to worry about this and we almost always want to
          new_defs.push({type:'fc', num_neurons: def.num_classes});
        }

        if(def.type==='regression') {
          // add an fc layer here, there is no reason the user should
          // have to worry about this and we almost always want to
          new_defs.push({type:'fc', num_neurons: def.num_neurons});
        }

        if((def.type==='fc' || def.type==='conv') 
            && typeof(def.bias_pref) === 'undefined'){
          def.bias_pref = 0.0;
          if(typeof def.activation !== 'undefined' && def.activation === 'relu') {
            def.bias_pref = 0.1; // relus like a bit of positive bias to get gradients early
            // otherwise it's technically possible that a relu unit will never turn on (by chance)
            // and will never get any gradient and never contribute any computation. Dead relu.
          }
        }

        new_defs.push(def);

        if(typeof def.activation !== 'undefined') {
          if(def.activation==='relu') { new_defs.push({type:'relu'}); }
          else if (def.activation==='sigmoid') { new_defs.push({type:'sigmoid'}); }
          else if (def.activation==='tanh') { new_defs.push({type:'tanh'}); }
          else if (def.activation==='maxout') {
            // create maxout activation, and pass along group size, if provided
            var gs = def.group_size !== 'undefined' ? def.group_size : 2;
            new_defs.push({type:'maxout', group_size:gs});
          }
          else { console.log('ERROR unsupported activation ' + def.activation); }
        }
        if(typeof def.drop_prob !== 'undefined' && def.type !== 'dropout') {
          new_defs.push({type:'dropout', drop_prob: def.drop_prob});
        }

      }
      return new_defs;
    }
    defs = desugar(defs);

    // create the layers
    this.layers = [];
    for(var i=0;i<defs.length;i++) {
      var def = defs[i];
      if(i>0) {
        var prev = this.layers[i-1];
        def.in_sx = prev.out_sx;
        def.in_sy = prev.out_sy;
        def.in_depth = prev.out_depth;
      }

      switch(def.type) {
        case 'fc': this.layers.push(new convnet.FullyConnLayer(def)); break;
        case 'lrn': this.layers.push(new convnet.LocalResponseNormalizationLayer(def)); break;
        case 'dropout': this.layers.push(new convnet.DropoutLayer(def)); break;
        case 'input': this.layers.push(new convnet.InputLayer(def)); break;
        case 'softmax': this.layers.push(new convnet.SoftmaxLayer(def)); break;
        case 'regression': this.layers.push(new convnet.RegressionLayer(def)); break;
        case 'conv': this.layers.push(new convnet.ConvLayer(def)); break;
        case 'pool': this.layers.push(new convnet.PoolLayer(def)); break;
        case 'relu': this.layers.push(new convnet.ReluLayer(def)); break;
        case 'sigmoid': this.layers.push(new convnet.SigmoidLayer(def)); break;
        case 'tanh': this.layers.push(new convnet.TanhLayer(def)); break;
        case 'maxout': this.layers.push(new convnet.MaxoutLayer(def)); break;
        case 'svm': this.layers.push(new convnet.SVMLayer(def)); break;
        default: console.log('ERROR: UNRECOGNIZED LAYER TYPE: ' + def.type);
      }
    }
  },

  // forward prop the network. 
  // The trainer class passes is_training = true, but when this function is
  // called from outside (not from the trainer), it defaults to prediction mode
  forward: function(V, is_training) {
    if(typeof(is_training) === 'undefined') is_training = false;
    var act = this.layers[0].forward(V, is_training);
    for(var i=1;i<this.layers.length;i++) {
      act = this.layers[i].forward(act, is_training);
    }
    return act;
  },

  getCostLoss: function(V, y) {
    this.forward(V, false);
    var N = this.layers.length;
    var loss = this.layers[N-1].backward(y);
    return loss;
  },
  
  // backprop: compute gradients wrt all parameters
  backward: function(y) {
    var N = this.layers.length;
    var loss = this.layers[N-1].backward(y); // last layer assumed to be loss layer
    for(var i=N-2;i>=0;i--) { // first layer assumed input
      this.layers[i].backward();
    }
    return loss;
  },
  getParamsAndGrads: function() {
    // accumulate parameters and gradients for the entire network
    var response = [];
    for(var i=0;i<this.layers.length;i++) {
      var layer_reponse = this.layers[i].getParamsAndGrads();
      for(var j=0;j<layer_reponse.length;j++) {
        response.push(layer_reponse[j]);
      }
    }
    return response;
  },
  getPrediction: function() {
    // this is a convenience function for returning the argmax
    // prediction, assuming the last layer of the net is a softmax
    var S = this.layers[this.layers.length-1];
    assert(S.layer_type === 'softmax', 'getPrediction function assumes softmax as last layer of the net!');

    var p = S.out_act.w;
    var maxv = p[0];
    var maxi = 0;
    for(var i=1;i<p.length;i++) {
      if(p[i] > maxv) { maxv = p[i]; maxi = i;}
    }
    return maxi; // return index of the class with highest class probability
  },
  toJSON: function() {
    var json = {};
    json.layers = [];
    for(var i=0;i<this.layers.length;i++) {
      json.layers.push(this.layers[i].toJSON());
    }
    return json;
  },
  fromJSON: function(json) {
    this.layers = [];
    for(var i=0;i<json.layers.length;i++) {
      var Lj = json.layers[i]
      var t = Lj.layer_type;
      var L;
      if(t==='input') { L = new convnet.InputLayer(); }
      if(t==='relu') { L = new convnet.ReluLayer(); }
      if(t==='sigmoid') { L = new convnet.SigmoidLayer(); }
      if(t==='tanh') { L = new convnet.TanhLayer(); }
      if(t==='dropout') { L = new convnet.DropoutLayer(); }
      if(t==='conv') { L = new convnet.ConvLayer(); }
      if(t==='pool') { L = new convnet.PoolLayer(); }
      if(t==='lrn') { L = new convnet.LocalResponseNormalizationLayer(); }
      if(t==='softmax') { L = new convnet.SoftmaxLayer(); }
      if(t==='regression') { L = new convnet.RegressionLayer(); }
      if(t==='fc') { L = new convnet.FullyConnLayer(); }
      if(t==='maxout') { L = new convnet.MaxoutLayer(); }
      if(t==='svm') { L = new convnet.SVMLayer(); }
      L.fromJSON(Lj);
      this.layers.push(L);
    }
  }
}

convnet.Net = Net;


/*** convnet_trainers ***/
var Trainer = function(net, options) {

  this.net = net;

  var options = options || {};
  this.learning_rate = typeof options.learning_rate !== 'undefined' ? options.learning_rate : 0.01;
  this.l1_decay = typeof options.l1_decay !== 'undefined' ? options.l1_decay : 0.0;
  this.l2_decay = typeof options.l2_decay !== 'undefined' ? options.l2_decay : 0.0;
  this.batch_size = typeof options.batch_size !== 'undefined' ? options.batch_size : 1;
  this.method = typeof options.method !== 'undefined' ? options.method : 'sgd'; // sgd/adam/adagrad/adadelta/windowgrad/netsterov

  this.momentum = typeof options.momentum !== 'undefined' ? options.momentum : 0.9;
  this.ro = typeof options.ro !== 'undefined' ? options.ro : 0.95; // used in adadelta
  this.eps = typeof options.eps !== 'undefined' ? options.eps : 1e-8; // used in adam or adadelta
  this.beta1 = typeof options.beta1 !== 'undefined' ? options.beta1 : 0.9; // used in adam
  this.beta2 = typeof options.beta2 !== 'undefined' ? options.beta2 : 0.999; // used in adam

  this.k = 0; // iteration counter
  this.gsum = []; // last iteration gradients (used for momentum calculations)
  this.xsum = []; // used in adam or adadelta

  // check if regression is expected 
  if(this.net.layers[this.net.layers.length - 1].layer_type === "regression")
    this.regression = true;
  else
    this.regression = false;
}

Trainer.prototype = {
  train: function(x, y) {

    var start = new Date().getTime();
    this.net.forward(x, true); // also set the flag that lets the net know we're just training
    var end = new Date().getTime();
    var fwd_time = end - start;

    var start = new Date().getTime();
    var cost_loss = this.net.backward(y);
    var l2_decay_loss = 0.0;
    var l1_decay_loss = 0.0;
    var end = new Date().getTime();
    var bwd_time = end - start;

    if(this.regression && y.constructor !== Array)
      console.log("Warning: a regression net requires an array as training output vector.");
    
    this.k++;
    if(this.k % this.batch_size === 0) {

      var pglist = this.net.getParamsAndGrads();

      // initialize lists for accumulators. Will only be done once on first iteration
      if(this.gsum.length === 0 && (this.method !== 'sgd' || this.momentum > 0.0)) {
        // only vanilla sgd doesnt need either lists
        // momentum needs gsum
        // adagrad needs gsum
        // adam and adadelta needs gsum and xsum
        for(var i=0;i<pglist.length;i++) {
          this.gsum.push(convnet.zeros(pglist[i].params.length));
          if(this.method === 'adam' || this.method === 'adadelta') {
            this.xsum.push(convnet.zeros(pglist[i].params.length));
          } else {
            this.xsum.push([]); // conserve memory
          }
        }
      }

      // perform an update for all sets of weights
      for(var i=0;i<pglist.length;i++) {
        var pg = pglist[i]; // param, gradient, other options in future (custom learning rate etc)
        var p = pg.params;
        var g = pg.grads;

        // learning rate for some parameters.
        var l2_decay_mul = typeof pg.l2_decay_mul !== 'undefined' ? pg.l2_decay_mul : 1.0;
        var l1_decay_mul = typeof pg.l1_decay_mul !== 'undefined' ? pg.l1_decay_mul : 1.0;
        var l2_decay = this.l2_decay * l2_decay_mul;
        var l1_decay = this.l1_decay * l1_decay_mul;

        var plen = p.length;
        for(var j=0;j<plen;j++) {
          l2_decay_loss += l2_decay*p[j]*p[j]/2; // accumulate weight decay loss
          l1_decay_loss += l1_decay*Math.abs(p[j]);
          var l1grad = l1_decay * (p[j] > 0 ? 1 : -1);
          var l2grad = l2_decay * (p[j]);

          var gij = (l2grad + l1grad + g[j]) / this.batch_size; // raw batch gradient

          var gsumi = this.gsum[i];
          var xsumi = this.xsum[i];
          if(this.method === 'adam') {
            // adam update
            gsumi[j] = gsumi[j] * this.beta1 + (1- this.beta1) * gij; // update biased first moment estimate
            xsumi[j] = xsumi[j] * this.beta2 + (1-this.beta2) * gij * gij; // update biased second moment estimate
            var biasCorr1 = gsumi[j] * (1 - Math.pow(this.beta1, this.k)); // correct bias first moment estimate
            var biasCorr2 = xsumi[j] * (1 - Math.pow(this.beta2, this.k)); // correct bias second moment estimate
            var dx =  - this.learning_rate * biasCorr1 / (Math.sqrt(biasCorr2) + this.eps);
            p[j] += dx;
          } else if(this.method === 'adagrad') {
            // adagrad update
            gsumi[j] = gsumi[j] + gij * gij;
            var dx = - this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij;
            p[j] += dx;
          } else if(this.method === 'windowgrad') {
            // this is adagrad but with a moving window weighted average
            // so the gradient is not accumulated over the entire history of the run. 
            // it's also referred to as Idea #1 in Zeiler paper on Adadelta. Seems reasonable to me!
            gsumi[j] = this.ro * gsumi[j] + (1-this.ro) * gij * gij;
            var dx = - this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij; // eps added for better conditioning
            p[j] += dx;
          } else if(this.method === 'adadelta') {
            gsumi[j] = this.ro * gsumi[j] + (1-this.ro) * gij * gij;
            var dx = - Math.sqrt((xsumi[j] + this.eps)/(gsumi[j] + this.eps)) * gij;
            xsumi[j] = this.ro * xsumi[j] + (1-this.ro) * dx * dx; // yes, xsum lags behind gsum by 1.
            p[j] += dx;
          } else if(this.method === 'nesterov') {
          	var dx = gsumi[j];
          	gsumi[j] = gsumi[j] * this.momentum + this.learning_rate * gij;
              dx = this.momentum * dx - (1.0 + this.momentum) * gsumi[j];
              p[j] += dx;
          } else {
            // assume SGD
            if(this.momentum > 0.0) {
              // momentum update
              var dx = this.momentum * gsumi[j] - this.learning_rate * gij; // step
              gsumi[j] = dx; // back this up for next iteration of momentum
              p[j] += dx; // apply corrected gradient
            } else {
              // vanilla sgd
              p[j] +=  - this.learning_rate * gij;
            }
          }
          g[j] = 0.0; // zero out gradient so that we can begin accumulating anew
        }
      }
    }

    // appending softmax_loss for backwards compatibility, but from now on we will always use cost_loss
    // in future, TODO: have to completely redo the way loss is done around the network as currently 
    // loss is a bit of a hack. Ideally, user should specify arbitrary number of loss functions on any layer
    // and it should all be computed correctly and automatically. 
    return {fwd_time: fwd_time, bwd_time: bwd_time, 
            l2_decay_loss: l2_decay_loss, l1_decay_loss: l1_decay_loss,
            cost_loss: cost_loss, softmax_loss: cost_loss, 
            loss: cost_loss + l1_decay_loss + l2_decay_loss}
  }
}

convnet.Trainer = Trainer;
convnet.SGDTrainer = Trainer; // backwards compatibility


/*** convnet_magicnets ***/
// used utilities, make explicit local references
var randf = convnet.randf;
var randi = convnet.randi;
var Net = convnet.Net;
var Trainer = convnet.Trainer;
var maxmin = convnet.maxmin;
var randperm = convnet.randperm;
var weightedSample = convnet.weightedSample;
var getopt = convnet.getopt;
var arrUnique = convnet.arrUnique;

/*
A MagicNet takes data: a list of convnetjs.Vol(), and labels
which for now are assumed to be class indeces 0..K. MagicNet then:
- creates data folds for cross-validation
- samples candidate networks
- evaluates candidate networks on all data folds
- produces predictions by model-averaging the best networks
*/
var MagicNet = function(data, labels, opt) {
  var opt = opt || {};
  if(typeof data === 'undefined') { data = []; }
  if(typeof labels === 'undefined') { labels = []; }

  // required inputs
  this.data = data; // store these pointers to data
  this.labels = labels;

  // optional inputs
  this.train_ratio = getopt(opt, 'train_ratio', 0.7);
  this.num_folds = getopt(opt, 'num_folds', 10);
  this.num_candidates = getopt(opt, 'num_candidates', 50); // we evaluate several in parallel
  // how many epochs of data to train every network? for every fold?
  // higher values mean higher accuracy in final results, but more expensive
  this.num_epochs = getopt(opt, 'num_epochs', 50); 
  // number of best models to average during prediction. Usually higher = better
  this.ensemble_size = getopt(opt, 'ensemble_size', 10);

  // candidate parameters
  this.batch_size_min = getopt(opt, 'batch_size_min', 10);
  this.batch_size_max = getopt(opt, 'batch_size_max', 300);
  this.l2_decay_min = getopt(opt, 'l2_decay_min', -4);
  this.l2_decay_max = getopt(opt, 'l2_decay_max', 2);
  this.learning_rate_min = getopt(opt, 'learning_rate_min', -4);
  this.learning_rate_max = getopt(opt, 'learning_rate_max', 0);
  this.momentum_min = getopt(opt, 'momentum_min', 0.9);
  this.momentum_max = getopt(opt, 'momentum_max', 0.9);
  this.neurons_min = getopt(opt, 'neurons_min', 5);
  this.neurons_max = getopt(opt, 'neurons_max', 30);

  // computed
  this.folds = []; // data fold indices, gets filled by sampleFolds()
  this.candidates = []; // candidate networks that are being currently evaluated
  this.evaluated_candidates = []; // history of all candidates that were fully evaluated on all folds
  this.unique_labels = arrUnique(labels);
  this.iter = 0; // iteration counter, goes from 0 -> num_epochs * num_training_data
  this.foldix = 0; // index of active fold

  // callbacks
  this.finish_fold_callback = null;
  this.finish_batch_callback = null;

  // initializations
  if(this.data.length > 0) {
    this.sampleFolds();
    this.sampleCandidates();
  }
};

MagicNet.prototype = {

  // sets this.folds to a sampling of this.num_folds folds
  sampleFolds: function() {
    var N = this.data.length;
    var num_train = Math.floor(this.train_ratio * N);
    this.folds = []; // flush folds, if any
    for(var i=0;i<this.num_folds;i++) {
      var p = randperm(N);
      this.folds.push({train_ix: p.slice(0, num_train), test_ix: p.slice(num_train, N)});
    }
  },

  // returns a random candidate network
  sampleCandidate: function() {
    var input_depth = this.data[0].w.length;
    var num_classes = this.unique_labels.length;

    // sample network topology and hyperparameters
    var layer_defs = [];
    layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth: input_depth});
    var nl = weightedSample([0,1,2,3], [0.2, 0.3, 0.3, 0.2]); // prefer nets with 1,2 hidden layers
    for(var q=0;q<nl;q++) {
      var ni = randi(this.neurons_min, this.neurons_max);
      var act = ['tanh','maxout','relu'][randi(0,3)];
      if(randf(0,1)<0.5) {
        var dp = Math.random();
        layer_defs.push({type:'fc', num_neurons: ni, activation: act, drop_prob: dp});
      } else {
        layer_defs.push({type:'fc', num_neurons: ni, activation: act});
      }
    }
    layer_defs.push({type:'softmax', num_classes: num_classes});
    var net = new Net();
    net.makeLayers(layer_defs);

    // sample training hyperparameters
    var bs = randi(this.batch_size_min, this.batch_size_max); // batch size
    var l2 = Math.pow(10, randf(this.l2_decay_min, this.l2_decay_max)); // l2 weight decay
    var lr = Math.pow(10, randf(this.learning_rate_min, this.learning_rate_max)); // learning rate
    var mom = randf(this.momentum_min, this.momentum_max); // momentum. Lets just use 0.9, works okay usually ;p
    var tp = randf(0,1); // trainer type
    var trainer_def;
    if(tp<0.33) {
      trainer_def = {method:'adadelta', batch_size:bs, l2_decay:l2};
    } else if(tp<0.66) {
      trainer_def = {method:'adagrad', learning_rate: lr, batch_size:bs, l2_decay:l2};
    } else {
      trainer_def = {method:'sgd', learning_rate: lr, momentum: mom, batch_size:bs, l2_decay:l2};
    }
    
    var trainer = new Trainer(net, trainer_def);

    var cand = {};
    cand.acc = [];
    cand.accv = 0; // this will maintained as sum(acc) for convenience
    cand.layer_defs = layer_defs;
    cand.trainer_def = trainer_def;
    cand.net = net;
    cand.trainer = trainer;
    return cand;
  },

  // sets this.candidates with this.num_candidates candidate nets
  sampleCandidates: function() {
    this.candidates = []; // flush, if any
    for(var i=0;i<this.num_candidates;i++) {
      var cand = this.sampleCandidate();
      this.candidates.push(cand);
    }
  },

  step: function() {
    
    // run an example through current candidate
    this.iter++;

    // step all candidates on a random data point
    var fold = this.folds[this.foldix]; // active fold
    var dataix = fold.train_ix[randi(0, fold.train_ix.length)];
    for(var k=0;k<this.candidates.length;k++) {
      var x = this.data[dataix];
      var l = this.labels[dataix];
      this.candidates[k].trainer.train(x, l);
    }

    // process consequences: sample new folds, or candidates
    var lastiter = this.num_epochs * fold.train_ix.length;
    if(this.iter >= lastiter) {
      // finished evaluation of this fold. Get final validation
      // accuracies, record them, and go on to next fold.
      var val_acc = this.evalValErrors();
      for(var k=0;k<this.candidates.length;k++) {
        var c = this.candidates[k];
        c.acc.push(val_acc[k]);
        c.accv += val_acc[k];
      }
      this.iter = 0; // reset step number
      this.foldix++; // increment fold

      if(this.finish_fold_callback !== null) {
        this.finish_fold_callback();
      }

      if(this.foldix >= this.folds.length) {
        // we finished all folds as well! Record these candidates
        // and sample new ones to evaluate.
        for(var k=0;k<this.candidates.length;k++) {
          this.evaluated_candidates.push(this.candidates[k]);
        }
        // sort evaluated candidates according to accuracy achieved
        this.evaluated_candidates.sort(function(a, b) { 
          return (a.accv / a.acc.length) 
               > (b.accv / b.acc.length) 
               ? -1 : 1;
        });
        // and clip only to the top few ones (lets place limit at 3*ensemble_size)
        // otherwise there are concerns with keeping these all in memory 
        // if MagicNet is being evaluated for a very long time
        if(this.evaluated_candidates.length > 3 * this.ensemble_size) {
          this.evaluated_candidates = this.evaluated_candidates.slice(0, 3 * this.ensemble_size);
        }
        if(this.finish_batch_callback !== null) {
          this.finish_batch_callback();
        }
        this.sampleCandidates(); // begin with new candidates
        this.foldix = 0; // reset this
      } else {
        // we will go on to another fold. reset all candidates nets
        for(var k=0;k<this.candidates.length;k++) {
          var c = this.candidates[k];
          var net = new Net();
          net.makeLayers(c.layer_defs);
          var trainer = new Trainer(net, c.trainer_def);
          c.net = net;
          c.trainer = trainer;
        }
      }
    }
  },

  evalValErrors: function() {
    // evaluate candidates on validation data and return performance of current networks
    // as simple list
    var vals = [];
    var fold = this.folds[this.foldix]; // active fold
    for(var k=0;k<this.candidates.length;k++) {
      var net = this.candidates[k].net;
      var v = 0.0;
      for(var q=0;q<fold.test_ix.length;q++) {
        var x = this.data[fold.test_ix[q]];
        var l = this.labels[fold.test_ix[q]];
        net.forward(x);
        var yhat = net.getPrediction();
        v += (yhat === l ? 1.0 : 0.0); // 0 1 loss
      }
      v /= fold.test_ix.length; // normalize
      vals.push(v);
    }
    return vals;
  },

  // returns prediction scores for given test data point, as Vol
  // uses an averaged prediction from the best ensemble_size models
  // x is a Vol.
  predict_soft: function(data) {
    // forward prop the best networks
    // and accumulate probabilities at last layer into a an output Vol

    var eval_candidates = [];
    var nv = 0;
    if(this.evaluated_candidates.length === 0) {
      // not sure what to do here, first batch of nets hasnt evaluated yet
      // lets just predict with current candidates.
      nv = this.candidates.length;
      eval_candidates = this.candidates;
    } else {
      // forward prop the best networks from evaluated_candidates
      nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);
      eval_candidates = this.evaluated_candidates
    }

    // forward nets of all candidates and average the predictions
    var xout, n;
    for(var j=0;j<nv;j++) {
      var net = eval_candidates[j].net;
      var x = net.forward(data);
      if(j===0) { 
        xout = x; 
        n = x.w.length; 
      } else {
        // add it on
        for(var d=0;d<n;d++) {
          xout.w[d] += x.w[d];
        }
      }
    }
    // produce average
    for(var d=0;d<n;d++) {
      xout.w[d] /= nv;
    }
    return xout;
  },

  predict: function(data) {
    var xout = this.predict_soft(data);
    if(xout.w.length !== 0) {
      var stats = maxmin(xout.w);
      var predicted_label = stats.maxi; 
    } else {
      var predicted_label = -1; // error out
    }
    return predicted_label;

  },

  toJSON: function() {
    // dump the top ensemble_size networks as a list
    var nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);
    var json = {};
    json.nets = [];
    for(var i=0;i<nv;i++) {
      json.nets.push(this.evaluated_candidates[i].net.toJSON());
    }
    return json;
  },

  fromJSON: function(json) {
    this.ensemble_size = json.nets.length;
    this.evaluated_candidates = [];
    for(var i=0;i<this.ensemble_size;i++) {
      var net = new Net();
      net.fromJSON(json.nets[i]);
      var dummy_candidate = {};
      dummy_candidate.net = net;
      this.evaluated_candidates.push(dummy_candidate);
    }
  },

  // callback functions
  // called when a fold is finished, while evaluating a batch
  onFinishFold: function(f) { this.finish_fold_callback = f; },
  // called when a batch of candidates has finished evaluating
  onFinishBatch: function(f) { this.finish_batch_callback = f; }
  
};

convnet.MagicNet = MagicNet;


};
BundleModuleCode['plugins/ml/ann']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Thomas Wagenaar, Stefan Bosse, 
 **    $VERSION:     1.8.1X
 **
 **    $INFO:
 **
 ** https://github.com/wagenaartje/neataptic
 ** Not portable!
 **
 **    $ENDOFINFO
 **
*/

/*******************************************************************************
                                      CONFIG
*******************************************************************************/

// Config
var config = {
  groupId   : 0,
  warnings  : false,
  version   : '1.8.1X',
};

/*******************************************************************************
                                  ACTIVATION FUNCTIONS
*******************************************************************************/

// https://en.wikipedia.org/wiki/Activation_function
// https://stats.stackexchange.com/questions/115258/comprehensive-list-of-activation-functions-in-neural-networks-with-pros-cons
var activation = {
  LOGISTIC: function LOGISTIC (x, derivate) {
    var fx = 1 / (1 + Math.exp(-x));
    if (!derivate) return fx;
    return fx * (1 - fx);
  },
  TANH: function TANH (x, derivate) {
    if (derivate) return 1 - Math.pow(Math.tanh(x), 2);
    return Math.tanh(x);
  },
  IDENTITY: function IDENTITY (x, derivate) {
    return derivate ? 1 : x;
  },
  STEP: function STEP (x, derivate) {
    return derivate ? 0 : x > 0 ? 1 : 0;
  },
  RELU: function RELU (x, derivate) {
    if (derivate) return x > 0 ? 1 : 0;
    return x > 0 ? x : 0;
  },
  SOFTSIGN: function SOFTSIGN (x, derivate) {
    var d = 1 + Math.abs(x);
    if (derivate) return x / Math.pow(d, 2);
    return x / d;
  },
  // Group activation
  SOFTMAX: function SOFTMAX (x, derivate, group) {
    var self=this;
    /* softmax function requires states of group members */
    /* group members can be already updated! */
    if (!derivate) {
      var sum = 0;
      group.nodes.forEach(function (node) {
        if (node.update>self.update) sum += Math.exp(node.state); // already computed x==state
        else sum +=  Math.exp(node.preactivate());
      });
      return Math.exp(x)/sum;
    } else {
      // https://stackoverflow.com/questions/55788902/clear-implementation-of-softmax-and-its-derivative
      var factor=0,
          denom = 0;
      group.nodes.forEach(function (node) {
            var part;
            if (node.update>self.update) {
              part = Math.exp(node.state); // already computed x==state
            } else {
              part = Math.exp(node.preactivate());
            }
            if (node != self) factor += part;
            sum += part;
          })
      var comm = -Math.pow(Math.exp(x),2);
    }
  },
  SINUSOID: function SINUSOID (x, derivate) {
    if (derivate) return Math.cos(x);
    return Math.sin(x);
  },
  GAUSSIAN: function GAUSSIAN (x, derivate) {
    var d = Math.exp(-Math.pow(x, 2));
    if (derivate) return -2 * x * d;
    return d;
  },
  BENT_IDENTITY: function BENT_IDENTITY (x, derivate) {
    var d = Math.sqrt(Math.pow(x, 2) + 1);
    if (derivate) return x / (2 * d) + 1;
    return (d - 1) / 2 + x;
  },
  BIPOLAR: function BIPOLAR (x, derivate) {
    return derivate ? 0 : x > 0 ? 1 : -1;
  },
  BIPOLAR_SIGMOID: function BIPOLAR_SIGMOID (x, derivate) {
    var d = 2 / (1 + Math.exp(-x)) - 1;
    if (derivate) return 1 / 2 * (1 + d) * (1 - d);
    return d;
  },
  HARD_TANH: function HARD_TANH (x, derivate) {
    if (derivate) return x > -1 && x < 1 ? 1 : 0;
    return Math.max(-1, Math.min(1, x));
  },
  ABSOLUTE: function ABSOLUTE (x, derivate) {
    if (derivate) return x < 0 ? -1 : 1;
    return Math.abs(x);
  },
  INVERSE: function INVERSE (x, derivate) {
    if (derivate) return -1;
    return 1 - x;
  },
  // https://arxiv.org/pdf/1706.02515.pdf
  SELU: function SELU (x, derivate) {
    var alpha = 1.6732632423543772848170429916717;
    var scale = 1.0507009873554804934193349852946;
    var fx = x > 0 ? x : alpha * Math.exp(x) - alpha;
    if (derivate) { return x > 0 ? scale : (fx + alpha) * scale; }
    return fx * scale;
  }
};

/*******************************************************************************
                                      MUTATION
*******************************************************************************/

// https://en.wikipedia.org/wiki/mutation_(genetic_algorithm)
var mutation = {
  ADD_NODE: {
    name: 'ADD_NODE'
  },
  SUB_NODE: {
    name: 'SUB_NODE',
    keep_gates: true
  },
  ADD_CONN: {
    name: 'ADD_CONN'
  },
  SUB_CONN: {
    name: 'REMOVE_CONN'
  },
  MOD_WEIGHT: {
    name: 'MOD_WEIGHT',
    min: -1,
    max: 1
  },
  MOD_BIAS: {
    name: 'MOD_BIAS',
    min: -1,
    max: 1
  },
  MOD_ACTIVATION: {
    name: 'MOD_ACTIVATION',
    mutateOutput: true,
    allowed: [
      activation.LOGISTIC,
      activation.TANH,
      activation.RELU,
      activation.IDENTITY,
      activation.STEP,
      activation.SOFTSIGN,
      activation.SINUSOID,
      activation.GAUSSIAN,
      activation.BENT_IDENTITY,
      activation.BIPOLAR,
      activation.BIPOLAR_SIGMOID,
      activation.HARD_TANH,
      activation.ABSOLUTE,
      activation.INVERSE,
      activation.SELU
    ]
  },
  ADD_SELF_CONN: {
    name: 'ADD_SELF_CONN'
  },
  SUB_SELF_CONN: {
    name: 'SUB_SELF_CONN'
  },
  ADD_GATE: {
    name: 'ADD_GATE'
  },
  SUB_GATE: {
    name: 'SUB_GATE'
  },
  ADD_BACK_CONN: {
    name: 'ADD_BACK_CONN'
  },
  SUB_BACK_CONN: {
    name: 'SUB_BACK_CONN'
  },
  SWAP_NODES: {
    name: 'SWAP_NODES',
    mutateOutput: true
  }
};

mutation.ALL = [
  mutation.ADD_NODE,
  mutation.SUB_NODE,
  mutation.ADD_CONN,
  mutation.SUB_CONN,
  mutation.MOD_WEIGHT,
  mutation.MOD_BIAS,
  mutation.MOD_ACTIVATION,
  mutation.ADD_GATE,
  mutation.SUB_GATE,
  mutation.ADD_SELF_CONN,
  mutation.SUB_SELF_CONN,
  mutation.ADD_BACK_CONN,
  mutation.SUB_BACK_CONN,
  mutation.SWAP_NODES
];

mutation.FFW = [
  mutation.ADD_NODE,
  mutation.SUB_NODE,
  mutation.ADD_CONN,
  mutation.SUB_CONN,
  mutation.MOD_WEIGHT,
  mutation.MOD_BIAS,
  mutation.MOD_ACTIVATION,
  mutation.SWAP_NODES
];

/*******************************************************************************
                                      SELECTION
*******************************************************************************/

// https://en.wikipedia.org/wiki/Selection_(genetic_algorithm)

var selection = {
  FITNESS_PROPORTIONATE: {
    name: 'FITNESS_PROPORTIONATE'
  },
  POWER: {
    name: 'POWER',
    power: 4
  },
  TOURNAMENT: {
    name: 'TOURNAMENT',
    size: 5,
    probability: 0.5
  }
};

/*******************************************************************************
                                      CROSSOVER
*******************************************************************************/

// https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm)
var crossover = {
  SINGLE_POINT: {
    name: 'SINGLE_POINT',
    config: [0.4]
  },
  TWO_POINT: {
    name: 'TWO_POINT',
    config: [0.4, 0.9]
  },
  UNIFORM: {
    name: 'UNIFORM'
  },
  AVERAGE: {
    name: 'AVERAGE'
  }
};

/*******************************************************************************
                                    COST FUNCTIONS
*******************************************************************************/

// https://en.wikipedia.org/wiki/Loss_function
var cost = {
  // Cross entropy error
  CROSS_ENTROPY: function (target, output) {
    var error = 0;
    for (var i = 0; i < output.length; i++) {
      // Avoid negative and zero numbers, use 1e-15 http://bit.ly/2p5W29A
      error -= target[i] * Math.log(Math.max(output[i], 1e-15)) + (1 - target[i]) * Math.log(1 - Math.max(output[i], 1e-15));
    }
    return error / output.length;
  },
  // Mean Squared Error
  MSE: function (target, output) {
    var error = 0;
    for (var i = 0; i < output.length; i++) {
      error += Math.pow(target[i] - output[i], 2);
    }

    return error / output.length;
  },
  // Binary error
  BINARY: function (target, output) {
    var misses = 0;
    for (var i = 0; i < output.length; i++) {
      misses += Math.round(target[i] * 2) !== Math.round(output[i] * 2);
    }

    return misses;
  },
  // Mean Absolute Error
  MAE: function (target, output) {
    var error = 0;
    for (var i = 0; i < output.length; i++) {
      error += Math.abs(target[i] - output[i]);
    }

    return error / output.length;
  },
  // Mean Absolute Percentage Error
  MAPE: function (target, output) {
    var error = 0;
    for (var i = 0; i < output.length; i++) {
      error += Math.abs((output[i] - target[i]) / Math.max(target[i], 1e-15));
    }

    return error / output.length;
  },
  // Mean Squared Logarithmic Error
  MSLE: function (target, output) {
    var error = 0;
    for (var i = 0; i < output.length; i++) {
      error += Math.log(Math.max(target[i], 1e-15)) - Math.log(Math.max(output[i], 1e-15));
    }

    return error;
  },
  // Hinge loss, for classifiers
  HINGE: function (target, output) {
    var error = 0;
    for (var i = 0; i < output.length; i++) {
      error += Math.max(0, 1 - target[i] * output[i]);
    }

    return error;
  }
};


/*******************************************************************************
                                    GATING
*******************************************************************************/

// Specifies how to gate a connection between two groups of multiple neurons
var gating = {
  OUTPUT: {
    name: 'OUTPUT'
  },
  INPUT: {
    name: 'INPUT'
  },
  SELF: {
    name: 'SELF'
  }
};


/*******************************************************************************
                                    CONNECTION
*******************************************************************************/

// Specifies in what manner two groups are connected
var connection = {
  ALL_TO_ALL: {
    name: 'OUTPUT'
  },
  ALL_TO_ELSE: {
    name: 'INPUT'
  },
  ONE_TO_ONE: {
    name: 'SELF'
  }
};


/*******************************************************************************
                                      RATE
*******************************************************************************/

// https://stackoverflow.com/questions/30033096/what-is-lr-policy-in-caffe/30045244
var rate = {
  FIXED: function () {
    var func = function (baseRate, iteration) { return baseRate; };
    return func;
  },
  STEP: function (gamma, stepSize) {
    gamma = gamma || 0.9;
    stepSize = stepSize || 100;

    var func = function (baseRate, iteration) {
      return baseRate * Math.pow(gamma, Math.floor(iteration / stepSize));
    };

    return func;
  },
  EXP: function (gamma) {
    gamma = gamma || 0.999;

    var func = function (baseRate, iteration) {
      return baseRate * Math.pow(gamma, iteration);
    };

    return func;
  },
  INV: function (gamma, power) {
    gamma = gamma || 0.001;
    power = power || 2;

    var func = function (baseRate, iteration) {
      return baseRate * Math.pow(1 + gamma * iteration, -power);
    };

    return func;
  }
};

/*******************************************************************************
                                  METHODS
*******************************************************************************/

var methods = {
  activation: activation,
  mutation: mutation,
  selection: selection,
  crossover: crossover,
  cost: cost,
  gating: gating,
  connection: connection,
  rate: rate
};

/*******************************************************************************
                                      CONNECTION
*******************************************************************************/

function Connection (from, to, weight) {
  this.from = from;
  this.to = to;
  this.gain = 1;

  this.weight = (typeof weight === 'undefined') ? Math.random() * 0.2 - 0.1 : weight;

  this.gater = null;
  this.elegibility = 0;

  // For tracking momentum
  this.previousDeltaWeight = 0;

  // Batch training
  this.totalDeltaWeight = 0;

  this.xtrace = {
    nodes: [],
    values: []
  };
}

Connection.prototype = {
  /**
   * Converts the connection to a json object
   */
  toJSON: function () {
    var json = {
      weight: this.weight
    };

    return json;
  }
};

/**
 * Returns an innovation ID
 * https://en.wikipedia.org/wiki/Pairing_function (Cantor pairing function)
 */
Connection.innovationID = function (a, b) {
  return 1 / 2 * (a + b) * (a + b + 1) + b;
};

/*******************************************************************************
                                 NETWORK
*******************************************************************************/


/* Easier variable naming */
var mutation = methods.mutation;

function Network (input, output) {
  if (typeof input === 'undefined' || typeof output === 'undefined') {
    throw new Error('No input or output size given');
  }

  this.input = input;
  this.output = output;

  // Store all the node and connection genes
  this.nodes = []; // Stored in activation order
  this.connections = [];
  this.gates = [];
  this.selfconns = [];

  // Regularization
  this.dropout = 0;

  // Create input and output nodes
  var i;
  for (i = 0; i < this.input + this.output; i++) {
    var type = i < this.input ? 'input' : 'output';
    this.nodes.push(new Node(type,{layerid:type=='input'?0:1}));
  }

  // Connect input nodes with output nodes directly
  for (i = 0; i < this.input; i++) {
    for (var j = this.input; j < this.output + this.input; j++) {
      // https://stats.stackexchange.com/a/248040/147931
      var weight = Math.random() * this.input * Math.sqrt(2 / this.input);
      this.connect(this.nodes[i], this.nodes[j], weight);
    }
  }
}

Network.prototype = {
  /**
   * Activates the network
   */
  activate: function (input, training) {
    var output = [];

    // Activate nodes chronologically
    for (var i = 0; i < this.nodes.length; i++) {
      if (this.nodes[i].type === 'input') {
        this.nodes[i].activate(input[i]);
      } else if (this.nodes[i].type === 'output') {
        var activation = this.nodes[i].activate();
        output.push(activation);
      } else {
        if (training) this.nodes[i].mask = Math.random() < this.dropout ? 0 : 1;
        this.nodes[i].activate();
      }
    }

    return output;
  },

  // make a snapshot of the network (weights, biases)
  // add snapshot to this object
  backup : function () {
    if (!this.snapshots) this.snapshots=[];
    this.snapshots.push(
      { 
       nodes : this.nodes.map(function (node) {
          return {
            bias        : node.bias,
            activation  : node.activation,
            state       : node.state,
            mask        : node.mask,
            previousDeltaBias: node.previousDeltaBias,
            totalDeltaBias: node.totalDeltaBias,
            derivative: node.derivative,
          }}),
        connections : this.connections.map(function (conn) {
          return {
            gain    : conn.gain,
            weight  : conn.weight,
            elegibility : conn.elegibility,
            previousDeltaWeight : conn.previousDeltaWeight,
          }}),
    });
  },
  
  /**
   * Clear the context of the network
   */
  clear: function () {
    for (var i = 0; i < this.nodes.length; i++) {
      this.nodes[i].clear();
    }
  },

  /**
   * Connects the from node to the to node
   */
  connect: function (from, to, weight) {
    var connections = from.connect(to, weight);

    for (var i = 0; i < connections.length; i++) {
      var connection = connections[i];
      if (from !== to) {
        this.connections.push(connection);
      } else {
        this.selfconns.push(connection);
      }
    }

    return connections;
  },

  /*
  *  Post configure network after construction (e.g., by assigning activation/squash functions)
  */
  configure : function (options) {
    if (options.activation && typeof options.activation == 'string') { // apply to all nodes
      this.nodes.forEach(function (node) {
        if (!methods.activation[options.activation]) throw "Network.configure: EINVALID (activation)";
        node.squash=methods.activation[options.activation];
      });
    }
    if (options.activation && typeof options.activation == 'function') { // apply to all nodes
      this.nodes.forEach(function (node) {
        node.squash=options.activation;
      });
    }
    if (options.activation && typeof options.activation == 'object') { // each for one layer
      this.groups.forEach(function (group,index) {
        group.nodes.forEach(function (node) {
          var f = typeof options.activation[index] == 'function'?
                   options.activation[index]: methods.activation[options.activation[index]];
          if (!f) throw "Network.configure: EINVALID (activation)";
          node.squash=f;
        })
      });
    }
  },
  
  /**
   * Disconnects the from node from the to node
   */
  disconnect: function (from, to) {
    // Delete the connection in the network's connection array
    var connections = from === to ? this.selfconns : this.connections;

    for (var i = 0; i < connections.length; i++) {
      var connection = connections[i];
      if (connection.from === from && connection.to === to) {
        if (connection.gater !== null) this.ungate(connection);
        connections.splice(i, 1);
        break;
      }
    }

    // Delete the connection at the sending and receiving neuron
    from.disconnect(to);
  },

  /**
   * Evolves the network to reach a lower error on a dataset
   */
  evolve: function (set, options) {
    if (set[0].input.length !== this.input || set[0].output.length !== this.output) {
      throw new Error('Dataset input/output size should be same as network input/output size!');
    }

    // Read the options
    options = options || {};
    var targetError = typeof options.error !== 'undefined' ? options.error : 0.05;
    var growth = typeof options.growth !== 'undefined' ? options.growth : 0.0001;
    var cost = options.cost || methods.cost.MSE;
    var amount = options.amount || 1;


    var start = Date.now();

    if (typeof options.iterations === 'undefined' && typeof options.error === 'undefined') {
      throw new Error('At least one of the following options must be specified: error, iterations');
    } else if (typeof options.error === 'undefined') {
      targetError = -1; // run until iterations
    } else if (typeof options.iterations === 'undefined') {
      options.iterations = 0; // run until target error
    }

    var fitnessFunction;
    {
      // Create the fitness function
      fitnessFunction = function (genome) {
        var score = 0;
        for (var i = 0; i < amount; i++) {
          score -= genome.test(set, cost).error;
        }

        score -= (genome.nodes.length - genome.input - genome.output + genome.connections.length + genome.gates.length) * growth;
        score = isNaN(score) ? -Infinity : score; // this can cause problems with fitness proportionate selection

        return score / amount;
      };
    } 

    // Intialise the NEAT instance
    options.network = this;
    var neat = new Neat(this.input, this.output, fitnessFunction, options);

    var error = -Infinity;
    var bestFitness = -Infinity;
    var bestGenome;

    while (error < -targetError && (options.iterations === 0 || neat.generation < options.iterations)) {
      var fittest = neat.evolve();
      var fitness = fittest.score;
      error = fitness + (fittest.nodes.length - fittest.input - fittest.output + fittest.connections.length + fittest.gates.length) * growth;

      if (fitness > bestFitness) {
        bestFitness = fitness;
        bestGenome = fittest;
      }

      if (options.log && neat.generation % options.log === 0) {
        console.log('iteration', neat.generation, 'fitness', fitness, 'error', -error);
      }

      if (options.schedule && neat.generation % options.schedule.iterations === 0) {
        options.schedule.function({ fitness: fitness, error: -error, iteration: neat.generation });
      }
    }


    if (typeof bestGenome !== 'undefined') {
      this.nodes = bestGenome.nodes;
      this.connections = bestGenome.connections;
      this.selfconns = bestGenome.selfconns;
      this.gates = bestGenome.gates;

      if (options.clear) this.clear();
    }

    return {
      error: -error,
      iterations: neat.generation,
      time: Date.now() - start
    };
  },

  /**
   * Gate a connection with a node
   */
  gate: function (node, connection) {
    if (this.nodes.indexOf(node) === -1) {
      throw new Error('This node is not part of the network!');
    } else if (connection.gater != null) {
      if (config.warnings) console.warn('This connection is already gated!');
      return;
    }
    node.gate(connection);
    this.gates.push(connection);
  },

  /**
   * Creates a json that can be used to create a graph with d3 and webcola
   */
  graph: function (width, height) {
    var input = 0;
    var output = 0;

    var json = {
      nodes: [],
      links: [],
      constraints: [{
        type: 'alignment',
        axis: 'x',
        offsets: []
      }, {
        type: 'alignment',
        axis: 'y',
        offsets: []
      }]
    };

    var i;
    for (i = 0; i < this.nodes.length; i++) {
      var node = this.nodes[i];

      if (node.type === 'input') {
        if (this.input === 1) {
          json.constraints[0].offsets.push({
            node: i,
            offset: 0
          });
        } else {
          json.constraints[0].offsets.push({
            node: i,
            offset: 0.8 * width / (this.input - 1) * input++
          });
        }
        json.constraints[1].offsets.push({
          node: i,
          offset: 0
        });
      } else if (node.type === 'output') {
        if (this.output === 1) {
          json.constraints[0].offsets.push({
            node: i,
            offset: 0
          });
        } else {
          json.constraints[0].offsets.push({
            node: i,
            offset: 0.8 * width / (this.output - 1) * output++
          });
        }
        json.constraints[1].offsets.push({
          node: i,
          offset: -0.8 * height
        });
      }

      json.nodes.push({
        id: i,
        name: node.type === 'hidden' ? node.squash.name : node.type.toUpperCase(),
        activation: node.activation,
        bias: node.bias
      });
    }

    var connections = this.connections.concat(this.selfconns);
    for (i = 0; i < connections.length; i++) {
      var connection = connections[i];
      if (connection.gater == null) {
        json.links.push({
          source: this.nodes.indexOf(connection.from),
          target: this.nodes.indexOf(connection.to),
          weight: connection.weight
        });
      } else {
        // Add a gater 'node'
        var index = json.nodes.length;
        json.nodes.push({
          id: index,
          activation: connection.gater.activation,
          name: 'GATE'
        });
        json.links.push({
          source: this.nodes.indexOf(connection.from),
          target: index,
          weight: 1 / 2 * connection.weight
        });
        json.links.push({
          source: index,
          target: this.nodes.indexOf(connection.to),
          weight: 1 / 2 * connection.weight
        });
        json.links.push({
          source: this.nodes.indexOf(connection.gater),
          target: index,
          weight: connection.gater.activation,
          gate: true
        });
      }
    }

    return json;
  },

  // return node arrays of layer array with status information (nodes)
  // optional with activation data (number [])
  monitor : function (what,data) {
    what=what||'activation';
    function collect(node) {
      switch (what) {
        case 'node': return node;
        case 'weights':
          return node.connections.in.map(function (c) {
            return c.weight;
          })
        case 'sum':
          var result=node.connections.in.map(function (c) {
            return c.weight*c.from.activation;
          })
          if (result.length) return result.reduce(function (a,b) { return a+b });
          else return node.activation;
        default:
          return node[what]
      }    
    }
    if (data) this.activate(data);
    if (this.groups && this.groups.length)
      return this.groups.map(function (layer) {
         return layer.nodes.map(collect);
      });
    else if (this.layers && this.layers.length)     
      return this.layers.map(function (layer) {
        return layer.output.nodes.map(collect);
      });
  },
  
  /**
   * Mutates the network with the given method
   */
  mutate: function (method) {
    if (typeof method === 'undefined') {
      throw new Error('No (correct) mutate method given!');
    }

    var i, j;
    switch (method) {
      case mutation.ADD_NODE:
        // Look for an existing connection and place a node in between
        var connection = this.connections[Math.floor(Math.random() * this.connections.length)];
        var gater = connection.gater;
        this.disconnect(connection.from, connection.to);

        // Insert the new node right before the old connection.to
        var toIndex = this.nodes.indexOf(connection.to);
        var node = new Node('hidden');

        // Random squash function
        node.mutate(mutation.MOD_ACTIVATION);

        // Place it in this.nodes
        var minBound = Math.min(toIndex, this.nodes.length - this.output);
        this.nodes.splice(minBound, 0, node);

        // Now create two new connections
        var newConn1 = this.connect(connection.from, node)[0];
        var newConn2 = this.connect(node, connection.to)[0];

        // Check if the original connection was gated
        if (gater != null) {
          this.gate(gater, Math.random() >= 0.5 ? newConn1 : newConn2);
        }
        break;
      case mutation.SUB_NODE:
        // Check if there are nodes left to remove
        if (this.nodes.length === this.input + this.output) {
          if (config.warnings) console.warn('No more nodes left to remove!');
          break;
        }

        // Select a node which isn't an input or output node
        var index = Math.floor(Math.random() * (this.nodes.length - this.output - this.input) + this.input);
        this.remove(this.nodes[index]);
        break;
      case mutation.ADD_CONN:
        // Create an array of all uncreated (feedforward) connections
        var available = [];
        for (i = 0; i < this.nodes.length - this.output; i++) {
          var node1 = this.nodes[i];
          for (j = Math.max(i + 1, this.input); j < this.nodes.length; j++) {
            var node2 = this.nodes[j];
            if (!node1.isProjectingTo(node2)) available.push([node1, node2]);
          }
        }

        if (available.length === 0) {
          if (config.warnings) console.warn('No more connections to be made!');
          break;
        }

        var pair = available[Math.floor(Math.random() * available.length)];
        this.connect(pair[0], pair[1]);
        break;
      case mutation.SUB_CONN:
        // List of possible connections that can be removed
        var possible = [];

        for (i = 0; i < this.connections.length; i++) {
          var conn = this.connections[i];
          // Check if it is not disabling a node
          if (conn.from.connections.out.length > 1 && conn.to.connections.in.length > 1 && this.nodes.indexOf(conn.to) > this.nodes.indexOf(conn.from)) {
            possible.push(conn);
          }
        }

        if (possible.length === 0) {
          if (config.warnings) console.warn('No connections to remove!');
          break;
        }

        var randomConn = possible[Math.floor(Math.random() * possible.length)];
        this.disconnect(randomConn.from, randomConn.to);
        break;
      case mutation.MOD_WEIGHT:
        var allconnections = this.connections.concat(this.selfconns);

        var connection = allconnections[Math.floor(Math.random() * allconnections.length)];
        var modification = Math.random() * (method.max - method.min) + method.min;
        connection.weight += modification;
        break;
      case mutation.MOD_BIAS:
        // Has no effect on input node, so they are excluded
        var index = Math.floor(Math.random() * (this.nodes.length - this.input) + this.input);
        var node = this.nodes[index];
        node.mutate(method);
        break;
      case mutation.MOD_ACTIVATION:
        // Has no effect on input node, so they are excluded
        if (!method.mutateOutput && this.input + this.output === this.nodes.length) {
          if (config.warnings) console.warn('No nodes that allow mutation of activation function');
          break;
        }

        var index = Math.floor(Math.random() * (this.nodes.length - (method.mutateOutput ? 0 : this.output) - this.input) + this.input);
        var node = this.nodes[index];

        node.mutate(method);
        break;
      case mutation.ADD_SELF_CONN:
        // Check which nodes aren't selfconnected yet
        var possible = [];
        for (i = this.input; i < this.nodes.length; i++) {
          var node = this.nodes[i];
          if (node.connections.self.weight === 0) {
            possible.push(node);
          }
        }

        if (possible.length === 0) {
          if (config.warnings) console.warn('No more self-connections to add!');
          break;
        }

        // Select a random node
        var node = possible[Math.floor(Math.random() * possible.length)];

        // Connect it to himself
        this.connect(node, node);
        break;
      case mutation.SUB_SELF_CONN:
        if (this.selfconns.length === 0) {
          if (config.warnings) console.warn('No more self-connections to remove!');
          break;
        }
        var conn = this.selfconns[Math.floor(Math.random() * this.selfconns.length)];
        this.disconnect(conn.from, conn.to);
        break;
      case mutation.ADD_GATE:
        var allconnections = this.connections.concat(this.selfconns);

        // Create a list of all non-gated connections
        var possible = [];
        for (i = 0; i < allconnections.length; i++) {
          var conn = allconnections[i];
          if (conn.gater === null) {
            possible.push(conn);
          }
        }

        if (possible.length === 0) {
          if (config.warnings) console.warn('No more connections to gate!');
          break;
        }

        // Select a random gater node and connection, can't be gated by input
        var index = Math.floor(Math.random() * (this.nodes.length - this.input) + this.input);
        var node = this.nodes[index];
        var conn = possible[Math.floor(Math.random() * possible.length)];

        // Gate the connection with the node
        this.gate(node, conn);
        break;
      case mutation.SUB_GATE:
        // Select a random gated connection
        if (this.gates.length === 0) {
          if (config.warnings) console.warn('No more connections to ungate!');
          break;
        }

        var index = Math.floor(Math.random() * this.gates.length);
        var gatedconn = this.gates[index];

        this.ungate(gatedconn);
        break;
      case mutation.ADD_BACK_CONN:
        // Create an array of all uncreated (backfed) connections
        var available = [];
        for (i = this.input; i < this.nodes.length; i++) {
          var node1 = this.nodes[i];
          for (j = this.input; j < i; j++) {
            var node2 = this.nodes[j];
            if (!node1.isProjectingTo(node2)) available.push([node1, node2]);
          }
        }

        if (available.length === 0) {
          if (config.warnings) console.warn('No more connections to be made!');
          break;
        }

        var pair = available[Math.floor(Math.random() * available.length)];
        this.connect(pair[0], pair[1]);
        break;
      case mutation.SUB_BACK_CONN:
        // List of possible connections that can be removed
        var possible = [];

        for (i = 0; i < this.connections.length; i++) {
          var conn = this.connections[i];
          // Check if it is not disabling a node
          if (conn.from.connections.out.length > 1 && conn.to.connections.in.length > 1 && this.nodes.indexOf(conn.from) > this.nodes.indexOf(conn.to)) {
            possible.push(conn);
          }
        }

        if (possible.length === 0) {
          if (config.warnings) console.warn('No connections to remove!');
          break;
        }

        var randomConn = possible[Math.floor(Math.random() * possible.length)];
        this.disconnect(randomConn.from, randomConn.to);
        break;
      case mutation.SWAP_NODES:
        // Has no effect on input node, so they are excluded
        if ((method.mutateOutput && this.nodes.length - this.input < 2) ||
          (!method.mutateOutput && this.nodes.length - this.input - this.output < 2)) {
          if (config.warnings) console.warn('No nodes that allow swapping of bias and activation function');
          break;
        }

        var index = Math.floor(Math.random() * (this.nodes.length - (method.mutateOutput ? 0 : this.output) - this.input) + this.input);
        var node1 = this.nodes[index];
        index = Math.floor(Math.random() * (this.nodes.length - (method.mutateOutput ? 0 : this.output) - this.input) + this.input);
        var node2 = this.nodes[index];

        var biasTemp = node1.bias;
        var squashTemp = node1.squash;

        node1.bias = node2.bias;
        node1.squash = node2.squash;
        node2.bias = biasTemp;
        node2.squash = squashTemp;
        break;
    }
  },

  // apply uniformly distributed noise to bias of nodes and weights of connections (perc=[0,1])
  // supported layers: 'hidden'|'output'
  noise : function (perc,layers) {
    layers=layers||['hidden'];
    this.nodes.forEach(function (node) {
      if (layers.indexOf(node.type)!=-1) {
        node.bias += ((Math.random()-0.5)*perc*node.bias);
      }
    });
    this.connections.forEach(function (conn) {
      if (layers.indexOf(conn.to.type)!=-1) {
        conn.weight += ((Math.random()-0.5)*perc*conn.weight);
      }
    });
  },
  
  /**
   * Activates the network without calculating elegibility traces and such
   */
  noTraceActivate: function (input) {
    var output = [];

    // Activate nodes chronologically
    for (var i = 0; i < this.nodes.length; i++) {
      if (this.nodes[i].type === 'input') {
        this.nodes[i].noTraceActivate(input[i]);
      } else if (this.nodes[i].type === 'output') {
        var activation = this.nodes[i].noTraceActivate();
        output.push(activation);
      } else {
        this.nodes[i].noTraceActivate();
      }
    }

    return output;
  },

  /**
   * Backpropagate the network
   */
  propagate: function (rate, momentum, update, target) {
    if (typeof target === 'undefined' || target.length !== this.output) {
      throw new Error('Output target length should match network output length');
    }

    var targetIndex = target.length;

    // Propagate output nodes
    var i;
    for (i = this.nodes.length - 1; i >= this.nodes.length - this.output; i--) {
      this.nodes[i].propagate(rate, momentum, update, target[--targetIndex]);
    }

    // Propagate hidden and input nodes
    for (i = this.nodes.length - this.output - 1; i >= this.input; i--) {
      this.nodes[i].propagate(rate, momentum, update);
    }
  },
  
  // Experimental
  // Naive regularization of saturated nodes by adjusting the node bias to the negative 
  // weighted input summation (resulting value sum0) if the activation output of a node is
  // outside the interval [low,high] and (if there is optional activation by
  // data series data) the saturation occures more than threshold (0,1] times scaled
  // to the number of data points (or 1).
  // For a data series (|data|>1) the mean summation output is used for bias adjustment.
  regularizeBias : function (data,low,high,sum0,threshold) {
    var network = this;
    data=data||[null]
    if (low==undefined)       low=0.02; // assuming logistic/sigmoid transfer function
    if (high==undefined)      high=0.98;
    if (sum0==undefined)      sum0=0;
    if (threshold==undefined) threshold=1;
    
    var biasmap    = network.monitor('bias'),
        nodes      = network.monitor('node'),
        candimap   = [],
        sumaccumap = [];
    data.forEach(function (sample) {
      if (sample) network.activate(sample,false);
      var actmap = network.monitor('activation'),
          summap = network.monitor('sum');
      var satN=0;
      actmap.forEach(function (actlayer,layeri) {
        if (!candimap[layeri])   candimap[layeri]=Array.init(actlayer.length);
        if (!sumaccumap[layeri]) sumaccumap[layeri]=Array.init(actlayer.length);      
        actlayer.forEach(function (act,nodej) {
          sumaccumap[layeri][nodej] += summap[layeri][nodej];
          if (act<low ||
              act>high) {
            // saturated node  
            satN++;
            var node = nodes[layeri][nodej],
                sum  = summap[layeri][nodej];
            // node.bias=-sum+sum0;
            candimap[layeri][nodej]++;
          }
        });
      });
    })
    var satN=0;
    candimap.forEach(function (layer,layeri) {
      layer.forEach(function (count,nodej) {
        if (count/data.length>=threshold) {
          satN++;
          var node = nodes[layeri][nodej],
              sum  = sumaccumap[layeri][nodej]/data.length;
          node.bias=-sum+sum0;
        }
      });
    });
    return { adjusted:satN, candidates: candimap, summap : sumaccumap }
  },

  /**
   *  Removes a node from the network
   */
  remove: function (node) {
    var index = this.nodes.indexOf(node);

    if (index === -1) {
      throw new Error('This node does not exist in the network!');
    }

    // Keep track of gaters
    var gaters = [];

    // Remove selfconnections from this.selfconns
    this.disconnect(node, node);

    // Get all its inputting nodes
    var inputs = [];
    for (var i = node.connections.in.length - 1; i >= 0; i--) {
      var connection = node.connections.in[i];
      if (mutation.SUB_NODE.keep_gates && connection.gater !== null && connection.gater !== node) {
        gaters.push(connection.gater);
      }
      inputs.push(connection.from);
      this.disconnect(connection.from, node);
    }

    // Get all its outputing nodes
    var outputs = [];
    for (i = node.connections.out.length - 1; i >= 0; i--) {
      var connection = node.connections.out[i];
      if (mutation.SUB_NODE.keep_gates && connection.gater !== null && connection.gater !== node) {
        gaters.push(connection.gater);
      }
      outputs.push(connection.to);
      this.disconnect(node, connection.to);
    }

    // Connect the input nodes to the output nodes (if not already connected)
    var connections = [];
    for (i = 0; i < inputs.length; i++) {
      var input = inputs[i];
      for (var j = 0; j < outputs.length; j++) {
        var output = outputs[j];
        if (!input.isProjectingTo(output)) {
          var conn = this.connect(input, output);
          connections.push(conn[0]);
        }
      }
    }

    // Gate random connections with gaters
    for (i = 0; i < gaters.length; i++) {
      if (connections.length === 0) break;

      var gater = gaters[i];
      var connIndex = Math.floor(Math.random() * connections.length);

      this.gate(gater, connections[connIndex]);
      connections.splice(connIndex, 1);
    }

    // Remove gated connections gated by this node
    for (i = node.connections.gated.length - 1; i >= 0; i--) {
      var conn = node.connections.gated[i];
      this.ungate(conn);
    }

    // Remove selfconnection
    this.disconnect(node, node);

    // Remove the node from this.nodes
    this.nodes.splice(index, 1);
  },

  // restore network from a snapshot from the past
  // options parameter back specifies the n oldest snapshot in the range {1,..,#snaps}
  // otherwise the last (newest) snapshot is removed and restored (default behaviour)
  restore : function (back) {
    var self=this;
    if (!this.snapshots || this.snapshots.length==0) return;
    var snapshot = back==undefined?this.snapshots.pop():this.snapshots[this.snapshots.length-back];
    snapshot.nodes.forEach(function (nodeS,index) {
      var node = self.nodes[index];
      Object.assign(node,nodeS);
    })
    snapshot.connections.forEach(function (connS,index) {
      var conn = self.connections[index];
      Object.assign(conn,connS);
    })  
  },
  



  /**
   * Sets the value of a property for every node in this network
   */
  set: function (values) {
    for (var i = 0; i < this.nodes.length; i++) {
      this.nodes[i].bias = values.bias || this.nodes[i].bias;
      this.nodes[i].squash = values.squash || this.nodes[i].squash;
    }
  },
  /**
   * Serialize to send to workers efficiently
   */
  serialize: function () {
    var activations = [];
    var states = [];
    var conns = [];
    var squashes = [
      'LOGISTIC', 'TANH', 'IDENTITY', 'STEP', 'RELU', 'SOFTSIGN', 'SINUSOID',
      'GAUSSIAN', 'BENT_IDENTITY', 'BIPOLAR', 'BIPOLAR_SIGMOID', 'HARD_TANH',
      'ABSOLUTE', 'INVERSE', 'SELU'
    ];

    conns.push(this.input);
    conns.push(this.output);

    var i;
    for (i = 0; i < this.nodes.length; i++) {
      var node = this.nodes[i];
      node.index = i;
      activations.push(node.activation);
      states.push(node.state);
    }

    for (i = this.input; i < this.nodes.length; i++) {
      var node = this.nodes[i];
      conns.push(node.index);
      conns.push(node.bias);
      conns.push(squashes.indexOf(node.squash.name));

      conns.push(node.connections.self.weight);
      conns.push(node.connections.self.gater == null ? -1 : node.connections.self.gater.index);

      for (var j = 0; j < node.connections.in.length; j++) {
        var conn = node.connections.in[j];

        conns.push(conn.from.index);
        conns.push(conn.weight);
        conns.push(conn.gater == null ? -1 : conn.gater.index);
      }

      conns.push(-2); // stop token -> next node
    }

    return [activations, states, conns];
  },

  /**
   * Creates a standalone function of the network which can be run without the
   * need of a library
   */
  standalone: function () {
    var present = [];
    var activations = [];
    var states = [];
    var lines = [];
    var functions = [];

    var i;
    for (i = 0; i < this.input; i++) {
      var node = this.nodes[i];
      activations.push(node.activation);
      states.push(node.state);
    }

    lines.push('for(var i = 0; i < input.length; i++) A[i] = input[i];');

    // So we don't have to use expensive .indexOf()
    for (i = 0; i < this.nodes.length; i++) {
      this.nodes[i].index = i;
    }

    for (i = this.input; i < this.nodes.length; i++) {
      var node = this.nodes[i];
      activations.push(node.activation);
      states.push(node.state);

      var functionIndex = present.indexOf(node.squash.name);

      if (functionIndex === -1) {
        functionIndex = present.length;
        present.push(node.squash.name);
        functions.push(node.squash.toString());
      }

      var incoming = [];
      for (var j = 0; j < node.connections.in.length; j++) {
        var conn = node.connections.in[j];
        var computation = "A[" + conn.from.index + "] * " + conn.weight;
        
        if (conn.gater != null) {
          computation += " * A[" + conn.gater.index + "]";
        }

        incoming.push(computation);
      }

      if (node.connections.self.weight) {
        var conn = node.connections.self;
        var computation = "S[" + i + "] * " + conn.weight;

        if (conn.gater != null) {
          computation += " * A[" + conn.gater.index + "]";
        }

        incoming.push(computation);
      }

      var line1 = "S[" + i + "] = " + incoming.join(' + ') + " + " + node.bias + ";";
      var line2 = "A[" + i + "] = F[" + functionIndex + "](S[" + i + "])" + (!node.mask ? ' * ' + node.mask : '') + ";";
      lines.push(line1);
      lines.push(line2);
    }

    var output = [];
    for (i = this.nodes.length - this.output; i < this.nodes.length; i++) {
      output.push("A[" + i + "]");
    }

    output = "return [" + output.join(',') + "];";
    lines.push(output);

    var total = '';
    
    total += "var F = [" + functions.toString() + "];\r\n"; 
    total += "var A = [" + activations.toString() + "];\r\n";
    total += "var S = [" + states.toString() + "];\r\n";
    total += "function activate(input){\r\n" + lines.join('\r\n') + "\r\n}";
    return total;
  },

  /**
   * Tests a set and returns the error and elapsed time
   */
  test: function (set, cost) {
    if (cost == undefined) cost = methods.cost.MSE;
    // Check if dropout is enabled, set correct mask
    var i;
    if (this.dropout) {
      for (i = 0; i < this.nodes.length; i++) {
        if (this.nodes[i].type === 'hidden' || this.nodes[i].type === 'constant') {
          this.nodes[i].mask = 1 - this.dropout;
        }
      }
    }

    var error = 0;
    var start = Date.now();

    for (i = 0; i < set.length; i++) {
      var input = set[i].input;
      var target = set[i].output;
      var output = this.noTraceActivate(input);
      error += cost(target, output);
    }

    error /= set.length;

    var results = {
      error: error,
      time: Date.now() - start
    };

    return results;
  },

  /**
   * Train the given set to this network
   */
  train: function (set, options) {
    if (set[0].input.length !== this.input || set[0].output.length !== this.output) {
      throw new Error('Dataset input/output size should be same as network input/output size!');
    }

    options = options || {};

    // Warning messages
    if (typeof options.rate === 'undefined') {
      if (config.warnings) console.warn('Using default learning rate, please define a rate!');
    }
    if (typeof options.iterations === 'undefined') {
      if (config.warnings) console.warn('No target iterations given, running until error is reached!');
    }

    // Read the options
    var targetError = options.error || 0.05;
    var cost = options.cost || methods.cost.MSE;
    var baseRate = options.rate || 0.3;
    var dropout = options.dropout || 0;
    var momentum = options.momentum || 0;
    var batchSize = options.batchSize || 1; // online learning
    var ratePolicy = options.ratePolicy || methods.rate.FIXED();

    var start = Date.now();

    if (batchSize > set.length) {
      throw new Error('Batch size must be smaller or equal to dataset length!');
    } else if (typeof options.iterations === 'undefined' && typeof options.error === 'undefined') {
      throw new Error('At least one of the following options must be specified: error, iterations');
    } else if (typeof options.error === 'undefined') {
      targetError = -1; // run until iterations
    } else if (typeof options.iterations === 'undefined') {
      options.iterations = 0; // run until target error
    }

    // Save to network
    this.dropout = dropout;

    if (options.crossValidate) {
      var numTrain = Math.ceil((1 - options.crossValidate.testSize) * set.length);
      var trainSet = set.slice(0, numTrain);
      var testSet = set.slice(numTrain);
    }

    // Loops the training process
    var currentRate = baseRate;
    var iteration = 0;
    var error = 1;

    var i, j, x;
    while (error > targetError && (options.iterations === 0 || iteration < options.iterations)) {
      if (options.crossValidate && error <= options.crossValidate.testError) break;

      iteration++;

      // Update the rate
      currentRate = ratePolicy(baseRate, iteration);

      // Checks if cross validation is enabled
      if (options.crossValidate) {
        this._trainSet(trainSet, batchSize, currentRate, momentum, cost);
        if (options.clear) this.clear();
        error = this.test(testSet, cost).error;
        if (options.clear) this.clear();
      } else {
        error = this._trainSet(set, batchSize, currentRate, momentum, cost);
        if (options.clear) this.clear();
      }

      // Checks for options such as scheduled logs and shuffling
      if (options.shuffle) {
        for (j, x, i = set.length; i; j = Math.floor(Math.random() * i), x = set[--i], set[i] = set[j], set[j] = x);
      }

      if (options.log && iteration % options.log === 0) {
        console.log('iteration', iteration, 'error', error, 'rate', currentRate);
      }

      if (options.schedule && iteration % options.schedule.iterations === 0) {
        options.schedule.function({ error: error, iteration: iteration });
      }
    }

    if (options.clear) this.clear();

    if (dropout) {
      for (i = 0; i < this.nodes.length; i++) {
        if (this.nodes[i].type === 'hidden' || this.nodes[i].type === 'constant') {
          this.nodes[i].mask = 1 - this.dropout;
        }
      }
    }

    return {
      error: error,
      iterations: iteration,
      time: Date.now() - start
    };
  },

  /**
   * Performs one training epoch and returns the error
   * private function used in this.train
   */
  _trainSet: function (set, batchSize, currentRate, momentum, costFunction) {
    var errorSum = 0;
    for (var i = 0; i < set.length; i++) {
      var input = set[i].input;
      var target = set[i].output;

      var update = !!((i + 1) % batchSize === 0 || (i + 1) === set.length);

      var output = this.activate(input, true);
      this.propagate(currentRate, momentum, update, target);
      errorSum += costFunction(target, output);
    }
    return errorSum / set.length;
  },



 /**
   * Convert the network to a json object
   */
  toJSON: function () {
    var json = {
      nodes: [],
      connections: [],
      input: this.input,
      output: this.output,
      dropout: this.dropout
    };

    // So we don't have to use expensive .indexOf()
    var i;
    for (i = 0; i < this.nodes.length; i++) {
      this.nodes[i].index = i;
    }

    for (i = 0; i < this.nodes.length; i++) {
      var node = this.nodes[i];
      var tojson = node.toJSON();
      tojson.index = i;
      json.nodes.push(tojson);

      if (node.connections.self.weight !== 0) {
        var tojson = node.connections.self.toJSON();
        tojson.from = i;
        tojson.to = i;

        tojson.gater = node.connections.self.gater != null ? node.connections.self.gater.index : null;
        json.connections.push(tojson);
      }
    }

    for (i = 0; i < this.connections.length; i++) {
      var conn = this.connections[i];
      var tojson = conn.toJSON();
      tojson.from = conn.from.index;
      tojson.to = conn.to.index;

      tojson.gater = conn.gater != null ? conn.gater.index : null;

      json.connections.push(tojson);
    }

    return json;
  },

  /**
   *  Remove the gate of a connection
   */
  ungate: function (connection) {
    var index = this.gates.indexOf(connection);
    if (index === -1) {
      throw new Error('This connection is not gated!');
    }

    this.gates.splice(index, 1);
    connection.gater.ungate(connection);
  },


};

/**
 * Convert a json object to a network
 */
Network.fromJSON = function (json) {
  var network = new Network(json.input, json.output);
  network.dropout = json.dropout;
  network.nodes = [];
  network.connections = [];
  network.groups = [];
  network.layers = [];
  var i;
  for (i = 0; i < json.nodes.length; i++) {
    var node = Node.fromJSON(json.nodes[i]);
    // reconstrct layers and groups
    network.nodes.push(node);
    if (!network.layers[node.layerid]) network.layers[node.layerid]={
      nodes       : [],
      connections : {in:[],out:[]},  // TODO
      input       : [],  // TODO
      output      : {nodes:[],connections:[]},  // TODO
    };
    network.layers[node.layerid].nodes.push(node);
    if (!network.groups[node.layerid]) network.groups[node.layerid]={
      nodes:[],
      connections:[] // TODO
    };
    network.groups[node.layerid].nodes.push(node);
  }

  for (i = 0; i < json.connections.length; i++) {
    var conn = json.connections[i];
    var connection = network.connect(network.nodes[conn.from], network.nodes[conn.to])[0];
    connection.weight = conn.weight;
    if (conn.gater != null) {
      network.gate(network.nodes[conn.gater], connection);
    }
    network.connections.push(connection);
  }
  return network;
};

/**
 * Merge two networks into one
 */
Network.merge = function (network1, network2) {
  // Create a copy of the networks
  network1 = Network.fromJSON(network1.toJSON());
  network2 = Network.fromJSON(network2.toJSON());

  // Check if output and input size are the same
  if (network1.output !== network2.input) {
    throw new Error('Output size of network1 should be the same as the input size of network2!');
  }

  // Redirect all connections from network2 input from network1 output
  var i;
  for (i = 0; i < network2.connections.length; i++) {
    var conn = network2.connections[i];
    if (conn.from.type === 'input') {
      var index = network2.nodes.indexOf(conn.from);

      // redirect
      conn.from = network1.nodes[network1.nodes.length - 1 - index];
    }
  }

  // Delete input nodes of network2
  for (i = network2.input - 1; i >= 0; i--) {
    network2.nodes.splice(i, 1);
  }

  // Change the node type of network1's output nodes (now hidden)
  for (i = network1.nodes.length - network1.output; i < network1.nodes.length; i++) {
    network1.nodes[i].type = 'hidden';
  }

  // Create one network from both networks
  network1.connections = network1.connections.concat(network2.connections);
  network1.nodes = network1.nodes.concat(network2.nodes);

  return network1;
};

/**
 * Create an offspring from two parent networks
 */
Network.crossOver = function (network1, network2, equal) {
  if (network1.input !== network2.input || network1.output !== network2.output) {
    throw new Error("Networks don't have the same input/output size!");
  }

  // Initialise offspring
  var offspring = new Network(network1.input, network1.output);
  offspring.connections = [];
  offspring.nodes = [];

  // Save scores and create a copy
  var score1 = network1.score || 0;
  var score2 = network2.score || 0;

  // Determine offspring node size
  var size;
  if (equal || score1 === score2) {
    var max = Math.max(network1.nodes.length, network2.nodes.length);
    var min = Math.min(network1.nodes.length, network2.nodes.length);
    size = Math.floor(Math.random() * (max - min + 1) + min);
  } else if (score1 > score2) {
    size = network1.nodes.length;
  } else {
    size = network2.nodes.length;
  }

  // Rename some variables for easier reading
  var outputSize = network1.output;

  // Set indexes so we don't need indexOf
  var i;
  for (i = 0; i < network1.nodes.length; i++) {
    network1.nodes[i].index = i;
  }

  for (i = 0; i < network2.nodes.length; i++) {
    network2.nodes[i].index = i;
  }

  // Assign nodes from parents to offspring
  for (i = 0; i < size; i++) {
    // Determine if an output node is needed
    var node;
    if (i < size - outputSize) {
      var random = Math.random();
      node = random >= 0.5 ? network1.nodes[i] : network2.nodes[i];
      var other = random < 0.5 ? network1.nodes[i] : network2.nodes[i];

      if (typeof node === 'undefined' || node.type === 'output') {
        node = other;
      }
    } else {
      if (Math.random() >= 0.5) {
        node = network1.nodes[network1.nodes.length + i - size];
      } else {
        node = network2.nodes[network2.nodes.length + i - size];
      }
    }

    var newNode = new Node();
    newNode.bias = node.bias;
    newNode.squash = node.squash;
    newNode.type = node.type;

    offspring.nodes.push(newNode);
  }

  // Create arrays of connection genes
  var n1conns = {};
  var n2conns = {};

  // Normal connections
  for (i = 0; i < network1.connections.length; i++) {
    var conn = network1.connections[i];
    var data = {
      weight: conn.weight,
      from: conn.from.index,
      to: conn.to.index,
      gater: conn.gater != null ? conn.gater.index : -1
    };
    n1conns[Connection.innovationID(data.from, data.to)] = data;
  }

  // Selfconnections
  for (i = 0; i < network1.selfconns.length; i++) {
    var conn = network1.selfconns[i];
    var data = {
      weight: conn.weight,
      from: conn.from.index,
      to: conn.to.index,
      gater: conn.gater != null ? conn.gater.index : -1
    };
    n1conns[Connection.innovationID(data.from, data.to)] = data;
  }

  // Normal connections
  for (i = 0; i < network2.connections.length; i++) {
    var conn = network2.connections[i];
    var data = {
      weight: conn.weight,
      from: conn.from.index,
      to: conn.to.index,
      gater: conn.gater != null ? conn.gater.index : -1
    };
    n2conns[Connection.innovationID(data.from, data.to)] = data;
  }

  // Selfconnections
  for (i = 0; i < network2.selfconns.length; i++) {
    var conn = network2.selfconns[i];
    var data = {
      weight: conn.weight,
      from: conn.from.index,
      to: conn.to.index,
      gater: conn.gater != null ? conn.gater.index : -1
    };
    n2conns[Connection.innovationID(data.from, data.to)] = data;
  }

  // Split common conn genes from disjoint or excess conn genes
  var connections = [];
  var keys1 = Object.keys(n1conns);
  var keys2 = Object.keys(n2conns);
  for (i = keys1.length - 1; i >= 0; i--) {
    // Common gene
    if (typeof n2conns[keys1[i]] !== 'undefined') {
      var conn = Math.random() >= 0.5 ? n1conns[keys1[i]] : n2conns[keys1[i]];
      connections.push(conn);

      // Because deleting is expensive, just set it to some value
      n2conns[keys1[i]] = undefined;
    } else if (score1 >= score2 || equal) {
      connections.push(n1conns[keys1[i]]);
    }
  }

  // Excess/disjoint gene
  if (score2 >= score1 || equal) {
    for (i = 0; i < keys2.length; i++) {
      if (typeof n2conns[keys2[i]] !== 'undefined') {
        connections.push(n2conns[keys2[i]]);
      }
    }
  }

  // Add common conn genes uniformly
  for (i = 0; i < connections.length; i++) {
    var connData = connections[i];
    if (connData.to < size && connData.from < size) {
      var from = offspring.nodes[connData.from];
      var to = offspring.nodes[connData.to];
      var conn = offspring.connect(from, to)[0];

      conn.weight = connData.weight;

      if (connData.gater !== -1 && connData.gater < size) {
        offspring.gate(offspring.nodes[connData.gater], conn);
      }
    }
  }

  return offspring;
};

/*******************************************************************************
                                        architect
*******************************************************************************/


var architect = {
  /**
   * Constructs a network from a given array of connected nodes
   */
  Construct: function (list) {
    // Create a network
    var network = new Network(0, 0),
        layers=[],
        groups=[];

    // Transform all groups into nodes
    var nodes = [];

    var i;
    for (i = 0; i < list.length; i++) {
      var j;
      if (list[i] instanceof Group) {
        groups.push(list[i]);
        for (j = 0; j < list[i].nodes.length; j++) {
          nodes.push(list[i].nodes[j]);
        }
      } else if (list[i] instanceof Layer) {
        layers.push(list[i]);
        for (j = 0; j < list[i].nodes.length; j++) {
          for (var k = 0; k < list[i].nodes[j].nodes.length; k++) {
            nodes.push(list[i].nodes[j].nodes[k]);
          }
        }
      } else if (list[i] instanceof Node) {
        nodes.push(list[i]);
      }
    }

    // Determine input and output nodes
    var inputs = [];
    var outputs = [];
    for (i = nodes.length - 1; i >= 0; i--) {
      if (nodes[i].type === 'output' || nodes[i].connections.out.length + nodes[i].connections.gated.length === 0) {
        nodes[i].type = 'output';
        network.output++;
        outputs.push(nodes[i]);
        nodes.splice(i, 1);
      } else if (nodes[i].type === 'input' || !nodes[i].connections.in.length) {
        nodes[i].type = 'input';
        network.input++;
        inputs.push(nodes[i]);
        nodes.splice(i, 1);
      }
    }

    // Input nodes are always first, output nodes are always last
    nodes = inputs.concat(nodes).concat(outputs);

    if (network.input === 0 || network.output === 0) {
      throw new Error('Given nodes have no clear input/output node!');
    }

    for (i = 0; i < nodes.length; i++) {
      var j;
      for (j = 0; j < nodes[i].connections.out.length; j++) {
        network.connections.push(nodes[i].connections.out[j]);
      }
      for (j = 0; j < nodes[i].connections.gated.length; j++) {
        network.gates.push(nodes[i].connections.gated[j]);
      }
      if (nodes[i].connections.self.weight !== 0) {
        network.selfconns.push(nodes[i].connections.self);
      }
    }

    network.nodes   = nodes;
    network.layers  = layers;
    network.groups  = groups.map(function (layer) {
      // reverse node order 
      return {nodes:layer.nodes.reverse(),connections:layer.connections,layerid:layer.layerid} 
    });
    return network;
  },

  /**
   * Creates a multilayer perceptron (MLP)
   */
  Perceptron: function () {
    // Convert arguments to Array
    var layers = Array.prototype.slice.call(arguments).filter(function (e) { return e!=null });
    if (layers.length < 3) {
      throw new Error('You have to specify at least 3 layers');
    }

    // Create a list of nodes/groups
    var nodes = [];
    nodes.push(new Group(layers[0],{layerid:0}));
    for (var i = 1; i < layers.length; i++) {
      var layer = layers[i];
      layer = new Group(layer,{layerid:i});
      nodes.push(layer);
      nodes[i - 1].connect(nodes[i], methods.connection.ALL_TO_ALL);
    }

    // Construct the network
    return architect.Construct(nodes);
  },

  /**
   * Creates a randomly connected network
   */
  Random: function (input, hidden, output, options) {
    options = options || {};

    var connections = options.connections || hidden * 2;
    var backconnections = options.backconnections || 0;
    var selfconnections = options.selfconnections || 0;
    var gates = options.gates || 0;

    var network = new Network(input, output);

    var i;
    for (i = 0; i < hidden; i++) {
      network.mutate(methods.mutation.ADD_NODE);
    }

    for (i = 0; i < connections - hidden; i++) {
      network.mutate(methods.mutation.ADD_CONN);
    }

    for (i = 0; i < backconnections; i++) {
      network.mutate(methods.mutation.ADD_BACK_CONN);
    }

    for (i = 0; i < selfconnections; i++) {
      network.mutate(methods.mutation.ADD_SELF_CONN);
    }

    for (i = 0; i < gates; i++) {
      network.mutate(methods.mutation.ADD_GATE);
    }

    return network;
  },

  /**
   * Creates a long short-term memory network
   */
  LSTM: function () {
    var args = Array.prototype.slice.call(arguments);
    if (args.length < 3) {
      throw new Error('You have to specify at least 3 layers');
    }

    var last = args.pop();

    var outputLayer;
    if (typeof last === 'number') {
      outputLayer = new Group(last,{layerid:args.length});
      last = {};
    } else {
      outputLayer = new Group(args.pop(),{layerid:args.length}); // last argument
    }

    outputLayer.set({
      type: 'output'
    });

    var options = {};
    options.memoryToMemory = last.memoryToMemory || false;
    options.outputToMemory = last.outputToMemory || false;
    options.outputToGates = last.outputToGates || false;
    options.inputToOutput = last.inputToOutput === undefined ? true : last.inputToOutput;
    options.inputToDeep = last.inputToDeep === undefined ? true : last.inputToDeep;
    // set all conenction weights to this default value - otherwise a random value is chosen
    options.weight = last.weight;

    var inputLayer = new Group(args.shift(),{layerid:0}); // first argument
    inputLayer.set({
      type: 'input'
    });

    var blocks = args; // all the arguments in the middle

    var nodes = [];
    nodes.push(inputLayer);

    var previous = inputLayer;
    for (var i = 0; i < blocks.length; i++) {
      var block = blocks[i];

      // Init required nodes (in activation order)
      var inputGate = new Group(block,{layerid:i+1});
      var forgetGate = new Group(block,{layerid:i+1});
      var memoryCell = new Group(block,{layerid:i+1});
      var outputGate = new Group(block,{layerid:i+1});
      var outputBlock = i === blocks.length - 1 ? outputLayer : new Group(block,{layerid:i+1});

      inputGate.set({
        bias: 1
      });
      forgetGate.set({
        bias: 1
      });
      outputGate.set({
        bias: 1
      });

      // Connect the input with all the nodes
      var input = previous.connect(memoryCell, methods.connection.ALL_TO_ALL,options.weight);
      previous.connect(inputGate, methods.connection.ALL_TO_ALL,options.weight);
      previous.connect(outputGate, methods.connection.ALL_TO_ALL,options.weight);
      previous.connect(forgetGate, methods.connection.ALL_TO_ALL,options.weight);

      // Set up internal connections
      memoryCell.connect(inputGate, methods.connection.ALL_TO_ALL,options.weight);
      memoryCell.connect(forgetGate, methods.connection.ALL_TO_ALL,options.weight);
      memoryCell.connect(outputGate, methods.connection.ALL_TO_ALL,options.weight);
      var forget = memoryCell.connect(memoryCell, methods.connection.ONE_TO_ONE,options.weight);
      var output = memoryCell.connect(outputBlock, methods.connection.ALL_TO_ALL,options.weight);

      // Set up gates
      inputGate.gate(input, methods.gating.INPUT);
      forgetGate.gate(forget, methods.gating.SELF);
      outputGate.gate(output, methods.gating.OUTPUT);

      // Input to all memory cells
      if (options.inputToDeep && i > 0) {
        var input = inputLayer.connect(memoryCell, methods.connection.ALL_TO_ALL,options.weight);
        inputGate.gate(input, methods.gating.INPUT);
      }

      // Optional connections
      if (options.memoryToMemory) {
        var input = memoryCell.connect(memoryCell, methods.connection.ALL_TO_ELSE,options.weight);
        inputGate.gate(input, methods.gating.INPUT);
      }

      if (options.outputToMemory) {
        var input = outputLayer.connect(memoryCell, methods.connection.ALL_TO_ALL,options.weight);
        inputGate.gate(input, methods.gating.INPUT);
      }

      if (options.outputToGates) {
        outputLayer.connect(inputGate, methods.connection.ALL_TO_ALL,options.weight);
        outputLayer.connect(forgetGate, methods.connection.ALL_TO_ALL,options.weight);
        outputLayer.connect(outputGate, methods.connection.ALL_TO_ALL,options.weight);
      }

      // Add to array
      nodes.push(inputGate);
      nodes.push(forgetGate);
      nodes.push(memoryCell);
      nodes.push(outputGate);
      if (i !== blocks.length - 1) nodes.push(outputBlock);

      previous = outputBlock;
    }

    // input to output direct connection
    if (options.inputToOutput) {
      inputLayer.connect(outputLayer, methods.connection.ALL_TO_ALL,options.weight);
    }

    nodes.push(outputLayer);
    return architect.Construct(nodes);
  },

  /**
   * Creates a gated recurrent unit network
   */
  GRU: function () {
    var args = Array.prototype.slice.call(arguments);
    if (args.length < 3) {
      throw new Error('not enough layers (minimum 3) !!');
    }

    var inputLayer = new Group(args.shift(),{layerid:0}); // first argument
    var outputLayer = new Group(args.pop(),{layerid:args.length}); // last argument
    var blocks = args; // all the arguments in the middle

    var nodes = [];
    nodes.push(inputLayer);

    var previous = inputLayer;
    for (var i = 0; i < blocks.length; i++) {
      var layer = new Layer.GRU(blocks[i],{layerid:i+1});
      previous.connect(layer);
      previous = layer;
      nodes.push(layer);
    }

    previous.connect(outputLayer);
    nodes.push(outputLayer);

    return architect.Construct(nodes);
  },

  /**
   * Creates a hopfield network of the given size
   */
  Hopfield: function (size) {
    var input = new Group(size);
    var output = new Group(size);

    input.connect(output, methods.connection.ALL_TO_ALL);

    input.set({
      type: 'input'
    });
    output.set({
      squash: methods.activation.STEP,
      type: 'output'
    });

    var network = new architect.Construct([input, output]);

    return network;
  },

  /**
   * Creates a NARX network (remember previous inputs/outputs)
   */
  NARX: function (inputSize, hiddenLayers, outputSize, previousInput, previousOutput) {
    if (!Array.isArray(hiddenLayers)) {
      hiddenLayers = [hiddenLayers];
    }

    var nodes = [];

    var input = new Layer.Dense(inputSize);
    var inputMemory = new Layer.Memory(inputSize, previousInput);
    var hidden = [];
    var output = new Layer.Dense(outputSize);
    var outputMemory = new Layer.Memory(outputSize, previousOutput);

    nodes.push(input);
    nodes.push(outputMemory);

    for (var i = 0; i < hiddenLayers.length; i++) {
      var hiddenLayer = new Layer.Dense(hiddenLayers[i]);
      hidden.push(hiddenLayer);
      nodes.push(hiddenLayer);
      if (typeof hidden[i - 1] !== 'undefined') {
        hidden[i - 1].connect(hiddenLayer, methods.connection.ALL_TO_ALL);
      }
    }

    nodes.push(inputMemory);
    nodes.push(output);

    input.connect(hidden[0], methods.connection.ALL_TO_ALL);
    input.connect(inputMemory, methods.connection.ONE_TO_ONE, 1);
    inputMemory.connect(hidden[0], methods.connection.ALL_TO_ALL);
    hidden[hidden.length - 1].connect(output, methods.connection.ALL_TO_ALL);
    output.connect(outputMemory, methods.connection.ONE_TO_ONE, 1);
    outputMemory.connect(hidden[0], methods.connection.ALL_TO_ALL);

    input.set({
      type: 'input'
    });
    output.set({
      type: 'output'
    });

    return architect.Construct(nodes);
  },
  
  // Generic forward ANN
  Network : function () {
    config.groupid=0;
    var args = Array.prototype.slice.call(arguments);
    if (args.length < 2) {
      throw new Error('You have to specify at least 2 layers');
    }
    if (args.length==2) {
      // SLP
      var net = new Network(args[0],args[1]),
          groups = [{nodes:[]},{nodes:[]}];
      net.nodes.forEach(function (node) {
        if (node.type=='input') {
          node.layerid=0;
          groups[0].nodes.push(node);
        } else {
          node.layerid=1;
          groups[1].nodes.push(node);
        }
      });
      net.groups=groups;
      return net;
    } else return new architect.Perceptron(args[0],args[1],args[2],args[3],args[4],args[5],
                                           args[6],args[7],args[8],args[9]);
  },
  /*
    Construct mixed layer network:  
    typeof @options = {
       architect : string [] // Dense LSTM ...
       layers : number []  // number of nodes
       .. more options
     }
  */
  Layers : function (options) {
    var layers = [];
    var inputLayer,prevLay;
    for(var i in options.architect) {
      var layA=options.architect[i],
          layN=options.layers[i];
      if (!Layer[layA]) throw "ANN.Layer: invalid layer architect "+layA;
      var lay;
      if (layA=='LSTM') 
        lay = new Layer[layA](layN,
                              options,
                              inputLayer && inputLayer!=prevLay?inputLayer:null /* for inputToDeep*/,
                              null /* outputLayer ?*/);
      else
        lay = new Layer[layA](layN,options);
      if (layA=='Dense') inputLayer=lay;
      prevLay=lay;
      layers.push(lay);
    }
    for(var i in options.architect) {
      i=Number(i);
      var layA=options.architect[i],
          layN=options.layers[i],
          lay=layers[i];
      // handle some layer-to-layer connect options
      if (layA=='LSTM') {
        // input to output direct connection
        if (options.inputToOutput) { 
          var inputLayer=null,
              outputLayer=null;
          // search dense layers backward and forward
          if (options.architect[i-1]=='Dense') inputLayer=layers[i-1];
          if (inputLayer) for(var j=i+1;j<options.architect.length;j++) {
            if (options.architect[j]=='Dense') {
              outputLayer=layers[j];
              break;
            }
          }
          if (inputLayer && outputLayer) {
            console.log('inputToOutput')
            inputLayer.connect(outputLayer, methods.connection.ALL_TO_ALL,options.weight);
          }
        }
      }
    }
    prevLay=null;
    for(var i in options.architect) {
      var layA=options.architect[i],
          layN=options.layers[i],
          lay=layers[i];
      if (prevLay) prevLay.connect(lay); 
      prevLay=lay;
    }
    return layers;  
  }
  
};




/*******************************************************************************
                                         NODE
*******************************************************************************/

function Node (type,options) {
  this.bias = (type === 'input') ? 0 : Math.random() * 0.2 - 0.1;
  this.squash = methods.activation.LOGISTIC;
  this.type = type || 'hidden';

  this.activation = 0;
  this.state = 0;
  this.old = 0;
  this.update = 0; // activation update cpunter / time stamp
  if (options && options.layerid != undefined) this.layerid=options.layerid;
  if (options && options.group) this.group=options.group;
  // For dropout
  this.mask = 1;

  // For tracking momentum
  this.previousDeltaBias = 0;

  // Batch training
  this.totalDeltaBias = 0;

  this.connections = {
    in: [],
    out: [],
    gated: [],
    self: new Connection(this, this, 0)
  };

  // Data for backpropagation
  this.error = {
    responsibility: 0,
    projected: 0,
    gated: 0
  };
}

Node.prototype = {
  /**
   * Activates the node
   */
  preactivate : function () {
    // Precompute the activation state without changing the state of the node actually!
    // required for group activation (softmax)
    // All activation sources coming from the node itself
    var state = this.connections.self.gain * this.connections.self.weight * this.state + this.bias;

    // Activation sources coming from connections
    var i;
    for (i = 0; i < this.connections.in.length; i++) {
      var connection = this.connections.in[i];
      state += connection.from.activation * connection.weight * connection.gain;
    }

    return state;
  },
  
  activate: function (input) {
    // Check if an input is given
    if (typeof input !== 'undefined') {
      this.activation = input;
      return this.activation;
    }

    this.old = this.state;

    var newstate = this.preactivate();
    
    // All activation sources coming from the node itself
    //this.state = this.connections.self.gain * this.connections.self.weight * this.state + this.bias;

    // Activation sources coming from connections
    //var i;
    //for (i = 0; i < this.connections.in.length; i++) {
    //  var connection = this.connections.in[i];
    //  this.state += connection.from.activation * connection.weight * connection.gain;
    //}

    // Squash the values received
    // The softmax function (group function) reqires entire layer group access to computer this activation!
    this.activation = this.squash(newstate, false, this.group) * this.mask;
    this.derivative = this.squash(newstate, true,  this.group);

    this.state = newstate;
    this.update++;
    
    // Update traces
    var nodes = [];
    var influences = [];

    for (i = 0; i < this.connections.gated.length; i++) {
      var conn = this.connections.gated[i];
      var node = conn.to;

      var index = nodes.indexOf(node);
      if (index > -1) {
        influences[index] += conn.weight * conn.from.activation;
      } else {
        nodes.push(node);
        influences.push(conn.weight * conn.from.activation +
          (node.connections.self.gater === this ? node.old : 0));
      }

      // Adjust the gain to this nodes' activation
      conn.gain = this.activation;
    }

    for (i = 0; i < this.connections.in.length; i++) {
      var connection = this.connections.in[i];

      // Elegibility trace
      connection.elegibility = this.connections.self.gain * this.connections.self.weight *
        connection.elegibility + connection.from.activation * connection.gain;

      // Extended trace
      for (var j = 0; j < nodes.length; j++) {
        var node = nodes[j];
        var influence = influences[j];

        var index = connection.xtrace.nodes.indexOf(node);

        if (index > -1) {
          connection.xtrace.values[index] = node.connections.self.gain * node.connections.self.weight *
            connection.xtrace.values[index] + this.derivative * connection.elegibility * influence;
        } else {
          // Does not exist there yet, might be through mutation
          connection.xtrace.nodes.push(node);
          connection.xtrace.values.push(this.derivative * connection.elegibility * influence);
        }
      }
    }

    return this.activation;
  },

  /**
   * Activates the node without calculating elegibility traces and such
   */
  noTraceActivate: function (input) {
    // Check if an input is given
    if (typeof input !== 'undefined') {
      this.activation = input;
      return this.activation;
    }

    // All activation sources coming from the node itself
    this.state = this.connections.self.gain * this.connections.self.weight * this.state + this.bias;

    // Activation sources coming from connections
    var i;
    for (i = 0; i < this.connections.in.length; i++) {
      var connection = this.connections.in[i];
      this.state += connection.from.activation * connection.weight * connection.gain;
    }

    // Squash the values received
    this.activation = this.squash(this.state);

    for (i = 0; i < this.connections.gated.length; i++) {
      this.connections.gated[i].gain = this.activation;
    }

    return this.activation;
  },

  /**
   * Back-propagate the error, aka learn
   */
  propagate: function (rate, momentum, update, target) {
    momentum = momentum || 0;
    rate = rate || 0.3;

    // Error accumulator
    var error = 0;

    // Output nodes get their error from the enviroment
    if (this.type === 'output') {
      this.error.responsibility = this.error.projected = target - this.activation;
    } else { // the rest of the nodes compute their error responsibilities by backpropagation
      // error responsibilities from all the connections projected from this node
      var i;
      for (i = 0; i < this.connections.out.length; i++) {
        var connection = this.connections.out[i];
        var node = connection.to;
        // Eq. 21
        error += node.error.responsibility * connection.weight * connection.gain;
      }

      // Projected error responsibility
      this.error.projected = this.derivative * error;

      // Error responsibilities from all connections gated by this neuron
      error = 0;

      for (i = 0; i < this.connections.gated.length; i++) {
        var conn = this.connections.gated[i];
        var node = conn.to;
        var influence = node.connections.self.gater === this ? node.old : 0;

        influence += conn.weight * conn.from.activation;
        error += node.error.responsibility * influence;
      }

      // Gated error responsibility
      this.error.gated = this.derivative * error;

      // Error responsibility
      this.error.responsibility = this.error.projected + this.error.gated;
    }

    if (this.type === 'constant') return;

    // Adjust all the node's incoming connections
    for (i = 0; i < this.connections.in.length; i++) {
      var connection = this.connections.in[i];

      var gradient = this.error.projected * connection.elegibility;

      for (var j = 0; j < connection.xtrace.nodes.length; j++) {
        var node = connection.xtrace.nodes[j];
        var value = connection.xtrace.values[j];
        gradient += node.error.responsibility * value;
      }

      // Adjust weight
      var deltaWeight = rate * gradient * this.mask;
      connection.totalDeltaWeight += deltaWeight;
      if (update) {
        connection.totalDeltaWeight += momentum * connection.previousDeltaWeight;
        connection.weight += connection.totalDeltaWeight;
        connection.previousDeltaWeight = connection.totalDeltaWeight;
        connection.totalDeltaWeight = 0;
      }
    }

    // Adjust bias
    var deltaBias = rate * this.error.responsibility;
    this.totalDeltaBias += deltaBias;
    if (update) {
      this.totalDeltaBias += momentum * this.previousDeltaBias;
      this.bias += this.totalDeltaBias;
      this.previousDeltaBias = this.totalDeltaBias;
      this.totalDeltaBias = 0;
    }
  },

  /**
   * Creates a connection from this node to the given node
   */
  connect: function (target, weight) {
    var connections = [];
    if (typeof target.bias !== 'undefined') { // must be a node!
      if (target === this) {
        // Turn on the self connection by setting the weight
        if (this.connections.self.weight !== 0) {
          if (config.warnings) console.warn('This connection already exists!');
        } else {
          this.connections.self.weight = weight || 1;
        }
        connections.push(this.connections.self);
      } else if (this.isProjectingTo(target)) {
        throw new Error('Already projecting a connection to this node!');
      } else {
        var connection = new Connection(this, target, weight);
        target.connections.in.push(connection);
        this.connections.out.push(connection);

        connections.push(connection);
      }
    } else { // should be a group
      for (var i = 0; i < target.nodes.length; i++) {
        var connection = new Connection(this, target.nodes[i], weight);
        target.nodes[i].connections.in.push(connection);
        this.connections.out.push(connection);
        target.connections.in.push(connection);

        connections.push(connection);
      }
    }
    return connections;
  },

  /**
   * Disconnects this node from the other node
   */
  disconnect: function (node, twosided) {
    if (this === node) {
      this.connections.self.weight = 0;
      return;
    }

    for (var i = 0; i < this.connections.out.length; i++) {
      var conn = this.connections.out[i];
      if (conn.to === node) {
        this.connections.out.splice(i, 1);
        var j = conn.to.connections.in.indexOf(conn);
        conn.to.connections.in.splice(j, 1);
        if (conn.gater !== null) conn.gater.ungate(conn);
        break;
      }
    }

    if (twosided) {
      node.disconnect(this);
    }
  },

  /**
   * Make this node gate a connection
   */
  gate: function (connections) {
    if (!Array.isArray(connections)) {
      connections = [connections];
    }

    for (var i = 0; i < connections.length; i++) {
      var connection = connections[i];

      this.connections.gated.push(connection);
      connection.gater = this;
    }
  },

  /**
   * Removes the gates from this node from the given connection(s)
   */
  ungate: function (connections) {
    if (!Array.isArray(connections)) {
      connections = [connections];
    }

    for (var i = connections.length - 1; i >= 0; i--) {
      var connection = connections[i];

      var index = this.connections.gated.indexOf(connection);
      this.connections.gated.splice(index, 1);
      connection.gater = null;
      connection.gain = 1;
    }
  },

  /**
   * Clear the context of the node
   */
  clear: function () {
    for (var i = 0; i < this.connections.in.length; i++) {
      var connection = this.connections.in[i];

      connection.elegibility = 0;
      connection.xtrace = {
        nodes: [],
        values: []
      };
    }

    for (i = 0; i < this.connections.gated.length; i++) {
      var conn = this.connections.gated[i];
      conn.gain = 0;
    }

    this.error.responsibility = this.error.projected = this.error.gated = 0;
    this.old = this.state = this.activation = 0;
  },

  /**
   * Mutates the node with the given method
   */
  mutate: function (method) {
    if (typeof method === 'undefined') {
      throw new Error('No mutate method given!');
    } else if (!(method.name in methods.mutation)) {
      throw new Error('This method does not exist!');
    }

    switch (method) {
      case methods.mutation.MOD_ACTIVATION:
        // Can't be the same squash
        var squash = method.allowed[(method.allowed.indexOf(this.squash) + Math.floor(Math.random() * (method.allowed.length - 1)) + 1) % method.allowed.length];
        this.squash = squash;
        break;
      case methods.mutation.MOD_BIAS:
        var modification = Math.random() * (method.max - method.min) + method.min;
        this.bias += modification;
        break;
    }
  },

  /**
   * Checks if this node is projecting to the given node
   */
  isProjectingTo: function (node) {
    if (node === this && this.connections.self.weight !== 0) return true;

    for (var i = 0; i < this.connections.out.length; i++) {
      var conn = this.connections.out[i];
      if (conn.to === node) {
        return true;
      }
    }
    return false;
  },

  /**
   * Checks if the given node is projecting to this node
   */
  isProjectedBy: function (node) {
    if (node === this && this.connections.self.weight !== 0) return true;

    for (var i = 0; i < this.connections.in.length; i++) {
      var conn = this.connections.in[i];
      if (conn.from === node) {
        return true;
      }
    }

    return false;
  },

  /**
   * Converts the node to a json object
   */
  toJSON: function () {
    var json = {
      bias: this.bias,
      type: this.type,
      squash: this.squash.name,
      layerid : this.layerid,
      groupid : this.group && this.group.id,
      mask: this.mask
    };

    return json;
  }
};

/**
 * Convert a json object to a node
 */
Node.fromJSON = function (json) {
  var node = new Node();
  node.bias = json.bias;
  node.type = json.type;
  node.mask = json.mask;
  node.layerid = json.layerid;
  node.squash = methods.activation[json.squash];
  node.groupid = json.groupid; // TODO recreate node.group=Group() for all nodes with groupid
  return node;
};

/*******************************************************************************
                                         Group
*******************************************************************************/

function Layer () {
  this.output = null;

  this.nodes = [];
  this.connections = { in: [],
    out: [],
    self: []
  };
}

Layer.prototype = {
  /**
   * Activates all the nodes in the group
   */
  activate: function (value) {
    var values = [];

    if (typeof value !== 'undefined' && value.length !== this.nodes.length) {
      throw new Error('Array with values should be same as the amount of nodes!');
    }

    for (var i = 0; i < this.nodes.length; i++) {
      var activation;
      if (typeof value === 'undefined') {
        activation = this.nodes[i].activate();
      } else {
        activation = this.nodes[i].activate(value[i]);
      }

      values.push(activation);
    }

    return values;
  },

  /**
   * Propagates all the node in the group
   */
  propagate: function (rate, momentum, target) {
    if (typeof target !== 'undefined' && target.length !== this.nodes.length) {
      throw new Error('Array with values should be same as the amount of nodes!');
    }

    for (var i = this.nodes.length - 1; i >= 0; i--) {
      if (typeof target === 'undefined') {
        this.nodes[i].propagate(rate, momentum, true);
      } else {
        this.nodes[i].propagate(rate, momentum, true, target[i]);
      }
    }
  },

  /**
   * Connects the nodes in this group to nodes in another group or just a node
   */
  connect: function (target, method, weight) {
    var connections;
    if (target instanceof Group || target instanceof Node) {
      connections = this.output.connect(target, method, weight);
    } else if (target instanceof Layer) {
      connections = target.input(this, method, weight);
    }

    return connections;
  },

  /**
   * Make nodes from this group gate the given connection(s)
   */
  gate: function (connections, method) {
    this.output.gate(connections, method);
  },

  /**
   * Sets the value of a property for every node
   */
  set: function (values) {
    for (var i = 0; i < this.nodes.length; i++) {
      var node = this.nodes[i];

      if (node instanceof Node) {
        if (typeof values.bias !== 'undefined') {
          node.bias = values.bias;
        }

        node.squash = values.squash || node.squash;
        node.type = values.type || node.type;
      } else if (node instanceof Group) {
        node.set(values);
      }
    }
  },

  /**
   * Disconnects all nodes from this group from another given group/node
   */
  disconnect: function (target, twosided) {
    twosided = twosided || false;

    // In the future, disconnect will return a connection so indexOf can be used
    var i, j, k;
    if (target instanceof Group) {
      for (i = 0; i < this.nodes.length; i++) {
        for (j = 0; j < target.nodes.length; j++) {
          this.nodes[i].disconnect(target.nodes[j], twosided);

          for (k = this.connections.out.length - 1; k >= 0; k--) {
            var conn = this.connections.out[k];

            if (conn.from === this.nodes[i] && conn.to === target.nodes[j]) {
              this.connections.out.splice(k, 1);
              break;
            }
          }

          if (twosided) {
            for (k = this.connections.in.length - 1; k >= 0; k--) {
              var conn = this.connections.in[k];

              if (conn.from === target.nodes[j] && conn.to === this.nodes[i]) {
                this.connections.in.splice(k, 1);
                break;
              }
            }
          }
        }
      }
    } else if (target instanceof Node) {
      for (i = 0; i < this.nodes.length; i++) {
        this.nodes[i].disconnect(target, twosided);

        for (j = this.connections.out.length - 1; j >= 0; j--) {
          var conn = this.connections.out[j];

          if (conn.from === this.nodes[i] && conn.to === target) {
            this.connections.out.splice(j, 1);
            break;
          }
        }

        if (twosided) {
          for (k = this.connections.in.length - 1; k >= 0; k--) {
            var conn = this.connections.in[k];

            if (conn.from === target && conn.to === this.nodes[i]) {
              this.connections.in.splice(k, 1);
              break;
            }
          }
        }
      }
    }
  },

  /**
   * Clear the context of this group
   */
  clear: function () {
    for (var i = 0; i < this.nodes.length; i++) {
      this.nodes[i].clear();
    }
  }
};

Layer.Dense = function (size) {
  // Create the layer
  var layer = new Layer();

  // Init required nodes (in activation order)
  var block = new Group(size);

  layer.nodes.push(block);
  layer.output = block;

  layer.input = function (from, method, weight) {
    if (from instanceof Layer) from = from.output;
    method = method || methods.connection.ALL_TO_ALL;
    return from.connect(block, method, weight);
  };

  return layer;
};

Layer.LSTM = function (size,options,inputLayer,outputLayer) {
  options=options||{}
  // Create the layer
  var layer = new Layer();

  // Init required nodes (in activation order)
  var inputGate = new Group(size);
  var forgetGate = new Group(size);
  var memoryCell = new Group(size);
  var outputGate = new Group(size);
  var outputBlock = new Group(size);

  inputGate.set({
    bias: 1
  });
  forgetGate.set({
    bias: 1
  });
  outputGate.set({
    bias: 1
  });

  // Set up internal connections
  memoryCell.connect(inputGate, methods.connection.ALL_TO_ALL);
  memoryCell.connect(forgetGate, methods.connection.ALL_TO_ALL);
  memoryCell.connect(outputGate, methods.connection.ALL_TO_ALL);
  var forget = memoryCell.connect(memoryCell, methods.connection.ONE_TO_ONE);
  var output = memoryCell.connect(outputBlock, methods.connection.ALL_TO_ALL);

  // Set up gates
  forgetGate.gate(forget, methods.gating.SELF);
  outputGate.gate(output, methods.gating.OUTPUT);

  // Add to nodes array
  layer.nodes = [inputGate, forgetGate, memoryCell, outputGate, outputBlock];

  // Define output
  layer.output = outputBlock;

  layer.input = function (from, method, weight) {
    if (from instanceof Layer) from = from.output;
    method = method || methods.connection.ALL_TO_ALL;
    var connections = [];

    var input = from.connect(memoryCell, method, weight);
    connections = connections.concat(input);

    connections = connections.concat(from.connect(inputGate, method, weight));
    connections = connections.concat(from.connect(outputGate, method, weight));
    connections = connections.concat(from.connect(forgetGate, method, weight));

    inputGate.gate(input, methods.gating.INPUT);

    return connections;
  };

  // @blab TODO TBC Optional connections
  // Input to all memory cells
  if (inputLayer && options.inputToDeep) {
    console.log('inputToDeep')
    var input = inputLayer.connect(memoryCell, methods.connection.ALL_TO_ALL,options.weight);
    inputGate.gate(input, methods.gating.INPUT);
  }
  // Optional connections
  if (options.memoryToMemory) {
    console.log('memoryToMemory')
    var input = memoryCell.connect(memoryCell, methods.connection.ALL_TO_ELSE,options.weight);
    inputGate.gate(input, methods.gating.INPUT);
  }
  if (options.outputToMemory) {
    console.log('outputToMemory')
    var input = outputLayer.connect(memoryCell, methods.connection.ALL_TO_ALL,options.weight);
    inputGate.gate(input, methods.gating.INPUT);
  }
  if (outputLayer && options.outputToGates) {
    console.log('outputToGates')
    outputLayer.connect(inputGate, methods.connection.ALL_TO_ALL,options.weight);
    outputLayer.connect(forgetGate, methods.connection.ALL_TO_ALL,options.weight);
    outputLayer.connect(outputGate, methods.connection.ALL_TO_ALL,options.weight);
  }

  return layer;
};

Layer.GRU = function (size,options) {
  // Create the layer
  var layer = new Layer();
  var layerid = options && options.layerid;
  var updateGate = new Group(size,layerid!=undefined?{layerid:layerid}:{});
  var inverseUpdateGate = new Group(size,layerid!=undefined?{layerid:layerid}:{});
  var resetGate = new Group(size,layerid!=undefined?{layerid:layerid}:{});
  var memoryCell = new Group(size,layerid!=undefined?{layerid:layerid}:{});
  var output = new Group(size,layerid!=undefined?{layerid:layerid}:{});
  var previousOutput = new Group(size,layerid!=undefined?{layerid:layerid}:{});

  previousOutput.set({
    bias: 0,
    squash: methods.activation.IDENTITY,
    type: 'constant'
  });
  memoryCell.set({
    squash: methods.activation.TANH
  });
  inverseUpdateGate.set({
    bias: 0,
    squash: methods.activation.INVERSE,
    type: 'constant'
  });
  updateGate.set({
    bias: 1
  });
  resetGate.set({
    bias: 0
  });

  // Update gate calculation
  previousOutput.connect(updateGate, methods.connection.ALL_TO_ALL);

  // Inverse update gate calculation
  updateGate.connect(inverseUpdateGate, methods.connection.ONE_TO_ONE, 1);

  // Reset gate calculation
  previousOutput.connect(resetGate, methods.connection.ALL_TO_ALL);

  // Memory calculation
  var reset = previousOutput.connect(memoryCell, methods.connection.ALL_TO_ALL);

  resetGate.gate(reset, methods.gating.OUTPUT); // gate

  // Output calculation
  var update1 = previousOutput.connect(output, methods.connection.ALL_TO_ALL);
  var update2 = memoryCell.connect(output, methods.connection.ALL_TO_ALL);

  updateGate.gate(update1, methods.gating.OUTPUT);
  inverseUpdateGate.gate(update2, methods.gating.OUTPUT);

  // Previous output calculation
  output.connect(previousOutput, methods.connection.ONE_TO_ONE, 1);

  // Add to nodes array
  layer.nodes = [updateGate, inverseUpdateGate, resetGate, memoryCell, output, previousOutput];

  layer.output = output;

  layer.input = function (from, method, weight) {
    if (from instanceof Layer) from = from.output;
    method = method || methods.connection.ALL_TO_ALL;
    var connections = [];

    connections = connections.concat(from.connect(updateGate, method, weight));
    connections = connections.concat(from.connect(resetGate, method, weight));
    connections = connections.concat(from.connect(memoryCell, method, weight));

    return connections;
  };

  return layer;
};

Layer.Memory = function (size, memory) {
  // Create the layer
  var layer = new Layer();
  // Because the output can only be one group, we have to put the nodes all in óne group

  var previous = null;
  var i;
  for (i = 0; i < memory; i++) {
    var block = new Group(size);

    block.set({
      squash: methods.activation.IDENTITY,
      bias: 0,
      type: 'constant'
    });

    if (previous != null) {
      previous.connect(block, methods.connection.ONE_TO_ONE, 1);
    }

    layer.nodes.push(block);
    previous = block;
  }

  layer.nodes.reverse();

  for (i = 0; i < layer.nodes.length; i++) {
    layer.nodes[i].nodes.reverse();
  }

  // Because output can only be óne group, fit all memory nodes in óne group
  var outputGroup = new Group(0);
  for (var group in layer.nodes) {
    outputGroup.nodes = outputGroup.nodes.concat(layer.nodes[group].nodes);
  }
  layer.output = outputGroup;

  layer.input = function (from, method, weight) {
    if (from instanceof Layer) from = from.output;
    method = method || methods.connection.ALL_TO_ALL;

    if (from.nodes.length !== layer.nodes[layer.nodes.length - 1].nodes.length) {
      throw new Error('Previous layer size must be same as memory size');
    }

    return from.connect(layer.nodes[layer.nodes.length - 1], methods.connection.ONE_TO_ONE, 1);
  };

  return layer;
};


/*******************************************************************************
                                         Group
*******************************************************************************/

function Group (size,options) {
  this.nodes = [];
  this.connections = {
    in: [],
    out: [],
    self: []
  };
  this.id=config.groupId++;
  if (options && options.layerid!=undefined) this.layerid=options.layerid;
  for (var i = 0; i < size; i++) {
    var node = new Node(null,this.layerid!=undefined?{layerid:this.layerid,group:this}:{group:this});
    this.nodes.push(node);
  }
}

Group.prototype = {
  /**
   * Activates all the nodes in the group
   */
  activate: function (value) {
    var values = [];

    if (typeof value !== 'undefined' && value.length !== this.nodes.length) {
      throw new Error('Array with values should be same as the amount of nodes!');
    }

    for (var i = 0; i < this.nodes.length; i++) {
      var activation;
      if (typeof value === 'undefined') {
        activation = this.nodes[i].activate();
      } else {
        activation = this.nodes[i].activate(value[i]);
      }

      values.push(activation);
    }

    return values;
  },

  /**
   * Propagates all the node in the group
   */
  propagate: function (rate, momentum, target) {
    if (typeof target !== 'undefined' && target.length !== this.nodes.length) {
      throw new Error('Array with values should be same as the amount of nodes!');
    }

    for (var i = this.nodes.length - 1; i >= 0; i--) {
      if (typeof target === 'undefined') {
        this.nodes[i].propagate(rate, momentum, true);
      } else {
        this.nodes[i].propagate(rate, momentum, true, target[i]);
      }
    }
  },

  /**
   * Connects the nodes in this group to nodes in another group or just a node
   */
  connect: function (target, method, weight) {
    var connections = [];
    var i, j;
    if (target instanceof Group) {
      if (typeof method === 'undefined') {
        if (this !== target) {
          if (config.warnings) console.warn('No group connection specified, using ALL_TO_ALL');
          method = methods.connection.ALL_TO_ALL;
        } else {
          if (config.warnings) console.warn('No group connection specified, using ONE_TO_ONE');
          method = methods.connection.ONE_TO_ONE;
        }
      }
      if (method === methods.connection.ALL_TO_ALL || method === methods.connection.ALL_TO_ELSE) {
        for (i = 0; i < this.nodes.length; i++) {
          for (j = 0; j < target.nodes.length; j++) {
            if (method === methods.connection.ALL_TO_ELSE && this.nodes[i] === target.nodes[j]) continue;
            var connection = this.nodes[i].connect(target.nodes[j], weight);
            this.connections.out.push(connection[0]);
            target.connections.in.push(connection[0]);
            connections.push(connection[0]);
          }
        }
      } else if (method === methods.connection.ONE_TO_ONE) {
        if (this.nodes.length !== target.nodes.length) {
          throw new Error('From and To group must be the same size!');
        }

        for (i = 0; i < this.nodes.length; i++) {
          var connection = this.nodes[i].connect(target.nodes[i], weight);
          this.connections.self.push(connection[0]);
          connections.push(connection[0]);
        }
      }
    } else if (target instanceof Layer) {
      connections = target.input(this, method, weight);
    } else if (target instanceof Node) {
      for (i = 0; i < this.nodes.length; i++) {
        var connection = this.nodes[i].connect(target, weight);
        this.connections.out.push(connection[0]);
        connections.push(connection[0]);
      }
    }

    return connections;
  },

  /**
   * Make nodes from this group gate the given connection(s)
   */
  gate: function (connections, method) {
    if (typeof method === 'undefined') {
      throw new Error('Please specify Gating.INPUT, Gating.OUTPUT');
    }

    if (!Array.isArray(connections)) {
      connections = [connections];
    }

    var nodes1 = [];
    var nodes2 = [];

    var i, j;
    for (i = 0; i < connections.length; i++) {
      var connection = connections[i];
      if (!nodes1.includes(connection.from)) nodes1.push(connection.from);
      if (!nodes2.includes(connection.to)) nodes2.push(connection.to);
    }

    switch (method) {
      case methods.gating.INPUT:
        for (i = 0; i < nodes2.length; i++) {
          var node = nodes2[i];
          var gater = this.nodes[i % this.nodes.length];

          for (j = 0; j < node.connections.in.length; j++) {
            var conn = node.connections.in[j];
            if (connections.includes(conn)) {
              gater.gate(conn);
            }
          }
        }
        break;
      case methods.gating.OUTPUT:
        for (i = 0; i < nodes1.length; i++) {
          var node = nodes1[i];
          var gater = this.nodes[i % this.nodes.length];

          for (j = 0; j < node.connections.out.length; j++) {
            var conn = node.connections.out[j];
            if (connections.includes(conn)) {
              gater.gate(conn);
            }
          }
        }
        break;
      case methods.gating.SELF:
        for (i = 0; i < nodes1.length; i++) {
          var node = nodes1[i];
          var gater = this.nodes[i % this.nodes.length];

          if (connections.includes(node.connections.self)) {
            gater.gate(node.connections.self);
          }
        }
    }
  },

  /**
   * Sets the value of a property for every node
   */
  set: function (values) {
    for (var i = 0; i < this.nodes.length; i++) {
      if (typeof values.bias !== 'undefined') {
        this.nodes[i].bias = values.bias;
      }

      this.nodes[i].squash = values.squash || this.nodes[i].squash;
      this.nodes[i].type = values.type || this.nodes[i].type;
    }
  },

  /**
   * Disconnects all nodes from this group from another given group/node
   */
  disconnect: function (target, twosided) {
    twosided = twosided || false;

    // In the future, disconnect will return a connection so indexOf can be used
    var i, j, k;
    if (target instanceof Group) {
      for (i = 0; i < this.nodes.length; i++) {
        for (j = 0; j < target.nodes.length; j++) {
          this.nodes[i].disconnect(target.nodes[j], twosided);

          for (k = this.connections.out.length - 1; k >= 0; k--) {
            var conn = this.connections.out[k];

            if (conn.from === this.nodes[i] && conn.to === target.nodes[j]) {
              this.connections.out.splice(k, 1);
              break;
            }
          }

          if (twosided) {
            for (k = this.connections.in.length - 1; k >= 0; k--) {
              var conn = this.connections.in[k];

              if (conn.from === target.nodes[j] && conn.to === this.nodes[i]) {
                this.connections.in.splice(k, 1);
                break;
              }
            }
          }
        }
      }
    } else if (target instanceof Node) {
      for (i = 0; i < this.nodes.length; i++) {
        this.nodes[i].disconnect(target, twosided);

        for (j = this.connections.out.length - 1; j >= 0; j--) {
          var conn = this.connections.out[j];

          if (conn.from === this.nodes[i] && conn.to === target) {
            this.connections.out.splice(j, 1);
            break;
          }
        }

        if (twosided) {
          for (j = this.connections.in.length - 1; j >= 0; j--) {
            var conn = this.connections.in[j];

            if (conn.from === target && conn.to === this.nodes[i]) {
              this.connections.in.splice(j, 1);
              break;
            }
          }
        }
      }
    }
  },

  /**
   * Clear the context of this group
   */
  clear: function () {
    for (var i = 0; i < this.nodes.length; i++) {
      this.nodes[i].clear();
    }
  }
};

/* Easier variable naming */
var selection = methods.selection;

/*******************************************************************************
                                         NEAT
*******************************************************************************/

function Neat (input, output, fitness, options) {
  this.input = input; // The input size of the networks
  this.output = output; // The output size of the networks
  this.fitness = fitness; // The fitness function to evaluate the networks

  // Configure options
  options = options || {};
  this.equal = options.equal || false;
  this.clear = options.clear || false;
  this.popsize = options.popsize || 50;
  this.elitism = options.elitism || 0;
  this.provenance = options.provenance || 0;
  this.mutationRate = options.mutationRate || 0.3;
  this.mutationAmount = options.mutationAmount || 1;

  this.fitnessPopulation = options.fitnessPopulation || false;

  this.selection = options.selection || methods.selection.POWER;
  this.crossover = options.crossover || [
    methods.crossover.SINGLE_POINT,
    methods.crossover.TWO_POINT,
    methods.crossover.UNIFORM,
    methods.crossover.AVERAGE
  ];
  this.mutation = options.mutation || methods.mutation.FFW;

  this.template = options.network || false;

  this.maxNodes = options.maxNodes || Infinity;
  this.maxConns = options.maxConns || Infinity;
  this.maxGates = options.maxGates || Infinity;

  // Custom mutation selection function if given
  this.selectMutationMethod = typeof options.mutationSelection === 'function' ? options.mutationSelection.bind(this) : this.selectMutationMethod;

  // Generation counter
  this.generation = 0;

  // Initialise the genomes
  this.createPool(this.template);
}

Neat.prototype = {
  /**
   * Create the initial pool of genomes
   */
  createPool: function (network) {
    this.population = [];

    for (var i = 0; i < this.popsize; i++) {
      var copy;
      if (this.template) {
        copy = Network.fromJSON(network.toJSON());
      } else {
        copy = new Network(this.input, this.output);
      }
      copy.score = undefined;
      this.population.push(copy);
    }
  },

  /**
   * Evaluates, selects, breeds and mutates population
   */
  evolve: function () {
    // Check if evaluated, sort the population
    if (typeof this.population[this.population.length - 1].score === 'undefined') {
      this.evaluate();
    }
    this.sort();

    var fittest = Network.fromJSON(this.population[0].toJSON());
    fittest.score = this.population[0].score;

    var newPopulation = [];

    // Elitism
    var elitists = [];
    for (var i = 0; i < this.elitism; i++) {
      elitists.push(this.population[i]);
    }

    // Provenance
    for (i = 0; i < this.provenance; i++) {
      newPopulation.push(Network.fromJSON(this.template.toJSON()));
    }

    // Breed the next individuals
    for (i = 0; i < this.popsize - this.elitism - this.provenance; i++) {
      newPopulation.push(this.getOffspring());
    }

    // Replace the old population with the new population
    this.population = newPopulation;
    this.mutate();

    // this.population.push(...elitists);
    var _this$population;
    (_this$population = this.population).push.apply(_this$population, elitists); 

    // Reset the scores
    for (i = 0; i < this.population.length; i++) {
      this.population[i].score = undefined;
    }

    this.generation++;

    return fittest;
  },

  /**
   * Breeds two parents into an offspring, population MUST be surted
   */
  getOffspring: function () {
    var parent1 = this.getParent();
    var parent2 = this.getParent();

    return Network.crossOver(parent1, parent2, this.equal);
  },

  /**
   * Selects a random mutation method for a genome according to the parameters
   */
  selectMutationMethod: function (genome) {
    var mutationMethod = this.mutation[Math.floor(Math.random() * this.mutation.length)];

    if (mutationMethod === methods.mutation.ADD_NODE && genome.nodes.length >= this.maxNodes) {
      if (config.warnings) console.warn('maxNodes exceeded!');
      return;
    }

    if (mutationMethod === methods.mutation.ADD_CONN && genome.connections.length >= this.maxConns) {
      if (config.warnings) console.warn('maxConns exceeded!');
      return;
    }

    if (mutationMethod === methods.mutation.ADD_GATE && genome.gates.length >= this.maxGates) {
      if (config.warnings) console.warn('maxGates exceeded!');
      return;
    }

    return mutationMethod;
  },

  /**
   * Mutates the given (or current) population
   */
  mutate: function () {
    // Elitist genomes should not be included
    for (var i = 0; i < this.population.length; i++) {
      if (Math.random() <= this.mutationRate) {
        for (var j = 0; j < this.mutationAmount; j++) {
          var mutationMethod = this.selectMutationMethod(this.population[i]);
          this.population[i].mutate(mutationMethod);
        }
      }
    }
  },

  /**
   * Evaluates the current population
   */
  evaluate: function () {
    var i;
    if (this.fitnessPopulation) {
      if (this.clear) {
        for (i = 0; i < this.population.length; i++) {
          this.population[i].clear();
        }
      }
      this.fitness(this.population);
    } else {
      for (i = 0; i < this.population.length; i++) {
        var genome = this.population[i];
        if (this.clear) genome.clear();
        genome.score = this.fitness(genome);
      }
    }
  },

  /**
   * Sorts the population by score
   */
  sort: function () {
    this.population.sort(function (a, b) {
      return b.score - a.score;
    });
  },

  /**
   * Returns the fittest genome of the current population
   */
  getFittest: function () {
    // Check if evaluated
    if (typeof this.population[this.population.length - 1].score === 'undefined') {
      this.evaluate();
    }
    if (this.population[0].score < this.population[1].score) {
      this.sort();
    }

    return this.population[0];
  },

  /**
   * Returns the average fitness of the current population
   */
  getAverage: function () {
    if (typeof this.population[this.population.length - 1].score === 'undefined') {
      this.evaluate();
    }

    var score = 0;
    for (var i = 0; i < this.population.length; i++) {
      score += this.population[i].score;
    }

    return score / this.population.length;
  },

  /**
   * Gets a genome based on the selection function
   * @return {Network} genome
   */
  getParent: function () {
    var i;
    switch (this.selection) {
      case selection.POWER:
        if (this.population[0].score < this.population[1].score) this.sort();

        var index = Math.floor(Math.pow(Math.random(), this.selection.power) * this.population.length);
        return this.population[index];
      case selection.FITNESS_PROPORTIONATE:
        // As negative fitnesses are possible
        // https://stackoverflow.com/questions/16186686/genetic-algorithm-handling-negative-fitness-values
        // this is unnecessarily run for every individual, should be changed

        var totalFitness = 0;
        var minimalFitness = 0;
        for (i = 0; i < this.population.length; i++) {
          var score = this.population[i].score;
          minimalFitness = score < minimalFitness ? score : minimalFitness;
          totalFitness += score;
        }

        minimalFitness = Math.abs(minimalFitness);
        totalFitness += minimalFitness * this.population.length;

        var random = Math.random() * totalFitness;
        var value = 0;

        for (i = 0; i < this.population.length; i++) {
          var genome = this.population[i];
          value += genome.score + minimalFitness;
          if (random < value) return genome;
        }

        // if all scores equal, return random genome
        return this.population[Math.floor(Math.random() * this.population.length)];
      case selection.TOURNAMENT:
        if (this.selection.size > this.popsize) {
          throw new Error('Your tournament size should be lower than the population size, please change methods.selection.TOURNAMENT.size');
        }

        // Create a tournament
        var individuals = [];
        for (i = 0; i < this.selection.size; i++) {
          var random = this.population[Math.floor(Math.random() * this.population.length)];
          individuals.push(random);
        }

        // Sort the tournament individuals by score
        individuals.sort(function (a, b) {
          return b.score - a.score;
        });

        // Select an individual
        for (i = 0; i < this.selection.size; i++) {
          if (Math.random() < this.selection.probability || i === this.selection.size - 1) {
            return individuals[i];
          }
        }
    }
  },
  
  
  test: function (L,data) {
    
  },

  /**
   * Export the current population to a json object
   */
  export: function () {
    var json = [];
    for (var i = 0; i < this.population.length; i++) {
      var genome = this.population[i];
      json.push(genome.toJSON());
    }

    return json;
  },

  /**
   * Import population from a json object
   */
  import: function (json) {
    var population = [];
    for (var i = 0; i < json.length; i++) {
      var genome = json[i];
      population.push(Network.fromJSON(genome));
    }
    this.population = population;
    this.popsize = population.length;
  }
};


var Neataptic = {
  methods: methods,
  Connection: Connection,
  architect: architect,
  Network: Network,
  config: config,
  Group: Group,
  Layer: Layer,
  Node: Node,
  Neat: Neat
};

module.exports = Neataptic
};
BundleModuleCode['plugins/ml/pca']=function (module,exports,global,process){
// https://github.com/bitanath/pca
var PCA = (function () {
    var options = {};
    /**
     * The first step is to subtract the mean and center data
     * 
     * @param {Array} matrix - data in an mXn matrix format
     * @returns 
     */
    function computeDeviationMatrix(matrix) {
        var unit = unitSquareMatrix(matrix.length);
        return subtract(matrix, scale(multiply(unit, matrix), 1 / matrix.length));
    }
    /**
     * Computes variance from deviation
     * 
     * @param {Array} deviation - data minus mean as calculated from computeDeviationMatrix
     * @returns 
     */
    function computeDeviationScores(deviation) {
        var devSumOfSquares = multiply(transpose(deviation), deviation);
        return devSumOfSquares;
    }
    /**
     * Calculates the var covar square matrix using either population or sample
     * 
     * @param {Array} devSumOfSquares 
     * @param {boolean} sample - true/false whether data is from sample or not
     * @returns 
     */
    function computeVarianceCovariance(devSumOfSquares, sample) {
        var varianceCovariance;
        if (sample)
            varianceCovariance = scale(devSumOfSquares, 1 / (devSumOfSquares.length - 1));
        else
            varianceCovariance = scale(devSumOfSquares, 1 / (devSumOfSquares.length));
        return varianceCovariance;
    }
    /**
     * Matrix is the deviation sum of squares as computed earlier
     * 
     * @param {Array} matrix - output of computeDeviationScores
     * @returns 
     */
    function computeSVD(matrix) {
        var result = svd(matrix);
        if (options.verbose) console.log(result)
        var eigenvectors = result.U;
        var eigenvalues = result.S;
        var results = eigenvalues.map(function (value, i) {
            var obj = {};
            obj.eigenvalue = value;
            obj.vector = eigenvectors.map(function (vector, j) {
                return -1 * vector[i]; //HACK prevent completely negative vectors
            });
            return obj;
        });
        return results;
    }
    /**
     * Get reduced dataset after removing some dimensions
     * 
     * @param {Array} data - initial matrix started out with
     * @param {rest} vectors - eigenvectors selected as part of process
     * @returns 
     */
    function computeAdjustedData(data) {
        for (var _len = arguments.length, vectorObjs = new Array(_len > 1 ? _len - 1 : 0), 
            _key = 1; _key < _len; _key++) {
            vectorObjs[_key - 1] = arguments[_key];
        }
        //FIXME no need to transpose vectors since they're already in row normal form
        var vectors = vectorObjs.map(function(v){return v.vector});
        var matrixMinusMean = computeDeviationMatrix(data);
        var adjustedData = multiply(vectors, transpose(matrixMinusMean));
        var unit = unitSquareMatrix(data.length);
        var avgData = scale(multiply(unit, data), -1 / data.length); //NOTE get the averages to add back

        var formattedAdjustData = formatData(adjustedData, 2);
        return {
            adjustedData: adjustedData,
            formattedAdjustedData: formattedAdjustData,
            avgData: avgData,
            selectedVectors: vectors
        };
    }

    /**
     * Get original data set from reduced data set (decompress)
     * @param {*} adjustedData = formatted or unformatted adjusted data
     * @param {*} vectors = selectedVectors
     * @param {*} avgData = avgData
     */
    function computeOriginalData(adjustedData, vectors, avgData) {
        var originalWithoutMean = transpose(multiply(transpose(vectors), adjustedData));
        var originalWithMean = subtract(originalWithoutMean, avgData);
        var formattedData = formatData(originalWithMean, 2);
        return {
            originalData: originalWithMean,
            formattedOriginalData: formattedData
        }
    }

    /**
     * Get percentage explained, or loss
     * @param {*} vectors 
     * @param {*} selected 
     */
    function computePercentageExplained(vectors) {
        for (var _len = arguments.length, selected = new Array(_len > 1 ? _len - 1 : 0),
             _key = 1; _key < _len; _key++) {
            selected[_key - 1] = arguments[_key];
        }
        var total = vectors.map(function (v) {
            return v.eigenvalue
        }).reduce(function (a, b) {
            return a + b;
        });
        var explained = selected.map(function (v) {
            return v.eigenvalue
        }).reduce(function (a, b) {
            return a + b;
        });
        return (explained / total);
    }

    function getEigenVectors(data) {
        return computeSVD(computeVarianceCovariance(computeDeviationScores(computeDeviationMatrix(data)), false));
    }

    function analyseTopResult(data) {
        var eigenVectors = getEigenVectors(data);
        var sorted = eigenVectors.sort(function (a, b) {
            return b.eigenvalue - a.eigenvalue;
        });
        console.log('Sorted Vectors', sorted);
        var selected = sorted[0].vector;
        return computeAdjustedData(data, selected);
    }

    function formatData(data, precision) {
        var TEN = Math.pow(10, precision || 2);
        return data.map(function (d, i) {
            return d.map(function (n) {
                return Math.round(n * TEN) / TEN;
            })
        })
    }
    /**
     * Multiplies AxB, where A and B are matrices of nXm and mXn dimensions
     * @param {} a 
     * @param {*} b 
     */
    function multiply(a, b) {
        if (!a[0] || !b[0] || !a.length || !b.length) {
            throw new Error('Both A and B should be matrices');
        }

        if (b.length !== a[0].length) {
            throw new Error('Columns in A should be the same as the number of rows in B');
        }
        var product = [];

        for (var i = 0; i < a.length; i++) {
            product[i] = []; //initialize a new row
            for (var j = 0; j < b[0].length; j++) {
                for (var k = 0; k < a[0].length; k++) {
                    (product[i])[j] = !!(product[i])[j] ? (product[i])[j] + (a[i])[k] * (b[k])[j] : (a[i])[k] * (b[k])[j];
                }
            }
        }
        return product;
    }
    /**
     * Utility function to subtract matrix b from a
     * 
     * @param {any} a 
     * @param {any} b 
     * @returns 
     */
    function subtract(a, b) {
        if (!(a.length === b.length && a[0].length === b[0].length))
            throw new Error('Both A and B should have the same dimensions');
        var result = [];
        for (var i = 0; i < a.length; i++) {
            result[i] = [];
            for (var j = 0; j < b[0].length; j++) {
                (result[i])[j] = (a[i])[j] - (b[i])[j];
            }
        }
        return result;
    }
    /**
     * Multiplies a matrix into a factor
     * 
     * @param {any} matrix 
     * @param {any} factor 
     * @returns 
     */
    function scale(matrix, factor) {
        var result = [];
        for (var i = 0; i < matrix.length; i++) {
            result[i] = [];
            for (var j = 0; j < matrix[0].length; j++) {
                (result[i])[j] = (matrix[i])[j] * factor;
            }
        }
        return result;
    }

    /**
     * Generates a unit square matrix
     * @param {*} rows = number of rows to fill
     */
    function unitSquareMatrix(rows) {
        var result = [];
        for (var i = 0; i < rows; i++) {
            result[i] = [];
            for (var j = 0; j < rows; j++) {
                (result[i])[j] = 1;
            }
        }
        return result;
    }
    /**
     * Transposes a matrix, converts rows to columns
     * @param {*} matrix 
     */
    function transpose(matrix) {
        var operated = clone(matrix);
        return operated[0].map(function (m, c) {
            return matrix.map(function (r) {
                return r[c];
            });
        });
    }
    /**
     * Deep Clones a matrix
     * @param {*} arr 
     */
    function clone(arr) {
        var string = JSON.stringify(arr);
        var result = JSON.parse(string);
        return result;
    }

    /**
     * Compute the thin SVD from G. H. Golub and C. Reinsch, Numer. Math. 14, 403-420 (1970)
     * From the Numeric JS Implementation Copyright (C) 2011 by Sébastien Loisel
     * The C implementation from which this has been taken may be found here: http://www.public.iastate.edu/~dicook/JSS/paper/code/svd.c
     * @param {*} A = m*n matrix
     */
    function svd(A) {
        var temp;
        var prec = Math.pow(2, -52) // assumes double prec
        var tolerance = 1.e-64 / prec;
        var itmax = 50;
        var c = 0;
        var i = 0;
        var j = 0;
        var k = 0;
        var l = 0;
        var u = clone(A);
        var m = u.length;
        var n = u[0].length;

        if (m < n) throw "Need more rows than columns"

        var e = new Array(n); //vector1
        var q = new Array(n); //vector2
        for (i = 0; i < n; i++) e[i] = q[i] = 0.0;
        var v = rep([n, n], 0);

        function pythag(a, b) {
            a = Math.abs(a)
            b = Math.abs(b)
            if (a > b)
                return a * Math.sqrt(1.0 + (b * b / a / a))
            else if (b == 0.0)
                return a
            return b * Math.sqrt(1.0 + (a * a / b / b))
        }

        //rep function
        function rep(s, v, k) {
            if (typeof k === "undefined") {
                k = 0;
            }
            var n = s[k],
                ret = Array(n),
                i;
            if (k === s.length - 1) {
                for (i = n - 2; i >= 0; i -= 2) {
                    ret[i + 1] = v;
                    ret[i] = v;
                }
                if (i === -1) {
                    ret[0] = v;
                }
                return ret;
            }
            for (i = n - 1; i >= 0; i--) {
                ret[i] = rep(s, v, k + 1);
            }
            return ret;
        }

        //Householder's reduction to bidiagonal form

        var f = 0.0;
        var g = 0.0;
        var h = 0.0;
        var x = 0.0;
        var y = 0.0;
        var z = 0.0;
        var s = 0.0;

        for (i = 0; i < n; i++) {
            e[i] = g; //vector
            s = 0.0; //sum
            l = i + 1; //stays i+1
            for (j = i; j < m; j++)
                s += (u[j][i] * u[j][i]);
            if (s <= tolerance)
                g = 0.0;
            else {
                f = u[i][i];
                g = Math.sqrt(s);
                if (f >= 0.0) g = -g;
                h = f * g - s
                u[i][i] = f - g;
                for (j = l; j < n; j++) {
                    s = 0.0
                    for (k = i; k < m; k++)
                        s += u[k][i] * u[k][j]
                    f = s / h
                    for (k = i; k < m; k++)
                        u[k][j] += f * u[k][i]
                }
            }
            q[i] = g
            s = 0.0
            for (j = l; j < n; j++)
                s = s + u[i][j] * u[i][j]
            if (s <= tolerance)
                g = 0.0
            else {
                f = u[i][i + 1]
                g = Math.sqrt(s)
                if (f >= 0.0) g = -g
                h = f * g - s
                u[i][i + 1] = f - g;
                for (j = l; j < n; j++) e[j] = u[i][j] / h
                for (j = l; j < m; j++) {
                    s = 0.0
                    for (k = l; k < n; k++)
                        s += (u[j][k] * u[i][k])
                    for (k = l; k < n; k++)
                        u[j][k] += s * e[k]
                }
            }
            y = Math.abs(q[i]) + Math.abs(e[i])
            if (y > x)
                x = y
        }

        // accumulation of right hand transformations
        for (i = n - 1; i != -1; i += -1) {
            if (g != 0.0) {
                h = g * u[i][i + 1]
                for (j = l; j < n; j++)
                    v[j][i] = u[i][j] / h //u is array, v is square of columns
                for (j = l; j < n; j++) {
                    s = 0.0
                    for (k = l; k < n; k++)
                        s += u[i][k] * v[k][j]
                    for (k = l; k < n; k++)
                        v[k][j] += (s * v[k][i])
                }
            }
            for (j = l; j < n; j++) {
                v[i][j] = 0;
                v[j][i] = 0;
            }
            v[i][i] = 1;
            g = e[i]
            l = i
        }

        // accumulation of left hand transformations
        for (i = n - 1; i != -1; i += -1) {
            l = i + 1
            g = q[i]
            for (j = l; j < n; j++)
                u[i][j] = 0;
            if (g != 0.0) {
                h = u[i][i] * g
                for (j = l; j < n; j++) {
                    s = 0.0
                    for (k = l; k < m; k++) s += u[k][i] * u[k][j];
                    f = s / h
                    for (k = i; k < m; k++) u[k][j] += f * u[k][i];
                }
                for (j = i; j < m; j++) u[j][i] = u[j][i] / g;
            } else
                for (j = i; j < m; j++) u[j][i] = 0;
            u[i][i] += 1;
        }

        // diagonalization of the bidiagonal form
        prec = prec * x
        for (k = n - 1; k != -1; k += -1) {
            for (var iteration = 0; iteration < itmax; iteration++) { // test f splitting
                var test_convergence = false
                for (l = k; l != -1; l += -1) {
                    if (Math.abs(e[l]) <= prec) {
                        test_convergence = true
                        break
                    }
                    if (Math.abs(q[l - 1]) <= prec)
                        break
                }
                if (!test_convergence) { // cancellation of e[l] if l>0
                    c = 0.0
                    s = 1.0
                    var l1 = l - 1
                    for (i = l; i < k + 1; i++) {
                        f = s * e[i]
                        e[i] = c * e[i]
                        if (Math.abs(f) <= prec)
                            break
                        g = q[i]
                        h = pythag(f, g)
                        q[i] = h
                        c = g / h
                        s = -f / h
                        for (j = 0; j < m; j++) {
                            y = u[j][l1]
                            z = u[j][i]
                            u[j][l1] = y * c + (z * s)
                            u[j][i] = -y * s + (z * c)
                        }
                    }
                }
                // test f convergence
                z = q[k]
                if (l == k) { //convergence
                    if (z < 0.0) { //q[k] is made non-negative
                        q[k] = -z
                        for (j = 0; j < n; j++)
                            v[j][k] = -v[j][k]
                    }
                    break //break out of iteration loop and move on to next k value
                }
                if (iteration >= itmax - 1)
                    throw 'Error: no convergence.'
                // shift from bottom 2x2 minor
                x = q[l]
                y = q[k - 1]
                g = e[k - 1]
                h = e[k]
                f = ((y - z) * (y + z) + (g - h) * (g + h)) / (2.0 * h * y)
                g = pythag(f, 1.0)
                if (f < 0.0)
                    f = ((x - z) * (x + z) + h * (y / (f - g) - h)) / x
                else
                    f = ((x - z) * (x + z) + h * (y / (f + g) - h)) / x
                // next QR transformation
                c = 1.0
                s = 1.0
                for (i = l + 1; i < k + 1; i++) {
                    g = e[i]
                    y = q[i]
                    h = s * g
                    g = c * g
                    z = pythag(f, h)
                    e[i - 1] = z
                    c = f / z
                    s = h / z
                    f = x * c + g * s
                    g = -x * s + g * c
                    h = y * s
                    y = y * c
                    for (j = 0; j < n; j++) {
                        x = v[j][i - 1]
                        z = v[j][i]
                        v[j][i - 1] = x * c + z * s
                        v[j][i] = -x * s + z * c
                    }
                    z = pythag(f, h)
                    q[i - 1] = z
                    c = f / z
                    s = h / z
                    f = c * g + s * y
                    x = -s * g + c * y
                    for (j = 0; j < m; j++) {
                        y = u[j][i - 1]
                        z = u[j][i]
                        u[j][i - 1] = y * c + z * s
                        u[j][i] = -y * s + z * c
                    }
                }
                e[l] = 0.0
                e[k] = f
                q[k] = x
            }
        }

        for (i = 0; i < q.length; i++)
            if (q[i] < prec) q[i] = 0

        //sort eigenvalues	
        for (i = 0; i < n; i++) {
            for (j = i - 1; j >= 0; j--) {
                if (q[j] < q[i]) {
                    c = q[j]
                    q[j] = q[i]
                    q[i] = c
                    for (k = 0; k < u.length; k++) {
                        temp = u[k][i];
                        u[k][i] = u[k][j];
                        u[k][j] = temp;
                    }
                    for (k = 0; k < v.length; k++) {
                        temp = v[k][i];
                        v[k][i] = v[k][j];
                        v[k][j] = temp;
                    }
                    i = j
                }
            }
        }

        return {
            U: u,
            S: q,
            V: v
        }
    }

    return {
        computeDeviationScores: computeDeviationScores,
        computeDeviationMatrix: computeDeviationMatrix,
        computeSVD: computeSVD,
        computePercentageExplained: computePercentageExplained,
        computeOriginalData: computeOriginalData,
        computeVarianceCovariance: computeVarianceCovariance,
        computeAdjustedData: computeAdjustedData,
        getEigenVectors: getEigenVectors,
        analyseTopResult: analyseTopResult,
        transpose: transpose,
        multiply: multiply,
        clone: clone,
        scale: scale,
        options:options
    }
})();

if(typeof module !== 'undefined')
module.exports = PCA;
};
BundleModuleCode['plugins/ml/dbclust']=function (module,exports,global,process){
/**
 * DBSCAN - Density based clustering
 *
 * https://github.com/uhho/density-clustering
 *
 * @author Lukasz Krawczyk <contact@lukaszkrawczyk.eu>
 * @copyright MIT
 */

/**
 * DBSCAN class construcotr
 * @constructor
 *
 * @param {Array} dataset
 * @param {number} epsilon
 * @param {number} minPts
 * @param {function} distanceFunction
 * @returns {DBSCAN}
 */
function DBSCAN(dataset, epsilon, minPts, distanceFunction) {
  if (!(this instanceof DBSCAN)) return new DBSCAN(dataset, epsilon, minPts, distanceFunction);
  /** @type {Array} */
  this.dataset = [];
  /** @type {number} */
  this.epsilon = 1;
  /** @type {number} */
  this.minPts = 2;
  /** @type {function} */
  this.distance = this._euclideanDistance;
  /** @type {Array} */
  this.clusters = [];
  /** @type {Array} */
  this.noise = [];

  // temporary variables used during computation

  /** @type {Array} */
  this._visited = [];
  /** @type {Array} */
  this._assigned = [];
  /** @type {number} */
  this._datasetLength = 0;

  this._init(dataset, epsilon, minPts, distanceFunction);
};

/******************************************************************************/
// public functions

/**
 * Start clustering
 *
 * @param {Array} dataset
 * @param {number} epsilon
 * @param {number} minPts
 * @param {function} distanceFunction
 * @returns {undefined}
 * @access public
 */
DBSCAN.prototype.run = function(dataset, epsilon, minPts, distanceFunction) {
  this._init(dataset, epsilon, minPts, distanceFunction);

  for (var pointId = 0; pointId < this._datasetLength; pointId++) {
    // if point is not visited, check if it forms a cluster
    if (this._visited[pointId] !== 1) {
      this._visited[pointId] = 1;

      // if closest neighborhood is too small to form a cluster, mark as noise
      var neighbors = this._regionQuery(pointId);

      if (neighbors.length < this.minPts) {
        this.noise.push(pointId);
      } else {
        // create new cluster and add point
        var clusterId = this.clusters.length;
        this.clusters.push([]);
        this._addToCluster(pointId, clusterId);

        this._expandCluster(clusterId, neighbors);
      }
    }
  }

  return this.clusters;
};

/******************************************************************************/
// protected functions

/**
 * Set object properties
 *
 * @param {Array} dataset
 * @param {number} epsilon
 * @param {number} minPts
 * @param {function} distance
 * @returns {undefined}
 * @access protected
 */
DBSCAN.prototype._init = function(dataset, epsilon, minPts, distance) {

  if (dataset) {

    if (!(dataset instanceof Array)) {
      throw Error('Dataset must be of type array, ' +
        typeof dataset + ' given');
    }

    this.dataset = dataset;
    this.clusters = [];
    this.noise = [];

    this._datasetLength = dataset.length;
    this._visited = new Array(this._datasetLength);
    this._assigned = new Array(this._datasetLength);
  }

  if (epsilon) {
    this.epsilon = epsilon;
  }

  if (minPts) {
    this.minPts = minPts;
  }

  if (distance) {
    this.distance = distance;
  }
};

/**
 * Expand cluster to closest points of given neighborhood
 *
 * @param {number} clusterId
 * @param {Array} neighbors
 * @returns {undefined}
 * @access protected
 */
DBSCAN.prototype._expandCluster = function(clusterId, neighbors) {

  /**
   * It's very important to calculate length of neighbors array each time,
   * as the number of elements changes over time
   */
  for (var i = 0; i < neighbors.length; i++) {
    var pointId2 = neighbors[i];

    if (this._visited[pointId2] !== 1) {
      this._visited[pointId2] = 1;
      var neighbors2 = this._regionQuery(pointId2);

      if (neighbors2.length >= this.minPts) {
        neighbors = this._mergeArrays(neighbors, neighbors2);
      }
    }

    // add to cluster
    if (this._assigned[pointId2] !== 1) {
      this._addToCluster(pointId2, clusterId);
    }
  }
};

/**
 * Add new point to cluster
 *
 * @param {number} pointId
 * @param {number} clusterId
 */
DBSCAN.prototype._addToCluster = function(pointId, clusterId) {
  this.clusters[clusterId].push(pointId);
  this._assigned[pointId] = 1;
};

/**
 * Find all neighbors around given point
 *
 * @param {number} pointId,
 * @param {number} epsilon
 * @returns {Array}
 * @access protected
 */
DBSCAN.prototype._regionQuery = function(pointId) {
  var neighbors = [];

  for (var id = 0; id < this._datasetLength; id++) {
    var dist = this.distance(this.dataset[pointId], this.dataset[id]);
    if (dist < this.epsilon) {
      neighbors.push(id);
    }
  }

  return neighbors;
};

/******************************************************************************/
// helpers

/**
 * @param {Array} a
 * @param {Array} b
 * @returns {Array}
 * @access protected
 */
DBSCAN.prototype._mergeArrays = function(a, b) {
  var len = b.length;

  for (var i = 0; i < len; i++) {
    var P = b[i];
    if (a.indexOf(P) < 0) {
      a.push(P);
    }
  }

  return a;
};

/**
 * Calculate euclidean distance in multidimensional space
 *
 * @param {Array} p
 * @param {Array} q
 * @returns {number}
 * @access protected
 */
DBSCAN.prototype._euclideanDistance = function(p, q) {
  var sum = 0;
  var i = Math.min(p.length, q.length);

  while (i--) {
    sum += (p[i] - q[i]) * (p[i] - q[i]);
  }

  return Math.sqrt(sum);
};


/**
 * KMEANS clustering
 *
 * @author Lukasz Krawczyk <contact@lukaszkrawczyk.eu>
 * @copyright MIT
 */

/**
 * KMEANS class constructor
 * @constructor
 *
 * @param {Array} dataset
 * @param {number} k - number of clusters
 * @param {function} distance - distance function
 * @returns {KMEANS}
 */
 function KMEANS(dataset, k, distance) {
  this.k = 3; // number of clusters
  this.dataset = []; // set of feature vectors
  this.assignments = []; // set of associated clusters for each feature vector
  this.centroids = []; // vectors for our clusters

  this.init(dataset, k, distance);
}

/**
 * @returns {undefined}
 */
KMEANS.prototype.init = function(dataset, k, distance) {
  this.assignments = [];
  this.centroids = [];

  if (typeof dataset !== 'undefined') {
    this.dataset = dataset;
  }

  if (typeof k !== 'undefined') {
    this.k = k;
  }

  if (typeof distance !== 'undefined') {
    this.distance = distance;
  }
};

/**
 * @returns {undefined}
 */
KMEANS.prototype.run = function(dataset, k) {
  this.init(dataset, k);

  var len = this.dataset.length;

  // initialize centroids
  for (var i = 0; i < this.k; i++) {
    this.centroids[i] = this.randomCentroid();
	}

  var change = true;
  while(change) {

    // assign feature vectors to clusters
    change = this.assign();

    // adjust location of centroids
    for (var centroidId = 0; centroidId < this.k; centroidId++) {
      var mean = new Array(maxDim);
      var count = 0;

      // init mean vector
      for (var dim = 0; dim < maxDim; dim++) {
        mean[dim] = 0;
      }

      for (var j = 0; j < len; j++) {
        var maxDim = this.dataset[j].length;

        // if current cluster id is assigned to point
        if (centroidId === this.assignments[j]) {
          for (var dim = 0; dim < maxDim; dim++) {
            mean[dim] += this.dataset[j][dim];
          }
          count++;
        }
      }

      if (count > 0) {
        // if cluster contain points, adjust centroid position
        for (var dim = 0; dim < maxDim; dim++) {
          mean[dim] /= count;
        }
        this.centroids[centroidId] = mean;
      } else {
        // if cluster is empty, generate new random centroid
        this.centroids[centroidId] = this.randomCentroid();
        change = true;
      }
    }
  }

  return this.getClusters();
};

/**
 * Generate random centroid
 *
 * @returns {Array}
 */
KMEANS.prototype.randomCentroid = function() {
  var maxId = this.dataset.length -1;
  var centroid;
  var id;

  do {
    id = Math.round(Math.random() * maxId);
    centroid = this.dataset[id];
  } while (this.centroids.indexOf(centroid) >= 0);

  return centroid;
}

/**
 * Assign points to clusters
 *
 * @returns {boolean}
 */
KMEANS.prototype.assign = function() {
  var change = false;
  var len = this.dataset.length;
  var closestCentroid;

  for (var i = 0; i < len; i++) {
    closestCentroid = this.argmin(this.dataset[i], this.centroids, this.distance);

    if (closestCentroid != this.assignments[i]) {
      this.assignments[i] = closestCentroid;
      change = true;
    }
  }

  return change;
}

/**
 * Extract information about clusters
 *
 * @returns {undefined}
 */
KMEANS.prototype.getClusters = function() {
  var clusters = new Array(this.k);
  var centroidId;

  for (var pointId = 0; pointId < this.assignments.length; pointId++) {
    centroidId = this.assignments[pointId];

    // init empty cluster
    if (typeof clusters[centroidId] === 'undefined') {
      clusters[centroidId] = [];
    }

    clusters[centroidId].push(pointId);
  }

  return clusters;
};

// utils

/**
 * @params {Array} point
 * @params {Array.<Array>} set
 * @params {Function} f
 * @returns {number}
 */
KMEANS.prototype.argmin = function(point, set, f) {
  var min = Number.MAX_VALUE;
  var arg = 0;
  var len = set.length;
  var d;

  for (var i = 0; i < len; i++) {
    d = f(point, set[i]);
    if (d < min) {
      min = d;
      arg = i;
    }
  }

  return arg;
};

/**
 * Euclidean distance
 *
 * @params {number} p
 * @params {number} q
 * @returns {number}
 */
KMEANS.prototype.distance = function(p, q) {
  var sum = 0;
  var i = Math.min(p.length, q.length);

  while (i--) {
    var diff = p[i] - q[i];
    sum += diff * diff;
  }

  return Math.sqrt(sum);
};

if (typeof module !== 'undefined' && module.exports) {
  module.exports = KMEANS;
}

/**
 * PriorityQueue
 * Elements in this queue are sorted according to their value
 *
 * @author Lukasz Krawczyk <contact@lukaszkrawczyk.eu>
 * @copyright MIT
 */

/**
 * PriorityQueue class construcotr
 * @constructor
 *
 * @example
 * queue: [1,2,3,4]
 * priorities: [4,1,2,3]
 * > result = [1,4,2,3]
 *
 * @param {Array} elements
 * @param {Array} priorities
 * @param {string} sorting - asc / desc
 * @returns {PriorityQueue}
 */
function PriorityQueue(elements, priorities, sorting) {
  /** @type {Array} */
  this._queue = [];
  /** @type {Array} */
  this._priorities = [];
  /** @type {string} */
  this._sorting = 'desc';

  this._init(elements, priorities, sorting);
};

/**
 * Insert element
 *
 * @param {Object} ele
 * @param {Object} priority
 * @returns {undefined}
 * @access public
 */
PriorityQueue.prototype.insert = function(ele, priority) {
  var indexToInsert = this._queue.length;
  var index = indexToInsert;

  while (index--) {
    var priority2 = this._priorities[index];
    if (this._sorting === 'desc') {
      if (priority > priority2) {
        indexToInsert = index;
      }
    } else {
      if (priority < priority2) {
        indexToInsert = index;
      }
    }
  }

  this._insertAt(ele, priority, indexToInsert);
};

/**
 * Remove element
 *
 * @param {Object} ele
 * @returns {undefined}
 * @access public
 */
PriorityQueue.prototype.remove = function(ele) {
  var index = this._queue.length;

  while (index--) {
    var ele2 = this._queue[index];
    if (ele === ele2) {
      this._queue.splice(index, 1);
      this._priorities.splice(index, 1);
      break;
    }
  }
};

/**
 * For each loop wrapper
 *
 * @param {function} func
 * @returs {undefined}
 * @access public
 */
PriorityQueue.prototype.forEach = function(func) {
  this._queue.forEach(func);
};

/**
 * @returns {Array}
 * @access public
 */
PriorityQueue.prototype.getElements = function() {
  return this._queue;
};

/**
 * @param {number} index
 * @returns {Object}
 * @access public
 */
PriorityQueue.prototype.getElementPriority = function(index) {
  return this._priorities[index];
};

/**
 * @returns {Array}
 * @access public
 */
PriorityQueue.prototype.getPriorities = function() {
  return this._priorities;
};

/**
 * @returns {Array}
 * @access public
 */
PriorityQueue.prototype.getElementsWithPriorities = function() {
  var result = [];

  for (var i = 0, l = this._queue.length; i < l; i++) {
    result.push([this._queue[i], this._priorities[i]]);
  }

  return result;
};

/**
 * Set object properties
 *
 * @param {Array} elements
 * @param {Array} priorities
 * @returns {undefined}
 * @access protected
 */
PriorityQueue.prototype._init = function(elements, priorities, sorting) {

  if (elements && priorities) {
    this._queue = [];
    this._priorities = [];

    if (elements.length !== priorities.length) {
      throw new Error('Arrays must have the same length');
    }

    for (var i = 0; i < elements.length; i++) {
      this.insert(elements[i], priorities[i]);
    }
  }

  if (sorting) {
    this._sorting = sorting;
  }
};

/**
 * Insert element at given position
 *
 * @param {Object} ele
 * @param {number} index
 * @returns {undefined}
 * @access protected
 */
PriorityQueue.prototype._insertAt = function(ele, priority, index) {
  if (this._queue.length === index) {
    this._queue.push(ele);
    this._priorities.push(priority);
  } else {
    this._queue.splice(index, 0, ele);
    this._priorities.splice(index, 0, priority);
  }
};



/**
 * OPTICS - Ordering points to identify the clustering structure
 *
 * @author Lukasz Krawczyk <contact@lukaszkrawczyk.eu>
 * @copyright MIT
 */

/**
 * OPTICS class constructor
 * @constructor
 *
 * @param {Array} dataset
 * @param {number} epsilon
 * @param {number} minPts
 * @param {function} distanceFunction
 * @returns {OPTICS}
 */
function OPTICS(dataset, epsilon, minPts, distanceFunction) {
  /** @type {number} */
  this.epsilon = 1;
  /** @type {number} */
  this.minPts = 1;
  /** @type {function} */
  this.distance = this._euclideanDistance;

  // temporary variables used during computation

  /** @type {Array} */
  this._reachability = [];
  /** @type {Array} */
  this._processed = [];
  /** @type {number} */
  this._coreDistance = 0;
  /** @type {Array} */
  this._orderedList = [];

  this._init(dataset, epsilon, minPts, distanceFunction);
}

/******************************************************************************/
// pulic functions

/**
 * Start clustering
 *
 * @param {Array} dataset
 * @returns {undefined}
 * @access public
 */
OPTICS.prototype.run = function(dataset, epsilon, minPts, distanceFunction) {
  this._init(dataset, epsilon, minPts, distanceFunction);

  for (var pointId = 0, l = this.dataset.length; pointId < l; pointId++) {
    if (this._processed[pointId] !== 1) {
      this._processed[pointId] = 1;
      this.clusters.push([pointId]);
      var clusterId = this.clusters.length - 1;

      this._orderedList.push(pointId);
      var priorityQueue = new PriorityQueue(null, null, 'asc');
      var neighbors = this._regionQuery(pointId);

      // using priority queue assign elements to new cluster
      if (this._distanceToCore(pointId) !== undefined) {
        this._updateQueue(pointId, neighbors, priorityQueue);
        this._expandCluster(clusterId, priorityQueue);
      }
    }
  }

  return this.clusters;
};

/**
 * Generate reachability plot for all points
 *
 * @returns {array}
 * @access public
 */
OPTICS.prototype.getReachabilityPlot = function() {
  var reachabilityPlot = [];

  for (var i = 0, l = this._orderedList.length; i < l; i++) {
    var pointId = this._orderedList[i];
    var distance = this._reachability[pointId];

    reachabilityPlot.push([pointId, distance]);
  }

  return reachabilityPlot;
};

/******************************************************************************/
// protected functions

/**
 * Set object properties
 *
 * @param {Array} dataset
 * @param {number} epsilon
 * @param {number} minPts
 * @param {function} distance
 * @returns {undefined}
 * @access protected
 */
OPTICS.prototype._init = function(dataset, epsilon, minPts, distance) {

  if (dataset) {

    if (!(dataset instanceof Array)) {
      throw Error('Dataset must be of type array, ' +
        typeof dataset + ' given');
    }

    this.dataset = dataset;
    this.clusters = [];
    this._reachability = new Array(this.dataset.length);
    this._processed = new Array(this.dataset.length);
    this._coreDistance = 0;
    this._orderedList = [];
  }

  if (epsilon) {
    this.epsilon = epsilon;
  }

  if (minPts) {
    this.minPts = minPts;
  }

  if (distance) {
    this.distance = distance;
  }
};

/**
 * Update information in queue
 *
 * @param {number} pointId
 * @param {Array} neighbors
 * @param {PriorityQueue} queue
 * @returns {undefined}
 * @access protected
 */
OPTICS.prototype._updateQueue = function(pointId, neighbors, queue) {
  var self = this;

  this._coreDistance = this._distanceToCore(pointId);
  neighbors.forEach(function(pointId2) {
    if (self._processed[pointId2] === undefined) {
      var dist = self.distance(self.dataset[pointId], self.dataset[pointId2]);
      var newReachableDistance = Math.max(self._coreDistance, dist);

      if (self._reachability[pointId2] === undefined) {
        self._reachability[pointId2] = newReachableDistance;
        queue.insert(pointId2, newReachableDistance);
      } else {
        if (newReachableDistance < self._reachability[pointId2]) {
          self._reachability[pointId2] = newReachableDistance;
          queue.remove(pointId2);
          queue.insert(pointId2, newReachableDistance);
        }
      }
    }
  });
};

/**
 * Expand cluster
 *
 * @param {number} clusterId
 * @param {PriorityQueue} queue
 * @returns {undefined}
 * @access protected
 */
OPTICS.prototype._expandCluster = function(clusterId, queue) {
  var queueElements = queue.getElements();

  for (var p = 0, l = queueElements.length; p < l; p++) {
    var pointId = queueElements[p];
    if (this._processed[pointId] === undefined) {
      var neighbors = this._regionQuery(pointId);
      this._processed[pointId] = 1;

      this.clusters[clusterId].push(pointId);
      this._orderedList.push(pointId);

      if (this._distanceToCore(pointId) !== undefined) {
        this._updateQueue(pointId, neighbors, queue);
        this._expandCluster(clusterId, queue);
      }
    }
  }
};

/**
 * Calculating distance to cluster core
 *
 * @param {number} pointId
 * @returns {number}
 * @access protected
 */
OPTICS.prototype._distanceToCore = function(pointId) {
  var l = this.epsilon;
  for (var coreDistCand = 0; coreDistCand < l; coreDistCand++) {
    var neighbors = this._regionQuery(pointId, coreDistCand);
    if (neighbors.length >= this.minPts) {
      return coreDistCand;
    }
  }

  return;
};

/**
 * Find all neighbors around given point
 *
 * @param {number} pointId
 * @param {number} epsilon
 * @returns {Array}
 * @access protected
 */
OPTICS.prototype._regionQuery = function(pointId, epsilon) {
  epsilon = epsilon || this.epsilon;
  var neighbors = [];

  for (var id = 0, l = this.dataset.length; id < l; id++) {
    if (this.distance(this.dataset[pointId], this.dataset[id]) < epsilon) {
      neighbors.push(id);
    }
  }

  return neighbors;
};

/******************************************************************************/
// helpers

/**
 * Calculate euclidean distance in multidimensional space
 *
 * @param {Array} p
 * @param {Array} q
 * @returns {number}
 * @access protected
 */
OPTICS.prototype._euclideanDistance = function(p, q) {
  var sum = 0;
  var i = Math.min(p.length, q.length);

  while (i--) {
    sum += (p[i] - q[i]) * (p[i] - q[i]);
  }

  return Math.sqrt(sum);
};

function Utils() {

}


KMEANS.prototype.getRandomVector = function(extremes) {
  var maxDim = extremes.length;
  var x = [];
  var r = 0;
  
  // calculate radius of n-sphere which covers all points in dataset
  var nSphereRadius = 0;
  for (var i = 0; i < maxDim; i++) {
    var extreme = extremes[i];
    var er = Math.max(extreme.center - extreme.min, extreme.center - extreme.max);
    if (er > nSphereRadius)
      nSphereRadius = er;
  }
  
  for (var i = 0; i < maxDim; i++) {
    var val = (Math.random() * 2) - 1;
    // adjust to radius of n-sphere
    x.push(val);
    r += val * val;
  }
      
  r = Math.sqrt(r);
  
  for (var i = 0; i < maxDim; i++) {
    x[i] /= r;
    // resize to fit n-sphere
    x[i] *= nSphereRadius;
    x[i] += extremes[i].center;
  }
  
  return x;
}


module.exports = {
      DBSCAN: DBSCAN,
      KMEANS: KMEANS,
      OPTICS: OPTICS,
      PriorityQueue: PriorityQueue
};
};
BundleModuleCode['plugins/ml/reg']=function (module,exports,global,process){
/* https://github.com/chen0040/js-regression */
var jsregression = jsregression || {};

(function (jsr) {
    'use strict';
	var LinearRegression = function (config) {
        config = config || {};
        
        if (!config.iterations) {
            config.iterations = 1000;
        }
        if (!config.alpha) {
            config.alpha = 0.001;
        }
        if (!config.lambda) {
            config.lambda = 0.0;
        }
        if(!config.trace) {
            config.trace = false;
        }
        
        this.iterations = config.iterations;
        this.alpha = config.alpha;
        this.lambda = config.lambda;
        this.costThres = config.cost||0;
        this.errorThres = config.error||0;
        this.trace = config.trace;
        this.dynamic = config.dynamic;  // dynamic alpha rate
    };
    
    LinearRegression.prototype.fit = function (data) {
        var N = data.length, X = [], Y = [];
        this.dim = data[0].length;

    
        for (var i=0; i < N; ++i) {
            var row = data[i];
            var x_i = [];
            var y_i = row[row.length-1];
            x_i.push(1.0);
            for(var j=0; j < row.length-1; ++j) {
                x_i.push(row[j]);
            }
            Y.push(y_i);
            X.push(x_i);
        }
        
        this.theta = [];
        
        for (var d = 0; d < this.dim; ++d) {
            this.theta.push(0.0);
        }
        
        var cost,lastCost=0, lastVx, lastTheta, alpha=this.alpha;
        for (var k = 0; k < this.iterations; ++k) {
            var Vx = this.grad(X, Y, this.theta);
            
            for(var d = 0; d < this.dim; ++d) {
                this.theta[d] = this.theta[d] - alpha * Vx[d];
                if (isNaN(this.theta[d])) 
                 throw Error ('LinearRegression.fit: parameter overflow, probably alpha rate to high! (alpha:'+alpha+', step:'+k+')')
            }
            
            if (this.errorThres && this.error(X,Y,this.theta) < this.errorThres) break;
            if (this.costThres && this.cost(X,Y,this.theta) < this.costThres) break;
            if (this.dynamic) {
              // experimental dynamic aloha rate adaptation
              if (lastVx) {
                var gMax=0, gradVx = lastVx.map(function (vx,index) {
                  var g = Math.abs(Vx[index]/vx);
                  gMax = Math.max(gMax,g)
                  return g
                })
                // if some gradVx > XX then lower alpha
                if (gMax > 2) {
                  alpha /= 2;
                } else if (gMax < 1 && (1-gMax) < 0.01) alpha *= 2;
              }
              lastVx = Vx.slice();
              lastTheta = this.theta.slice();
              // console.log(alpha,Vx);
            }
            if(this.trace) {
                console.log('theta: ',this.theta)
                console.log('cost at iteration ' + k + ': ' + cost+' alpha:'+alpha);
            }
        }
        
        return {
            theta: this.theta,
            dim: this.dim,
            cost: this.cost(X, Y, this.theta),
            error: this.error(X, Y, this.theta),
            iterations : k,
            config: {
                alpha: this.alpha,
                lambda: this.lambda,
                iterations: this.iterations 
            }
        };
    };
    
    LinearRegression.prototype.grad = function(X, Y, theta) {
        var N = X.length;
        
        var Vtheta = [];
        
        for(var d = 0; d < this.dim; ++d){
            var g = 0;
            for(var i = 0; i < N; ++i){
                var x_i = X[i];
                var y_i = Y[i];
                
                var predicted = this.h(x_i, theta);
                
                g += (predicted - y_i) * x_i[d];  
            }
            
            g = (g + this.lambda * theta[d]) / N;
            
            Vtheta.push(g);
        }
        
        return Vtheta;
    };
    
    LinearRegression.prototype.h = function(x_i, theta) {
        var predicted = 0.0;
        for(var d = 0; d < this.dim; ++d) {
            predicted += x_i[d] * theta[d];
        }
        return predicted;
    }
    
    LinearRegression.prototype.cost = function(X, Y, theta) {
      
        var N = X.length;
        var cost = 0;
        for(var i = 0; i < N; ++i){
            var x_i = X[i];
            var predicted = this.h(x_i, theta);
            cost += (predicted - Y[i]) * (predicted - Y[i]);
        }
        
        for(var d = 0; d < this.dim; ++d) {
            cost += this.lambda * theta[d] * theta[d];
        }
        
        return cost / (2.0 * N);
    };

    LinearRegression.prototype.error = function(X, Y, theta) {
      
        var N = X.length;
        var err = 0;
        for(var i = 0; i < N; ++i){
            var x_i = X[i];
            var predicted = this.h(x_i, theta);
            err += (predicted - Y[i]) * (predicted - Y[i]);
        }
        
        
        return err / (N);
    };
    
    LinearRegression.prototype.transform = function(x) {
        if(x[0].length){ // x is a matrix            
            var predicted_array = [];
            for(var i=0; i < x.length; ++i){
                var predicted = this.transform(x[i]);
                predicted_array.push(predicted);
            }
            return predicted_array;
        }
        
        // x is a row vector
        var x_i = [];
        x_i.push(1.0);
        for(var j=0; j < x.length; ++j){
            x_i.push(x[j]);
        }
        return this.h(x_i, this.theta);
    };

    LinearRegression.prototype.toFunction = function () {
      var self=this, foo;
      var fcode = 'foo=function (x) { return '
      fcode += (self.theta.map(function (p,index) {
        var xx=[]; for (var i=0;i<index;i++) xx.push('x');
        return self.theta[index]+(xx.length?'*'+xx.join('*'):'');
      }).join('+'))
      fcode += '}';
      eval(fcode);
      return foo
    }
    
    jsr.LinearRegression = LinearRegression;
    
    var LogisticRegression = function(config) {
        var config = config || {};
        if(!config.alpha){
            config.alpha = 0.001;
        }
        if(!config.iterations) {
            config.iterations = 100;
        }
        if(!config.lambda) {
            config.lambda = 0;
        }
        this.alpha = config.alpha;
        this.lambda = config.lambda;
        this.iterations = config.iterations;
    }
    
    LogisticRegression.prototype.fit = function(data) {
        this.dim = data[0].length;
        var N = data.length;
        
        var X = [];
        var Y = [];
        for(var i=0; i < N; ++i){
            var row = data[i];
            var x_i = [];
            var y_i = row[row.length-1];
            x_i.push(1.0);
            for(var j=0; j < row.length-1; ++j){
                x_i.push(row[j]);
            }
            X.push(x_i);
            Y.push(y_i);
        }
        
        this.theta = [];
        for(var d = 0; d < this.dim; ++d){
            this.theta.push(0.0);
        }
        
        for(var iter = 0; iter < this.iterations; ++iter){
            var theta_delta = this.grad(X, Y, this.theta);
            for(var d = 0; d < this.dim; ++d){
                this.theta[d] = this.theta[d] - this.alpha * theta_delta[d];        
            }
        }
        
        this.threshold = this.computeThreshold(X, Y);
        
        return {
            theta: this.theta,
            threshold: this.threshold,
            cost: this.cost(X, Y, this.theta),
            config: {
                alpha: this.alpha,
                lambda: this.lambda,
                iterations: this.iterations 
            }
        }
    };
    
    LogisticRegression.prototype.computeThreshold = function(X, Y){
        var threshold=1.0, N = X.length;
        
        for (var i = 0; i < N; ++i) {
            var prob = this.transform(X[i]);
            if(Y[i] == 1 && threshold > prob){
                threshold = prob;
            }
        }
        
        return threshold;
    }
    
    LogisticRegression.prototype.grad = function(X, Y, theta) {
        var N = X.length;
        var Vx = [];
        for(var d = 0; d < this.dim; ++d) {
            var sum = 0.0;
            for(var i = 0; i < N; ++i){
                var x_i = X[i];
                var predicted = this.h(x_i, theta);
                sum += ((predicted - Y[i]) * x_i[d] + this.lambda * theta[d]) / N;
            }    
            Vx.push(sum);
        }
        
        return Vx;
        
    }
    
    LogisticRegression.prototype.h = function(x_i, theta) {
        var gx = 0.0;
        for(var d = 0; d < this.dim; ++d){
            gx += theta[d] * x_i[d];
        }
        return 1.0 / (1.0 + Math.exp(-gx));
    }
    
    LogisticRegression.prototype.transform = function(x) {
        if(x[0].length){ // x is a matrix            
            var predicted_array = [];
            for(var i=0; i < x.length; ++i){
                var predicted = this.transform(x[i]);
                predicted_array.push(predicted);
            }
            return predicted_array;
        }
        
        var x_i = [];
        x_i.push(1.0);
        for(var j=0; j < x.length; ++j){
            x_i.push(x[j]);
        }
        return this.h(x_i, this.theta);
    }
    
    LogisticRegression.prototype.cost = function(X, Y, theta) {
        var N = X.length;
        var sum = 0;
        for(var i = 0; i < N; ++i){
            var y_i = Y[i];
            var x_i = X[i];
            sum += - (y_i * Math.log(this.h(x_i, theta)) + (1-y_i) * Math.log(1 - this.h(x_i, theta))) / N;
        }
        
        for(var d = 0; d < this.dim; ++d) {
            sum += (this.lambda * theta[d] * theta[d]) / (2.0 * N);
        }
        return sum;
    };
    
    jsr.LogisticRegression = LogisticRegression;
    
    var MultiClassLogistic = function(config){
        var config = config || {};
        if(!config.alpha){
            config.alpha = 0.001;
        }
        if(!config.iterations) {
            config.iterations = 100;
        }
        if(!config.lambda) {
            config.lambda = 0;
        }
        this.alpha = config.alpha;
        this.lambda = config.lambda;
        this.iterations = config.iterations;
    };
    
    MultiClassLogistic.prototype.fit = function(data, classes) {
        this.dim = data[0].length;
        var N = data.length;
        
        if(!classes){
            classes = [];
            for(var i=0; i < N; ++i){
                var found = false;
                var label = data[i][this.dim-1];
                for(var j=0; j < classes.length; ++j){
                    if(label == classes[j]){
                        found = true;
                        break;
                    }
                }
                if(!found){
                    classes.push(label);
                }
            }
        }
        
        this.classes = classes;
        
        this.logistics = {};
        var result = {};
        for(var k = 0; k < this.classes.length; ++k){
            var c = this.classes[k];
            this.logistics[c] = new jsr.LogisticRegression({
                alpha: this.alpha,
                lambda: this.lambda,
                iterations: this.iterations
            });
            var data_c = [];
            for(var i=0; i < N; ++i){
                var row = [];
                for(var j=0; j < this.dim-1; ++j){
                    row.push(data[i][j]);
                }
                row.push(data[i][this.dim-1] == c ? 1 : 0);
                data_c.push(row);
            }
            result[c] = this.logistics[c].fit(data_c);
        }
        return result;
    };
    
    MultiClassLogistic.prototype.transform = function(x) {
        if(x[0].length){ // x is a matrix            
            var predicted_array = [];
            for(var i=0; i < x.length; ++i){
                var predicted = this.transform(x[i]);
                predicted_array.push(predicted);
            }
            return predicted_array;
        }
        
        
        
        var max_prob = 0.0;
        var best_c = '';
        for(var k = 0; k < this.classes.length; ++k) {
            var c = this.classes[k];
            var prob_c = this.logistics[c].transform(x);
            if(max_prob < prob_c){
                max_prob = prob_c;
                best_c = c;
            }
        }
        
        return best_c;
    }
    
    
    
    jsr.MultiClassLogistic = MultiClassLogistic;

})(jsregression);

var module = module || {};
if(module) {
	module.exports = jsregression;
}
};
BundleModuleCode['plugins/ml/pre']=function (module,exports,global,process){
/**
 **      ==============================
 **       O           O      O   OOOO
 **       O           O     O O  O   O
 **       O           O     O O  O   O
 **       OOOO   OOOO O     OOO  OOOO
 **       O   O       O    O   O O   O
 **       O   O       O    O   O O   O
 **       OOOO        OOOO O   O OOOO
 **      ==============================
 **      Dr. Stefan Bosse http://www.bsslab.de
 **
 **      COPYRIGHT: THIS SOFTWARE, EXECUTABLE AND SOURCE CODE IS OWNED
 **                 BY THE AUTHOR(S).
 **                 THIS SOURCE CODE MAY NOT BE COPIED, EXTRACTED,
 **                 MODIFIED, OR OTHERWISE USED IN A CONTEXT
 **                 OUTSIDE OF THE SOFTWARE SYSTEM.
 **
 **    $AUTHORS:     Stefan Bosse
 **    $INITIAL:     (C) 2006-2021 BSSLAB
 **    $CREATED:     8-2-16 by sbosse.
 **    $VERSION:     1.20.1X
 **
 **    $INFO:
 **
 **  JavaScript Machine Learning API: Data Preprocessing
 **
 **    $ENDOFINFO
 */

var Io = Require('com/io');
var Comp = Require('com/compat');
var _ = undefined;
var none = null;

var isArray   = Comp.obj.isArray,
    isNumber  = Comp.obj.isNumber,
    isObject  = Comp.obj.isObject,
    isMatrix  = Comp.obj.isMatrix;
/**
 * Computes Log with base-2
 * @private
 */
function log2(n) {
  return Math.log(n) / Math.log(2);
}

function obj2Array(row,features) {
  return features.map(function (attr) { return row[attr] });
}
function objSlice(row,features) {
  var o = {};
  features.forEach(function (attr) { o[attr]=row[attr] });
  return o;
}
function array2Object(row,features) {
  var result={};
  row.forEach(function (x,index) { result[features[index]]=x });
  return result;
}

// transform [v][] -> v[]
function relax(mat) {
  if (isMatrix(mat) && mat[0].length==1) return mat.map(function (row) { return row[0]})
  else return mat;
}

// transform v[] -> [v][]
function wrap(mat) {
  if (!isMatrix(mat)) return mat.map(function (v) { return [v]})
  else return mat
}

function Constructor(f, args) {
    return function() {
        f.apply(this, args);
    };
};

/* Common data transformation between different formats (X)
**
** 1a. need='xy':   data={$x:'a,$y:'b}[]    -> {x:{$x} [], y:'b[]}
** 1b. need='xy':   data=('a|'b)[][]        -> {x:'a [][], y:'b[]}
** 1b. need='xy':   data={input:[],output:[]}[]    -> {x:'a [][], y:'b[]}
** 1c. need='xry':  data=('a|'b)[][]        -> {x:{$x} [], y:'b[]}
** 1c. need='io':   data=number[][]         -> {input:number, output:number} []
** 1d. need='io':   data={$x:number,$y:number}[] -> {input:number [], output:number []} []
** 2. need='xmy':   data=number [][]    -> {x:'a [][], y:'b[]}
** 2b. need='xmy':   data={$x:'a,$y:'b}[]    -> {x:'a [][], y:'b[]}
** 3. need='d':     data={x:'a[][],y:'b[]}} -> {$x:'a,$y:'b}[]
** 4. need='dm':    data={x:'a[][],y;'b[]}  -> ('a|'b)[][]
** 5. need='m':     data={$x:'a}[]          -> 'a [][]
** 5b. need='m':     data={x:'a [],y:'a[]}[]          -> 'a [][]
** 6. need='a':     data={$x:'a}            -> 'a []
** 7. need='scale'  data='a []              -> 'a [] (features)
** 8. need='r':     data='a [][]            -> {$x:'a}[]
**
** typeof options = {
**   scale:   {k:number|number[], off:number|number[], shift:number|number[]} is transformation of input data,
**            | {}[] | [min,max] | 'auto',
**   xscale:  {k:number|number[], off:number|number[], shift:number|number[]} is transformation of input data,
**            | {}[] 
**   yscale:  {k:number|number[], off:number|number[], shift:number|number[]} is transformation of output data,
**            | {}[]
**   features : string [] | number [] is feature variable list,
**   target: string | number is output variable,
**   targets : number [] is output variables list,
**   labels: string [] // ANN: y-vector output mapping (one label == one y[0,1] vector //
**
**/

// Scale (compress) data
function scale(vrow,scala) {
  if (!scala) return vrow;
  if (typeof vrow == 'number') {
    if (typeof scala.k == 'number')
      return scala.shift+(vrow-scala.off)*scala.k
    else if (scala.length)
      return scala[0].shift+(vrow-scala[0].off)*scala[0].k;
    else
      return scala.shift+(vrow-scala.off[0])*scala.k[0];
  }
  if (typeof scala.k == 'number')
    return vrow.map(function (col,i) { 
      return scala.shift+(col-scala.off)*scala.k })
  else if (scala.length)
    return vrow.map(function (col,i) { 
      return scala[i].shift+(col-scala[i].off)*scala[i].k })
  else
    return vrow.map(function (col,i) { 
      return scala.shift+(col-scala.off[i])*scala.k[i] })
}
// Unscale (decompress) data
function unscale(vrow,scala) {
  if (!scala) return vrow;
  if (typeof vrow == 'number') {
    if (typeof scala.k == 'number')
      return (vrow-scala.shift)/scala.k+scala.off
    else if (scala.length)
      return (vrow-scala[0].shift)/scala[0].k+scala[0].off
    else
      return (vrow-scala.shift)/scala.k[0]+scala.off[0]
  }
  if (typeof scala.k == 'number')
    return vrow.map(function (col,i) { 
      return (col-scala.shift)/scala.k+scala.off })
  else if (scala.length)
    return vrow.map(function (col,i) { 
      return (col-scala[i].shift)/scala[i].k+scala[i].off })  
  else
    return vrow.map(function (col,i) { 
      return (vrow-scala.shift)/scala.k[i]+scala.off[i] })  
}

// [a,b] auto scaler of data tables
function autoScale(data,features,shift) {
  var min=[],
      max=[],
      row=data[0];
  if (Comp.obj.isArray(row)) {
    for(var i=0;i<data.length;i++) {
      row=data[i];
      for(var j=0;j<row.length;j++) {
        if (min[j]==undefined) min[j]=row[j]; else min[j]=Math.min(row[j],min[j]);
        if (max[j]==undefined) max[j]=row[j]; else max[j]=Math.max(row[j],max[j]);
      }  
    }
  } else if (Comp.obj.isObj(row)) {
    if (!features) features=Object.keys(row);
    for(var i=0;i<data.length;i++) {
      row=data[i];
      for(var j=0;j<features.length;j++) {
        if (min[j]==undefined) min[j]=row[features[j]]; else min[j]=Math.min(row[features[j]],min[j]);
        if (max[j]==undefined) max[j]=row[features[j]]; else max[j]=Math.max(row[features[j]],max[j]);
      }  
    }    
  } 
  
  shift=shift||0;
  if (min.length==1)
  return {
      k:(1-shift)/(max[0]-min[0]),
      off:min[0],
      shift:shift,
      min:min[0],
      max:max[0]
  }
  else
  return {
      k:min.map(function (a,i) { var b=max[i]; return (1-shift)/(b-a)}),
      off:min,
      shift:shift,
      min:min,
      max:max
  }
}

function toScale(min,max,lower,upper) {
  if (lower==undefined) lower=0;
  if (upper==undefined) upper=1;
  if (typeof min == 'number')
  return {
      k:(upper-lower)/(max-min),
      off:min,
      shift:lower,
      min:min,
      max:max
  }
  else if (min.length==1)
  return {
      k:(upper-lower)/(max[0]-min[0]),
      off:min[0],
      shift:lower,
      min:min[0],
      max:max[0]
  }
  else
  return {
      k:min.map(function (a,i) { var b=max[i]; return (upper-lower)/(b-a)}),
      off:min,
      shift:lower,
      min:min,
      max:max
  }
}
function preprocess(data,need,options) {
  var row,x,y,_data;
  options=options||{};
  var scala=options.scale || options.xscale, scalaY;
  // wrap array
  function array(data) {
    return isArray(data)?data:[data]
  } 
  // map categorical variable on numeric vector (one element for each label)  
  function map(data,labels,bipolar) {
    return labels.map(function (x) {
      if (data==x) return 1;
      else return bipolar?-1:0;
    })
  }
  function scalemat(mat,scala) {
    if (!scala) return mat;
    return mat.map(function (row) { return scale(row,scala) });
  }
  // TODO: options.targets
  
  if (isArray(data)) {
    row=data[0];
    switch (need) {
      case 'xy':
      case 'xry':
        if ((options.target||options.targets)!=undefined && options.features!=undefined) {
          if (isArray(row) && need=='xy') {
            if (Number(options.target)==row.length-1) {
              x=data.map(function (row) { return scale(row.slice(0,options.target),scala) });
              y=data.map(function (row) { return row[options.target] })
            }
          } else  if (isObject(row)) {
            if (typeof options.target == 'string') {
              x=data.map(function (row) { return scale(objSlice(row,options.features),scala) });
              y=data.map(function (row) { return row[options.target] });
            }
          }
        } else if (row.input && row.output) {
          x=data.map(function (row) { return row.input });
          y=data.map(function (row) { return row.output });
        }
        if (x && y) return {x:x,y:y}
        break;
      case 'a':
        if (isArray(data) && typeof data[0] != 'object') return {data:data};  
        if (isObject(data) && options.features!=undefined) {
          return { data:data.map(function (row) { 
                    return scale(objSlice(row,options.features),scala) })};
        }
        break;
      case 'm':
        if (isArray(row.x) && isArry(row.y)) {
          return { data:data.map(function (row) { 
                    return scale(row.x,scala).concat(scale(row.y,options.yscale)) })};                  
        }
        if (isMatrix(data) && !scala) return {data:data};
        else if (isMatrix(data) && !options.features) {
          // just scale data
          return { data:data.map(function (row) { 
                    return scale(row,scala) })};        
        } 
        if (isObject(row)) {
          if (!options.features) options.features=Object.keys(data[0]);
          return { data:data.map(function (row) { 
                    return scale(obj2Array(row,options.features),scala) })};
        }
       break;  
      case 'r':
       if (!isArray(row) && isObject(row)) return {data:data};
        if (isArray(row)) {
          if (!options.features) options.features=row.map(function (x,i) { return String(i) });
          return { data:data.map(function (row) { 
                    return scale(array2Object(row,options.features),scala) })};
        }
       break;  
      case 'xmy':
        if (isObject(row) && options.features!=undefined && (options.target||options.targets)!=undefined) {
          return isObject(options.target)?
                 { x:data.map(function (row) { 
                      return scale(obj2Array(row,options.features),scala) }),
                   y:data.map(function (row) { return scale(obj2Array(row,options.target),options.yscale)})}:
                 { x:data.map(function (row) { 
                      return scale(obj2Array(row,options.features),scala) }),
                   y:data.map(function (row) { return scale(row[options.target],options.yscale)})};
       }
       break;  
      case 'io':
        if (isArray(row) && (options.target||options.targets)!=undefined) {
          // number [][] 
          if (scala=='auto') scala=autoScale(data,null);
          if (Number(options.target)==row.length-1) {
            _data=data.map(function (row) { return { input :scale(row.slice(0,options.target),scala),
                                                     output:scale(array(row[options.target]),options.yscale) }});
            return _data
          } else {
            _data=data.map(function (row) { return { input :scale(obj2Array(row,options.features),scala),
                                                     output:options.targets?
                                                            scale(array(obj2Array(row,options.targets)),options.yscale) 
                                                            :
                                                            scale(array(row[options.target]),options.yscale) }});
            return _data          
          }
        } else if (isArray(row.x) && isArray(row.y)) {
          return data.map(function (row) {
                  return { input:scale(row.x,scala),
                           output:scale(row.y,options.yscale) }});       
        } else if (isObject(row) && !row.input && (options.target||options.targets)!=undefined && options.features!=undefined) {
          if (scala=='auto') scala=autoScale(data,options.features);
          _data=data.map(function (row) { return { input :scale(obj2Array(row,options.features),scala),
                                                   output:options.labels?
                                                          map(array(row[options.target]),options.labels)
                                                          :
                                                          options.targets?
                                                          scale(array(obj2Array(row,options.targets)),options.yscale) 
                                                          :
                                                          scale(array(row[options.target]),options.yscale) }});
          return _data
        } else if (row.input && row.output) {
          if (scala) {
            if (scala=='auto') scala=autoScale(data.input,null);
            _data=data.map(function (row) { return { input :scale(row.input,scala),
                                                   output:scale(row.output,options.yscale) }});
            return _data          
          } else return data;  // { input:number [], output: number [] } []
        } 
        break;
      case 'scale':
        if (isArray(row) && options.scale!=undefined) {
          if (options.features)
            return data.map(function (row) { return scale(obj2Array(row,options.features),options.scale) })
          else      
            return data.map(function (row) { return scale(row,options.scale) })
        }
    }
  } else if (data.x && data.y) {
    if (isArray(data.x) && isArray(data.y)) {
      row=data.x[0];
      if (scala=='auto') {
        scala=autoScale(data.x,null);
        scalaY=autoScale(data.y,null);
      } else scalaY=options.yscale;
      switch (need) {
        case 'io':
        if (isArray(row)) {
          // x:number [][] 
          _data=data.x.map(function (row, rowi) { return { input:scale(row,scala),
                                                           output:array(data.y[rowi]) }});
          return _data          
        } else if (isNumber(row)) {
          // x: number []
          _data=data.x.map(function (row, rowi) { return { input:scale(array(row),scala),
                                                           output:array(data.y[rowi]) }});        
          return _data          
        }
        if (isObject(row) && options.features!=undefined) {
          // x: {}

          _data=data.x.map(function (row, rowi) { return { input:scale(obj2Array(row,options.features),scala),
                                                           output:array(data.y[rowi]) }});
          return _data          
        }
        break;
        case 'xm':
          if (isArray(row)) return data.x;
          break;
        case 'xmy':
          if (isArray(row)) return { x:scalemat(data.x,scala), y:scalemat(data.y,scalaY||options.yscale||scala)};
          break;
        case 'xmya':
          if (isArray(row)) return { x:data.x, y:data.y.map(array)};
          break;
        case 'd':
          return data.x.map(function (row,rowi) {
            var newrow={};
            if (options.features && options.target) {
              options.features.forEach(function (f,coli) {
                newrow[f]=row[coli];
              });
              newrow[options.target]=data.y[rowi];
            } else {
              row.forEach(function (col,f) {
                newrow[String(f)]=col;                
              });
              newrow[String(row.length)]=data.y[rowi];
            }
            return newrow;
          })
          break;
      } 
    }   
  }
}

// randomly split data table in two paritions (e.g., training/test)
// function ([],nuµber,number) -> [partA [],partB [],?indexmapA [],?indexmapB []]
function split (data,partA,partB,withmap) {
  var A=[],B=[],mapA=[],mapB=[],index;
  if (partA==undefined) throw "ML.split: missing partA size";
  if (partB==undefined) { partB=data.length-partA };
  if (data.length < (partA+partB)) throw new Error('EINVALID');
  function shuffle(array) {
    var m = array.length, t, i;
    // While there remain elements to shuffle\u2026
    while (m) {
      // Pick a remaining element\u2026
      i = Math.floor(Math.random() * m--);
      // And swap it with the current element.
      t = array[m];
      array[m] = array[i];
      array[i] = t;
    }
    return array;
  }
  index=Array(data.length).fill().map(function (x,i) { return i });
  index=shuffle(index);
  for(var i=0;i<partA;i++) {
    A.push(data[index[i]]);
    mapA.push(index[i]);
  }
  for(var j=0;j<partB;j++) {
    B.push(data[index[i+j]]);
    mapB.push(index[i+j]);
  }
  return withmap?[A,B,mapA,mapB]:[A,B]
}

module.exports = {
  array2Object:array2Object,
  autoScale:autoScale,
  obj2Array:obj2Array,
  objSlice:objSlice,
  preprocess:preprocess,
  relax:relax,
  scale:scale,
  split:split,
  toScale:toScale,
  unscale:unscale,
  wrap:wrap,
}
};
BundleModuleCode['plugins/ml/sa']=function (module,exports,global,process){
// @justyy
// https://github.com/DoctorLai/simulated_annealling

var SimulatedAnnealing = function (options, generateNewSolution, generateNeighbor, acceptNeighbor) {
	// Set Parameters
    var coolingFactor            = options.coolingFactor || 0.05;
    var stabilizingFactor        = options.stabilizingFactor || 1.005;
    var freezingTemperature      = options.freezingTemperature || 0.001;
    var currentSystemTemperature = options.initialTemperature || 20;
    var curStabilizor            = options.initialStabilizer || 35;    

    // Init solution
    var currentSysEnergy         = generateNewSolution();

    // Probability Function
    // Higher Temperature means more likely to accept worse solutions, and vice versa
    var Prob = function (t, d) {
	    if (d < 0) {
	        return true;
	    }
	    var C = Math.exp(-d / t);
	    var R = Math.random();
	    return (R < C);
    }

    // One Iteration of Process and Return: Should we Continue?
    var _Do = function ()  {
	    if (currentSystemTemperature > freezingTemperature) {
	        for (var i = 0; i < curStabilizor; ++ i) {
	            var newEnergy = generateNeighbor(),
	                energyDelta = newEnergy - currentSysEnergy;

	            if (Prob(currentSystemTemperature, energyDelta)) {
	                // accept this neighbour 
	                acceptNeighbor();
	                // update energey
	                currentSysEnergy = newEnergy;
	            }
	        }
	        // temperature is cooling down
	        currentSystemTemperature = currentSystemTemperature - coolingFactor;
	        // so it is less likely to accept worse solutions
	        curStabilizor = curStabilizor * stabilizingFactor;
	        return true;
	    }
    	currentSystemTemperature = freezingTemperature;
    	return false;	    
	}

	// Get Current System Energy
	var _GetCurrentEnergy = function () {
		return currentSysEnergy;
	}

	// Get Current Temperature
	var _GetCurrentTemperature = () => {
		return currentSystemTemperature;
	}

	// Export Methods
	return {
		Do: function() {
			return _Do();
		},

		GetCurrentEnergy: function() {
			return _GetCurrentEnergy();
		},

		GetCurrentTemperature: function() {
			return _GetCurrentTemperature();
		}
	}
}

// module exports the Simulated Annealing Object
module.exports = { 
	SimulatedAnnealing : SimulatedAnnealing
} 
};
BundleModuleCode['plugins/math/druid']=function (module,exports,global,process){
// https://renecutura.eu v0.6.0 Copyright 2022 Rene Cutura
(function (global, factory) {
typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :
typeof define === 'function' && define.amd ? define(['exports'], factory) :
(global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.druid = global.druid || {}));
})(this, (function (exports) { 'use strict';

// polyfill a ?? b
function LOR (a,b) { return a==undefined?b:a }

/**
 * Computes the euclidean distance (<code>l<sub>2</sub></code>) between <code>a</code> and <code>b</code>.
 * @memberof module:metrics
 * @alias euclidean
 * @param {Number[]} a
 * @param {Number[]} b
 * @returns {Number} the euclidean distance between <code>a</code> and <code>b</code>.
 */
function euclidean (a, b) {
    return Math.sqrt(euclidean_squared(a, b));
}

/**
 * Numerical stable summation with the Kahan summation algorithm.
 * @memberof module:numerical
 * @alias kahan_sum
 * @param {Array} summands - Array of values to sum up.
 * @returns {number} The sum.
 * @see {@link https://en.wikipedia.org/wiki/Kahan_summation_algorithm}
 */
function kahan_sum (summands) {
    let n = summands.length;
    let sum = 0;
    let compensation = 0;
    let y, t;

    for (let i = 0; i < n; ++i) {
        y = summands[i] - compensation;
        t = sum + y;
        compensation = t - sum - y;
        sum = t;
    }
    return sum;
}

/**
 * Numerical stable summation with the Neumair summation algorithm.
 * @memberof module:numerical
 * @alias neumair_sum
 * @param {Number[]} summands - Array of values to sum up.
 * @returns {Number} The sum.
 * @see {@link https://en.wikipedia.org/wiki/Kahan_summation_algorithm#Further_enhancements}
 */
function neumair_sum (summands) {
    const n = summands.length;
    let sum = 0;
    let compensation = 0;

    for (let i = 0; i < n; ++i) {
        const summand = summands[i];
        const t = sum + summand;
        if (Math.abs(sum) >= Math.abs(summand)) {
            compensation += sum - t + summand;
        } else {
            compensation += summand - t + sum;
        }
        sum = t;
    }
    return sum + compensation;
}

/**
 * Computes the squared euclidean distance (l<sub>2</sub><sup>2</sup>) between <code>a</code> and <code>b</code>.
 * @memberof module:metrics
 * @alias euclidean_squared
 * @param {Number[]} a
 * @param {Number[]} b
 * @returns {Number} the squared euclidean distance between <code>a</code> and <code>b</code>.
 */
function euclidean_squared (a, b) {
    if (a.length != b.length) return undefined;
    const n = a.length;
    const s = new Float64Array(n);
    for (let i = 0; i < n; ++i) {
        const x = a[i];
        const y = b[i];
        const x_y = x - y;
        s[i] = x_y * x_y;
    }
    return neumair_sum(s);
}

/**
 * Computes the cosine distance (not similarity) between {@link a} and {@link b}.
 * @memberof module:metrics
 * @alias cosine
 * @param {Number[]} a
 * @param {Number[]} b
 * @returns {Number} The cosine distance between {@link a} and {@link b}.
 * 
 * @example
 * import * as druid from "@saehrimnir/druidjs";
 * 
 * druid.cosine([1,0],[1,1]) == 0.7853981633974484 == π/4;
 * 
 */
function cosine (a, b) {
    if (a.length !== b.length) return undefined;
    let n = a.length;
    let sum = 0;
    let sum_a = 0;
    let sum_b = 0;
    for (let i = 0; i < n; ++i) {
        sum += a[i] * b[i];
        sum_a += a[i] * a[i];
        sum_b += b[i] * b[i];
    }
    return Math.acos(sum / (Math.sqrt(sum_a) * Math.sqrt(sum_b)));
}

/**
 * Computes the manhattan distance (<code>l<sub>1</sub></code>) between <code>a</code> and <code>b</code>.
 * @memberof module:metrics
 * @alias manhattan
 * @param {Array<Number>} a
 * @param {Array<Number>} b
 * @returns {Number} the manhattan distance between <code>a</code> and <code>b</code>.
 */ 
function manhattan (a, b) {
    if (a.length != b.length) return undefined;
    const n = a.length;
    let sum = 0;
    for (let i = 0; i < n; ++i) {
        sum += Math.abs(a[i] - b[i]);
    }
    return sum;
}

/**
 * Computes the chebyshev distance (L<sub>∞</sub>) between {@link a} and {@link b}.
 * @memberof module:metrics
 * @alias chebyshev
 * @param {Number[]} a
 * @param {Number[]} b
 * @returns {Number} the chebyshev distance between {@link a} and {@link b}.
 */
function chebyshev (a, b) {
    if (a.length != b.length) return undefined;
    const n = a.length;
    let res = [];
    for (let i = 0; i < n; ++i) {
        res.push(Math.abs(a[i] - b[i]));
    }
    return Math.max(...res);
}

/**
 * Computes the canberra distance between <code>a</code> and <code>b</code>.
 * @memberof module:metrics
 * @alias canberra
 * @param {Number[]} a 
 * @param {Number[]} b 
 * @returns {Number} the canberra distance between <code>a</code> and <code>b</code>.
 * @see {@link https://en.wikipedia.org/wiki/Canberra_distance}
 */
function canberra(a, b) {
    if (a.length !== b.length) return undefined;
    const n = a.length;
    let sum = 0;
    for (let i = 0; i < n; ++i) {
        sum += (Math.abs(a[i] - b[i]) / (Math.abs(a[i]) + Math.abs(b[i])));
    }
    return sum;
}

/**
 * Computes the jaccard distance between <code>a</code> and <code>b</code>.
 * @memberof module:metrics
 * @alias jaccard
 * @param {Number[]} a
 * @param {Number[]} b
 * @returns {Number} the jaccard distance between <code>a</code> and <code>b</code>.
 */
function jaccard (a, b) {
    if (a.length != b.length) return undefined;
    const n = a.length;
    let num_non_zero = 0;
    let num_equal = 0;
    for (let i = 0; i < n; ++i) {
        const x = a[i] != 0;
        const y = b[i] != 0;
        num_non_zero += x || y;
        num_equal += x && y;
    }
    return (num_non_zero - num_equal) / num_non_zero;
}

/**
 * Computes the hamming distance between <code>a</code> and <code>b</code>.
 * @memberof module:metrics
 * @alias hamming
 * @param {Number[]} a
 * @param {Number[]} b
 * @returns {Number} the hamming distance between <code>a</code> and <code>b</code>.
 */
function hamming (a, b) {
    if (a.length != b.length) return undefined;
    const n = a.length;
    let disagree = 0;
    for (let i = 0; i < n; ++i) {
        const x = a[i];
        const y = b[i];
        disagree += x != y;
    }
    return disagree / n;
}

/**
 * Computes the Sokal-Michener distance between <code>a</code> and <code>b</code>.
 * @memberof module:metrics
 * @alias sokal_michener
 * @param {Number[]} a 
 * @param {Number[]} b 
 * @returns {Number} the Sokal-Michener distance between <code>a</code> and <code>b</code>.  
 */
function sokal_michener(a, b) {
    if (a.length != b.length) return undefined
    const n = a.length;
    let num_not_equal = 0;
    for (let i = 0; i < n; ++i) {
        const x = a[i] != 0;
        const y = b[i] != 0;
        num_not_equal += x != y;
    }
    return (2 * num_not_equal) / (n + num_not_equal);
}

/**
 * Computes the yule distance between <code>a</code> and <code>b</code>.
 * @memberof module:metrics
 * @alias yule
 * @param {Number[]} a
 * @param {Number[]} b
 * @returns {Number} the yule distance between <code>a</code> and <code>b</code>.
 */
function yule (a, b) {
    if (a.length != b.length) return undefined;
    const n = a.length;
    let num_true_true = 0;
    let num_true_false = 0;
    let num_false_true = 0;
    for (let i = 0; i < n; ++i) {
        const x = a[i] != 0;
        const y = b[i] != 0;
        num_true_true += x && y;
        num_true_false += x && !y;
        num_false_true += !x && x;
    }
    const num_false_false = n - num_true_true - num_true_false - num_false_true;
    return num_true_false == 0 || num_false_true == 0 ? 0 : (2 * num_true_false * num_false_true) / (num_true_true * num_false_false + num_true_false * num_false_true);
}

/**
 * Computes the k-nearest neighbors of each row of {@link A}.
 * @memberof module:matrix
 * @alias k_nearest_neigbhors
 * @param {Matrix} A - Either the data matrix, or a distance matrix.
 * @param {Number} k - The number of neighbors to compute.
 * @param {Function|"precomputed"} [metric=euclidean]
 * @returns {Array<Object>} -
 */
function k_nearest_neighbors (A, k, metric = euclidean) {
    const rows = A.shape[0];
    let D = metric == "precomputed" ? A : distance_matrix(A, metric);
    let nN = new Array(rows);
    for (let row = 0; row < rows; ++row) {
        nN[row] = Array.from(D.row(row))
            .map((distance, col) => {
                return {
                    i: row,
                    j: col,
                    distance: distance,
                };
            })
            .sort((a, b) => a.distance - b.distance)
            .slice(1, k + 1);
    }
    return nN;
}

/**
 * Computes the distance matrix of datamatrix {@link A}.
 * @memberof module:matrix
 * @alias distance_matrix
 * @param {Matrix} A - Matrix.
 * @param {Function} [metric=euclidean] - The diistance metric.
 * @returns {Matrix} D - The distance matrix of {@link A}.
 */
function distance_matrix (A, metric = euclidean) {
    let n = A.shape[0];
    const D = new Matrix(n, n);
    for (let i = 0; i < n; ++i) {
        const A_i = A.row(i);
        for (let j = i + 1; j < n; ++j) {
            const dist = metric(A_i, A.row(j));
            D.set_entry(i, j, dist);
            D.set_entry(j, i, dist);
        }
    }
    return D;
}

/**
 * Creates an Array containing {@link number} numbers from {@link start} to {@link end}.
 * If <code>{@link number} = null</null>.
 * @memberof module:matrix
 * @alias linspace
 * @param {Number} start - Start value.
 * @param {Number} end - End value.
 * @param {Number} [number = null] - Number of number between {@link start} and {@link end}.
 * @returns {Array} - An array with {@link number} entries, beginning at {@link start} ending at {@link end}.
 */
function linspace (start, end, number = null) {
    if (!number) {
        number = Math.max(Math.round(end - start) + 1, 1);
    }
    if (number < 2) {
        return number === 1 ? [start] : [];
    }
    let result = new Array(number);
    number -= 1;
    for (let i = number; i >= 0; --i) {
        result[i] = (i * end + (number - i) * start) / number;
    }
    return result;
}

//import { neumair_sum } from "../numerical/index";

/**
 * Computes the norm of a vector, by computing its distance to **0**.
 * @memberof module:matrix
 * @alias norm
 * @param {Matrix|Array<Number>|Float64Array} v - Vector.
 * @param {Function} [metric = euclidean] - Which metric should be used to compute the norm.
 * @returns {Number} - The norm of {@link v}.
 */
function norm (v, metric = euclidean) {
    let vector = null;
    if (v instanceof Matrix) {
        let [rows, cols] = v.shape;
        if (rows === 1) vector = v.row(0);
        else if (cols === 1) vector = v.col(0);
        else throw new Error("Matrix must be 1d!");
    } else {
        vector = v;
    }
    const n = vector.length;
    const zeros = new Float64Array(n);
    return metric(vector, zeros);
}

/**
 * Normalizes Vector {@link v}.
 * @memberof module:matrix
 * @alias normalize
 * @param {Array<Number>|Float64Array} v - Vector
 * @param {Function} metric 
 * @returns {Array<Number>|Float64Array} - The normalized vector with length 1.
 */
function normalize(v, metric = euclidean)  {
    const v_norm = norm(v, metric);
    return v.map(value => value / v_norm);
}

/**
 * Computes the QR Decomposition of the Matrix {@link A} using Gram-Schmidt process.
 * @memberof module:linear_algebra
 * @alias qr
 * @param {Matrix} A
 * @returns {{R: Matrix, Q: Matrix}}
 * @see {@link https://en.wikipedia.org/wiki/QR_decomposition#Using_the_Gram%E2%80%93Schmidt_process}
 */
function qr_gramschmidt (A) {
    const [rows, cols] = A.shape;
    const Q = new Matrix(rows, cols, "identity");
    const R = new Matrix(cols, cols, 0);

    for (let j = 0; j < cols; ++j) {
        let v = A.col(j);
        for (let i = 0; i < j; ++i) {
            const q = Q.col(i);
            const q_dot_v = neumair_sum(q.map((q_, k) => q_ * v[k]));
            R.set_entry(i, j, q_dot_v);
            v = v.map((v_, k) => v_ - q_dot_v * q[k]);
        }
        const v_norm = norm(v, euclidean);
        for (let k = 0; k < rows; ++k) {
            Q.set_entry(k, j, v[k] / v_norm);
        }
        R.set_entry(j, j, v_norm);
    }
    return { R, Q };
}

/**
 * Computes the QR Decomposition of the Matrix {@link A} with householder transformations.
 * @memberof module:linear_algebra
 * @alias qr_householder
 * @param {Matrix} A
 * @returns {{R: Matrix, Q: Matrix}}
 * @see {@link https://en.wikipedia.org/wiki/QR_decomposition#Using_Householder_reflections}
 * @see {@link http://mlwiki.org/index.php/Householder_Transformation}
 */
function qr_householder (A) {
    const [rows, cols] = A.shape;
    const Q = new Matrix(rows, rows, "I");
    const R = A.clone();

    for (let j = 0; j < cols; ++j) {
        const x = Matrix.from(R.col(j).slice(j));
        const x_norm = norm(x);
        const x0 = x.entry(0, 0);
        const rho = -Math.sign(x0);
        const u1 = x0 - rho * x_norm;
        const u = x.divide(u1).set_entry(0, 0, 1);
        const beta = (-rho * u1) / x_norm;

        const u_outer_u = u.outer(u);
        const R_block = R.get_block(j, 0);
        const new_R = R_block.sub(u_outer_u.dot(R_block).mult(beta));
        const Q_block = Q.get_block(0, j);
        const new_Q = Q_block.sub(Q_block.dot(u_outer_u).mult(beta));
        R.set_block(j, 0, new_R);
        Q.set_block(0, j, new_Q);
    }
    return { R, Q };
}

/**
 * Computes the {@link k} biggest Eigenvectors and Eigenvalues from Matrix {@link A} with the QR-Algorithm.
 * @memberof module:linear_algebra
 * @alias simultaneous_poweriteration
 * @param {Matrix} A - The Matrix
 * @param {Number} k - The number of eigenvectors and eigenvalues to compute.
 * @param {Object} parameters - Object containing parameterization of the simultanious poweriteration method.
 * @param {Number} [parameters.max_iterations=100] - The number of maxiumum iterations the algorithm should run.
 * @param {Number|Randomizer} [parameters.seed=1212] - The seed value or a randomizer used in the algorithm.
 * @param {Function} [parameters.qr=qr_gramschmidt] - The QR technique to use.
 * @param {Number} [parameters.tol=1e-8] - Allowed error for stopping criteria
 * @returns {{eigenvalues: Array, eigenvectors: Array}} - The {@link k} biggest eigenvectors and eigenvalues of Matrix {@link A}.
 */
function simultaneous_poweriteration (A, k = 2, {seed = 1212, max_iterations = 100, qr = qr_gramschmidt, tol = 1e-8} = {}) {
    const randomizer = seed instanceof Randomizer ? seed : new Randomizer(seed);
    if (!(A instanceof Matrix)) A = Matrix.from(A);
    const n = A.shape[0];
    let { Q, R } = qr(new Matrix(n, k, () => (randomizer.random - .5) * 2));
    while (max_iterations--) {
        const oldQ = Q.clone();
        const Z = A.dot(Q);
        const QR = qr(Z);
        Q = QR.Q;
        R = QR.R;
        const error = euclidean_squared(Q.values, oldQ.values);
        if (error < tol) {
            break;
        }
    }

    const eigenvalues = R.diag;
    const eigenvectors = Q.transpose().to2dArray;
    return { eigenvalues, eigenvectors };
}

/**
 * Computes the inner product between two arrays of the same length.
 * @memberof module:linear_algebra
 * @alias inner_product
 * @param {Array|Float64Array} a - Array a
 * @param {Array|Float64Array} b - Array b
 * @returns The inner product between {@link a} and {@link b}
 */
function inner_product (a, b) {
    const N = a.length;
    if (N != b.length) {
        throw new Error("Array a and b must have the same length!")
    }
    let sum = 0;
    for (let i = 0; i < N; ++i) {
        sum += a * b;
    }
    return sum;
}

/**
 * @class
 * @alias Matrix
 * @requires module:numerical/neumair_sum
 */
class Matrix {
    /**
     * creates a new Matrix. Entries are stored in a Float64Array.
     * @memberof module:matrix
     * @param {number} rows - The amount of rows of the matrix.
     * @param {number} cols - The amount of columns of the matrix.
     * @param {(function|string|number)} value=0 - Can be a function with row and col as parameters, a number, or "zeros", "identity" or "I", or "center".
     *  - **function**: for each entry the function gets called with the parameters for the actual row and column.
     *  - **string**: allowed are
     *      - "zero", creates a zero matrix.
     *      - "identity" or "I", creates an identity matrix.
     *      - "center", creates an center matrix.
     *  - **number**: create a matrix filled with the given value.
     * @example
     *
     * let A = new Matrix(10, 10, () => Math.random()); //creates a 10 times 10 random matrix.
     * let B = new Matrix(3, 3, "I"); // creates a 3 times 3 identity matrix.
     * @returns {Matrix} returns a {@link rows} times {@link cols} Matrix filled with {@link value}.
     */
    constructor(rows = null, cols = null, value = null) {
        this._rows = rows;
        this._cols = cols;
        this._data = null;
        if (rows && cols) {
            if (!value) {
                this._data = new Float64Array(rows * cols);
                return this;
            }
            if (typeof value === "function") {
                this._data = new Float64Array(rows * cols);
                for (let row = 0; row < rows; ++row) {
                    for (let col = 0; col < cols; ++col) {
                        this._data[row * cols + col] = value(row, col);
                    }
                }
                return this;
            }
            if (typeof value === "string") {
                if (value === "zeros") {
                    return new Matrix(rows, cols, 0);
                }
                if (value === "identity" || value === "I") {
                    this._data = new Float64Array(rows * cols);
                    for (let row = 0; row < rows; ++row) {
                        this._data[row * cols + row] = 1;
                    }
                    return this;
                }
                if (value === "center" && rows == cols) {
                    this._data = new Float64Array(rows * cols);
                    value = (i, j) => (i === j ? 1 : 0) - 1 / rows;
                    for (let row = 0; row < rows; ++row) {
                        for (let col = 0; col < cols; ++col) {
                            this._data[row * cols + col] = value(row, col);
                        }
                    }
                    return this;
                }
            }
            if (typeof value === "number") {
                this._data = new Float64Array(rows * cols);
                for (let row = 0; row < rows; ++row) {
                    for (let col = 0; col < cols; ++col) {
                        this._data[row * cols + col] = value;
                    }
                }
                return this;
            }
            if (typeof value != "undefined" && value instanceof Float64Array) {
                this._data = value;
                return this;
            }
        }
        return this;
    }

    /**
     * Creates a Matrix out of {@link A}.
     * @param {(Matrix|Array|Float64Array|number)} A - The matrix, array, or number, which should converted to a Matrix.
     * @param {"row"|"col"|"diag"} [type = "row"] - If {@link A} is a Array or Float64Array, then type defines if it is a row- or a column vector.
     * @returns {Matrix}
     *
     * @example
     * let A = Matrix.from([[1, 0], [0, 1]]); //creates a two by two identity matrix.
     * let S = Matrix.from([1, 2, 3], "diag"); // creates a 3 by 3 matrix with 1, 2, 3 on its diagonal. [[1, 0, 0], [0, 2, 0], [0, 0, 3]]
     */
    static from(A, type = "row") {
        if (A instanceof Matrix) {
            return A.clone();
        } else if (Array.isArray(A) || A instanceof Float64Array) {
            let m = A.length;
            if (m === 0) throw new Error("Array is empty");
            // 1d
            if (!Array.isArray(A[0]) && !(A[0] instanceof Float64Array)) {
                if (type === "row") {
                    return new Matrix(1, m, (_, j) => A[j]);
                } else if (type === "col") {
                    return new Matrix(m, 1, (i) => A[i]);
                } else if (type === "diag") {
                    return new Matrix(m, m, (i, j) => (i == j ? A[i] : 0));
                } else {
                    throw new Error("1d array has NaN entries");
                }
                // 2d
            } else if (Array.isArray(A[0]) || A[0] instanceof Float64Array) {
                let n = A[0].length;
                for (let row = 0; row < m; ++row) {
                    if (A[row].length !== n) {
                        throw new Error("various array lengths");
                    }
                }
                return new Matrix(m, n, (i, j) => A[i][j]);
            }
        } else if (typeof A === "number") {
            return new Matrix(1, 1, A);
        } else {
            throw new Error("error");
        }
    }

    /**
     * Returns the {@link row}<sup>th</sup> row from the Matrix.
     * @param {Number} row
     * @returns {Float64Array}
     */
    row(row) {
        const data = this.values;
        const cols = this._cols;
        return data.subarray(row * cols, (row + 1) * cols);
    }

    /**
     * Returns an generator yielding each row of the Matrix.
     * @yields {Float64Array}
     */
    *iterate_rows() {
        const cols = this._cols;
        const rows = this._rows;
        const data = this.values;
        for (let row = 0; row < rows; ++row) {
            yield data.subarray(row * cols, (row + 1) * cols);
        }
    }

    /**
     * Makes a {@link Matrix} object an iterable object.
     * @yields {Float64Array}
     */
    *[Symbol.iterator]() {
        for (const row of this.iterate_rows()) {
            yield row;
        }
    }

    /**
     * Sets the entries of {@link row}<sup>th</sup> row from the Matrix to the entries from {@link values}.
     * @param {Number} row
     * @param {Array} values
     * @returns {Matrix}
     */
    set_row(row, values) {
        const cols = this._cols;
        if ((Array.isArray(values) || values instanceof Float64Array) && values.length === cols) {
            const offset = row * cols;
            for (let col = 0; col < cols; ++col) {
                this.values[offset + col] = values[col];
            }
        } else if (values instanceof Matrix && values.shape[1] === cols && values.shape[0] === 1) {
            const offset = row * cols;
            for (let col = 0; col < cols; ++col) {
                this.values[offset + col] = values._data[col];
            }
        } else {
            throw new Error("Values not valid! Needs to be either an Array, a Float64Array, or a fitting Matrix!")
        }
        return this;
    }

    /**
     * Returns the {@link col}<sup>th</sup> column from the Matrix.
     * @param {Number} col
     * @returns {Array}
     */
    col(col) {
        const result_col = new Float64Array(this._rows);
        for (let row = 0; row < this._rows; ++row) {
            result_col[row] = this.values[row * this._cols + col];
        }
        return result_col;
    }

    /**
     * Returns the {@link col}<sup>th</sup> entry from the {@link row}<sup>th</sup> row of the Matrix.
     * @param {int} row
     * @param {int} col
     * @returns {float64}
     */
    entry(row, col) {
        return this.values[row * this._cols + col];
    }

    /**
     * Sets the {@link col}<sup>th</sup> entry from the {@link row}<sup>th</sup> row of the Matrix to the given {@link value}.
     * @param {int} row
     * @param {int} col
     * @param {float64} value
     * @returns {Matrix}
     */
    set_entry(row, col, value) {
        this.values[row * this._cols + col] = value;
        return this;
    }

    /**
     * Returns a new transposed Matrix.
     * @returns {Matrix}
     */
    transpose() {
        let B = new Matrix(this._cols, this._rows, (row, col) => this.entry(col, row));
        return B;
    }

    /**
     * Returns a new transposed Matrix. Short-form of {@function transpose}.
     * @returns {Matrix}
     */
    get T() {
        return this.transpose();
    }

    /**
     * Returns the inverse of the Matrix.
     * @returns {Matrix}
     */
    inverse() {
        const rows = this._rows;
        const cols = this._cols;
        let B = new Matrix(rows, 2 * cols, (i, j) => {
            if (j >= cols) {
                return i === j - cols ? 1 : 0;
            } else {
                return this.entry(i, j);
            }
        });
        let h = 0;
        let k = 0;
        while (h < rows && k < cols) {
            var i_max = 0;
            let max_val = -Infinity;
            for (let i = h; i < rows; ++i) {
                let val = Math.abs(B.entry(i, k));
                if (max_val < val) {
                    i_max = i;
                    max_val = val;
                }
            }
            if (B.entry(i_max, k) == 0) {
                k++;
            } else {
                // swap rows
                for (let j = 0; j < 2 * cols; ++j) {
                    let h_val = B.entry(h, j);
                    let i_val = B.entry(i_max, j);
                    B.set_entry(h, j, h_val);
                    B.set_entry(i_max, j, i_val);
                }
                for (let i = h + 1; i < rows; ++i) {
                    let f = B.entry(i, k) / B.entry(h, k);
                    B.set_entry(i, k, 0);
                    for (let j = k + 1; j < 2 * cols; ++j) {
                        B.set_entry(i, j, B.entry(i, j) - B.entry(h, j) * f);
                    }
                }
                h++;
                k++;
            }
        }

        for (let row = 0; row < rows; ++row) {
            let f = B.entry(row, row);
            for (let col = row; col < 2 * cols; ++col) {
                B.set_entry(row, col, B.entry(row, col) / f);
            }
        }

        for (let row = rows - 1; row >= 0; --row) {
            let B_row_row = B.entry(row, row);
            for (let i = 0; i < row; i++) {
                let B_i_row = B.entry(i, row);
                let f = B_i_row / B_row_row;
                for (let j = i; j < 2 * cols; ++j) {
                    let B_i_j = B.entry(i, j);
                    let B_row_j = B.entry(row, j);
                    B_i_j = B_i_j - B_row_j * f;
                    B.set_entry(i, j, B_i_j);
                }
            }
        }

        return new Matrix(rows, cols, (i, j) => B.entry(i, j + cols));
    }

    /**
     * Returns the dot product. If {@link B} is an Array or Float64Array then an Array gets returned. If {@link B} is a Matrix then a Matrix gets returned.
     * @param {(Matrix|Array|Float64Array)} B the right side
     * @returns {(Matrix|Array)}
     */
    dot(B) {
        if (B instanceof Matrix) {
            let A = this;
            if (A.shape[1] !== B.shape[0]) {
                throw new Error(`A.dot(B): A is a ${A.shape.join(" ⨯ ")}-Matrix, B is a ${B.shape.join(" ⨯ ")}-Matrix: 
                A has ${A.shape[1]} cols and B ${B.shape[0]} rows. 
                Must be equal!`);
            }
            let I = A.shape[1];
            let C = new Matrix(A.shape[0], B.shape[1], (row, col) => {
                const A_i = A.row(row);
                const B_i = B.col(col);
                let sum = 0;
                for (let i = 0; i < I; ++i) {
                    sum += A_i[i] * B_i[i];
                }
                return sum;
            });
            return C;
        } else if (Array.isArray(B) || B instanceof Float64Array) {
            let rows = this._rows;
            if (B.length !== rows) {
                throw new Error(`A.dot(B): A has ${rows} cols and B has ${B.length} rows. Must be equal!`);
            }
            let C = new Array(rows);
            for (let row = 0; row < rows; ++row) {
                C[row] = neumair_sum(this.row(row).map((e) => e * B[row]));
            }
            return C;
        } else {
            throw new Error(`B must be Matrix or Array`);
        }
    }

    /**
     * Computes the outer product from {@link this} and {@link B}.
     * @param {Matrix} B
     * @returns {Matrix}
     */
    outer(B) {
        let A = this;
        let l = A._data.length;
        let r = B._data.length;
        if (l != r) return undefined;
        let C = new Matrix();
        C.shape = [
            l,
            l,
            (i, j) => {
                if (i <= j) {
                    return A._data[i] * B._data[j];
                } else {
                    return C.entry(j, i);
                }
            },
        ];
        return C;
    }

    /**
     * Appends matrix {@link B} to the matrix.
     * @param {Matrix} B - matrix to append.
     * @param {"horizontal"|"vertical"|"diag"} [type = "horizontal"] - type of concatenation.
     * @returns {Matrix}
     * @example
     *
     * let A = Matrix.from([[1, 1], [1, 1]]); // 2 by 2 matrix filled with ones.
     * let B = Matrix.from([[2, 2], [2, 2]]); // 2 by 2 matrix filled with twos.
     *
     * A.concat(B, "horizontal"); // 2 by 4 matrix. [[1, 1, 2, 2], [1, 1, 2, 2]]
     * A.concat(B, "vertical"); // 4 by 2 matrix. [[1, 1], [1, 1], [2, 2], [2, 2]]
     * A.concat(B, "diag"); // 4 by 4 matrix. [[1, 1, 0, 0], [1, 1, 0, 0], [0, 0, 2, 2], [0, 0, 2, 2]]
     */
    concat(B, type = "horizontal") {
        const A = this;
        const [rows_A, cols_A] = A.shape;
        const [rows_B, cols_B] = B.shape;
        if (type == "horizontal") {
            if (rows_A != rows_B) {
                throw new Error(`A.concat(B, "horizontal"): A and B need same number of rows, A has ${rows_A} rows, B has ${rows_B} rows.`);
            }
            const X = new Matrix(rows_A, cols_A + cols_B, "zeros");
            X.set_block(0, 0, A);
            X.set_block(0, cols_A, B);
            return X;
        } else if (type == "vertical") {
            if (cols_A != cols_B) {
                throw new Error(`A.concat(B, "vertical"): A and B need same number of columns, A has ${cols_A} columns, B has ${cols_B} columns.`);
            }
            const X = new Matrix(rows_A + rows_B, cols_A, "zeros");
            X.set_block(0, 0, A);
            X.set_block(rows_A, 0, B);
            return X;
        } else if (type == "diag") {
            const X = new Matrix(rows_A + rows_B, cols_A + cols_B, "zeros");
            X.set_block(0, 0, A);
            X.set_block(rows_A, cols_A, B);
            return X;
        } else {
            throw new Error(`type must be "horizontal" or "vertical", but type is ${type}!`);
        }
    }

    /**
     * Writes the entries of B in A at an offset position given by {@link offset_row} and {@link offset_col}.
     * @param {int} offset_row
     * @param {int} offset_col
     * @param {Matrix} B
     * @returns {Matrix}
     */
    set_block(offset_row, offset_col, B) {
        let [rows, cols] = B.shape;
        for (let row = 0; row < rows; ++row) {
            if (row > this._rows) {
                continue;
            }
            for (let col = 0; col < cols; ++col) {
                if (col > this._cols) {
                    continue;
                }
                this.set_entry(row + offset_row, col + offset_col, B.entry(row, col));
            }
        }
        return this;
    }

    /**
     * Extracts the entries from the {@link start_row}<sup>th</sup> row to the {@link end_row}<sup>th</sup> row, the {@link start_col}<sup>th</sup> column to the {@link end_col}<sup>th</sup> column of the matrix.
     * If {@link end_row} or {@link end_col} is empty, the respective value is set to {@link this.rows} or {@link this.cols}.
     * @param {Number} start_row
     * @param {Number} start_col
     * @param {Number} [end_row = null]
     * @param {Number} [end_col = null]
     * @returns {Matrix} Returns a end_row - start_row times end_col - start_col matrix, with respective entries from the matrix.
     * @example
     *
     * let A = Matrix.from([[1, 2, 3], [4, 5, 6], [7, 8, 9]]); // a 3 by 3 matrix.
     *
     * A.get_block(1, 1); // [[5, 6], [8, 9]]
     * A.get_block(0, 0, 1, 1); // [[1]]
     * A.get_block(1, 1, 2, 2); // [[5]]
     * A.get_block(0, 0, 2, 2); // [[1, 2], [4, 5]]
     */
    get_block(start_row, start_col, end_row = null, end_col = null) {
        const [rows, cols] = this.shape;
        end_row = LOR(end_row ,rows);
        end_col = LOR(end_col ,cols);
        if (end_row <= start_row || end_col <= start_col) {
            throw new Error(`
                end_row must be greater than start_row, and 
                end_col must be greater than start_col, but
                end_row = ${end_row}, start_row = ${start_row}, end_col = ${end_col}, and start_col = ${start_col}!`);
        }
        const X = new Matrix(end_row - start_row, end_col - start_col, "zeros");
        for (let row = start_row, new_row = 0; row < end_row; ++row, ++new_row) {
            for (let col = start_col, new_col = 0; col < end_col; ++col, ++new_col) {
                X.set_entry(new_row, new_col, this.entry(row, col));
            }
        }
        return X;
        //return new Matrix(end_row - start_row, end_col - start_col, (i, j) => this.entry(i + start_row, j + start_col));
    }

    /**
     * Returns a new array gathering entries defined by the indices given by argument.
     * @param {Array<Number>} row_indices - Array consists of indices of rows for gathering entries of this matrix
     * @param {Array<Number>} col_indices  - Array consists of indices of cols for gathering entries of this matrix
     * @returns {Matrix}
     */
    gather(row_indices, col_indices) {
        const N = row_indices.length;
        const D = col_indices.length;

        const R = new Matrix(N, D);
        for (let i = 0; i < N; ++i) {
            const row_index = row_indices[i];
            for (let j = 0; j < N; ++j) {
                const col_index = col_indices[j];
                R.set_entry(i, j, this.entry(row_index, col_index));
            }
        }

        return R;
    }

    /**
     * Applies a function to each entry of the matrix.
     * @private
     * @param {Function} f function takes 2 parameters, the value of the actual entry and a value given by the function {@link v}. The result of {@link f} gets writen to the Matrix.
     * @param {Function} v function takes 2 parameters for row and col, and returns a value witch should be applied to the colth entry of the rowth row of the matrix.
     */
    _apply_array(f, v) {
        const data = this.values;
        const [rows, cols] = this.shape;
        for (let row = 0; row < rows; ++row) {
            const offset = row * cols;
            for (let col = 0; col < cols; ++col) {
                const i = offset + col;
                data[i] = f(data[i], v(row, col));
            }
        }
        return this;
    }

    _apply_rowwise_array(values, f) {
        return this._apply_array(f, (_, j) => values[j]);
    }

    _apply_colwise_array(values, f) {
        const data = this.values;
        const [rows, cols] = this.shape;
        for (let row = 0; row < rows; ++row) {
            const offset = row * cols;
            for (let col = 0; col < cols; ++col) {
                const i = offset + col;
                data[i] = f(data[i], values[row]);
            }
        }
        return this;
    }

    _apply(value, f) {
        let data = this.values;
        if (value instanceof Matrix) {
            let [value_rows, value_cols] = value.shape;
            let [rows, cols] = this.shape;
            if (value_rows === 1) {
                if (cols !== value_cols) {
                    throw new Error(`cols !== value_cols`);
                }
                for (let row = 0; row < rows; ++row) {
                    for (let col = 0; col < cols; ++col) {
                        data[row * cols + col] = f(data[row * cols + col], value.entry(0, col));
                    }
                }
            } else if (value_cols === 1) {
                if (rows !== value_rows) {
                    throw new Error(`rows !== value_rows`);
                }
                for (let row = 0; row < rows; ++row) {
                    for (let col = 0; col < cols; ++col) {
                        data[row * cols + col] = f(data[row * cols + col], value.entry(row, 0));
                    }
                }
            } else if (rows == value_rows && cols == value_cols) {
                for (let row = 0; row < rows; ++row) {
                    for (let col = 0; col < cols; ++col) {
                        data[row * cols + col] = f(data[row * cols + col], value.entry(row, col));
                    }
                }
            } else {
                throw new Error(`error`);
            }
        } else if (Array.isArray(value)) {
            let rows = this._rows;
            let cols = this._cols;
            if (value.length === rows) {
                for (let row = 0; row < rows; ++row) {
                    for (let col = 0; col < cols; ++col) {
                        data[row * cols + col] = f(data[row * cols + col], value[row]);
                    }
                }
            } else if (value.length === cols) {
                for (let row = 0; row < rows; ++row) {
                    for (let col = 0; col < cols; ++col) {
                        data[row * cols + col] = f(data[row * cols + col], value[col]);
                    }
                }
            } else {
                throw new Error(`error`);
            }
        } else {
            for (let i = 0, n = this._rows * this._cols; i < n; ++i) {
                data[i] = f(data[i], value);
            }
        }
        return this;
    }

    /**
     * Clones the Matrix.
     * @returns {Matrix}
     */
    clone() {
        let B = new Matrix();
        B._rows = this._rows;
        B._cols = this._cols;
        B._data = this.values.slice(0);
        return B;
    }

    /**
     * Entrywise multiplication with {@link value}.
     * @param {Matrix|Array|Number} value
     * @param {Object} [options]
     * @param {Boolean} [options.inline = false]  - If true, applies multiplication to the element, otherwise it creates first a copy and applies the multiplication on the copy.
     * @returns {Matrix}
     * @example
     *
     * let A = Matrix.from([[1, 2], [3, 4]]); // a 2 by 2 matrix.
     * let B = A.clone(); // B == A;
     *
     * A.mult(2); // [[2, 4], [6, 8]];
     * A.mult(B); // [[1, 4], [9, 16]];
     */
    mult(value, { inline = false } = {}) {
        const A = inline ? this : this.clone();
        return A._apply(value, (a, b) => a * b);
    }

    /**
     * Entrywise division with {@link value}.
     * @param {Matrix|Array|Number} value
     * @param {Object} [options]
     * @param {Boolean} [options.inline = false] - If true, applies division to the element, otherwise it creates first a copy and applies the division on the copy.
     * @returns {Matrix}
     * @example
     *
     * let A = Matrix.from([[1, 2], [3, 4]]); // a 2 by 2 matrix.
     * let B = A.clone(); // B == A;
     *
     * A.divide(2); // [[0.5, 1], [1.5, 2]];
     * A.divide(B); // [[1, 1], [1, 1]];
     */
    divide(value, { inline = false } = {}) {
        const A = inline ? this : this.clone();
        return A._apply(value, (a, b) => a / b);
    }

    /**
     * Entrywise addition with {@link value}.
     * @param {Matrix|Array|Number} value
     * @param {Object} [options]
     * @param {Boolean} [options.inline = false]  - If true, applies addition to the element, otherwise it creates first a copy and applies the addition on the copy.
     * @returns {Matrix}
     * @example
     *
     * let A = Matrix.from([[1, 2], [3, 4]]); // a 2 by 2 matrix.
     * let B = A.clone(); // B == A;
     *
     * A.add(2); // [[3, 4], [5, 6]];
     * A.add(B); // [[2, 4], [6, 8]];
     */
    add(value, {inline = false} = {}) {
        const A = inline ? this : this.clone();
        return A._apply(value, (a, b) => a + b);
    }

    /**
     * Entrywise subtraction with {@link value}.
     * @param {Matrix|Array|Number} value
     * @param {Object} [options]
     * @param {Boolean} [options.inline = false] - If true, applies subtraction to the element, otherwise it creates first a copy and applies the subtraction on the copy.
     * @returns {Matrix}
     * @example
     *
     * let A = Matrix.from([[1, 2], [3, 4]]); // a 2 by 2 matrix.
     * let B = A.clone(); // B == A;
     *
     * A.sub(2); // [[-1, 0], [1, 2]];
     * A.sub(B); // [[0, 0], [0, 0]];
     */
    sub(value, { inline = false } = {}) {
        const A = inline ? this : this.clone();
        return A._apply(value, (a, b) => a - b);
    }

    /**
     * Returns the number of rows and columns of the Matrix.
     * @returns {Array} An Array in the form [rows, columns].
     */
    get shape() {
        return [this._rows, this._cols];
    }

    /**
     * Returns the matrix in the given shape with the given function which returns values for the entries of the matrix.
     * @param {Array} parameter - takes an Array in the form [rows, cols, value], where rows and cols are the number of rows and columns of the matrix, and value is a function which takes two parameters (row and col) which has to return a value for the colth entry of the rowth row.
     * @returns {Matrix}
     */
    set shape([rows, cols, value = () => 0]) {
        this._rows = rows;
        this._cols = cols;
        this._data = new Float64Array(rows * cols);
        for (let row = 0; row < rows; ++row) {
            for (let col = 0; col < cols; ++col) {
                this._data[row * cols + col] = value(row, col);
            }
        }
        return this;
    }

    /**
     * Returns the Matrix as a Array of Float64Arrays.
     * @returns {Array<Float64Array>}
     */
    get to2dArray() {
        const result = [];
        for (const row of this.iterate_rows()) {
            result.push(row);
        }
        return result;
    }

    /**
     * Returns the Matrix as a Array of Arrays.
     * @returns {Array<Array>}
     */
    get asArray() {
        const result = [];
        for (const row of this.iterate_rows()) {
            result.push(Array.from(row));
        }
        return result;
    }

    /**
     * Returns the diagonal of the Matrix.
     * @returns {Float64Array}
     */
    get diag() {
        const rows = this._rows;
        const cols = this._cols;
        const min_row_col = Math.min(rows, cols);
        let result = new Float64Array(min_row_col);
        for (let i = 0; i < min_row_col; ++i) {
            result[i] = this.entry(i, i);
        }
        return result;
    }

    /**
     * Returns the mean of all entries of the Matrix.
     * @returns {Number}
     */
    get mean() {
        const sum = this.sum;
        const n = this._rows * this._cols;
        return sum / n;
    }

    /**
     * Returns the sum oof all entries of the Matrix.
     * @returns {Number}
     */
    get sum() {
        const data = this.values;
        return neumair_sum(data);
    }

    /**
     * Returns the sum oof all entries of the Matrix.
     * @returns {Float64Array}
     */
    get values() {
        const data = this._data;
        return data;
    }

    /**
     * Returns the mean of each row of the matrix.
     * @returns {Float64Array}
     */
    get meanRows() {
        const data = this.values;
        const rows = this._rows;
        const cols = this._cols;
        const result = Float64Array.from({ length: rows });
        for (let row = 0; row < rows; ++row) {
            result[row] = 0;
            for (let col = 0; col < cols; ++col) {
                result[row] += data[row * cols + col];
            }
            result[row] /= cols;
        }
        return result;
    }

    /** Returns the mean of each column of the matrix.
     * @returns {Float64Array}
     */
    get meanCols() {
        const data = this.values;
        const rows = this._rows;
        const cols = this._cols;
        const result = Float64Array.from({ length: cols });
        for (let col = 0; col < cols; ++col) {
            result[col] = 0;
            for (let row = 0; row < rows; ++row) {
                result[col] += data[row * cols + col];
            }
            result[col] /= rows;
        }
        return result;
    }

    /**
     * Solves the equation {@link A}x = {@link b} using the conjugate gradient method. Returns the result x.
     * @param {Matrix} A - Matrix
     * @param {Matrix} b - Matrix
     * @param {Randomizer} [randomizer=null]
     * @param {Number} [tol=1e-3]
     * @returns {Matrix}
     */
    static solve_CG(A, b, randomizer, tol = 1e-3) {
        if (randomizer === null) {
            randomizer = new Randomizer();
        }
        const rows = A.shape[0];
        const cols = b.shape[1];
        let result = new Matrix(rows, 0);
        for (let i = 0; i < cols; ++i) {
            const b_i = Matrix.from(b.col(i)).T;
            let x = new Matrix(rows, 1, () => randomizer.random);
            let r = b_i.sub(A.dot(x));
            let d = r.clone();
            do {
                const z = A.dot(d);
                const alpha = r.T.dot(r).entry(0, 0) / d.T.dot(z).entry(0, 0);
                x = x.add(d.mult(alpha));
                const r_next = r.sub(z.mult(alpha));
                const beta = r_next.T.dot(r_next).entry(0, 0) / r.T.dot(r).entry(0, 0);
                d = r_next.add(d.mult(beta));
                r = r_next;
            } while (Math.abs(r.mean) > tol);
            result = result.concat(x, "horizontal");
        }
        return result;
    }

    /**
     * Solves the equation {@link A}x = {@link b}. Returns the result x.
     * @param {Matrix} A - Matrix or LU Decomposition
     * @param {Matrix} b - Matrix
     * @returns {Matrix}
     */
    static solve(A, b) {
        let { L: L, U: U } = "L" in A && "U" in A ? A : Matrix.LU(A);
        let rows = L.shape[0];
        let x = b.clone();

        // forward
        for (let row = 0; row < rows; ++row) {
            for (let col = 0; col < row - 1; ++col) {
                x.set_entry(0, row, x.entry(0, row) - L.entry(row, col) * x.entry(1, col));
            }
            x.set_entry(0, row, x.entry(0, row) / L.entry(row, row));
        }

        // backward
        for (let row = rows - 1; row >= 0; --row) {
            for (let col = rows - 1; col > row; --col) {
                x.set_entry(0, row, x.entry(0, row) - U.entry(row, col) * x.entry(0, col));
            }
            x.set_entry(0, row, x.entry(0, row) / U.entry(row, row));
        }

        return x;
    }

    /**
     * {@link L}{@link U} decomposition of the Matrix {@link A}. Creates two matrices, so that the dot product LU equals A.
     * @param {Matrix} A
     * @returns {{L: Matrix, U: Matrix}} result - Returns the left triangle matrix {@link L} and the upper triangle matrix {@link U}.
     */
    static LU(A) {
        const rows = A.shape[0];
        const L = new Matrix(rows, rows, "zeros");
        const U = new Matrix(rows, rows, "identity");

        for (let j = 0; j < rows; ++j) {
            for (let i = j; i < rows; ++i) {
                let sum = 0;
                for (let k = 0; k < j; ++k) {
                    sum += L.entry(i, k) * U.entry(k, j);
                }
                L.set_entry(i, j, A.entry(i, j) - sum);
            }
            for (let i = j; i < rows; ++i) {
                if (L.entry(j, j) === 0) {
                    return undefined;
                }
                let sum = 0;
                for (let k = 0; k < j; ++k) {
                    sum += L.entry(j, k) * U.entry(k, i);
                }
                U.set_entry(j, i, (A.entry(j, i) - sum) / L.entry(j, j));
            }
        }

        return { L: L, U: U };
    }

    /**
     * Computes the determinante of {@link A}, by using the LU decomposition of {@link A}.
     * @param {Matrix} A
     * @returns {Number} det - Returns the determinate of the Matrix {@link A}.
     */
    static det(A) {
        const rows = A.shape[0];
        const { L, U } = Matrix.LU(A);
        const L_diag = L.diag;
        const U_diag = U.diag;
        let det = L_diag[0] * U_diag[0];
        for (let row = 1; row < rows; ++row) {
            det *= L_diag[row] * U_diag[row];
        }
        return det;
    }

    /**
     * Computes the {@link k} components of the SVD decomposition of the matrix {@link M}
     * @param {Matrix} M
     * @param {int} [k=2]
     * @returns {{U: Matrix, Sigma: Matrix, V: Matrix}}
     */
    static SVD(M, k = 2) {
        const MT = M.T;
        let MtM = MT.dot(M);
        let MMt = M.dot(MT);
        let { eigenvectors: V, eigenvalues: Sigma } = simultaneous_poweriteration(MtM, k);
        let { eigenvectors: U } = simultaneous_poweriteration(MMt, k);
        return { U: U, Sigma: Sigma.map((sigma) => Math.sqrt(sigma)), V: V };

        //Algorithm 1a: Householder reduction to bidiagonal form:
        /* const [m, n] = A.shape;
        let U = new Matrix(m, n, (i, j) => i == j ? 1 : 0);
        console.log(U.to2dArray)
        let V = new Matrix(n, m, (i, j) => i == j ? 1 : 0);
        console.log(V.to2dArray)
        let B = Matrix.bidiagonal(A.clone(), U, V);
        console.log(U,V,B)
        return { U: U, "Sigma": B, V: V }; */
    }
}

/**
 * @class
 * @memberof module:utils
 * @alias Randomizer
 */
class Randomizer {
    /**
     * Mersenne Twister random number generator.
     * @constructor
     * @param {Number} [_seed=new Date().getTime()] - The seed for the random number generator. If <code>_seed == null</code> then the actual time gets used as seed.
     * @see https://github.com/bmurray7/mersenne-twister-examples/blob/master/javascript-mersenne-twister.js
     */
    constructor(_seed) {
        this._N = 624;
        this._M = 397;
        this._MATRIX_A = 0x9908b0df;
        this._UPPER_MASK = 0x80000000;
        this._LOWER_MASK = 0x7fffffff;
        this._mt = new Array(this._N);
        this._mti = this.N + 1;

        this.seed = _seed || new Date().getTime();
        return this;
    }

    set seed(_seed) {
        this._seed = _seed;
        let mt = this._mt;

        mt[0] = _seed >>> 0;
        for (this._mti = 1; this._mti < this._N; this._mti += 1) {
            let mti = this._mti;
            let s = mt[mti - 1] ^ (mt[mti - 1] >>> 30);
            mt[mti] = ((((s & 0xffff0000) >>> 16) * 1812433253) << 16) + (s & 0x0000ffff) * 1812433253 + mti;
            mt[mti] >>>= 0;
        }
    }

    /**
     * Returns the seed of the random number generator.
     * @returns {Number} - The seed.
     */
    get seed() {
        return this._seed;
    }

    /**
     * Returns a float between 0 and 1.
     * @returns {Number} - A random number between [0, 1]
     */
    get random() {
        return this.random_int * (1.0 / 4294967296.0);
    }

    /**
     * Returns an integer between 0 and MAX_INTEGER.
     * @returns {Integer} - A random integer.
     */
    get random_int() {
        let y,
            mag01 = new Array(0x0, this._MATRIX_A);
        if (this._mti >= this._N) {
            let kk;

            /* if (this._mti == this._N + 1) {
                this.seed = 5489;
            } */

            let N_M = this._N - this._M;
            let M_N = this._M - this._N;

            for (kk = 0; kk < N_M; ++kk) {
                y = (this._mt[kk] & this._UPPER_MASK) | (this._mt[kk + 1] & this._LOWER_MASK);
                this._mt[kk] = this._mt[kk + this._M] ^ (y >>> 1) ^ mag01[y & 0x1];
            }
            for (; kk < this._N - 1; ++kk) {
                y = (this._mt[kk] & this._UPPER_MASK) | (this._mt[kk + 1] & this._LOWER_MASK);
                this._mt[kk] = this._mt[kk + M_N] ^ (y >>> 1) ^ mag01[y & 0x1];
            }

            y = (this._mt[this._N - 1] & this._UPPER_MASK) | (this._mt[0] & this._LOWER_MASK);
            this._mt[this._N - 1] = this._mt[this._M - 1] ^ (y >>> 1) ^ mag01[y & 0x1];

            this._mti = 0;
        }

        y = this._mt[(this._mti += 1)];
        y ^= y >>> 11;
        y ^= (y << 7) & 0x9d2c5680;
        y ^= (y << 15) & 0xefc60000;
        y ^= y >>> 18;

        return y >>> 0;
    }

    /**
     * Returns samples from an input Matrix or Array.
     * @param {Matrix|Array|Float64Array} A - The input Matrix or Array.
     * @param {Number} n - The number of samples.
     * @returns {Array} - A random selection form {@link A} of {@link n} samples.
     */
    choice(A, n) {
        if (A instanceof Matrix) {
            let rows = A.shape[0];
            if (n > rows) {
                throw new Error("n bigger than A!");
            }
            let sample = new Array(n);
            let index_list = linspace(0, rows - 1);
            for (let i = 0, l = index_list.length; i < n; ++i, --l) {
                let random_index = this.random_int % l;
                sample[i] = index_list.splice(random_index, 1)[0];
            }
            return sample.map((d) => A.row(d));
        } else if (Array.isArray(A) || A instanceof Float64Array) {
            let rows = A.length;
            if (n > rows) {
                throw new Error("n bigger than A!");
            }
            let sample = new Array(n);
            let index_list = linspace(0, rows - 1);
            for (let i = 0, l = index_list.length; i < n; ++i, --l) {
                let random_index = this.random_int % l;
                sample[i] = index_list.splice(random_index, 1)[0];
            }
            return sample.map((d) => A[d]);
        }
    }

    /**
     * @static
     * Returns samples from an input Matrix or Array.
     * @param {Matrix|Array|Float64Array} A - The input Matrix or Array.
     * @param {Number} n - The number of samples.
     * @param {Number} seed - The seed for the random number generator.
     * @returns {Array} - A random selection form {@link A} of {@link n} samples.
     */
    static choice(A, n, seed = 1212) {
        const R = new Randomizer(seed);
        return R.choice(A, n);
        /* let rows = A.shape[0];
        if (n > rows) {
            throw new Error("n bigger than A!");
        }
        let rand = new Randomizer(seed);
        let sample = new Array(n);
        let index_list = linspace(0, rows - 1);
        for (let i = 0, l = index_list.length; i < n; ++i, --l) {
            let random_index = rand.random_int % l;
            sample[i] = index_list.splice(random_index, 1)[0];
        }
        //return result;
        //return new Matrix(n, cols, (row, col) => A.entry(sample[row], col))
        return sample.map((d) => A.row(d)); */
    }
}

/**
 * Returns maximum in Array {@link values}.
 * @memberof module:utils
 * @alias max
 * @param {Array} values 
 * @returns {Number}
 */
function max (values) {
    let max;
    for (const value of values) {
        if (value != null && (max < value || (max === undefined && value >= value))) {
            max = value;
        }
    }
    return max;
}

/**
 * Returns maximum in Array {@link values}.
 * @memberof module:utils
 * @alias min
 * @param {Array} values
 * @returns {Number}
 */
function min (values) {
    let min;
    for (const value of values) {
        if (value != null && (min > value || (min === undefined && value <= value))) {
            min = value;
        }
    }
    return min;
}

/**
 * @class
 * @alias Heap
 */
class Heap {
    /**
     * A heap is a datastructure holding its elements in a specific way, so that the top element would be the first entry of an ordered list.
     * @constructor
     * @memberof module:datastructure
     * @alias Heap
     * @param {Array=} elements - Contains the elements for the Heap. {@link elements} can be null.
     * @param {Function} [accessor = (d) => d] - Function returns the value of the element.
     * @param {("min"|"max"|Function)} [comparator = "min"] - Function returning true or false defining the wished order of the Heap, or String for predefined function. ("min" for a Min-Heap, "max" for a Max_heap)
     * @returns {Heap}
     * @see {@link https://en.wikipedia.org/wiki/Binary_heap}
     */
    constructor(elements = null, accessor = d => d, comparator = "min") {
        if (elements) {
            return Heap.heapify(elements, accessor, comparator);
        } else {
            this._accessor = accessor;
            this._container = [];
            if (comparator == "min") {
                this._comparator = (a, b) => a < b;
            } else if (comparator == "max") {
                this._comparator = (a, b) => a > b;
            } else {
                this._comparator = comparator;
            }
            return this
        }
    }

    /**
     * Creates a Heap from an Array
     * @param {Array|Set} elements - Contains the elements for the Heap.
     * @param {Function=} [accessor = (d) => d] - Function returns the value of the element.
     * @param {(String=|Function)} [comparator = "min"] - Function returning true or false defining the wished order of the Heap, or String for predefined function. ("min" for a Min-Heap, "max" for a Max_heap)
     * @returns {Heap}
     */
    static heapify(elements, accessor = d => d, comparator = "min") {
        const heap = new Heap(null, accessor, comparator);
        const container = heap._container;
        for (const e of elements) {
            container.push({
                "element": e,
                "value": accessor(e),
            });
        }
        for (let i = Math.floor((elements.length / 2) - 1); i >= 0; --i) {
            heap._heapify_down(i);
        }
        return heap;
    }

    /**
     * Swaps elements of container array.
     * @private
     * @param {Number} index_a 
     * @param {Number} index_b 
     */
    _swap(index_a, index_b) {
        const container = this._container;
        [container[index_b], container[index_a]] = [container[index_a], container[index_b]];
        return;
    }

    /**
     * @private
     */
    _heapify_up() {
        const container = this._container;
        let index = container.length - 1;
        while (index > 0) {
            let parentIndex = Math.floor((index - 1) / 2);
            if (!this._comparator(container[index].value, container[parentIndex].value)) {
                break;
            } else {
            this._swap(parentIndex, index);
            index = parentIndex;
            }
        }
    }

    /**
     * Pushes the element to the heap.
     * @param {} element
     * @returns {Heap}
     */
    push(element) {
        const value = this._accessor(element);
        //const node = new Node(element, value);
        const node = {"element": element, "value": value};
        this._container.push(node);
        this._heapify_up();
        return this;
    }

    /**
     * @private
     * @param {Number} [start_index = 0] 
     */
    _heapify_down(start_index=0) {
        const container = this._container;
        const comparator = this._comparator;
        const length = container.length;
        let left = 2 * start_index + 1;
        let right = 2 * start_index + 2;
        let index = start_index;
        if (index > length) throw "index higher than length"
        if (left < length && comparator(container[left].value, container[index].value)) {
            index = left;
        }
        if (right < length && comparator(container[right].value, container[index].value)) {
            index = right;
        }
        if (index !== start_index) {
            this._swap(start_index, index);
            this._heapify_down(index);
        }
    }

    /**
     * Removes and returns the top entry of the heap.
     * @returns {Object} Object consists of the element and its value (computed by {@link accessor}).
     */
    pop() {
        const container = this._container;
        if (container.length === 0) {
            return null;
        } else if (container.length === 1) {
            return container.pop();
        }
        this._swap(0, container.length - 1);
        const item = container.pop();
        this._heapify_down();
        return item;
    }

    /**
     * Returns the top entry of the heap without removing it.
     * @returns {Object} Object consists of the element and its value (computed by {@link accessor}).
     */
    get first() {
        return this._container.length > 0 ? this._container[0] : null;
    }


    /**
     * Yields the raw data
     * @yields {Object} Object consists of the element and its value (computed by {@link accessor}).
     */
    * iterate() {
        for (let i = 0, n = this._container.length; i < n; ++i) {
            yield this._container[i].element;
        }
    }

    /**
     * Returns the heap as ordered array.
     * @returns {Array} Array consisting the elements ordered by {@link comparator}.
     */
    toArray() {
        return this.data()
            .sort((a,b) => this._comparator(a, b) ? -1 : 0)
    }

    /**
     * Returns elements of container array.
     * @returns {Array} Array consisting the elements.
     */
    data() {
        return this._container
            .map(d => d.element)
    }

    /**
     * Returns the container array.
     * @returns {Array} The container array.
     */
    raw_data() {
        return this._container;
    }

    /**
     * The size of the heap.
     * @returns {Number}
     */
    get length() {
        return this._container.length;
    }

    /**
     * Returns false if the the heap has entries, true if the heap has no entries.
     * @returns {Boolean}
     */
    get empty() {
        return this.length === 0;
    }
}

/**
 * @class
 * @alias DisjointSet
 * @see {@link https://en.wikipedia.org/wiki/Disjoint-set_data_structure}
 */
class DisjointSet {
    /**
     * @constructor
     * @alias DisjointSet
     * @memberof module:datastructure
     * @param {Array=} elements 
     * @returns {DisjointSet}
     */
    constructor(elements = null) {
        this._list = new Set();
        if (elements) {
            for (const e of elements) {
                this.make_set(e);
            }
        }
        return this;
    }

    make_set(x) {
        const list = this._list;
        if (!list.has(x)) {
            list.add(x);
            x.__disjoint_set = {};
            x.__disjoint_set.parent = x;
            x.__disjoint_set.children = new Set([x]);
            x.__disjoint_set.size = 1;
        }
        return this;
    }

    find(x) {
        const list = this._list;
        if (list.has(x)) {
            if (x.__disjoint_set.parent !== x) {
                x.__disjoint_set.children.add(...x);
                x.__disjoint_set.parent = this.find(x.__disjoint_set.parent);
                return x.__disjoint_set.parent;
            } else {
                return x;
            }
        } else {
            return null;
        }
    }

    union(x, y) {
        let node_x = this.find(x);
        let node_y = this.find(y);

        if (node_x === node_y) return this;
        if (node_x.__disjoint_set.size < node_y.__disjoint_set.size) [node_x, node_y] = [node_y, node_x];

        node_y.__disjoint_set.parent = node_x;
        // keep track of children?
        node_y.__disjoint_set.children.forEach(node_x.__disjoint_set.children.add, node_x.__disjoint_set.children);
        node_x.__disjoint_set.size += node_y.__disjoint_set.size;

        return this;
    }
}

/**
 * @class
 * @alias BallTree
 */
class BallTree {
    /**
     * Generates a BallTree with given {@link elements}.
     * @constructor
     * @memberof module:knn
     * @alias BallTree
     * @param {Array=} elements - Elements which should be added to the BallTree
     * @param {Function} [metric = euclidean] metric to use: (a, b) => distance
     * @see {@link https://en.wikipedia.org/wiki/Ball_tree}
     * @see {@link https://github.com/invisal/noobjs/blob/master/src/tree/BallTree.js}
     * @returns {BallTree}
     */
    constructor(elements = null, metric = euclidean) {
        this._Node = class {
            constructor(pivot, child1=null, child2=null, radius=null) {
                this.pivot = pivot;
                this.child1 = child1;
                this.child2 = child2;
                this.radius = radius;
            }
        };
        this._Leaf = class {
            constructor(points) {
                this.points = points;
            }
        };
        this._metric = metric;
        if (elements) {
            this.add(elements);
        }
        return this;
    }

    /**
     * 
     * @param {Array<*>} elements - new elements.
     * @returns {BallTree}
     */
    add(elements) {
        elements = elements.map((element, index) => {
            return {index: index, element: element}
        });
        this._root = this._construct(elements);
        return this;
    }

    /**
     * @private
     * @param {Array<*>} elements 
     * @returns {Node} root of balltree.
     */
    _construct(elements) {
        if (elements.length === 1) {
            return new this._Leaf(elements);
        } else {
            let c = this._greatest_spread(elements);
            let sorted_elements = elements.sort((a, b) => a.element[c] - b.element[c]);
            let n = sorted_elements.length;
            let p_index = Math.floor(n / 2);
            let p = elements[p_index];
            let L = sorted_elements.slice(0, p_index);
            let R = sorted_elements.slice(p_index, n);
            let radius = Math.max(...elements.map(d => this._metric(p.element, d.element)));
            let B;
            if (L.length > 0 && R.length > 0) {         
                B = new this._Node(p, this._construct(L), this._construct(R), radius);
            } else {
                B = new this._Leaf(elements);
            }
            return B;
        }
    }

    /**
     * @private
     * @param {Node} B 
     * @returns {Number}
     */
    _greatest_spread(B) {
        let d = B[0].element.length;
        let start = new Array(d);

        for (let i = 0; i < d; ++i) {
            start[i] = [Infinity, -Infinity];
        }

        let spread = B.reduce((acc, current) => {
            for (let i = 0; i < d; ++i) {
                acc[i][0] = Math.min(acc[i][0], current.element[i]);
                acc[i][1] = Math.max(acc[i][1], current.element[i]);
            }
            return acc;
        }, start);
        spread = spread.map(d => d[1] - d[0]);
        
        let c = 0;
        for (let i = 0; i < d; ++i) {
            c = spread[i] > spread[c] ? i : c;
        }
        return c;
    }

    /**
     * 
     * @param {*} t - query element.
     * @param {Number} [k = 5] - number of nearest neighbors to return.
     * @returns {Heap} - Heap consists of the {@link k} nearest neighbors.
     */
    search(t, k = 5) {
        return this._search(t, k, new Heap(null, d => this._metric(d.element, t), "max"), this._root);
    }

    /**
     * @private
     * @param {*} t - query element.
     * @param {Number} [k = 5] - number of nearest neighbors to return.
     * @param {Heap} Q - Heap consists of the currently found {@link k} nearest neighbors.
     * @param {Node|Leaf} B 
     */
    _search(t, k, Q, B) {
        // B is Node
        if (Q.length >= k && B.pivot && B.radius && this._metric(t, B.pivot.element) - B.radius >= Q.first.value) {
            return Q;
        } 
        if (B.child1) this._search(t, k, Q, B.child1);
        if (B.child2) this._search(t, k, Q, B.child2);
        
        // B is leaf
        if (B.points) {
            for (let i = 0, n = B.points.length; i < n; ++i) {
                let p = B.points[i];
                if (k > Q.length) {
                    Q.push(p);
                } else {
                    Q.push(p);
                    Q.pop();
                }
            }
        }
        return Q;
    }
}

/**
 * @class
 * @alias KNN
 */
class KNN {
    /**
     * Generates a KNN list with given {@link elements}.
     * @constructor
     * @memberof module:knn
     * @alias KNN
     * @param {Array=} elements - Elements which should be added to the KNN list
     * @param {Function|"precomputed"} [metric = euclidean] metric is either precomputed or a function to use: (a, b) => distance
     * @returns {KNN}
     */
    constructor(elements=null, metric=euclidean) {
        this._metric = metric;
        this._elements = elements instanceof Matrix ? elements : Matrix.from(elements);
        const N = this._elements.shape[0];
        if (metric === "precomputed") {
            this._D = this._elements.clone();
        } else {
            this._D = distance_matrix(this._elements, metric);
        }
        this.KNN = [];
        for (let row = 0; row < N; ++row) {
            const distances = this._D.row(row);
            const H = new Heap(null, d => d.value, "min");
            for (let j = 0; j < N; ++j) {
                H.push({
                    value: distances[j],
                    index: j,
                });
            }
            this.KNN.push(H);
        }
    }

    /**
     * 
     * @param {Array|Number} t - query element or index.
     * @param {Number} [k = 5] - number of nearest neighbors to return.
     * @returns {Heap} - Heap consists of the {@link k} nearest neighbors.
     */
    search(t, k = 5) {
        const metric = this._metric;
        const KNN = this.KNN;
        let H;
        if (Array.isArray(t)) {
            if (this._metric == "precomputed") {
                throw "Search by query element is only possible when not using a precomputed distance matrix!"
            } 
            const elements = this._elements;
            const N = KNN.length;
            let nearest_element_index = null;
            let nearest_dist = Infinity;
            for (let i = 0; i < N; ++i) {
                const element = elements.row(i);
                const dist = metric(t, element);
                if (dist < nearest_dist) {
                    nearest_element_index = i;
                    nearest_dist = dist;
                }
            }
            H = KNN[nearest_element_index];
        } else if (Number.isInteger(t)) {
            H = KNN[t];
        }

        let result = [];
        for (let i = 0; i < k; ++i) {
            result.push(H.pop());
        }
        result.forEach(res => H.push(res.element));
        return result
    }    
}

/**
 * @class
 * @alias DR
 * @borrows DR#parameter as DR#para
 * @borrows DR#parameter as DR#p
 */
class DR {
    /**
     * Takes the default parameters and seals them, remembers the type of input {@link X}, and initializes the random number generator.
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias DR
     * @param {Matrix|Array<Array<Number>>} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the seed value for the random number generator.
     * @returns {DR}
     */
    constructor(X, default_parameters, parameters) {
        this._parameters = Object.assign(Object.seal(default_parameters), parameters);
        if (Array.isArray(X)) {
            this._type = "array";
            this.X = Matrix.from(X);
        } else if (X instanceof Matrix) {
            this._type = "matrix";
            this.X = X;
        } else {
            throw new Error("No valid type for X!");
        }
        [this._N, this._D] = this.X.shape;
        this._randomizer = new Randomizer(this._parameters.seed);
        this._is_initialized = false;
        return this;
    }

    /**
     * Set and get parameters
     * @param {String} [name = null] - Name of the parameter. If not given then returns all parameters as an Object.
     * @param {any} [value = null] - Value of the parameter to set. If <code>name</code> is set and <code>value</code> is not given, returns the value of the respective parameter.
     * @returns {DR|any|Object} 
     * On setting a parameter, this function returns the DR object. 
     * If <code>name</code> is set and <code>value == null</code> then return actual parameter value.
     * If <code>name</code> is not given, then returns all parameters as an Object.
     * 
     * @example
     * '''
     * const DR = new druid.TSNE(X, {d: 3}); // creates a new DR object, with parameter for <code>d</code> = 3.
     * DR.parameter("d"); // returns 3,
     * DR.parameter("d", 2); // sets parameter <code>d</code> to 2 and returns <code>DR</code>.
     * '''
     */
    parameter(name = null, value = null) {
        if (name === null) {
            return Object.assign({}, this._parameters);
        }
        if (!this._parameters.hasOwnProperty(name)) {
            throw new Error(`${name} is not a valid parameter!`);
        }
        if (value !== null) {
            this._parameters[name] = value;
            this._is_initialized = false;
            return this;
        } else {
            return this._parameters[name];
        }
    }

    para(name = null, value = null) {
        return this.parameter(name, value);
    }

    p(name = null, value = null) {
        return this.parameter(name, value);
    }

    /**
     * Computes the projection.
     * @returns {Matrix} the projection.
     */
    transform() {
        this.check_init();
        return this.projection;
    }

    /**
     * Computes the projection.
     * @yields {Matrix|Number[][]} the intermediate steps of the projection.
     */
    *generator() {
        return this.transform();
    }

    /**
     * If the respective DR method has an <code>init</code> function, call it before <code>transform</code>.
     * @returns {DR}
     */
    check_init() {
        if (!this._is_initialized && typeof this.init === "function") {
            this.init();
            this._is_initialized = true;
        }
        return this;
    }

    /**
     * @returns {Matrix|Number[][]} the projection in the type of input <code>X</code>.
     */
    get projection() {
        if (this.hasOwnProperty("Y")) {
            this.check_init();
            return this._type === "matrix" ? this.Y : this.Y.to2dArray;
        } else {
            throw new Error("The dataset is not transformed yet!");
        }
    }

    /**
     * Computes the projection.
     * @param  {...unknown} args - Arguments the transform method of the respective DR method takes.
     * @returns {Promise<Matrix|Number[][]>} the dimensionality reduced dataset.
     */
    async transform_async(...args) {
        return this.transform(...args);
    }

    /**
     * Computes the projection.
     * @static
     * @param  {...unknown} args - Takes the same arguments of the constructor of the respective DR method.
     * @returns {Matrix|Array} the dimensionality reduced dataset.
     */
    static transform(...args) {
        let dr = new this(...args);
        return dr.transform();
    }

    /**
     * Computes the projection.
     * @static
     * @param  {...unknown} args - Takes the same arguments of the constructor of the respective DR method.
     * @returns {Promise} a promise yielding the dimensionality reduced dataset.
     */
    static async transform_async(...args) {
        return this.transform(...args);
    }

    /**
     * Computes the projection.
     * @static
     * @param  {...unknown} args - Takes the same arguments of the constructor of the respective DR method.
     * @returns {Generator} a generator yielding the intermediate steps of the dimensionality reduction method.
     */
    static *generator(...args) {
        const dr = new this(...args);
        const generator = dr.generator();
        for (const result of generator) {
            yield result;
        }
    }
}

/**
 * @class
 * @alias PCA
 * @augments DR
 */
class PCA extends DR {
    /**
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias PCA
     * @param {Matrix|Array<Array<Number>>} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @param {Number} [parameters.eig_args] - Parameters for the eigendecomposition algorithm.
     * @returns {PCA}
     */
    constructor(X, parameters) {
        super(X, { d: 2, seed: 1212, eig_args: {} }, parameters);
        if (!this._parameters.eig_args.hasOwnProperty("seed")) {
            this._parameters.eig_args.seed = this._randomizer;
        }
        return this;
    }

    /**
     * Transforms the inputdata {@link X} to dimensionality {@link d}. If parameter {@link A} is given, then project {@link A} with the principal components of {@link X}.
     * @param {null|Matrix|Array} [A = null] - If given, the data to project.
     * @returns {Matrix|Array} - The projected data.
     */
    transform(A = null) {
        const V = this.principal_components();
        if (A == null) {
            const X = this.X;
            this.Y = X.dot(V);
            return this.projection;
        } else if (Array.isArray(A)) {
            return Matrix.from(A).dot(V).asArray;
        } else if (A instanceof Matrix) {
            return A.dot(V);
        } else {
            throw new Error("No valid type for A!");
        }
    }

    /**
     * Computes the {@link d} principal components of Matrix {@link X}.
     * @returns {Matrix}
     */
    principal_components() {
        if (this.V) {
            return this.V;
        }
        const { d, eig_args } = this._parameters;
        const X = this.X;
        const means = Matrix.from(X.meanCols);
        const X_cent = X.sub(means);
        const C = X_cent.transpose().dot(X_cent);
        const { eigenvectors: V } = simultaneous_poweriteration(C, d, eig_args);
        this.V = Matrix.from(V).transpose();
        return this.V;
    }

    static principal_components(X, parameters) {
        const dr = new this(X, parameters);
        return dr.principal_components();
    }
}

/**
 * @class
 * @alias MDS
 * @extends DR
 */
class MDS extends DR {
    /**
     * Classical MDS.
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias MDS
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function|"precomputed"} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @param {Number} [parameters.eig_args] - Parameters for the eigendecomposition algorithm.
     */
    constructor(X, parameters) {
        super(X, { d: 2, metric: euclidean, seed: 1212, eig_args: {} }, parameters);
        if (!this._parameters.eig_args.hasOwnProperty("seed")) {
            this._parameters.eig_args.seed = this._randomizer;
        }
        return this;
    }

    /**
     * Transforms the inputdata {@link X} to dimensionality {@link d}.
     * @returns {Matrix|Array}
     */
    transform() {
        const X = this.X;
        const rows = X.shape[0];
        const { d, metric, eig_args } = this._parameters;
        const A = metric === "precomputed" ? X : distance_matrix(X, metric);
        const ai_ = A.meanCols;
        const a_j = A.meanRows;
        const a__ = A.mean;

        this._d_X = A;
        const B = new Matrix(rows, rows, (i, j) => A.entry(i, j) - ai_[i] - a_j[j] + a__);

        const { eigenvectors: V } = simultaneous_poweriteration(B, d, eig_args);
        this.Y = Matrix.from(V).transpose();

        return this.projection;
    }

    /**
     * @returns {Number} - the stress of the projection.
     */
    stress() {
        const N = this.X.shape[0];
        const Y = this.Y;
        const d_X = this._d_X;
        const d_Y = new Matrix();
        d_Y.shape = [
            N,
            N,
            (i, j) => {
                return i < j ? euclidean(Y.row(i), Y.row(j)) : d_Y.entry(j, i);
            },
        ];
        let top_sum = 0;
        let bottom_sum = 0;
        for (let i = 0; i < N; ++i) {
            for (let j = i + 1; j < N; ++j) {
                top_sum += Math.pow(d_X.entry(i, j) - d_Y.entry(i, j), 2);
                bottom_sum += Math.pow(d_X.entry(i, j), 2);
            }
        }
        return Math.sqrt(top_sum / bottom_sum);
    }
}

/**
 * @class
 * @alias ISOMAP
 * @extends DR
 */
class ISOMAP extends DR {
    /**
     * Isometric feature mapping (ISOMAP).
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias ISOMAP
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} parameters.neighbors - the number of neighbors {@link ISOMAP} should use to project the data.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @param {Number} [parameters.eig_args] - Parameters for the eigendecomposition algorithm.
     * @see {@link https://doi.org/10.1126/science.290.5500.2319}
     */
    constructor(X, parameters) {
        super(X, { neighbors: undefined, d: 2, metric: euclidean, seed: 1212, eig_args: {} }, parameters);
        this.parameter("neighbors", Math.min(LOR(this._parameters.neighbors , Math.max(Math.floor(this.X.shape[0] / 10), 2)), this._N - 1));
        if (!this._parameters.eig_args.hasOwnProperty("seed")) {
            this._parameters.eig_args.seed = this._randomizer;
        }
        return this;
    }

    /**
     * Computes the projection.
     * @returns {Matrix} Returns the projection.
     */
    transform() {
        this.check_init();
        const X = this.X;
        const rows = this._N;
        const { d, metric, eig_args, neighbors } = this._parameters;
        // TODO: make knn extern and parameter for constructor or transform?
        const D = new Matrix();
        D.shape = [rows, rows, (i, j) => (i <= j ? metric(X.row(i), X.row(j)) : D.entry(j, i))];
        const kNearestNeighbors = [];
        for (let i = 0; i < rows; ++i) {
            const row = [];
            for (let j = 0; j < rows; ++j) {
                row.push({
                    index: j,
                    distance: D.entry(i, j),
                });
            }
            const H = new Heap(row, (d) => d.distance, "min");
            kNearestNeighbors.push(H.toArray().slice(1, neighbors + 1));
        }

        /*D = dijkstra(kNearestNeighbors);*/
        // compute shortest paths
        // TODO: make extern
        /** @see {@link https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm} */
        const G = new Matrix(rows, rows, (i, j) => {
            const other = kNearestNeighbors[i].find((n) => n.index === j);
            return other ? other.distance : Infinity;
        });

        for (let i = 0; i < rows; ++i) {
            for (let j = 0; j < rows; ++j) {
                for (let k = 0; k < rows; ++k) {
                    G.set_entry(i, j, Math.min(G.entry(i, j), G.entry(i, k) + G.entry(k, j)));
                }
            }
        }

        let ai_ = new Float64Array(rows);
        let a_j = new Float64Array(rows);
        let a__ = 0;
        const A = new Matrix(rows, rows, (i, j) => {
            let val = G.entry(i, j);
            val = val === Infinity ? 0 : val;
            ai_[i] += val;
            a_j[j] += val;
            a__ += val;
            return val;
        });

        ai_ = ai_.map((v) => v / rows);
        a_j = a_j.map((v) => v / rows);
        a__ /= rows ** 2;
        const B = new Matrix(rows, rows, (i, j) => A.entry(i, j) - ai_[i] - a_j[j] + a__);

        // compute d eigenvectors
        const { eigenvectors: V } = simultaneous_poweriteration(B, d, eig_args);
        this.Y = Matrix.from(V).transpose();
        // return embedding
        return this.projection;
    }
}

/**
 * @class
 * @alias FASTMAP
 * @extends DR
 */
class FASTMAP extends DR {
    /**
     * FastMap: a fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias FASTMAP
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the dimensionality of the projection.
     * @returns {FASTMAP}
     * @see {@link https://doi.org/10.1145/223784.223812}
     */
    constructor(X, parameters) {
        super(X, { d: 2, metric: euclidean, seed: 1212 }, parameters);
        return this;
    }

    /**
     * Chooses two points which are the most distant in the actual projection.
     * @private
     * @param {Function} dist
     * @returns {Array} An array consisting of first index, second index, and distance between the two points.
     */
    _choose_distant_objects(dist) {
        const X = this.X;
        const N = X.shape[0];
        let a_index = (this._randomizer.random_int % N) - 1;
        let b_index = null;
        let max_dist = -Infinity;
        for (let i = 0; i < N; ++i) {
            const d_ai = dist(a_index, i);
            if (d_ai > max_dist) {
                max_dist = d_ai;
                b_index = i;
            }
        }
        max_dist = -Infinity;
        for (let i = 0; i < N; ++i) {
            const d_bi = dist(b_index, i);
            if (d_bi > max_dist) {
                max_dist = d_bi;
                a_index = i;
            }
        }
        return [a_index, b_index, max_dist];
    }

    /**
     * Computes the projection.
     * @returns {Matrix} The {@link d}-dimensional projection of the data matrix {@link X}.
     */
    transform() {
        const X = this.X;
        const N = X.shape[0];
        const { d, metric } = this._parameters;
        const Y = new Matrix(N, d, 0);
        let dist = (a, b) => metric(X.row(a), X.row(b));

        for (let _col = 0; _col < d; ++_col) {
            let old_dist = dist;
            // choose pivot objects
            const [a_index, b_index, d_ab] = this._choose_distant_objects(dist);
            if (d_ab !== 0) {
                // project the objects on the line (O_a, O_b)
                for (let i = 0; i < N; ++i) {
                    const d_ai = dist(a_index, i);
                    const d_bi = dist(b_index, i);
                    const y_i = (d_ai ** 2 + d_ab ** 2 - d_bi ** 2) / (2 * d_ab);
                    Y.set_entry(i, _col, y_i);
                }
                // consider the projections of the objects on a
                // hyperplane perpendicluar to the line (a, b);
                // the distance function D'() between two
                // projections is given by Eq.4
                dist = (a, b) => Math.sqrt(old_dist(a, b) ** 2 - (Y.entry(a, _col) - Y.entry(b, _col)) ** 2);
            }
        }
        // return embedding.
        this.Y = Y;
        return this.projection;
    }
}

/**
 * @class
 * @alias LDA
 * @extends DR
 */
class LDA extends DR {
    /**
     * Linear Discriminant Analysis.
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias LDA
     * @param {Matrix} X - The high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Array} parameters.labels - The labels / classes for each data point.
     * @param {number} [parameters.d = 2] - The dimensionality of the projection.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @param {Number} [parameters.eig_args] - Parameters for the eigendecomposition algorithm.
     * @see {@link https://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x}
     */
    constructor(X, parameters) {
        super(X, { labels: null, d: 2, seed: 1212, eig_args: {} }, parameters);
        if (!this._parameters.eig_args.hasOwnProperty("seed")) {
            this._parameters.eig_args.seed = this._randomizer;
        }
        return this;
    }

    /**
     * Transforms the inputdata {@link X} to dimenionality {@link d}.
     */
    transform() {
        const X = this.X;
        const [rows, cols] = X.shape;
        const { d, labels, eig_args } = this._parameters;
        if (labels === null || labels.length != rows) {
            throw new Error("LDA needs parameter label to every datapoint to work!");
        }
        const unique_labels = {};
        let label_id = 0;
        labels.forEach((l, i) => {
            if (l in unique_labels) {
                unique_labels[l].count++;
                unique_labels[l].rows.push(X.row(i));
            } else {
                unique_labels[l] = {
                    id: label_id++,
                    count: 1,
                    rows: [X.row(i)],
                };
            }
        });

        // create X_mean and vector means;
        const X_mean = X.mean;
        const V_mean = new Matrix(label_id, cols);
        for (const label in unique_labels) {
            const V = Matrix.from(unique_labels[label].rows);
            const v_mean = V.meanCols;
            for (let j = 0; j < cols; ++j) {
                V_mean.set_entry(unique_labels[label].id, j, v_mean[j]);
            }
        }
        // scatter_between
        let S_b = new Matrix(cols, cols);
        for (const label in unique_labels) {
            const v = V_mean.row(unique_labels[label].id);
            const m = new Matrix(cols, 1, (j) => v[j] - X_mean);
            const N = unique_labels[label].count;
            S_b = S_b.add(m.dot(m.transpose()).mult(N));
        }

        // scatter_within
        let S_w = new Matrix(cols, cols);
        for (const label in unique_labels) {
            const v = V_mean.row(unique_labels[label].id);
            const m = new Matrix(cols, 1, (j) => v[j]);
            const R = unique_labels[label].rows;
            for (let i = 0, n = unique_labels[label].count; i < n; ++i) {
                const row_v = new Matrix(cols, 1, (j, _) => R[i][j] - m.entry(j, 0));
                S_w = S_w.add(row_v.dot(row_v.transpose()));
            }
        }

        let { eigenvectors: V } = simultaneous_poweriteration(S_w.inverse().dot(S_b), d, eig_args);
        V = Matrix.from(V).transpose();
        this.Y = X.dot(V);

        // return embedding
        return this.projection;
    }
}

/**
 * @class
 * @alias LLE
 * @extends DR
 */
class LLE extends DR {
    /**
     * Locally Linear Embedding.
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias LLE
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} neighbors - the label / class of each data point.
     * @param {Number} [d = 2] - the dimensionality of the projection.
     * @param {Function} [metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [seed = 1212] - the dimensionality of the projection.
     * @param {Number} [parameters.eig_args] - Parameters for the eigendecomposition algorithm.
     * @see {@link https://doi.org/10.1126/science.290.5500.2323}
     */
    constructor(X, parameters) {
        super(X, { neighbors: undefined, d: 2, metric: euclidean, seed: 1212, eig_args: {} }, parameters);
        this.parameter("neighbors", Math.min(LOR(parameters.neighbors , Math.max(Math.floor(this._N / 10), 2)), this._N - 1));
        if (!this._parameters.eig_args.hasOwnProperty("seed")) {
            this._parameters.eig_args.seed = this._randomizer;
        }
        return this;
    }

    /**
     * Transforms the inputdata {@link X} to dimenionality {@link d}.
     */
    transform() {
        const X = this.X;
        const rows = this._N;
        const cols = this._D;
        const { neighbors, d, eig_args, metric } = this._parameters;
        const nN = k_nearest_neighbors(X, neighbors, metric);
        const O = new Matrix(neighbors, 1, 1);
        const W = new Matrix(rows, rows);

        for (let row = 0; row < rows; ++row) {
            const nN_row = nN[row];
            const Z = new Matrix(neighbors, cols, (i, j) => X.entry(nN_row[i].j, j) - X.entry(row, j));
            const C = Z.dot(Z.T);
            if (neighbors > cols) {
                const C_trace = neumair_sum(C.diag) / 1000;
                for (let j = 0; j < neighbors; ++j) {
                    C.set_entry(j, j, C.entry(j, j) + C_trace);
                }
            }
            // reconstruct;
            let w = Matrix.solve_CG(C, O, this._randomizer);
            w = w.divide(w.sum);
            for (let j = 0; j < neighbors; ++j) {
                W.set_entry(row, nN_row[j].j, w.entry(j, 0));
            }
        }
        // comp embedding
        const I = new Matrix(rows, rows, "identity");
        const IW = I.sub(W);
        const M = IW.T.dot(IW);
        const { eigenvectors: V } = simultaneous_poweriteration(M.T.inverse(), d + 1, eig_args);
        this.Y = Matrix.from(V.slice(1, 1 + d)).T;

        // return embedding
        return this.projection;
    }
}

/**
 * @class
 * @alias LTSA
 * @extends DR
 */
class LTSA extends DR {
    /**
     * Local Tangent Space Alignment
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias LTSA
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} parameters.neighbors - the number of neighbors {@link LTSA} should use to project the data.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @param {Number} [parameters.eig_args] - Parameters for the eigendecomposition algorithm.
     * @see {@link https://epubs.siam.org/doi/abs/10.1137/S1064827502419154}
     */
    constructor(X, parameters) {
        super(X, { neighbors: undefined, d: 2, metric: euclidean, seed: 1212, eig_args: {} }, parameters);
        this.parameter("neighbors", Math.min(LOR(parameters.neighbors , Math.max(Math.floor(this._N / 10), 2)), this._N - 1));
        if (!this._parameters.eig_args.hasOwnProperty("seed")) {
            this._parameters.eig_args.seed = this._randomizer;
        }
        if (this._D <= this.parameter("d")) {
            throw new Error(`Dimensionality of X (D = ${this._D}) must be greater than the required dimensionality of the result (d = ${this.parameter("d")})!`);
        }
        return this;
    }

    /**
     * Transforms the inputdata {@link X} to dimenionality {@link d}.
     */
    transform() {
        const X = this.X;
        const [rows, D] = X.shape;
        const { d, neighbors, metric, eig_args } = this._parameters;
        // 1.1 determine k nearest neighbors
        const nN = k_nearest_neighbors(X, neighbors, metric);
        // center matrix
        const O = new Matrix(D, D, "center");
        const B = new Matrix(rows, rows, 0);

        for (let row = 0; row < rows; ++row) {
            // 1.2 compute the d largest eigenvectors of the correlation matrix
            const I_i = [row, ...nN[row].map((n) => n.j)];
            let X_i = Matrix.from(I_i.map((n) => X.row(n)));
            // center X_i
            X_i = X_i.dot(O);
            // correlation matrix
            const C = X_i.dot(X_i.transpose());
            const { eigenvectors: g } = simultaneous_poweriteration(C, d, eig_args);
            //g.push(linspace(0, k).map(_ => 1 / Math.sqrt(k + 1)));
            const G_i_t = Matrix.from(g);
            // 2. Constructing alignment matrix
            const W_i = G_i_t.transpose()
                .dot(G_i_t)
                .add(1 / Math.sqrt(neighbors + 1));
            for (let i = 0; i < neighbors + 1; ++i) {
                for (let j = 0; j < neighbors + 1; ++j) {
                    B.set_entry(I_i[i], I_i[j], B.entry(I_i[i], I_i[j]) - (i === j ? 1 : 0) + W_i.entry(i, j));
                }
            }
        }

        // 3. Aligning global coordinates
        const { eigenvectors: Y } = simultaneous_poweriteration(B, d + 1, eig_args);
        this.Y = Matrix.from(Y.slice(1)).transpose();

        // return embedding
        return this.projection;
    }
}

/**
 * @class
 * @alias TSNE
 * @extends DR
 */
class TSNE extends DR {
    /**
     *
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias TSNE
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.perplexity = 50] - perplexity.
     * @param {Number} [parameters.epsilon = 10] - learning parameter.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function|"precomputed"} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @returns {TSNE}
     */
    constructor(X, parameters) {
        super(X, { perplexity: 50, epsilon: 10, d: 2, metric: euclidean, seed: 1212 }, parameters);
        [this._N, this._D] = this.X.shape;
        this._iter = 0;
        this.Y = new Matrix(this._N, this.parameter("d"), () => this._randomizer.random);
        return this;
    }

    /**
     *
     * @returns {TSNE}
     */
    init() {
        // init
        const Htarget = Math.log(this.parameter("perplexity"));
        const N = this._N;
        const D = this._D;
        const {metric} = this._parameters;
        const X = this.X;
        let Delta;
        if (metric =="precomputed") {
            Delta = druid.Matrix.from(X);
        } else {
            Delta = new Matrix(N, N);
            for (let i = 0; i < N; ++i) {
                const X_i = X.row(i);
                for (let j = i + 1; j < N; ++j) {
                    const distance = metric(X_i, X.row(j));
                    Delta.set_entry(i, j, distance);
                    Delta.set_entry(j, i, distance);
                }
            }
        }

        const P = new Matrix(N, N, "zeros");

        this._ystep = new Matrix(N, D, "zeros");
        this._gains = new Matrix(N, D, 1);

        // search for fitting sigma
        let prow = new Float64Array(N);
        const tol = 1e-4;
        const maxtries = 50;
        for (let i = 0; i < N; ++i) {
            let betamin = -Infinity;
            let betamax = Infinity;
            let beta = 1;
            let done = false;

            let num = 0;
            while (!done) {
                let psum = 0;
                for (let j = 0; j < N; ++j) {
                    let pj = Math.exp(-Delta.entry(i, j) * beta);
                    if (i === j) pj = 0;
                    prow[j] = pj;
                    psum += pj;
                }
                let Hhere = 0;
                for (let j = 0; j < N; ++j) {
                    let pj = psum === 0 ? 0 : prow[j] / psum;
                    prow[j] = pj;
                    if (pj > 1e-7) {
                        Hhere -= pj * Math.log(pj);
                    }
                }
                if (Hhere > Htarget) {
                    betamin = beta;
                    beta = betamax === Infinity ? beta * 2 : (beta + betamax) / 2;
                } else {
                    betamax = beta;
                    beta = betamin === -Infinity ? beta / 2 : (beta + betamin) / 2;
                }
                ++num;
                if (Math.abs(Hhere - Htarget) < tol) done = true;
                if (num >= maxtries) done = true;
            }

            for (let j = 0; j < N; ++j) {
                P.set_entry(i, j, prow[j]);
            }
        }

        //compute probabilities
        const Pout = new Matrix(N, N, "zeros");
        const N2 = N * 2;
        for (let i = 0; i < N; ++i) {
            for (let j = i; j < N; ++j) {
                const p = Math.max((P.entry(i, j) + P.entry(j, i)) / N2, 1e-100);
                Pout.set_entry(i, j, p);
                Pout.set_entry(j, i, p);
            }
        }
        this._P = Pout;
        return this;
    }

    /**
     *
     * @param {Number} [iterations=500] - Number of iterations.
     * @returns {Matrix|Number[][]} the projection.
     */
    transform(iterations = 500) {
        this.check_init();
        for (let i = 0; i < iterations; ++i) {
            this.next();
        }
        return this.projection;
    }

    /**
     *
     * @param {Number} [iterations=500] - number of iterations.
     * @yields {Matrix|Number[][]} - the projection.
     */
    *generator(iterations = 500) {
        this.check_init();
        for (let i = 0; i < iterations; ++i) {
            this.next();
            yield this.projection;
        }
        return this.projection;
    }

    /**
     * performs a optimization step
     * @private
     * @returns {Matrix}
     */
    next() {
        const iter = ++this._iter;
        const P = this._P;
        const ystep = this._ystep;
        const gains = this._gains;
        const N = this._N;
        const { d: dim, epsilon} = this._parameters;
        let Y = this.Y;

        //calc cost gradient;
        const pmul = iter < 100 ? 4 : 1;

        // compute Q dist (unnormalized)
        const Qu = new Matrix(N, N, "zeros");
        let qsum = 0;
        for (let i = 0; i < N; ++i) {
            for (let j = i + 1; j < N; ++j) {
                let dsum = 0;
                for (let d = 0; d < dim; ++d) {
                    const dhere = Y.entry(i, d) - Y.entry(j, d);
                    dsum += dhere * dhere;
                }
                const qu = 1 / (1 + dsum);
                Qu.set_entry(i, j, qu);
                Qu.set_entry(j, i, qu);
                qsum += 2 * qu;
            }
        }

        // normalize Q dist
        const Q = new Matrix(N, N, 0);
        for (let i = 0; i < N; ++i) {
            for (let j = i + 1; j < N; ++j) {
                const val = Math.max(Qu.entry(i, j) / qsum, 1e-100);
                Q.set_entry(i, j, val);
                Q.set_entry(j, i, val);
            }
        }

        const grad = new Matrix(N, dim, "zeros");
        for (let i = 0; i < N; ++i) {
            for (let j = 0; j < N; ++j) {
                const premult = 4 * (pmul * P.entry(i, j) - Q.entry(i, j)) * Qu.entry(i, j);
                for (let d = 0; d < dim; ++d) {
                    grad.set_entry(i, d, grad.entry(i, d) + premult * (Y.entry(i, d) - Y.entry(j, d)));
                }
            }
        }

        // perform gradient step
        let ymean = new Float64Array(dim);
        for (let i = 0; i < N; ++i) {
            for (let d = 0; d < dim; ++d) {
                const gid = grad.entry(i, d);
                const sid = ystep.entry(i, d);
                const gainid = gains.entry(i, d);

                let newgain = Math.sign(gid) === Math.sign(sid) ? gainid * 0.8 : gainid + 0.2;
                if (newgain < 0.01) newgain = 0.01;
                gains.set_entry(i, d, newgain);

                const momval = iter < 250 ? 0.5 : 0.8;
                const newsid = momval * sid - epsilon * newgain * gid;
                ystep.set_entry(i, d, newsid);

                Y.set_entry(i, d, Y.entry(i, d) + newsid);
                ymean[d] += Y.entry(i, d);
            }
        }

        for (let i = 0; i < N; ++i) {
            for (let d = 0; d < 2; ++d) {
                Y.set_entry(i, d, Y.entry(i, d) - ymean[d] / N);
            }
        }

        return this.Y;
    }
}

/**
 *
 * @memberof module:optimization
 * @alias powell
 * @param {Function} f
 * @param {Array} x0
 * @param {Number} [max_iter = 300]
 * @returns {Array}
 * @see http://optimization-js.github.io/optimization-js/optimization.js.html#line438
 */
function powell (f, x0, max_iter = 300) {
    const epsilon = 1e-2;
    const n = x0.length;
    let alpha = 1e-3;
    let pfx = 10000;
    let x = x0.slice();
    let fx = f(x);
    let convergence = false;

    while (max_iter-- >= 0 && !convergence) {
        convergence = true;
        for (let i = 0; i < n; ++i) {
            x[i] += 1e-6;
            let fxi = f(x);
            x[i] -= 1e-6;
            let dx = (fxi - fx) / 1e-6;
            if (Math.abs(dx) > epsilon) {
                convergence = false;
            }
            x[i] -= alpha * dx;
            fx = f(x);
        }
        alpha *= pfx >= fx ? 1.05 : 0.4;
        pfx = fx;
    }
    return x;
}

/**
 * @class
 * @alias UMAP
 * @extends DR
 */
class UMAP extends DR {
    /**
     *
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias UMAP
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.n_neighbors = 15] - size of the local neighborhood.
     * @param {Number} [parameters.local_connectivity = 1] - number of nearest neighbors connected in the local neighborhood.
     * @param {Number} [parameters.min_dist = 1] - controls how tightly points get packed together.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function} [parameters.metric = euclidean] - the metric which defines the distance between two points in the high-dimensional space.
     * @param {Number} [parameters._spread = 1] - The effective scale of embedded points. (In combination with {@link parameters.min_dist})
     * @param {Number} [parameters._set_op_mix_ratio = 1] - Interpolate between union and intersection.
     * @param {Number} [parameters._repulsion_strength = 1]  - Weighting applied to negative samples.
     * @param {Number} [parameters._negative_sample_rate = 5] - The number of negative samples per positive sample.
     * @param {Number} [parameters._n_epochs = 350] - The number of training epochs.
     * @param {Number} [parameter._initial_alpha = 1] - The initial learning rate for the optimization.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @returns {UMAP}
     */
    constructor(X, parameters) {
        super(X, { n_neighbors: 15, local_connectivity: 1, min_dist: 1, d: 2, metric: euclidean, seed: 1212, _spread: 1, _set_op_mix_ratio: 1, _repulsion_strength: 1, _negative_sample_rate: 5, _n_epochs: 350, _initial_alpha: 1 }, parameters);
        [this._N, this._D] = this.X.shape;
        /* let n_neighbors = Math.min(this._N - 1, parameters.n_neighbors);
        this.parameter("n_neighbors", n_neighbors);
        this.parameter("local_connectivity", Math.min(this.parameter("local_connectivity"), n_neighbors - 1)); */
        if (this.parameter("n_neighbors") > this._N) {
            throw new Error(`Parameter n_neighbors (=${this.parameter("n_neighbors")}) needs to be smaller than dataset size (N=${this._N})!`);
        }
        if (this.parameter("local_connectivity") > this.parameter("n_neighbors")) {
            throw new Error(`Parameter local_connectivity (=${this.parameter("local_connectivity")}) needs to be smaller than parameter n_neighbors (=${this.parameter("n_neighbors")})`);
        }
        this._iter = 0;
        const randomizer = this._randomizer;
        this.Y = new Matrix(this._N, this.parameter("d"), () => randomizer.random);
        return this;
    }

    /**
     * @private
     * @param {Number} spread
     * @param {Number} min_dist
     * @returns {Array}
     */
    _find_ab_params(spread, min_dist) {
        const curve = (x, a, b) => 1 / (1 + a * Math.pow(x, 2 * b));
        const xv = linspace(0, spread * 3, 300);
        const yv = linspace(0, spread * 3, 300);

        for (let i = 0, n = xv.length; i < n; ++i) {
            const xv_i = xv[i];
            yv[i] = xv_i < min_dist ? 1 : Math.exp(-(xv_i - min_dist) / spread);
        }

        const err = (p) => {
            const error = linspace(1, 300).map((_, i) => yv[i] - curve(xv[i], p[0], p[1]));
            return Math.sqrt(neumair_sum(error.map((e) => e * e)));
        };

        return powell(err, [1, 1]);
    }

    /**
     * @private
     * @param {Array<Array>} distances
     * @param {Array<Number>} sigmas
     * @param {Array<Number>} rhos
     * @returns {Array}
     */
    _compute_membership_strengths(distances, sigmas, rhos) {
        for (let i = 0, n = distances.length; i < n; ++i) {
            for (let j = 0, m = distances[i].length; j < m; ++j) {
                const v = distances[i][j].value - rhos[i];
                distances[i][j].value = v > 0 ? Math.exp(-v / sigmas[i]) : 1;
            }
        }
        return distances;
    }

    /**
     * @private
     * @param {KNN|BallTree} knn
     * @param {Number} k
     * @returns {Object}
     */
    _smooth_knn_dist(knn, k) {
        const SMOOTH_K_TOLERANCE = 1e-5;
        const MIN_K_DIST_SCALE = 1e-3;
        const n_iter = 64;
        const { local_connectivity, metric } = this._parameters;
        const target = Math.log2(k);
        const rhos = [];
        const sigmas = [];
        const X = this.X;
        const N = X.shape[0];
        //const distances = [...X].map(x_i => knn.search(x_i, k).raw_data().reverse());

        const distances = [];
        if (metric === "precomputed") {
            for (let i = 0; i < N; ++i) {
                distances.push(knn.search(i, k).reverse());
            }
        } else {
            for (const x_i of X) {
                distances.push(knn.search(x_i, k).raw_data().reverse());
            }
        }

        for (let i = 0; i < N; ++i) {
            let lo = 0;
            let hi = Infinity;
            let mid = 1;

            const search_result = distances[i];
            const non_zero_dist = search_result.filter((d) => d.value > 0);
            const non_zero_dist_length = non_zero_dist.length;
            if (non_zero_dist_length >= local_connectivity) {
                const index = Math.floor(local_connectivity);
                const interpolation = local_connectivity - index;
                if (index > 0) {
                    rhos.push(non_zero_dist[index - 1]);
                    if (interpolation > SMOOTH_K_TOLERANCE) {
                        rhos[i].value += interpolation * (non_zero_dist[index].value - non_zero_dist[index - 1]);
                    }
                } else {
                    rhos[i].value = interpolation * non_zero_dist[0].value;
                }
            } else if (non_zero_dist_length > 0) {
                rhos[i] = non_zero_dist[non_zero_dist_length - 1].value;
            }
            for (let x = 0; x < n_iter; ++x) {
                let psum = 0;
                for (let j = 0; j < k; ++j) {
                    const d = search_result[j].value - rhos[i];
                    psum += d > 0 ? Math.exp(-(d / mid)) : 1;
                }
                if (Math.abs(psum - target) < SMOOTH_K_TOLERANCE) {
                    break;
                }
                if (psum > target) {
                    [hi, mid] = [mid, (lo + hi) / 2];
                } else {
                    if (hi === Infinity) {
                        [lo, mid] = [mid, mid * 2];
                    } else {
                        [lo, mid] = [mid, (lo + hi) / 2];
                    }
                }
            }
            sigmas[i] = mid;

            const mean_ithd = search_result.reduce((a, b) => a + b.value, 0) / search_result.length;
            //let mean_d = null;
            if (rhos[i] > 0) {
                if (sigmas[i] < MIN_K_DIST_SCALE * mean_ithd) {
                    sigmas[i] = MIN_K_DIST_SCALE * mean_ithd;
                }
            } else {
                const mean_d = distances.reduce((acc, res) => acc + res.reduce((a, b) => a + b.value, 0) / res.length);
                if (sigmas[i] > MIN_K_DIST_SCALE * mean_d) {
                    sigmas[i] = MIN_K_DIST_SCALE * mean_d;
                }
            }
        }
        return {
            distances: distances,
            sigmas: sigmas,
            rhos: rhos,
        };
    }

    /**
     * @private
     * @param {Matrix} X
     * @param {Number} n_neighbors
     * @returns {Matrix}
     */
    _fuzzy_simplicial_set(X, n_neighbors) {
        const N = X.shape[0];
        const { metric, _set_op_mix_ratio } = this._parameters;
        const knn = metric === "precomputed" ? new KNN(X, "precomputed") : new BallTree(X.to2dArray, metric);
        let { distances, sigmas, rhos } = this._smooth_knn_dist(knn, n_neighbors);
        distances = this._compute_membership_strengths(distances, sigmas, rhos);
        const result = new Matrix(N, N, "zeros");
        for (let i = 0; i < N; ++i) {
            const distances_i = distances[i];
            for (let j = 0; j < distances_i.length; ++j) {
                result.set_entry(i, distances_i[j].element.index, distances_i[j].value);
            }
        }

        const transposed_result = result.T;
        const prod_matrix = result.mult(transposed_result);
        return result
            .add(transposed_result)
            .sub(prod_matrix)
            .mult(_set_op_mix_ratio)
            .add(prod_matrix.mult(1 - _set_op_mix_ratio));
    }

    /**
     * @private
     * @param {Number} n_epochs
     * @returns {Array}
     */
    _make_epochs_per_sample(n_epochs) {
        const weights = this._weights;
        const result = new Float32Array(weights.length).fill(-1);
        const weights_max = max(weights);
        const n_samples = weights.map((w) => n_epochs * (w / weights_max));
        for (let i = 0; i < result.length; ++i) if (n_samples[i] > 0) result[i] = Math.round(n_epochs / n_samples[i]);
        return result;
    }

    /**
     * @private
     * @param {Matrix} graph
     * @returns {Object}
     */
    _tocoo(graph) {
        const rows = [];
        const cols = [];
        const data = [];
        const [rows_n, cols_n] = graph.shape;
        for (let row = 0; row < rows_n; ++row) {
            for (let col = 0; col < cols_n; ++col) {
                const entry = graph.entry(row, col);
                if (entry !== 0) {
                    rows.push(row);
                    cols.push(col);
                    data.push(entry);
                }
            }
        }
        return {
            rows: rows,
            cols: cols,
            data: data,
        };
    }

    /**
     * Computes all necessary
     * @returns {UMAP}
     */
    init() {
        const { _spread, min_dist, n_neighbors, _n_epochs, _negative_sample_rate } = this._parameters;
        const [a, b] = this._find_ab_params(_spread, min_dist);
        this._a = a;
        this._b = b;
        this._graph = this._fuzzy_simplicial_set(this.X, n_neighbors);
        const { rows, cols, data: weights } = this._tocoo(this._graph);
        this._head = rows;
        this._tail = cols;
        this._weights = weights;
        this._epochs_per_sample = this._make_epochs_per_sample(_n_epochs);
        this._epochs_per_negative_sample = this._epochs_per_sample.map((d) => d * _negative_sample_rate);
        this._epoch_of_next_sample = this._epochs_per_sample.slice();
        this._epoch_of_next_negative_sample = this._epochs_per_negative_sample.slice();
        return this;
    }

    graph() {
        this.check_init();
        return { cols: this._head, rows: this._tail, weights: this._weights };
    }

    /**
     *
     * @param {Number} [iterations=350] - number of iterations.
     * @returns {Matrix|Array}
     */
    transform(iterations = 350) {
        if (this.parameter("_n_epochs") != iterations) {
            this.parameter("_n_epochs", iterations);
            this.init();
        }
        this.check_init();
        for (let i = 0; i < iterations; ++i) {
            this.next();
        }
        return this.projection;
    }

    /**
     *
     * @param {Number} [iterations=350] - number of iterations.
     * @returns {Matrix|Array}
     */
    *generator(iterations = 350) {
        if (this.parameter("_n_epochs") != iterations) {
            this.parameter("_n_epochs", iterations);
            this.init();
        }
        this.check_init();
        for (let i = 0; i < iterations; ++i) {
            this.next();
            yield this.projection;
        }
        return this.projection;
    }

    /**
     * @private
     * @param {Number} x
     * @returns {Number}
     */
    _clip(x) {
        if (x > 4) return 4;
        if (x < -4) return -4;
        return x;
    }

    /**
     * performs the optimization step.
     * @private
     * @param {Matrix} head_embedding
     * @param {Matrix} tail_embedding
     * @param {Matrix} head
     * @param {Matrix} tail
     * @returns {Matrix}
     */
    _optimize_layout(head_embedding, tail_embedding, head, tail) {
        const randomizer = this._randomizer;
        const { _repulsion_strength, d: dim } = this._parameters;
        const { _alpha: alpha, _a: a, _b: b, _epochs_per_sample: epochs_per_sample, _epochs_per_negative_sample: epochs_per_negative_sample, _epoch_of_next_negative_sample: epoch_of_next_negative_sample, _epoch_of_next_sample: epoch_of_next_sample, _clip: clip } = this;
        const tail_length = tail.length;

        for (let i = 0, n = epochs_per_sample.length; i < n; ++i) {
            if (epoch_of_next_sample[i] <= this._iter) {
                const j = head[i];
                const k = tail[i];
                const current = head_embedding.row(j);
                const other = tail_embedding.row(k);
                const dist = euclidean_squared(current, other);
                let grad_coeff = 0;
                if (dist > 0) {
                    grad_coeff = (-2 * a * b * Math.pow(dist, b - 1)) / (a * Math.pow(dist, b) + 1);
                }
                for (let d = 0; d < dim; ++d) {
                    const grad_d = clip(grad_coeff * (current[d] - other[d])) * alpha;
                    const c = current[d] + grad_d;
                    const o = other[d] - grad_d;
                    current[d] = c;
                    other[d] = o;
                    head_embedding.set_entry(j, d, c);
                    tail_embedding.set_entry(k, d, o);
                }
                epoch_of_next_sample[i] += epochs_per_sample[i];
                const n_neg_samples = (this._iter - epoch_of_next_negative_sample[i]) / epochs_per_negative_sample[i];
                for (let p = 0; p < n_neg_samples; ++p) {
                    const k = randomizer.random_int % tail_length;
                    const other = tail_embedding.row(tail[k]);
                    const dist = euclidean_squared(current, other);
                    let grad_coeff = 0;
                    if (dist > 0) {
                        grad_coeff = (2 * _repulsion_strength * b) / ((0.01 + dist) * (a * Math.pow(dist, b) + 1));
                    } else if (j === k) {
                        continue;
                    }
                    for (let d = 0; d < dim; ++d) {
                        const grad_d = clip(grad_coeff * (current[d] - other[d])) * alpha;
                        const c = current[d] + grad_d;
                        const o = other[d] - grad_d;
                        current[d] = c;
                        other[d] = o;
                        head_embedding.set_entry(j, d, c);
                        tail_embedding.set_entry(tail[k], d, o);
                    }
                }
                epoch_of_next_negative_sample[i] += n_neg_samples * epochs_per_negative_sample[i];
            }
        }
        return head_embedding;
    }

    /**
     * @private
     * @returns {Matrix}
     */
    next() {
        const iter = ++this._iter;
        const Y = this.Y;
        const { _initial_alpha, _n_epochs } = this._parameters;
        this._alpha = _initial_alpha * (1 - iter / _n_epochs);
        this.Y = this._optimize_layout(Y, Y, this._head, this._tail);

        return this.Y;
    }
}

/**
 * @class
 * @alias TriMap
 * @extends DR
 */
class TriMap extends DR {
    /**
     *
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias TriMap
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.weight_adj = 500] - scaling factor.
     * @param {Number} [parameters.c = 5] - number of triplets multiplier.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Number} [parameters.tol = 1e-8] -
     * @param {Function} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @returns {TriMap}
     * @see {@link https://arxiv.org/pdf/1910.00204v1.pdf}
     * @see {@link https://github.com/eamid/trimap}
     */
    constructor(X, parameters) {
        super(X, { weight_adj: 500, c: 5, d: 2, metric: euclidean, tol: 1e-8, seed: 1212 }, parameters);
        return this;
    }

    /**
     *
     * @param {Matrix} [pca = null] - Initial Embedding (if null then PCA gets used).
     * @param {KNN} [knn = null] - KNN Object (if null then BallTree gets used).
     */
    init(pca = null, knn = null) {
        const X = this.X;
        const N = X.shape[0];
        const { d, metric, c } = this._parameters;
        this.n_inliers = 2 * c;
        this.n_outliers = 1 * c;
        this.n_random = 1 * c;
        this.Y = pca || new PCA(X, d).transform();
        this.knn = knn || new BallTree(X.to2dArray, metric);
        const { triplets, weights } = this._generate_triplets(this.n_inliers, this.n_outliers, this.n_random);
        this.triplets = triplets;
        this.weights = weights;
        this.lr = (1000 * N) / triplets.shape[0];
        this.C = Infinity;
        this.vel = new Matrix(N, d, 0);
        this.gain = new Matrix(N, d, 1);
        return this;
    }

    /**
     * Generates {@link n_inliers} x {@link n_outliers} x {@link n_random} triplets.
     * @param {Number} n_inliers
     * @param {Number} n_outliers
     * @param {Number} n_random
     */
    _generate_triplets(n_inliers, n_outliers, n_random) {
        const { metric, weight_adj } = this._parameters;
        const X = this.X;
        const N = X.shape[0];
        const knn = this.knn;
        const n_extra = Math.min(n_inliers + 20, N);
        const nbrs = new Matrix(N, n_extra);
        const knn_distances = new Matrix(N, n_extra);
        for (let i = 0; i < N; ++i) {
            knn.search(X.row(i), n_extra + 1)
                .raw_data()
                .filter((d) => d.value != 0)
                .sort((a, b) => a.value - b.value)
                .forEach((d, j) => {
                    nbrs.set_entry(i, j, d.element.index);
                    knn_distances.set_entry(i, j, d.value);
                });
        }
        // scale parameter
        const sig = new Float64Array(N);
        for (let i = 0; i < N; ++i) {
            sig[i] = Math.max((knn_distances.entry(i, 3) + knn_distances.entry(i, 4) + knn_distances.entry(i, 5) + knn_distances.entry(i, 6)) / 4, 1e-10);
        }

        const P = this._find_p(knn_distances, sig, nbrs);

        let triplets = this._sample_knn_triplets(P, nbrs, n_inliers, n_outliers);
        let n_triplets = triplets.shape[0];
        const outlier_distances = new Float64Array(n_triplets);
        for (let i = 0; i < n_triplets; ++i) {
            const j = triplets.entry(i, 0);
            const k = triplets.entry(i, 2);
            outlier_distances[i] = metric(X.row(j), X.row(k));
        }
        let weights = this._find_weights(triplets, P, nbrs, outlier_distances, sig);

        if (n_random > 0) {
            const { random_triplets, random_weights } = this._sample_random_triplets(X, n_random, sig);
            triplets = triplets.concat(random_triplets, "vertical");
            weights = Float64Array.from([...weights, ...random_weights]);
        }
        n_triplets = triplets.shape[0];
        let max_weight = -Infinity;
        for (let i = 0; i < n_triplets; ++i) {
            if (isNaN(weights[i])) {
                weights[i] = 0;
            }
            if (max_weight < weights[i]) max_weight = weights[i];
        }
        let max_weight_2 = -Infinity;
        for (let i = 0; i < n_triplets; ++i) {
            weights[i] /= max_weight;
            weights[i] += 0.0001;
            weights[i] = Math.log(1 + weight_adj * weights[i]);
            if (max_weight_2 < weights[i]) max_weight_2 = weights[i];
        }
        for (let i = 0; i < n_triplets; ++i) {
            weights[i] /= max_weight_2;
        }
        return {
            triplets: triplets,
            weights: weights,
        };
    }

    /**
     * Calculates the similarity matrix P
     * @private
     * @param {Matrix} knn_distances - matrix of pairwise knn distances
     * @param {Float64Array} sig - scaling factor for the distances
     * @param {Matrix} nbrs - nearest neighbors
     * @returns {Matrix} pairwise similarity matrix
     */
    _find_p(knn_distances, sig, nbrs) {
        const [N, n_neighbors] = knn_distances.shape;
        return new Matrix(N, n_neighbors, (i, j) => {
            return Math.exp(-(knn_distances.entry(i, j) ** 2 / sig[i] / sig[nbrs.entry(i, j)]));
        });
    }

    /**
     * Sample nearest neighbors triplets based on the similarity values given in P.
     * @private
     * @param {Matrix} P - Matrix of pairwise similarities between each point and its neighbors given in matrix nbrs.
     * @param {Matrix} nbrs - Nearest neighbors indices for each point. The similarity values are given in matrix {@link P}. Row i corresponds to the i-th point.
     * @param {Number} n_inliers - Number of inlier points.
     * @param {Number} n_outliers - Number of outlier points.
     *
     */
    _sample_knn_triplets(P, nbrs, n_inliers, n_outliers) {
        const N = nbrs.shape[0];
        const triplets = new Matrix(N * n_inliers * n_outliers, 3);
        for (let i = 0; i < N; ++i) {
            let n_i = i * n_inliers * n_outliers;
            const sort_indices = this.__argsort(P.row(i).map((d) => -d));
            for (let j = 0; j < n_inliers; ++j) {
                let n_j = j * n_outliers;
                const sim = nbrs.entry(i, sort_indices[j]);
                const samples = this._rejection_sample(n_outliers, N, sort_indices.slice(0, j + 1));
                for (let k = 0; k < n_outliers; ++k) {
                    const index = n_i + n_j + k;
                    const out = samples[k];
                    triplets.set_entry(index, 0, i);
                    triplets.set_entry(index, 1, sim);
                    triplets.set_entry(index, 2, out);
                }
            }
        }
        return triplets;
    }

    /**
     * Should do the same as np.argsort()
     * @private
     * @param {Array} A
     */
    __argsort(A) {
        return A.map((d, i) => {
            return { d: d, i: i };
        })
            .sort((a, b) => a.d - b.d)
            .map((d) => d.i);
    }

    /**
     * Samples {@link n_samples} integers from a given interval [0, {@link max_int}] while rejection the values that are in the {@link rejects}.
     * @private
     * @param {*} n_samples
     * @param {*} max_int
     * @param {*} rejects
     */
    _rejection_sample(n_samples, max_int, rejects) {
        const randomizer = this._randomizer;
        const interval = linspace(0, max_int - 1).filter((d) => rejects.indexOf(d) < 0);
        return randomizer.choice(interval, Math.min(n_samples, interval.length - 2));
    }

    /**
     * Calculates the weights for the sampled nearest neighbors triplets
     * @private
     * @param {Matrix} triplets - Sampled Triplets.
     * @param {Matrix} P - Pairwise similarity matrix.
     * @param {Matrix} nbrs - nearest Neighbors
     * @param {Float64Array} outlier_distances - Matrix of pairwise outlier distances
     * @param {Float64Array} sig - scaling factor for the distances.
     */
    _find_weights(triplets, P, nbrs, outlier_distances, sig) {
        const n_triplets = triplets.shape[0];
        const weights = new Float64Array(n_triplets);
        for (let t = 0; t < n_triplets; ++t) {
            const i = triplets.entry(t, 0);
            const sim = nbrs.row(i).indexOf(triplets.entry(t, 1));
            const p_sim = P.entry(i, sim);
            let p_out = Math.exp(-(outlier_distances[t] ** 2 / (sig[i] * sig[triplets.entry(t, 2)])));
            if (p_out < 1e-20) p_out = 1e-20;
            weights[t] = p_sim / p_out;
        }
        return weights;
    }

    /**
     * Sample uniformly ranom triplets
     * @private
     * @param {Matrix} X - Data matrix.
     * @param {Number} n_random - Number of random triplets per point
     * @param {Float64Array} sig - Scaling factor for the distances
     */
    _sample_random_triplets(X, n_random, sig) {
        const metric = this.parameter("metric");
        const randomizer = this._randomizer;
        const N = X.shape[0];
        const random_triplets = new Matrix(N * n_random, 3);
        const random_weights = new Float64Array(N * n_random);
        for (let i = 0; i < N; ++i) {
            const n_i = i * n_random;
            const indices = [...linspace(0, i - 1), ...linspace(i + 1, N - 1)];
            for (let j = 0; j < n_random; ++j) {
                let [sim, out] = randomizer.choice(indices, 2);
                let p_sim = Math.exp(-(metric(X.row(i), X.row(sim)) ** 2 / (sig[i] * sig[sim])));
                if (p_sim < 1e-20) p_sim = 1e-20;
                let p_out = Math.exp(-(metric(X.row(i), X.row(out)) ** 2 / (sig[i] * sig[out])));
                if (p_out < 1e-20) p_out = 1e-20;

                if (p_sim < p_out) {
                    [sim, out] = [out, sim];
                    [p_sim, p_out] = [p_out, p_sim];
                }
                const index = n_i + j;
                random_triplets.set_entry(index, 0, i);
                random_triplets.set_entry(index, 1, sim);
                random_triplets.set_entry(index, 2, out);
                random_weights[index] = p_sim / p_out;
            }
        }
        return {
            random_triplets: random_triplets,
            random_weights: random_weights,
        };
    }

    /**
     * Computes the gradient for updating the embedding.
     * @param {Matrix} Y - The embedding
     */
    _grad(Y) {
        const n_inliers = this.n_inliers;
        const n_outliers = this.n_outliers;
        const triplets = this.triplets;
        const weights = this.weights;
        const [N, dim] = Y.shape;
        const n_triplets = triplets.shape[0];
        const grad = new Matrix(N, dim, 0);
        let y_ij = new Float64Array(dim);
        let y_ik = new Float64Array(dim);
        let d_ij = 1;
        let d_ik = 1;
        let n_viol = 0;
        let loss = 0;
        const n_knn_triplets = N * n_inliers * n_outliers;

        for (let t = 0; t < n_triplets; ++t) {
            const [i, j, k] = triplets.row(t);
            // update y_ij, y_ik, d_ij, d_ik
            if (t % n_outliers == 0 || t >= n_knn_triplets) {
                d_ij = 1;
                d_ik = 1;
                for (let d = 0; d < dim; ++d) {
                    const Y_id = Y.entry(i, d);
                    const Y_jd = Y.entry(j, d);
                    const Y_kd = Y.entry(k, d);
                    y_ij[d] = Y_id - Y_jd;
                    y_ik[d] = Y_id - Y_kd;
                    d_ij += y_ij[d] ** 2;
                    d_ik += y_ik[d] ** 2;
                }
                // update y_ik and d_ik only
            } else {
                d_ik = 1;
                for (let d = 0; d < dim; ++d) {
                    const Y_id = Y.entry(i, d);
                    const Y_kd = Y.entry(k, d);
                    y_ik[d] = Y_id - Y_kd;
                    d_ik += y_ik[d] ** 2;
                }
            }

            if (d_ij > d_ik) ++n_viol;
            loss += weights[t] / (1 + d_ik / d_ij);
            const w = (weights[t] / (d_ij + d_ik)) ** 2;
            for (let d = 0; d < dim; ++d) {
                const gs = y_ij[d] * d_ik * w;
                const go = y_ik[d] * d_ij * w;
                grad.set_entry(i, d, grad.entry(i, d) + gs - go);
                grad.set_entry(j, d, grad.entry(j, d) - gs);
                grad.set_entry(k, d, grad.entry(k, d) + go);
            }
        }
        return { grad, loss, n_viol };
    }

    /**
     *
     * @param {Number} max_iteration
     */
    transform(max_iteration = 400) {
        this.check_init();
        for (let iter = 0; iter < max_iteration; ++iter) {
            this._next(iter);
        }
        return this.projection;
    }

    /**
     * @param {Number} max_iteration
     * @yields {Matrix}
     * @returns {Matrix}
     */
    *generator(max_iteration = 800) {
        this.check_init();
        for (let iter = 0; iter < max_iteration; ++iter) {
            this._next(iter);
            yield this.projection;
        }
        return this.projection;
    }

    /**
     * Does the iteration step.
     * @private
     * @param {Number} iter
     */
    _next(iter) {
        const gamma = iter > 150 ? 0.5 : 0.3;
        const old_C = this.C;
        const vel = this.vel;
        const Y = this.Y.add(vel.mult(gamma));
        const { grad, loss, n_viol } = this._grad(Y);
        this.C = loss;
        this.Y = this._update_embedding(Y, iter, grad);
        this.lr *= old_C > loss + this._parameters.tol ? 1.01 : 0.9;
        return this.Y;
    }

    /**
     * Updates the embedding.
     * @private
     * @param {Matrix} Y
     * @param {Number} iter
     * @param {Matrix} grad
     */
    _update_embedding(Y, iter, grad) {
        const [N, dim] = Y.shape;
        const gamma = iter > 150 ? 0.9 : 0.5; // moment parameter
        const min_gain = 0.01;
        const gain = this.gain;
        const vel = this.vel;
        const lr = this.lr;
        for (let i = 0; i < N; ++i) {
            for (let d = 0; d < dim; ++d) {
                const new_gain = Math.sign(vel.entry(i, d)) != Math.sign(grad.entry(i, d)) ? gain.entry(i, d) + 0.2 : Math.max(gain.entry(i, d) * 0.8, min_gain);
                gain.set_entry(i, d, new_gain);
                vel.set_entry(i, d, gamma * vel.entry(i, d) - lr * gain.entry(i, d) * grad.entry(i, d));
                Y.set_entry(i, d, Y.entry(i, d) + vel.entry(i, d));
            }
        }
        return Y;
    }
}

/**
 * @class
 * @alias Hierarchical_Clustering
 */
class Hierarchical_Clustering {
    /**
     * @constructor
     * @memberof module:clustering
     * @alias Hierarchical_Clustering
     * @todo needs restructuring.
     * @param {Matrix} - Data or distance matrix if metric is 'precomputed'
     * @param {("single"|"complete"|"average")} [linkage = "complete"]
     * @param {Function|"precomputed"} [metric = euclidean]
     * @returns {Hierarchical_Clustering}
     */
    constructor(matrix, linkage = "complete", metric = euclidean) {
        this._id = 0;
        this._matrix = matrix instanceof Matrix ? matrix : Matrix.from(matrix);
        this._metric = metric;
        this._linkage = linkage;
        if (metric === "precomputed" && this._matrix.shape[0] !== this._matrix.shape[1]) {
            throw new Error("If metric is 'precomputed', then matrix has to be square!");
        }
        this.init();
        this.root = this.do();
        return this;
    }

    /**
     *
     * @param {Number} value - value where to cut the tree.
     * @param {("distance"|"depth")} [type = "distance"] - type of value.
     * @returns {Array<Array>} - Array of clusters with the indices of the rows in given {@link matrix}.
     */
    get_clusters(value, type = "distance") {
        let clusters = [];
        let accessor;
        switch (type) {
            case "distance":
                accessor = (d) => d.dist;
                break;
            case "depth":
                accessor = (d) => d.depth;
                break;
            default:
                throw new Error("invalid type");
        }
        this._traverse(this.root, accessor, value, clusters);
        return clusters;
    }

    /**
     * @private
     * @param {} node
     * @param {*} f
     * @param {*} value
     * @param {*} result
     */
    _traverse(node, f, value, result) {
        if (f(node) <= value) {
            result.push(node.leaves());
        } else {
            this._traverse(node.left, f, value, result);
            this._traverse(node.right, f, value, result);
        }
    }

    /**
     * computes the tree.
     */
    init() {
        const metric = this._metric;
        const A = this._matrix;
        const n = (this._n = A.shape[0]);
        const d_min = (this._d_min = new Float64Array(n));
        let distance_matrix;
        if (metric !== "precomputed") {
            distance_matrix = new Matrix(n, n, 0); //new Array(n);
            for (let i = 0; i < n; ++i) {
                d_min[i] = 0;
                //distance_matrix[i] = new Float64Array(n);
                for (let j = 0; j < n; ++j) {
                    distance_matrix.set_entry(i, j, i === j ? Infinity : metric(A.row(i), A.row(j)));
                    if (distance_matrix.entry(i, d_min[i]) > distance_matrix.entry(i, j)) {
                        d_min[i] = j;
                    }
                }
            }
        } else {
            distance_matrix = this._matrix.clone();
            for (let i = 0; i < n; ++i) {
                for (let j = 0; j < n; ++j) {
                    if (i === j) {
                        distance_matrix.set_entry(i, j, Infinity);
                    } else if (distance_matrix.entry(i, d_min[i]) > distance_matrix.entry(i, j)) {
                        d_min[i] = j;
                    }
                }
            }
        }
        this._distance_matrix = distance_matrix;
        const clusters = (this._clusters = new Array(n));
        const c_size = (this._c_size = new Uint16Array(n));
        for (let i = 0; i < n; ++i) {
            clusters[i] = [];
            clusters[i][0] = new Cluster(this._id++, null, null, 0, A.row(i), i, 1, 0);
            c_size[i] = 1;
        }
        return this;
    }

    /**
     * computes the tree.
     */
    do() {
        const n = this._n;
        const d_min = this._d_min;
        const D = this._distance_matrix;
        const clusters = this._clusters;
        const c_size = this._c_size;
        const linkage = this._linkage;
        let root = null;
        for (let p = 0, p_max = n - 1; p < p_max; ++p) {
            let c1 = 0;
            for (let i = 0; i < n; ++i) {
                let D_i_min = D.entry(i, d_min[i]);
                for (let j = i + 1; j < n; ++j) {
                    if (D_i_min > D.entry(i, j)) {
                        d_min[i] = j;
                        D_i_min = D.entry(i, d_min[i]);
                    }
                }
            }
            for (let i = 0; i < n; ++i) {
                if (D.entry(i, d_min[i]) < D.entry(c1, d_min[c1])) {
                    c1 = i;
                }
            }
            let c2 = d_min[c1];
            let c1_cluster = clusters[c1][0];
            let c2_cluster = clusters[c2][0];
            let c1_cluster_indices = c1_cluster.isLeaf ? [c1_cluster.index] : c1_cluster.index;
            let c2_cluster_indices = c2_cluster.isLeaf ? [c2_cluster.index] : c2_cluster.index;
            let indices = c1_cluster_indices.concat(c2_cluster_indices);
            let new_cluster = new Cluster(this._id++, c1_cluster, c2_cluster, D.entry(c1, c2), null, indices);
            c1_cluster.parent = new_cluster;
            c2_cluster.parent = new_cluster;
            clusters[c1].unshift(new_cluster);
            c_size[c1] += c_size[c2];
            for (let j = 0; j < n; ++j) {
                const D_c1_j = D.entry(c1, j);
                const D_c2_j = D.entry(c2, j);
                let value;
                switch (linkage) {
                    case "single":
                        value = Math.min(D_c1_j, D_c2_j);
                        break;
                    case "complete":
                        value = Math.max(D_c1_j, D_c2_j);
                        break;
                    case "average":
                        value = (c_size[c1] * D_c1_j + c_size[c2] * D_c2_j) / (c_size[c1] + c_size[j]);
                        break;
                }
                D.set_entry(j, c1, value);
                D.set_entry(c1, j, value);
            }

            D.set_entry(c1, c1, Infinity);
            for (let i = 0; i < n; ++i) {
                D.set_entry(i, c2, Infinity);
                D.set_entry(c2, i, Infinity);
            }

            /* for (let j = 0; j < n; ++j) {
                if (d_min[j] === c2) {
                    d_min[j] = c1;
                }
                if (D.entry(c1, j) < D.entry(c1, d_min[c1])) {
                    d_min[c1] = j;
                }
            } */
            root = new_cluster;
        }
        return root;
    }
}

class Cluster {
    constructor(id, left, right, dist, centroid, index, size, depth) {
        this.id = id;
        this.left = left;
        this.right = right;
        this.dist = dist;
        this.index = index;
        this.size = LOR(size , left.size) + right.size;
        this.depth = LOR(depth , 1) + Math.max(left.depth, right.depth);
        this.centroid = LOR(centroid , this._calculate_centroid(left, right));
        this.parent = null;
        return this;
    }

    _calculate_centroid(left, right) {
        const l_size = left.size;
        const r_size = right.size;
        const l_centroid = left.centroid;
        const r_centroid = right.centroid;
        const size = this.size;
        const n = left.centroid.length;
        const new_centroid = new Float64Array(n);
        for (let i = 0; i < n; ++i) {
            new_centroid[i] = (l_size * l_centroid[i] + r_size * r_centroid[i]) / size;
        }
        return new_centroid;
    }

    get isLeaf() {
        return this.depth === 0;
    }

    leaves() {
        if (this.isLeaf) return [this];
        const left = this.left;
        const right = this.right;
        return (left.isLeaf ? [left] : left.leaves()).concat(right.isLeaf ? [right] : right.leaves());
    }

    descendants() {
        if (this.isLeaf) return [this];
        const left_descendants = this.left.descendants();
        const right_descendants = this.right.descendants();
        return left_descendants.concat(right_descendants).concat([this]);
    }
}

/**
 * @class
 * @alias KMeans
 */
class KMeans {
    /**
     * @constructor
     * @memberof module:clustering
     * @alias KMeans
     * @todo needs restructuring. 
     * @param {Matrix} matrix 
     * @param {Numbers} K 
     * @param {Function} [metric = euclidean] 
     * @param {Number} [seed = 1987]
     * @param {Boolean} [init = true]
     * @returns {KMeans}
     */
    constructor(matrix, K, metric = euclidean, seed=1987, init = true) {
        this._metric = metric;
        this._matrix = matrix;
        this._K = K;
        const [N, D] = matrix.shape;
        this._N = N;
        this._D = D;
        if (K > N) K = N;
        this._randomizer = new Randomizer(seed);
        this._clusters = new Array(N).fill(undefined);
        this._cluster_centroids = this._get_random_centroids(K);
        if (init) this.init(K, this._cluster_centroids);
        return this;
    }

    /**
     * @returns {Array<Array>} - Array of clusters with the indices of the rows in given {@link matrix}. 
     */
    get_clusters() {
        const K = this._K;
        const clusters = this._clusters;
        const result = new Array(K).fill().map(() => new Array());
        clusters.forEach((c, i) => result[c].push(i));
        return result;
    }

    /**
     * @private
     * @param {Array} points 
     * @param {Array} candidates 
     */
    _furthest_point(points, candidates) {
        const A = this._matrix;
        const metric = this._metric;
        let i = points.length;
        let H = Heap.heapify(
            candidates, 
            (d) => {
                const Ad = A.row(d);
                let sum = 0;
                for (let j = 0; j < i; ++j) {
                    sum += metric(Ad, points[j]);
                }
                return sum;
            }, 
            "max"
        );
        return H.pop().element;
    }

    _get_random_centroids(K) {
        const N = this._N;
        const randomizer = this._randomizer;
        const A = this._matrix;
        const cluster_centroids = new Array(K).fill();
        const indices = linspace(0, N - 1);
        const random_point = randomizer.random_int % (N - 1);
        cluster_centroids[0] = A.row(random_point);
        const init_points = [random_point];
        const sample_size = Math.floor((N - K) / K);// / K
        for (let i = 1; i < K; ++i) {
            // sampling + kmeans++ improvement?
            const sample = randomizer.choice(indices.filter(d => init_points.indexOf(d) == -1), sample_size);
            const furthest_point = this._furthest_point(cluster_centroids.slice(0, i), sample);
            init_points.push(furthest_point);
            cluster_centroids[i] = A.row(furthest_point);
        }
        return cluster_centroids;
    }

    _iteration(cluster_centroids) {
        const K = cluster_centroids.length;
        const N = this._N;
        const D = this._D;
        const A = this._matrix;
        const metric = this._metric;
        const clusters = this._clusters;
        let clusters_changed = false;
        // find nearest cluster centroid.
        for (let i = 0; i < N; ++i) {
            const Ai = A.row(i);
            let min_dist = Infinity;
            let min_cluster = null;
            for (let j = 0; j < K; ++j) {
                let d = metric(cluster_centroids[j], Ai);
                if (d < min_dist) {
                    min_dist = d;
                    min_cluster = j; 
                }
            }
            if (clusters[i] !== min_cluster) {
                clusters_changed = true;
            }
            clusters[i] = min_cluster;
        }
        // update cluster centroid
        // reset cluster centroids to 0
        for (let i = 0; i < K; ++i) {
            const centroid = cluster_centroids[i];
            for (let j = 0; j < D; ++j) {
                centroid[j] = 0;
            }
        }
        // compute centroid
        this._compute_centroid(cluster_centroids);

        return {   
            "clusters_changed": clusters_changed,
            "cluster_centroids": cluster_centroids
        };
    }

    _compute_centroid(cluster_centroids) {
        const K = cluster_centroids.length;
        const N = this._N;
        const D = this._D;
        const A = this._matrix;
        const clusters = this._clusters;
        const cluster_counter = new Array(K).fill(0);

        for (let i = 0; i < N; ++i) {
            const Ai = A.row(i);
            const ci = clusters[i];
            cluster_counter[ci]++;
            const centroid = cluster_centroids[ci];
            for (let j = 0; j < D; ++j) {
                centroid[j] += Ai[j];
            }
        }
        for (let i = 0; i < K; ++i) {
            const n = cluster_counter[i];
            cluster_centroids[i] = cluster_centroids[i].map(c => c / n);
        }
        
    }

    /**
     * Computes {@link K} clusters out of the {@link matrix}.
     * @param {Number} K - number of clusters.
     */
    init(K, cluster_centroids) {
        if (!K) K = this._K;
        if (!cluster_centroids) cluster_centroids = this._get_random_centroids(K);
        let clusters_changed = false;
        do {
            const iteration_result = this._iteration(cluster_centroids);
            cluster_centroids = iteration_result.cluster_centroids;
            clusters_changed = iteration_result.clusters_changed;
        } while (clusters_changed)
    }
    
}

/**
 * @class
 * @alias KMedoids
 */
class KMedoids {
    /**
     * @constructor
     * @memberof module:clustering
     * @alias KMedoids
     * @todo needs restructuring. 
     * @param {Matrix} matrix - data matrix
     * @param {Numbers} K - number of clusters
     * @param {number} [max_iter=null] - maximum number of iterations. Default is 10 * Math.log10(N)
     * @param {Function} [metric = euclidean] - metric defining the dissimilarity 
     * @param {Number} [seed = 1212] - seed value for random number generator
     * @returns {KMedoids}
     * @see {@link https://link.springer.com/chapter/10.1007/978-3-030-32047-8_16} Faster k-Medoids Clustering: Improving the PAM, CLARA, and CLARANS Algorithms
     */
    constructor(matrix, K, max_iter=null, metric = euclidean, seed=1212) {
        this._metric = metric;
        this._matrix = matrix;
        this._A = this._matrix.to2dArray;
        this._K = K;
        const [N, D] = matrix.shape;
        this._N = N;
        this._D = D;
        this._max_iter = max_iter || 10 * Math.log10(N); 
        this._distance_matrix = new Matrix(N, N, "zeros");
        /* for (let i = 1; i < N; ++i) {
            for (let j = i + 1; j < N; ++j) {
                let dist = metric(this._A[i], this._A[j]);
                this._distance_matrix.set_entry(i, j, dist);
                this._distance_matrix.set_entry(j, i, dist)
            }
        } */
        if (K > N) K = N;
        this._randomizer = new Randomizer(seed);
        this._clusters = new Array(N).fill(undefined);
        this._cluster_medoids = this._get_random_medoids(K);
        //if (init) this.init(K, this._cluster_medoids);
        this._is_initialized = false;
        return this;
    }

    /**
     * @returns {Array<Array>} - Array of clusters with the indices of the rows in given {@link matrix}. 
     */
    get_clusters() {
        const K = this._K;
        const A = this._A;
        if (!this._is_initialized) {
            this.init(K, this._cluster_medoids);
        }
        const result = new Array(K).fill().map(() => new Array());
        A.forEach((x_j, j) => {
            result[this._nearest_medoid(x_j, j).index_nearest].push(j);
        });
        result.medoids = this._cluster_medoids;
        return result;
    }

//    async* generator() { @bslab+
    generator () {
        const max_iter = this._max_iter;
        // yield this.get_clusters();
        this.get_clusters();
        let finish = false;
        let i = 0;
        do {
            finish = this._iteration();
            // yield this.get_clusters();
            this.get_clusters();
        } while (!finish && ++i < max_iter)
    }

    /**
     * Algorithm 1. FastPAM1: Improved SWAP algorithm
     */
    /* _iteration_1() {
        const A = this._A;
        const N = this._N;
        const K = this._K;
        const medoids = this._cluster_medoids;
        let DeltaTD = 0;
        let m0 = null;
        let x0 = null;
        A.forEach((x_j, j) => {
            if (medoids.findIndex(m => m === j) < 0) {
                const nearest_medoid = this._nearest_medoid(x_j, j);
                const d_j = nearest_medoid.distance_nearest; // distance to current medoid
                const deltaTD = new Array(K).fill(-d_j); // change if making j a medoid
                A.forEach((x_o, o) => {
                    // disance to new medoid
                    const d_oj = this._get_distance(o, j, x_o, x_j);
                    const {
                        "index_nearest": n,
                        "distance_nearest": d_n,
                        "distance_second": d_s,
                    } = this._nearest_medoid(x_o, o); 
                    this._clusters[o] = n; // cached values
                    deltaTD[n] += Math.min(d_oj, d_s) - d_n; // loss change
                    if (d_oj < d_n) { // reassignment check
                        deltaTD.forEach((d_i, i) => {
                            if (n !== i) {
                                deltaTD[i] = d_i + d_oj - d_n; // update loss change
                            }
                        });
                    }
                });
                // choose best medoid i;
                const i = deltaTD
                    .map((d, i) => [d, i])
                    .sort((d1, d2) => d1[0] - d2[0])[0][1];
                const deltaTD_i = deltaTD[i];
                // store
                if (deltaTD_i < DeltaTD) {
                    DeltaTD = deltaTD_i;
                    m0 = i;
                    x0 = j;
                }
            }
        });

        if (DeltaTD >= 0) {
            return true // break loop if DeltaTD >= 0
        }
        // swap roles of medoid m and non-medoid x;
        medoids[m0] = x0;
        this._cluster_medoids = medoids;
        return false
    } */

    /** Algorithm 2. FastPAM2: SWAP with multiple candidates
     * 
     */
    _iteration() {
        const A = this._A;
        const K = this._K;
        const medoids = this._cluster_medoids;
        const cache = A.map((x_o, o) => this._nearest_medoid(x_o, o));
        // empty best candidates array
        const DeltaTD = new Array(K).fill(0);
        const xs = new Array(K).fill(null);
        A.forEach((x_j, j) => {
            if (medoids.findIndex(m => m === j) < 0) {
                const d_j = cache[j].distance_nearest; // distance to current medoid
                const deltaTD = new Array(K).fill(-d_j); // change if making j a medoid
                A.forEach((x_o, o) => {
                    if (j === o) return;
                    const d_oj = this._get_distance(o, j, x_o, x_j); // distance to new medoid
                    const {"index_nearest": n, "distance_nearest": d_n, "distance_second": d_s} = cache[o]; // cached
                    deltaTD[n] += Math.min(d_oj, d_s) - d_n; // loss change for x_o
                    // Reassignment check
                    if (d_oj < d_n) { 
                        // update loss change
                        for (let i = 0; i < K; ++i) {
                            if (i !== n) deltaTD[i] += d_oj - d_n;
                        }
                    }
                });
                // remember best swap for i;
                deltaTD
                    .map((d, i) => [d, i])
                    .filter(([d, i]) => d < DeltaTD[i])
                    .forEach(([d, i]) => {
                        if (d < DeltaTD[i]) {
                            DeltaTD[i] = d;
                            xs[i] = j;
                        }
                    });
            }
        });
        // stop if no improvements were found
        if (min(DeltaTD) >= 0) return true; 

        // execute all improvements
        while (min(DeltaTD) < 0) {
            // swap roles of medoid m_i and non_medoid xs_i
            const i = DeltaTD
                .map((d, i) => [d, i])
                .sort(([a], [b]) => a - b)[0][1];
            if (medoids.filter(m => m == xs[i]).length == 0) {
                medoids[i] = xs[i];
            }
            // disable the swap just performed
            DeltaTD[i] = 0; 
            // recompute TD for remaining swap candidates
            DeltaTD
                .map((d_j, j) => [d_j, j])
                .filter(([d_j]) => d_j < 0)
                .forEach(([_, j]) => {
                    const x_j = A[j];
                    let sum = 0;
                    A.forEach((x_o, o) => {
                        if (medoids.findIndex(m => m != j && m == o) >= 0) return;
                        if (i == j) return;
                        if (cache[o].index_nearest === medoids[j])
                            sum += (Math.min(this._get_distance(o, j, x_o, x_j), cache[o].distance_second) - cache[o].distance_nearest); 
                        else {
                            sum += (Math.min(this._get_distance(o, j, x_o, x_j) - cache[o].distance_nearest, 0));
                        }
                    });
                    DeltaTD[j] = sum;
                });
        }
        this._cluster_medoids = medoids;
        return false;
    }

    _get_distance(i, j, x_i=null, x_j=null) {
        if (i === j) return 0;
        const D = this._distance_matrix;
        const A = this._A;
        const metric = this._metric;
        let d_ij = D.entry(i, j);
        if (d_ij === 0) {
            d_ij = metric(x_i || A[i], x_j || A[j]);
            D.set_entry(i, j, d_ij);
            D.set_entry(j, i, d_ij);
        }
        return d_ij;
    }

    _nearest_medoid(x_j, j) {
        const medoids = this._cluster_medoids;
        const A = this._A;
        const [nearest, second] = medoids
            .map((m, i) => {
                const x_m = A[m]; 
                return [this._get_distance(j, m, x_j, x_m), i];
            })
            .sort((m1, m2) => m1[0] - m2[0]);
        
        return { 
            "distance_nearest": nearest[0], 
            "index_nearest": nearest[1],
            "distance_second": second[0],
            "index_second": second[1],
        };
    }

    /**
     * Computes {@link K} clusters out of the {@link matrix}.
     * @param {Number} K - number of clusters.
     */
    init(K, cluster_medoids) {
        if (!K) K = this._K;
        if (!cluster_medoids) cluster_medoids = this._get_random_medoids(K);
        const max_iter = this._max_iter;
        let finish = false;
        let i = 0;
        do {
            finish = this._iteration();
        } while (!finish && ++i < max_iter)
        return this;
    }

    /**
     * Algorithm 3. FastPAM LAB: Linear Approximate BUILD initialization.
     * @param {number} K - number of clusters
     * 
     */
    _get_random_medoids(K) {
        const N = this._N;
        const A = this._A;
        const indices = linspace(0, N - 1);
        const randomizer = this._randomizer;
        const n = Math.min(N, 10 + Math.ceil(Math.sqrt(N)));
        const TD = new Array(n).fill(Infinity);
        const medoids = [];
        // first medoid
        let TD0 = Infinity;
        let S = randomizer.choice(indices, n);
        for (let j = 0; j < n; ++j) {
            const S_j = S[j];
            const x_j = A[S_j];
            for (let o = 0; o < n; ++o) {
                if (o === j) continue;
                const x_o = A[S[o]];
                TD[j] += this._get_distance(j, o, x_j, x_o);
            }
            if (TD[j] < TD0) {
                TD0 = TD[j]; // smallest distance sum
                medoids.push(S_j);
            }
        }
        // other medoids
        for (let i = 1; i < K; ++i) {
            let DeltaTD = Infinity;
            S = randomizer.choice(indices.filter(index => medoids.findIndex(d => d === index) < 0), n);
            for (let j = 0; j < n; ++j) {
                let deltaTD = 0;
                const S_j = S[j];
                const x_j = A[S_j];
                for (let o = 0; o < n; ++o) {
                    if (o === j) continue;
                    const S_o = S[o];
                    const x_o = A[S_o];
                    let delta = this._get_distance(S_j, S_o, x_j, x_o) - min(medoids.map(m => this._get_distance(S_o, m, x_o)));
                    if (delta < 0) {
                        deltaTD = deltaTD + delta;
                    }
                }
                // best reduction
                if (deltaTD < DeltaTD) {
                    DeltaTD = deltaTD;
                    medoids.push(S_j);
                }
            }
            TD0 += DeltaTD;
        }
        return medoids.slice(0, K);
    }
    
}

/**
 * @class
 * @alias OPTICS
 */
class OPTICS {
    /**
     * **O**rdering **P**oints **T**o **I**dentify the **C**lustering **S**tructure.
     * @constructor
     * @memberof module:clustering
     * @alias OPTICS
     * @todo needs restructuring. 
     * @param {Matrix} matrix - the data.
     * @param {Number} epsilon - the minimum distance which defines whether a point is a neighbor or not.
     * @param {Number} min_points - the minimum number of points which a point needs to create a cluster. (Should be higher than 1, else each point creates a cluster.)
     * @param {Function} [metric = euclidean] - the distance metric which defines the distance between two points of the {@link matrix}.
     * @returns {OPTICS}
     * @see {@link https://www.dbs.ifi.lmu.de/Publikationen/Papers/OPTICS.pdf}
     * @see {@link https://en.wikipedia.org/wiki/OPTICS_algorithm}
     */
    constructor(matrix, epsilon, min_points, metric = euclidean) {
        this._matrix = matrix;
        this._epsilon = epsilon;
        this._min_points = min_points;
        this._metric = metric;

        this._ordered_list = [];
        this._clusters = [];
        this._DB = new Array(matrix.shape[0]).fill();
        this.init();
        return this;
    }

    /**
     * Computes the clustering.
     */
    init() {
        const ordered_list = this._ordered_list;
        const matrix = this._matrix;
        const N = matrix.shape[0];
        const DB = this._DB;
        const clusters = this._clusters;
        let cluster_index = this._cluster_index = 0;

        for (let i = 0; i < N; ++i) {
            DB[i] = {
                "element": matrix.row(i),
                "index": i,
                "reachability_distance": undefined,
                "processed": false,
            };
        }
        for (const p of DB) {
            if (p.processed) continue;
            p.neighbors = this._get_neighbors(p);
            p.processed = true;
            clusters.push([p.index]);
            cluster_index = clusters.length - 1;
            ordered_list.push(p);
            if (this._core_distance(p) != undefined) {
                const seeds = new Heap(null, d => d.reachability_distance, "min");
                this._update(p, seeds);
                this._expand_cluster(seeds, clusters[cluster_index]);
            }
        }
        return this;
    }

    /**
     * 
     * @private
     * @param {Object} p - a point of {@link matrix}.
     * @returns {Array} An array consisting of the {@link epsilon}-neighborhood of {@link p}.
     */
    _get_neighbors(p) {
        if ("neighbors" in p) return p.neighbors;
        const DB = this._DB;
        const metric = this._metric;
        const epsilon = this._epsilon;
        const neighbors = [];
        for (const q of DB) {
            if (q.index == p.index) continue;
            if (metric(p.element, q.element) < epsilon) {
                neighbors.push(q);
            }
        }
        return neighbors;
    }

    /**
     * 
     * @private
     * @param {Object} p - a point of {@link matrix}.
     * @returns {Number} The distance to the {@link min_points}-th nearest point of {@link p}, or undefined if the {@link epsilon}-neighborhood has fewer elements than {@link min_points}.
     */
    _core_distance(p) {
        const min_points = this._min_points;
        const metric = this._metric;
        if (p.neighbors && p.neighbors.length <= min_points) {
            return undefined;
        }
        return metric(p.element, p.neighbors[min_points].element);
    }

    /**
     * Updates the reachability distance of the points.
     * @private
     * @param {Object} p 
     * @param {Heap} seeds 
     */
    _update(p, seeds) {
        const metric = this._metric;
        const core_distance = this._core_distance(p);
        const neighbors = this._get_neighbors(p);//p.neighbors;
        for (const q of neighbors) {
            if (q.processed) continue;
            const new_reachability_distance = Math.max(core_distance, metric(p.element, q.element));
            //if (q.reachability_distance == undefined) { // q is not in seeds
            if (seeds.raw_data().findIndex(d => d.element == q) < 0) {
                q.reachability_distance = new_reachability_distance;
                seeds.push(q);
            } else { // q is in seeds
                if (new_reachability_distance < q.reachability_distance) {
                    q.reachability_distance = new_reachability_distance;
                    seeds = Heap.heapify(seeds.data(), d => d.reachability_distance, "min"); // seeds change key =/
                }
            }
        }
    }

    /**
     * Expands the {@link cluster} with points in {@link seeds}.
     * @private
     * @param {Heap} seeds 
     * @param {Array} cluster 
     */
    _expand_cluster(seeds, cluster) {
        const ordered_list = this._ordered_list;
        while (!seeds.empty) {
            const q = seeds.pop().element;
            q.neighbors = this._get_neighbors(q);
            q.processed = true;
            cluster.push(q.index);
            ordered_list.push(q);
            if (this._core_distance(q) != undefined) {
                this._update(q, seeds);
                this._expand_cluster(seeds, cluster);
            }
        }
    }

    /**
     * Returns an array of clusters.
     * @returns {Array<Array>} Array of clusters with the indices of the rows in given {@link matrix}.
     */
    get_clusters() {
        const clusters = [];
        const outliers = [];
        const min_points = this._min_points;
        for (const cluster of this._clusters) {
            if (cluster.length < min_points) {
                outliers.push(...cluster);
            } else {
                clusters.push(cluster);
            }
        }
        clusters.push(outliers);
        return clusters;
    }

    /**
     * @returns {Array} Returns an array, where the ith entry defines the cluster affirmation of the ith point of {@link matrix}. (-1 stands for outlier)
     */
    get_cluster_affirmation() {
        const N = this._matrix.shape[0];
        const result = new Array(N).fill();
        const clusters = this.get_clusters();
        for (let i = 0, n = clusters.length; i < n; ++i) {
            const cluster = clusters[i];
            for (const index of cluster) {
                result[index] = (i < n - 1) ? i : -1;
            }
        }
        return result;
    }
}

/**
 * @class
 * @alias LSP
 * @extends DR
 */
class LSP extends DR {
    /**
     * Least Squares Projection.
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias LSP
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.neighbors = Math.max(Math.floor(N / 10), 2)] - number of neighbors to consider.
     * @param {Number} [parameters.control_points = Math.ceil(Math.sqrt(N))] - number of controlpoints
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @returns {LSP}
     * @see {@link https://ieeexplore.ieee.org/document/4378370}
     * @todo accept precomputed distance matrix.
     */
    constructor(X, parameters) {
        super(X, { neighbors: undefined, control_points: undefined, d: 2, metric: euclidean, seed: 1212 }, parameters);
        this.parameter("neighbors", Math.min(LOR(parameters.neighbors , Math.max(Math.floor(this._N / 10), 2)), this._N - 1));
        this.parameter("control_points", Math.min(LOR(parameters.control_points , Math.ceil(Math.sqrt(this._N))), this._N - 1));
        this._is_initialized = false;
        return this;
    }

    /**
     *
     * @param {DR} DR - method used for position control points.
     * @param {Object} DR_parameters - Object containing parameters for the DR method which projects the control points
     * @returns {LSP}
     */
    init(DR = MDS, DR_parameters = {}, KNN = BallTree) {
        if (this._is_initialized) return this;
        const X = this.X;
        const N = this._N;
        const K = this.parameter("neighbors");
        const d = this.parameter("d");
        const seed = this.parameter("seed");
        const metric = this.parameter("metric");
        DR_parameters = Object.assign({d, metric, seed }, DR_parameters);
        const nc = this.parameter("control_points");
        const control_points = new KMedoids(X, nc, null, metric).get_clusters().medoids;
        const C = new Matrix(nc, N, "zeros");
        control_points.forEach((c_i, i) => {
            C.set_entry(i, c_i, 1);
        });
        const Y_C = new DR(Matrix.from(control_points.map((c_i) => X.row(c_i))), DR_parameters).transform();

        const XA = X.to2dArray;
        const knn = new KNN(XA, metric);
        const L = new Matrix(N, N, "I");
        const alpha = -1 / K;
        XA.forEach((x_i, i) => {
            for (const { index: j } of knn.search(x_i, K).iterate()) {
                if (i === j) continue;
                L.set_entry(i, j, alpha);
            }
        });
        const A = L.concat(C, "vertical");

        const z = new Matrix(N, d, "zeros");
        const b = z.concat(Y_C, "vertical");

        this._A = A;
        this._b = b;
        this._is_initialized = true;
        return this;
    }

    /**
     * Computes the projection.
     * @returns {Matrix} Returns the projection.
     */
    transform() {
        this.check_init();
        const A = this._A;
        const AT = A.T;
        const b = this._b;
        const ATA = AT.dot(A);
        const ATb = AT.dot(b);
        this.Y = Matrix.solve_CG(ATA, ATb, this._randomizer);
        return this.projection;
    }
}

/**
 * @class
 * @alias TopoMap
 * @memberof module:dimensionality_reduction
 * @extends DR
 */
class TopoMap extends DR {
    /**
     * TopoMap: A 0-dimensional Homology Preserving Projection of High-Dimensional Data.
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias TopoMap
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Function} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @returns {TopoMap}
     * @see {@link https://arxiv.org/pdf/2009.01512.pdf}
     */
    constructor(X, parameters) {
        super(X, { metric: euclidean, seed: 1212 }, parameters);
        [this._N, this._D] = this.X.shape;
        this._distance_matrix = new Matrix(this._N, this._N, 0);
        return this;
    }

    /**
     * @private
     */
    __lazy_distance_matrix(i, j, metric) {
        const D = this._distance_matrix;
        const X = this.X;
        const D_ij = D.entry(i, j);
        if (D_ij === 0) {
            let dist = metric(X.row(i), X.row(j));
            D.set_entry(i, j, dist);
            D.set_entry(j, i, dist);
            return dist;
        }
        return D_ij;
    }

    /**
     * Computes the minimum spanning tree, using a given metric
     * @private
     * @param {Function} metric
     * @see {@link https://en.wikipedia.org/wiki/Kruskal%27s_algorithm}
     */
    _make_minimum_spanning_tree(metric = euclidean) {
        const N = this._N;
        const X = [...this.X];

        let disjoint_set = new DisjointSet(X);
        const F = [];
        let E = [];
        for (let i = 0; i < N; ++i) {
            for (let j = i + 1; j < N; ++j) {
                E.push([i, j, this.__lazy_distance_matrix(i, j, metric)]);
            }
        }
        E = E.sort((a, b) => a[2] - b[2]);

        for (const [u, v, w] of E) {
            const set_u = disjoint_set.find(X[u]);
            const set_v = disjoint_set.find(X[v]);
            if (set_u !== set_v) {
                F.push([u, v, w]);
                disjoint_set.union(set_u, set_v);
            }
        }

        return F.sort((a, b) => a[2] - b[2]);
    }

    /**
     * initializes TopoMap. Sets all projcted points to zero, and computes a minimum spanning tree.
     */
    init() {
        const { metric} = this._parameters;
        this.Y = new Matrix(this._N, 2, 0);
        this._Emst = this._make_minimum_spanning_tree(metric);
        this._is_initialized = true;
        return this;
    }

    /**
     * Returns true if Point C is left of line AB.
     * @private
     * @param {Array} PointA - Point A of line AB
     * @param {Array} PointB - Point B of line AB
     * @param {Array} PointC - Point C
     * @returns {Boolean}
     */
    __hull_cross([ax, ay], [bx, by], [sx, sy]) {
        return (bx - ax) * (sy - ay) - (by - ay) * (sx - ax) <= 0;
    }

    /**
     * Computes the convex hull of the set of Points S
     * @private
     * @param {Array} S - Set of Points.
     * @see {@link https://en.wikibooks.org/wiki/Algorithm_Implementation/Geometry/Convex_hull/Monotone_chain#JavaScript}
     * @returns {Array} convex hull of S. Starts at the bottom-most point and continues counter-clockwise.
     */
    __hull(S) {
        const points = S.sort(([x1, y1], [x2, y2]) => y1 - y2 || x1 - x2);
        const N = points.length;
        if (N <= 2) return points;

        const lower = [];
        for (let i = 0; i < N; ++i) {
            while (lower.length >= 2 && this.__hull_cross(lower[lower.length - 2], lower[lower.length - 1], points[i])) {
                lower.pop();
            }
            lower.push(points[i]);
        }
        const upper = [];
        for (let i = N - 1; i >= 0; --i) {
            while (upper.length >= 2 && this.__hull_cross(upper[upper.length - 2], upper[upper.length - 1], points[i])) {
                upper.pop();
            }
            upper.push(points[i]);
        }
        upper.pop();
        lower.pop();
        return lower.concat(upper);
    }

    /**
     * Finds the angle to rotate Point A and B to lie on a line parallel to the x-axis.
     * @private
     * @param {Array} PointA
     * @param {Array} PointB
     * @return {Object} Object containing the sinus- and cosinus-values for a rotation.
     */
    __findAngle([p1x, p1y], [p2x, p2y]) {
        const n = euclidean([p1x, p1y], [p2x, p2y]);
        if (n === 0)
            return {
                sin: 0,
                cos: 1,
            };
        const vec = [(p2x - p1x) / n, (p2y - p1y) / n];
        const cos = vec[0];
        let sin = Math.sqrt(1 - cos * cos);
        sin = vec[1] >= 0 ? -sin : sin;
        return {
            sin: sin,
            cos: cos,
        };
    }

    /**
     * @private
     * @param {Array} hull
     * @param {Array} p
     * @param {Bool} topEdge
     */
    __align_hull(hull, p, topEdge) {
        let v = -1;
        let d2;
        for (let i = 0; i < hull.length; ++i) {
            const d = euclidean(hull[i], p);
            if (v === -1) {
                d2 = d;
                v = i;
            } else {
                if (d2 > d) {
                    d2 = d;
                    v = i;
                }
            }
        }

        let v1;
        let v2;
        if (topEdge) {
            v1 = hull[v];
            v2 = hull[(v + 1) % hull.length];
        } else {
            if (v == 0) v = hull.length - 1;
            v1 = hull[v];
            v2 = hull[(v - 1) % hull.length];
        }

        const transformation = {
            tx: -hull[v][0],
            ty: -hull[v][1],
        };

        if (hull.length >= 2) {
            const { sin, cos } = this.__findAngle(v1, v2);
            transformation.sin = sin;
            transformation.cos = cos;
        } else {
            transformation.sin = 0;
            transformation.cos = 1;
        }

        return transformation;
    }

    /**
     * @private
     * @param {Array} Point - The point which should get transformed.
     * @param {Object} Transformation - contains the values for translation and rotation.
     */
    __transform([px, py], { tx, ty, sin, cos }) {
        let x = px + tx;
        let y = py + ty;
        let xx = x * cos - y * sin;
        let yy = x * sin + y * cos;
        return [xx, yy];
    }

    /**
     * Calls {@link __transform} for each point in Set C
     * @private
     * @param {Array} C - Set of points.
     * @param {Object} t - Transform object.
     * @param {Number} yOffset - value to offset set C.
     */
    __transform_component(C, t, yOffset) {
        const N = C.length;
        for (let i = 0; i < N; ++i) {
            const c = C[i];
            const [cx, cy] = this.__transform(c, t);
            c[0] = cx;
            c[1] = cy + yOffset;
        }
    }

    /**
     * @private
     * @param {Array} u - point u
     * @param {Array} v - point v
     * @param {Number} w - edge weight w
     */
    __align_components(u, v, w) {
        const points_u = [...u.__disjoint_set.children];
        const points_v = [...v.__disjoint_set.children];

        const hull_u = this.__hull(points_u);
        const hull_v = this.__hull(points_v);

        const t_u = this.__align_hull(hull_u, u, false);
        const t_v = this.__align_hull(hull_v, v, true);

        this.__transform_component(points_u, t_u, 0);
        this.__transform_component(points_v, t_v, w);
    }

    /**
     * Transforms the inputdata {@link X} to dimensionality 2.
     */
    transform() {
        if (!this._is_initialized) this.init();
        const Emst = this._Emst;
        const Y = this.Y.to2dArray;
        const components = new DisjointSet(
            Y.map((y, i) => {
                y.i = i;
                return y;
            })
        );

        for (const [u, v, w] of Emst) {
            const component_u = components.find(Y[u]);
            const component_v = components.find(Y[v]);
            if (component_u === component_v) continue;
            this.__align_components(component_u, component_v, w);
            components.union(component_u, component_v);
        }
        return this.projection;
    }

    *generator() {
        if (!this._is_initialized) this.init();
        const Emst = this._Emst;
        const Y = this.Y.to2dArray;
        const components = new DisjointSet(
            Y.map((y, i) => {
                y.i = i;
                return y;
            })
        );

        for (const [u, v, w] of Emst) {
            const component_u = components.find(Y[u]);
            const component_v = components.find(Y[v]);
            if (component_u === component_v) continue;
            this.__align_components(component_u, component_v, w);
            components.union(component_u, component_v);
            yield this.projection;
        }
        return this.projection;
    }
}

/**
 * @class
 * @alias SAMMON
 * @extends DR
 */
class SAMMON extends DR {
    /**
     * SAMMON's Mapping
     * @constructor
     * @memberof module:dimensionality_reduction
     * @alias SAMMON
     * @param {Matrix} X - the high-dimensional data.
     * @param {Object} parameters - Object containing parameterization of the DR method.
     * @param {Number} [parameters.d = 2] - the dimensionality of the projection.
     * @param {Function|"precomputed"} [parameters.metric = euclidean] - the metric which defines the distance between two points.
     * @param {"PCA"|"MDS"|"random"} [parameters.init = "random"] - Either "PCA" or "MDS", with which SAMMON initialiates the projection. With "random" a random matrix gets used as starting point.
     * @param {Object} [parameters.init_parameters] - Parameters for the {@link init}-DR method.
     * @param {Number} [parameters.seed = 1212] - the seed for the random number generator.
     * @returns {SAMMON}
     * @see {@link https://arxiv.org/pdf/2009.01512.pdf}
     */
    constructor(X, parameters) {
        super(X, { magic: 0.1, d: 2, metric: euclidean, seed: 1212, init_DR: "random", init_parameters: {} }, parameters);
        return this;
    }

    /**
     * initializes the projection.
     * @private
     */
    init() {
        const N = this.X.shape[0];
        const { d, metric, init_DR: init_DR, init_parameters: DR_parameters } = this._parameters;
        if (init_DR === "random") {
            const randomizer = this._randomizer;
            this.Y = new Matrix(N, d, () => randomizer.random);
        } else if (["PCA", "MDS"].includes(init_DR)) {
            this.Y = Matrix.from(init_DR == "PCA" ? PCA.transform(this.X, DR_parameters) : MDS.transform(this.X, DR_parameters));
        } else {
            throw new Error('init_DR needs to be either "random" or a DR method!')
        }
        this.distance_matrix = metric == "precomputed" ? Matrix.from(this.X) : distance_matrix(this.X, metric);
        return this;
    }

    /**
     * Transforms the inputdata {@link X} to dimenionality 2.
     * @param {Number} [max_iter=200] - Maximum number of iteration steps.
     * @returns {Matrix|Array} - The projection of {@link X}.
     */
    transform(max_iter = 200) {
        if (!this._is_initialized) this.init();
        for (let j = 0; j < max_iter; ++j) {
            this._step();
        }
        return this.projection;
    }

    /**
     * Transforms the inputdata {@link X} to dimenionality 2.
     * @param {Number} [max_iter=200] - Maximum number of iteration steps.
     * @returns {Generator} - A generator yielding the intermediate steps of the projection of {@link X}.
     */
    *generator(max_iter = 200) {
        if (!this._is_initialized) this.init();

        for (let j = 0; j < max_iter; ++j) {
            this._step();
            yield this.projection;
        }

        return this.projection;
    }

    _step() {
        const MAGIC = this.parameter("magic");
        const D = this.distance_matrix;
        const N = this.X.shape[0];
        const { d, metric } = this._parameters;
        let Y = this.Y;

        let G = new Matrix(N, d, 0);

        let sum = new Float64Array(d);
        for (let i = 0; i < N; ++i) {
            let e1 = new Float64Array(d);
            let e2 = new Float64Array(d);
            const Yi = Y.row(i);
            for (let j = 0; j < N; ++j) {
                if (i === j) continue;
                const Yj = Y.row(j);
                const delta = new Float64Array(d);
                for (let k = 0; k < d; ++k) {
                    delta[k] = Yi[k] - Yj[k];
                }
                const dY = metric(Yi, Yj);
                const dX = D.entry(i, j);
                const dq = dX - dY;
                const dr = Math.max(dX * dY, 1e-2);
                for (let k = 0; k < d; ++k) {
                    e1[k] += (delta[k] * dq) / dr;
                    e2[k] += (dq - (Math.pow(delta[k], 2) * (1 + dq / dY)) / dY) / dr;
                }
            }
            for (let k = 0; k < d; ++k) {
                const val = Y.entry(i, k) + ((MAGIC * e1[k]) / Math.abs(e2[k]) || 0);
                G.set_entry(i, k, val);
                sum[k] += val;
            }
        }
        for (let k = 0; k < d; ++k) {
            sum[k] /= N;
        }

        for (let i = 0; i < N; ++i) {
            for (let k = 0; k < d; ++k) {
                Y.set_entry(i, k, G.entry(i, k) - sum[k]);
            }
        }
        return Y;
    }
}

class SQDMDS extends DR {
    /**
     * SQuadMDS: a lean Stochastic Quartet MDS improving global structure preservation in neighbor embedding like t-SNE and UMAP.
     * @constructor
     * @memberof module:dimensionality_reduction
     * @param {Matrix|Number[][]} X
     * @param {Object} [parameters]
     * @param {Number} [parameters.d=2]
     * @param {Function} [parameters.metric = euclidean]
     * @param {Number} [parameters.decay_start = 0.1] - Percentage of iterations using exaggeration phase. If random init: it is recommended to start the decay later to give the time for the global config to adjust with big steps.
     * @param {Number} [parameters.decay_cte = 0.34] - Controls the decay of the learning parameter.
     * @param {Object} [parameters.init_DR]
     * @returns {SQDMDS}
     * @see {@link https://arxiv.org/pdf/2202.12087.pdf}
     */
    constructor(X, parameters) {
        super(
            X,
            {
                d: 2,
                metric: euclidean,
                seed: 1212,
                decay_start: 0.1,
                decay_cte: 0.34, // 0.34
                init_DR: {type: "random"}
            },
            parameters
        );

        return this;
    }

    /**
     * @private
     */
    init() {
        const N = this._N;
        const d = this.parameter("d");

        // initialize helpers.
        this._add = this.__add(d);
        this._sub_div = this.__sub_div(d);
        this._minus = this.__minus(d);
        this._mult = this.__mult(d);
        this._LR_init = Math.max(2, 0.005 * N);
        this._LR = this._LR_init;
        this._offset = -Math.exp(-1 / this.parameter("decay_cte"));
        this._momentums = new Matrix(N, d, 0);
        this._grads = new Matrix(N, d, 0);
        this._indices = linspace(0, N - 1);
        // initialize projection.
        const R = this._randomizer;
        this.Y = new Matrix(N, d, () => R.random - 0.5);

        // preparing metric for optimization.
        const this_metric = this.parameter("metric");
        if (this_metric === "precomputed") {
            this._HD_metric = function (i, j, X) {
                return X.entry(i, j);
            };
            this._HD_metric_exaggeration = function (i, j, X) {
                return Math.pow(X.entry(i, j), 2);
            };
        } else {
            this._HD_metric = function (i, j, X) {
                return this_metric(X.row(i), X.row(j));
            };
            if (this_metric == euclidean) {
                this._HD_metric_exaggeration = function (i, j, X) {
                    return euclidean_squared(X.row(i), X.row(j));
                };
            } else {
                this._HD_metric_exaggeration = function (i, j, X) {
                    return Math.pow(this_metric(X.row(i), X.row(j)), 2);
                };
            }
        }
        return;
    }

    /**
     * Computes the projection.
     * @param {Number} [iterations=500] - Number of iterations.
     * @returns {Matrix|Number[][]} the projection.
     */
    transform(iterations = 500) {
        this.check_init();
        this._decay_start = Math.round(this.parameter("decay_start") * iterations);
        for (let i = 0; i < iterations; ++i) {
            this._step(i, iterations);
        }
        return this.projection;
    }

    /**
     * Computes the projection.
     * @param {Number} [iterations=500] - number of iterations.
     * @yields {Matrix|Number[][]} the intermediate steps of the projection.
     */
    *generator(iterations = 500) {
        this.check_init();
        this._decay_start = Math.round(this.parameter("decay_start") * iterations);
        for (let i = 0; i < iterations; ++i) {
            this._step(i, iterations);
            yield this.projection;
        }
        return this.projection;
    }

    /**
     * Performs an optimization step.
     * @private
     * @param {Number} i - Acutal iteration.
     * @param {Number} iterations - Number of iterations.
     */
    _step(i, iterations) {
        const decay_start = this._decay_start;
        if (i > decay_start) {
            const decay_cte = this.parameter("decay_cte");
            const offset = this._offset;
            const ratio = (i - decay_start) / (iterations - decay_start);
            this._LR = this._LR_init * (Math.exp(-(ratio * ratio) / decay_cte) + offset);
            this._distance_exaggeration = false;
        } else {
            this._distance_exaggeration = true;
        }
        this._nestrov_iteration(this._distance_exaggeration);
    }

    /**
     * Creates quartets of non overlapping indices.
     * @private
     * @returns {Number[][]}
     */
    __quartets() {
        const N = this._N;
        const max_N = N - (N % 4);
        const R = this._randomizer;
        const shuffled_indices = R.choice(this._indices, max_N);
        const result = [];
        for (let i = 0; i < max_N; i += 4) {
            result.push(Uint32Array.of(shuffled_indices[i], shuffled_indices[i + 1], shuffled_indices[i + 2], shuffled_indices[i + 3]));
        }
        return result;
    }

    /**
     * Computes and applies gradients, and updates momentum.
     * @private
     * @param {Boolean} distance_exaggeration
     */
    _nestrov_iteration(distance_exaggeration) {
        const momentums = this._momentums.mult(0.99, { inline: true });
        const LR = this._LR;
        const grads = this._fill_MDS_grads(this.Y.add(momentums), this._grads, distance_exaggeration);
        const [n, d] = momentums.shape;
        for (let i = 0; i < n; ++i) {
            const g_i = grads.row(i);
            const g_i_norm = norm(g_i);
            if (g_i_norm == 0) continue;
            const mul = LR / g_i_norm;
            const m_i = momentums.row(i);
            for (let j = 0; j < d; ++j) {
                m_i[j] -= mul * g_i[j];
            }
        } // momentums -= (LR / norm) * grads
        this.Y.add(momentums, { inline: true });
    }

    /**
     * Computes the gradients.
     * @param {Matrix} Y - The Projection.
     * @param {Matrix} grads - The gradients.
     * @param {Boolean} [exaggeration = false] - Whether or not to use early exaggeration.
     * @param {Boolean} [zero_grad = true] - Whether or not to reset the gradient in the beginning.
     * @returns {Matrix} the gradients.
     */
    _fill_MDS_grads(Y, grads, exaggeration = false, zero_grad = true) {
        if (zero_grad) {
            // compute new gradients
            grads.values.fill(0);
        }
        const add = this._add;
        const X = this.X;
        let HD_metric;
        if (exaggeration == true) {
            HD_metric = this._HD_metric_exaggeration;
        } else {
            HD_metric = this._HD_metric;
        }

        const D_quartet = new Float64Array(6);
        const quartets = this.__quartets();
        for (const [i, j, k, l] of quartets) {
            // compute quartet's HD distances.
            D_quartet[0] = HD_metric(i, j, X);
            D_quartet[1] = HD_metric(i, k, X);
            D_quartet[2] = HD_metric(i, l, X);
            D_quartet[3] = HD_metric(j, k, X);
            D_quartet[4] = HD_metric(j, l, X);
            D_quartet[5] = HD_metric(k, l, X);

            const D_quartet_sum = neumair_sum(D_quartet);

            if (D_quartet_sum > 0) {
                for (let i = 0; i < 6; ++i) {
                    D_quartet[i] /= D_quartet_sum;
                    D_quartet[i] += 1e-11;
                }
            }
            const [gi, gj, gk, gl] = this._compute_quartet_grads(Y, [i, j, k, l], D_quartet);

            // add is inline, row acces the matrix
            add(grads.row(i), gi);
            add(grads.row(j), gj);
            add(grads.row(k), gk);
            add(grads.row(l), gl);
        }
        return grads;
    }

    /**
     * Quartet gradients for a projection.
     * @private
     * @param {Matrix} Y - The acutal projection.
     * @param {Number[]} quartet - The indices of the quartet.
     * @param {Number[]} D_hd - The high-dimensional distances of the quartet.
     * @returns {Number[][]} the gradients for the quartet.
     */
    _compute_quartet_grads(Y, quartet, [p_ab, p_ac, p_ad, p_bc, p_bd, p_cd]) {
        const [a, b, c, d] = quartet.map((index) => Y.row(index));
        // LD distances, add a small number just in case
        const d_ab = euclidean(a, b) + 1e-12;
        const d_ac = euclidean(a, c) + 1e-12;
        const d_ad = euclidean(a, d) + 1e-12;
        const d_bc = euclidean(b, c) + 1e-12;
        const d_bd = euclidean(b, d) + 1e-12;
        const d_cd = euclidean(c, d) + 1e-12;
        const sum_LD_dist = neumair_sum([d_ab, d_ac, d_ad, d_bc, d_bd, d_cd]);

        // for each element of the sum: use the same gradient function and just permute the points given in input.
        const [gA1, gB1, gC1, gD1] = this._ABCD_grads(a, b, c, d, d_ab, d_ac, d_ad, d_bc, d_bd, d_cd, p_ab, sum_LD_dist);
        const [gA2, gC2, gB2, gD2] = this._ABCD_grads(a, c, b, d, d_ac, d_ab, d_ad, d_bc, d_cd, d_bd, p_ac, sum_LD_dist);
        const [gA3, gD3, gC3, gB3] = this._ABCD_grads(a, d, c, b, d_ad, d_ac, d_ab, d_cd, d_bd, d_bc, p_ad, sum_LD_dist);
        const [gB4, gC4, gA4, gD4] = this._ABCD_grads(b, c, a, d, d_bc, d_ab, d_bd, d_ac, d_cd, d_ad, p_bc, sum_LD_dist);
        const [gB5, gD5, gA5, gC5] = this._ABCD_grads(b, d, a, c, d_bd, d_ab, d_bc, d_ad, d_cd, d_ac, p_bd, sum_LD_dist);
        const [gC6, gD6, gA6, gB6] = this._ABCD_grads(c, d, a, b, d_cd, d_ac, d_bc, d_ad, d_bd, d_ab, p_cd, sum_LD_dist);

        const add = this._add;
        const gA = add(gA1, gA2, gA3, gA4, gA5, gA6);
        const gB = add(gB1, gB2, gB3, gB4, gB5, gB6);
        const gC = add(gC1, gC2, gC3, gC4, gC5, gC6);
        const gD = add(gD1, gD2, gD3, gD4, gD5, gD6);

        return [gA, gB, gC, gD];
    }

    /**
     * Gradients for one element of the loss function's sum.
     * @private
     */
    _ABCD_grads(a, b, c, d, d_ab, d_ac, d_ad, d_bc, d_bd, d_cd, p_ab, sum_LD_dist) {
        const ratio = d_ab / sum_LD_dist;
        const twice_ratio = 2 * ((p_ab - ratio) / sum_LD_dist);
        const minus = this._minus;
        const add = this._add;
        const mult = this._mult;
        const sub_div = this._sub_div;
        // no side effects because sub_div creates new arrays, and the inline functions work on this new created arrays.
        const gA = mult(minus(mult(add(sub_div(a, b, d_ab), sub_div(a, c, d_ac), sub_div(a, d, d_ad)), ratio), sub_div(a, b, d_ab)), twice_ratio);
        const gB = mult(minus(mult(add(sub_div(b, a, d_ab), sub_div(b, c, d_bc), sub_div(b, d, d_bd)), ratio), sub_div(b, a, d_ab)), twice_ratio);
        const gC = mult(add(sub_div(c, a, d_ac), sub_div(c, b, d_bc), sub_div(c, d, d_cd)), ratio * twice_ratio);
        const gD = mult(add(sub_div(d, a, d_ad), sub_div(d, b, d_bd), sub_div(d, c, d_cd)), ratio * twice_ratio);
        return [gA, gB, gC, gD];
    }

    /**
     * Inline!
     */
    __minus(d) {
        return (a, b) => {
            for (let i = 0; i < d; ++i) {
                a[i] -= b[i];
            }
            return a;
        };
    }

    /**
     * Inline!
     */
    __add(d) {
        return (...summands) => {
            const n = summands.length;
            const s1 = summands[0];
            for (let j = 1; j < n; ++j) {
                const summand = summands[j];
                for (let i = 0; i < d; ++i) {
                    s1[i] += summand[i];
                }
            }
            return s1;
        };
    }

    /**
     * Inline!
     */
    __mult(d) {
        return (a, v) => {
            for (let i = 0; i < d; ++i) {
                a[i] *= v;
            }
            return a;
        };
    }

    /**
     * Creates a new array <code>(x - y) / div</code>
     */
    __sub_div(d) {
        return (x, y, div) => {
            return Float64Array.from({ length: d }, (_, i) => (x[i] - y[i]) / div);
        };
    }
}

var version="0.6.0";

exports.BallTree = BallTree;
exports.DisjointSet = DisjointSet;
exports.FASTMAP = FASTMAP;
exports.Heap = Heap;
exports.Hierarchical_Clustering = Hierarchical_Clustering;
exports.ISOMAP = ISOMAP;
exports.KMeans = KMeans;
exports.KMedoids = KMedoids;
exports.KNN = KNN;
exports.LDA = LDA;
exports.LLE = LLE;
exports.LSP = LSP;
exports.LTSA = LTSA;
exports.MDS = MDS;
exports.Matrix = Matrix;
exports.OPTICS = OPTICS;
exports.PCA = PCA;
exports.Randomizer = Randomizer;
exports.SAMMON = SAMMON;
exports.SQDMDS = SQDMDS;
exports.TSNE = TSNE;
exports.TopoMap = TopoMap;
exports.TriMap = TriMap;
exports.UMAP = UMAP;
exports.canberra = canberra;
exports.chebyshev = chebyshev;
exports.cosine = cosine;
exports.distance_matrix = distance_matrix;
exports.euclidean = euclidean;
exports.euclidean_squared = euclidean_squared;
exports.hamming = hamming;
exports.inner_product = inner_product;
exports.jaccard = jaccard;
exports.k_nearest_neighbors = k_nearest_neighbors;
exports.kahan_sum = kahan_sum;
exports.linspace = linspace;
exports.manhattan = manhattan;
exports.max = max;
exports.min = min;
exports.neumair_sum = neumair_sum;
exports.norm = norm;
exports.normalize = normalize;
exports.powell = powell;
exports.qr = qr_gramschmidt;
exports.qr_householder = qr_householder;
exports.simultaneous_poweriteration = simultaneous_poweriteration;
exports.sokal_michener = sokal_michener;
exports.version = version;
exports.yule = yule;

Object.defineProperty(exports, '__esModule', { value: true });

}));
//# sourceMappingURL=druid.js.map
};
BundleModuleCode['plugins/ml/som']=function (module,exports,global,process){
// SOM Algorithm
// https://github.com/mljs/som
// Array/Typedarray version
// Ver 1.2.1

'use strict';

function squaredEuclidean(p, q) {
  let d = 0;
  for (let i = 0; i < p.length; i++) {
    d += (p[i] - q[i]) * (p[i] - q[i]);
  }
  return d;
}

function round(v,decimals) {
  return Number(v.toFixed(decimals))
}

var NodeSquare = Require('plugins/ml/ml/som/node-square'),
    NodeHexagonal = Require('plugins/ml/ml/som/node-hexagonal');

var defaultOptions = {
    fields: 3,
    randomizer: Math.random,
    distance: squaredEuclidean,
    iterations: 10,
    learningRate: 0.1,
    gridType: 'rect',
    torus: true,
    method: 'random'
};

function SOM(x, y, options, reload) {
    this.x = x;
    this.y = y;

    options = options || {};
    this.options = {};
    for (var i in defaultOptions) {
        if (options.hasOwnProperty(i)) {
            this.options[i] = options[i];
        } else {
            this.options[i] = defaultOptions[i];
        }
    }

    if (typeof this.options.fields === 'number') {
        this.numWeights = this.options.fields;
    } else if (Array.isArray(this.options.fields)) {
        this.numWeights = this.options.fields.length;
        var converters = getConverters(this.options.fields);
        this.extractor = converters.extractor;
        this.creator = converters.creator;
    } else {
        throw new Error('Invalid fields definition');
    }

    if (this.options.gridType === 'rect') {
        this.NodeType = NodeSquare;
        this.gridDim = {
            x: x,
            y: y
        };
    } else {
        this.NodeType = NodeHexagonal;
        var hx = this.x - Math.floor(this.y / 2);
        this.gridDim = {
            x: hx,
            y: this.y,
            z: -(0 - hx - this.y)
        };
    }

    this.torus = this.options.torus;
    this.distanceMethod = this.torus ? 'getDistanceTorus' : 'getDistance';

    this.distance = this.options.distance;

    this.maxDistance = getMaxDistance(this.distance, this.numWeights);

    if (reload === true) { // For model loading
        this.done = true;
        return;
    }
    if (!(x > 0 && y > 0)) {
        throw new Error('x and y must be positive');
    }

    this.times = {
        findBMU: 0,
        adjust: 0
    };

    this.randomizer = this.options.randomizer;

    this.iterationCount = 0;
    this.iterations = this.options.iterations;

    this.startLearningRate = this.learningRate = this.options.learningRate;

    this.mapRadius = Math.floor(Math.max(x, y) / 2);

    this.algorithmMethod = this.options.method;

    this.initNodes();

    this.done = false;
}

// typeof @trainingValue= Vector | Array | TypedArray | object

SOM.prototype.adjust = function adjust(trainingValue, neighbourhoodRadius) {
    var now = Date.now(),
        x, y, dist, influence;

    var bmu = this.findBestMatchingUnit(trainingValue);
    if (!bmu) throw "SOM.adjust: No matching BMU found.";
    var now2 = Date.now();
    this.times.findBMU += now2 - now;

    var radiusLimit = Math.floor(neighbourhoodRadius);
    
    var xMin = bmu.x - radiusLimit,
        xMax = bmu.x + radiusLimit,
        yMin = bmu.y - radiusLimit,
        yMax = bmu.y + radiusLimit;

    for (x = xMin; x <= xMax; x++) {
        var theX = x;
        if (x < 0) {
            theX += this.x;
        } else if (x >= this.x) {
            theX -= this.x;
        }
        for (y = yMin; y <= yMax; y++) {
            var theY = y;
            if (y < 0) {
                theY += this.y;
            } else if (y >= this.y) {
                theY -= this.y;
            }

            dist = bmu[this.distanceMethod](this.nodes[theX][theY]);

            if (dist < neighbourhoodRadius) {
                influence = Math.exp(-dist / (2 * neighbourhoodRadius));
                this.nodes[theX][theY].adjustWeights(trainingValue, this.learningRate, influence);
            }

        }
    }

    this.times.adjust += (Date.now() - now2);

};

// Approximate weights (reduce precision, decrease model export size)
SOM.prototype.approximate = function approximateModel(precision) {
  precision = checkOption(precision,2);

  var min0,max0,min,max;
  for (var i = 0; i < this.x; i++) {
    for (var j = 0; j < this.y; j++) {
      this.nodes[i][j].weights=this.nodes[i][j].weights.map(function (w) {
        if (min0 == undefined) max0=w,min0=w;
        else max0=Math.max(max0,w),min0=Math.min(min0,w);
        w=round(w,precision);
        if (min == undefined) max=w,min=w;
        else max=Math.max(max,w),min=Math.min(min,w);
        return w;
      });
    }
  }
  var error=round((1-(max-min)/(max0-min0))*100,4);
  return {max:max,min:min,min0:min0,max0:max0,error:error}
}

SOM.prototype.export = function exportModel() {
    var model = {
        name: 'SOM'
    };
    model.options = {
        fields: this.options.fields,
        gridType: this.options.gridType,
        torus: this.options.torus
    };
    model.data = new Array(this.x);
    for (var i = 0; i < this.x; i++) {
        model.data[i] = new Array(this.y);
        for (var j = 0; j < this.y; j++) {
            model.data[i][j] = this.nodes[i][j].weights;
        }
    }
    if (!this.done) {
        model.ready = false;
    }
    return model;
};

SOM.prototype.findBestMatchingUnit = function findBestMatchingUnit(candidate) {

    var bmu,
        lowest = Infinity,
        dist;

    for (var i = 0; i < this.x; i++) {
        for (var j = 0; j < this.y; j++) {
            dist = this.distance(this.nodes[i][j].weights, candidate);
            if (dist < lowest) {
                lowest = dist;
                bmu = this.nodes[i][j];
            }
        }
    }

    return bmu;

};

SOM.prototype.getConvertedNodes = function getConvertedNodes() {
    var result = new Array(this.x);
    for (var i = 0; i < this.x; i++) {
        result[i] = new Array(this.y);
        for (var j = 0; j < this.y; j++) {
            var node = this.nodes[i][j];
            result[i][j] = this.creator ? this.creator(node.weights) : node.weights;
        }
    }
    return result;
};

// As seen in http://www.scholarpedia.org/article/Kohonen_network
SOM.prototype.getQuantizationError = function getQuantizationError() {
    var fit = this.getFit(),
        l = fit.length,
        sum = 0;
    for (var i = 0; i < l; i++) {
        sum += fit[i];
    }
    return sum / l;
};

SOM.prototype.getFit = function getFit(dataset) {
    if (!dataset) {
        dataset = this.trainingSet;
    }
    var l = dataset.length,
        bmu,
        result = new Array(l);
    for (var i = 0; i < l; i++) {
        bmu = this.findBestMatchingUnit(dataset[i]);
        result[i] = Math.sqrt(this.distance(dataset[i], bmu.weights));
    }
    return result;
};

SOM.prototype.getUMatrix = function getUMatrix() {
    var matrix = new Array(this.x);
    for (var i = 0; i < this.x; i++) {
        matrix[i] = new Array(this.y);
        for (var j = 0; j < this.y; j++) {
            var node = this.nodes[i][j],
                nX = node.getNeighbors('x'),
                nY = node.getNeighbors('y');
            var sum = 0,
                total = 0,
                self = this;
            if(nX[0]) {
                total++;
                sum += self.distance(node.weights, nX[0].weights);
            }
            if(nX[1]) {
                total++;
                sum += self.distance(node.weights, nX[1].weights);
            }
            if(nY[0]) {
                total++;
                sum += self.distance(node.weights, nY[0].weights);
            }
            if(nY[1]) {
                total++;
                sum += self.distance(node.weights, nY[1].weights);
            }
            matrix[i][j] = sum / total;
        }
    }
    return matrix;
};

SOM.prototype.initNodes = function initNodes() {
    var now = Date.now(),
        i, j, k;
    this.nodes = new Array(this.x);
    for (i = 0; i < this.x; i++) {
        this.nodes[i] = new Array(this.y);
        for (j = 0; j < this.y; j++) {
            var weights = new Array(this.numWeights);
            for (k = 0; k < this.numWeights; k++) {
                weights[k] = this.randomizer();
            }
            this.nodes[i][j] = new this.NodeType(i, j, weights, this);
        }
    }
    this.times.initNodes = Date.now() - now;
};

SOM.load = function loadModel(model, distance) {
    if (model.name === 'SOM') {
        var x = model.data.length,
            y = model.data[0].length;
        if (distance) {
            model.options.distance = distance;
        }
        var som = new SOM(x, y, model.options, true);
        som.nodes = new Array(x);
        for (var i = 0; i < x; i++) {
            som.nodes[i] = new Array(y);
            for (var j = 0; j < y; j++) {
                som.nodes[i][j] = new som.NodeType(i, j, model.data[i][j], som);
            }
        }
        return som;
    } else {
        throw new Error('expecting a SOM model');
    }
};

SOM.prototype.predict = function predict(data, computePosition) {
    if (typeof data === 'boolean') {
        computePosition = data;
        data = null;
    }
    if (!data) {
        data = this.trainingSet;
    }
    if (Array.isArray(data) && (Array.isArray(data[0]) || (typeof data[0] === 'object'))) { // predict a dataset
        var self = this;
        return data.map(function (element) {
            return self.predictOne(element, computePosition);
        });
    } else { // predict a single element
        return this.predictOne(data, computePosition);
    }
};

SOM.prototype.predictOne = function predictOne(element, computePosition) {
    if (!Array.isArray(element) && !Utils.isTypedArray(element)) {
        element = this.extractor(element);
    }
    var bmu = this.findBestMatchingUnit(element);
    var result = [bmu.x, bmu.y];
    if (computePosition) {
        result[2] = bmu.getPosition(element);
    }
    return result;
};

// typeof @trainingSet = (Array|TypedArray) Array|Matrix|MatrixTA

SOM.prototype.setTraining = function setTraining(trainingSet) {
   if (this.trainingSet) {
        throw new Error('training set has already been set');
    }
    var now = Date.now();
    if (Math.Matrix && Math.Matrix.isMatrix(trainingSet)) {
      trainingSet=trainingSet.data;
    } else if (Math.MatrixTA && Math.MatrixTA.isMatrix(trainingSet)) {
      var _trainingSet=[];
      for(var i=0;i<trainingSet.rows;i++) {
        _trainingSet.push(trainingSet.getRow(i)); // Array
      }
      trainingSet=_trainingSet;
    }
    var convertedSet = trainingSet;
    var i, l = trainingSet.length;
    
    if (this.extractor) {
        convertedSet = new Array(l);
        for (i = 0; i < l; i++) {
            convertedSet[i] = this.extractor(trainingSet[i]);
        }
    }
    this.numIterations = this.iterations * l;

    if (this.algorithmMethod === 'random') {
        this.timeConstant = this.numIterations / Math.log(this.mapRadius);
    } else {
        this.timeConstant = l / Math.log(this.mapRadius);
    }
    this.trainingSet = convertedSet;
    this.times.setTraining = Date.now() - now;
};

SOM.prototype.train = function train(trainingSet,options) {
  if (options && options.iterations) {
    this.iterations=options.iterations;
    this.numIterations = this.iterations * trainingSet.length;
  }
  if (!this.done) {
      this.setTraining(trainingSet);
      var needTrain = true;
      while (needTrain){
          needTrain = this.trainOne();
      }
  }
};


SOM.prototype.trainOne = function trainOne() {
    if (this.done) {
        return false;
    } else if (this.numIterations-- > 0) {
        var neighbourhoodRadius,
            trainingValue,
            trainingSetFactor;

        if (this.algorithmMethod === 'random') { // Pick a random value of the training set at each step
            neighbourhoodRadius = this.mapRadius * Math.exp(-this.iterationCount / this.timeConstant);
            trainingValue = getRandomValue(this.trainingSet, this.randomizer);
            this.adjust(trainingValue, neighbourhoodRadius);
            this.learningRate = this.startLearningRate * Math.exp(-this.iterationCount / this.numIterations);
        } else { // Get next input vector
            trainingSetFactor = -Math.floor(this.iterationCount / this.trainingSet.length);
            neighbourhoodRadius = this.mapRadius * Math.exp(trainingSetFactor / this.timeConstant);
            trainingValue = this.trainingSet.getRow(this.iterationCount % this.trainingSet.length);
            this.adjust(trainingValue, neighbourhoodRadius);
            if (((this.iterationCount + 1) % this.trainingSet.length) === 0) {
                this.learningRate = this.startLearningRate * Math.exp(trainingSetFactor / Math.floor(this.numIterations / this.trainingSet.length));
            }
        }
        this.iterationCount++;
        return true;
    } else {
        this.done = true;
        return false;
    }
};



function getConverters(fields) {
    var l = fields.length,
        normalizers = new Array(l),
        denormalizers = new Array(l),
        range;
    for (var i = 0; i < l; i++) {
        range = fields[i].range;
        normalizers[i] = getNormalizer(range[0], range[1]);
        denormalizers[i] = getDenormalizer(range[0], range[1]);
    }
    return {
        extractor: function extractor(value) {
            var result = new Array(l);
            for (var j = 0; j < l; j++) {
                result[j] = normalizers[j](value[fields[j].name]);
            }
            return result;
        },
        creator: function creator(value) {
            var result = {};
            for (var j = 0; j < l; j++) {
                result[fields[j].name] = denormalizers[j](value[j]);
            }
            return result;
        }
    };
}

function getNormalizer(min, max) {
    return function normalizer(value) {
        return (value - min) / (max - min);
    };
}

function getDenormalizer(min, max) {
    return function denormalizer(value) {
        return (min + value * (max - min));
    };
}

function getRandomValue(arr, randomizer) {
    return arr.getRow(Math.floor(randomizer() * arr.length));
}

function getMaxDistance(distance, numWeights) {
    var zero = new Array(numWeights),
        one = new Array(numWeights);
    for (var i = 0; i < numWeights; i++) {
        zero[i] = 0;
        one[i] = 1;
    }
    return distance(zero, one);
}

module.exports = SOM;

};
BundleModuleCode['plugins/ml/ml/som/node-square']=function (module,exports,global,process){
'use strict';

function NodeSquare(x, y, weights, som) {
    this.x = x;
    this.y = y;
    this.weights = weights;
    this.som = som;
    this.neighbors = {};
}

NodeSquare.prototype.adjustWeights = function adjustWeights(target, learningRate, influence) {
    for (var i = 0, ii = this.weights.length; i < ii; i++) {
        this.weights[i] += learningRate * influence * (target[i] - this.weights[i]);
    }
};

NodeSquare.prototype.getDistance = function getDistance(otherNode) {
    return Math.max(Math.abs(this.x - otherNode.x), Math.abs(this.y - otherNode.y));
};

NodeSquare.prototype.getDistanceTorus = function getDistanceTorus(otherNode) {
    var distX = Math.abs(this.x - otherNode.x),
        distY = Math.abs(this.y - otherNode.y);
    return Math.max(Math.min(distX, this.som.gridDim.x - distX), Math.min(distY, this.som.gridDim.y - distY));
};

NodeSquare.prototype.getNeighbors = function getNeighbors(xy) {
    if (!this.neighbors[xy]) {
        this.neighbors[xy] = new Array(2);

        // left or bottom neighbor
        var v;
        if (this[xy] > 0) {
            v = this[xy] - 1;
        } else if (this.som.torus) {
            v = this.som.gridDim[xy] - 1;
        }
        if (typeof v !== 'undefined') {
            var x, y;
            if (xy === 'x') {
                x = v;
                y = this.y;
            } else {
                x = this.x;
                y = v;
            }
            this.neighbors[xy][0] = this.som.nodes[x][y];
        }

        // top or right neighbor
        var w;
        if (this[xy] < (this.som.gridDim[xy] - 1)) {
            w = this[xy] + 1;
        } else if (this.som.torus) {
            w = 0;
        }
        if (typeof w !== 'undefined') {
            if (xy === 'x') {
                x = w;
                y = this.y;
            } else {
                x = this.x;
                y = w;
            }
            this.neighbors[xy][1] = this.som.nodes[x][y];
        }
    }
    return this.neighbors[xy];
};

NodeSquare.prototype.getPos = function getPos(xy, element) {
    var neighbors = this.getNeighbors(xy),
        distance = this.som.distance,
        bestNeighbor,
        direction;
    if(neighbors[0]) {
        if (neighbors[1]) {
            var dist1 = distance(element, neighbors[0].weights),
                dist2 = distance(element, neighbors[1].weights);
            if(dist1 < dist2) {
                bestNeighbor = neighbors[0];
                direction = -1;
            } else {
                bestNeighbor = neighbors[1];
                direction = 1;
            }
        } else {
            bestNeighbor = neighbors[0];
            direction = -1;
        }
    } else {
        bestNeighbor = neighbors[1];
        direction = 1;
    }
    var simA = 1 - distance(element, this.weights),
        simB = 1 - distance(element, bestNeighbor.weights);
    var factor = ((simA - simB) / (2 - simA - simB));
    return 0.5 + 0.5 * factor * direction;
};

NodeSquare.prototype.getPosition = function getPosition(element) {
    return [
        this.getPos('x', element),
        this.getPos('y', element)
    ];
};

module.exports = NodeSquare;
};
BundleModuleCode['plugins/ml/ml/som/node-hexagonal']=function (module,exports,global,process){
'use strict';

var NodeSquare = Require('plugins/ml/ml/som/node-square');

function NodeHexagonal(x, y, weights, som) {

    NodeSquare.call(this, x, y, weights, som);

    this.hX = x - Math.floor(y / 2);
    this.z = 0 - this.hX - y;

}

NodeHexagonal.prototype = new NodeSquare();
NodeHexagonal.prototype.constructor = NodeHexagonal;

NodeHexagonal.prototype.getDistance = function getDistanceHexagonal(otherNode) {
    return Math.max(Math.abs(this.hX - otherNode.hX), Math.abs(this.y - otherNode.y), Math.abs(this.z - otherNode.z));
};

NodeHexagonal.prototype.getDistanceTorus = function getDistanceTorus(otherNode) {
    var distX = Math.abs(this.hX - otherNode.hX),
        distY = Math.abs(this.y - otherNode.y),
        distZ = Math.abs(this.z - otherNode.z);
    return Math.max(Math.min(distX, this.som.gridDim.x - distX), Math.min(distY, this.som.gridDim.y - distY), Math.min(distZ, this.som.gridDim.z - distZ));
};

NodeHexagonal.prototype.getPosition = function getPosition() {
    throw new Error('Unimplemented : cannot get position of the points for hexagonal grid');
};

module.exports = NodeHexagonal;
};
BundleModuleCode['plugins/ml/helpers']=function (module,exports,global,process){
//     wink-helpers
//     Functions for cross validation, shuffle, cartesian product and more
//
//     https://github.com/winkjs/wink-helpers
//
//     Copyright (C) 2017-18  GRAYPE Systems Private Limited
//
//     This file is part of “wink-helpers”.
//
//     Permission is hereby granted, free of charge, to any person obtaining a
//     copy of this software and associated documentation files (the "Software"),
//     to deal in the Software without restriction, including without limitation
//     the rights to use, copy, modify, merge, publish, distribute, sublicense,
//     and/or sell copies of the Software, and to permit persons to whom the
//     Software is furnished to do so, subject to the following conditions:
//
//     The above copyright notice and this permission notice shall be included
//     in all copies or substantial portions of the Software.
//
//     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
//     DEALINGS IN THE SOFTWARE.

//
var helpers = Object.create( null );

// ### Private Functions

// #### Product Reducer (Callback)

// Callback function used by `reduce` inside the `product()` function.
// Follows the standard guidelines of `reduce()` callback function.
var productReducer = function ( prev, curr ) {
  var c,
      cmax = curr.length;
  var p,
      pmax = prev.length;
  var result = [];

  for ( p = 0; p < pmax; p += 1 ) {
    for ( c = 0; c < cmax; c += 1 ) {
      result.push( prev[ p ].concat( curr[ c ] ) );
    }
  }
  return ( result );
}; // productReducer()

// ### Public Function

// ### Array Helpers

helpers.array = Object.create( null);

// #### is Array

// Tests if argument `v` is a JS array; returns `true` if it is, otherwise returns `false`.
helpers.array.isArray = function ( v ) {
  return ( ( v !== undefined ) && ( v !== null ) && ( Object.prototype.toString.call( v ) === '[object Array]' ) );
}; // isArray()


// #### sorting helpers

// Set of helpers to sort either numbers or strings. For key/value pairs,
// the format for each element must be `[ key, value ]`.
// Sort helper to sort an array in ascending order.
helpers.array.ascending = function ( a, b ) {
  return ( a > b ) ? 1 :
            ( a === b ) ? 0 : -1;
}; // ascending()

// Sort helper to sort an array in descending order.
helpers.array.descending = function ( a, b ) {
  return ( b > a ) ? 1 :
            ( b === a ) ? 0 : -1;
}; // descending()

// Sort helper to sort an array of `[ key, value ]` in ascending order by **key**.
helpers.array.ascendingOnKey = function ( a, b ) {
  return ( a[ 0 ] > b[ 0 ] ) ? 1 :
            ( a[ 0 ] === b[ 0 ] ) ? 0 : -1;
}; // ascendingOnKey()

// Sort helper to sort an array of `[ key, value ]` in descending order by **key**.
helpers.array.descendingOnKey = function ( a, b ) {
  return ( b[ 0 ] > a[ 0 ] ) ? 1 :
            ( b[ 0 ] === a[ 0 ] ) ? 0 : -1;
}; // descendingOnKey()

// Sort helper to sort an array of `[ key, value ]` in ascending order by **value**.
helpers.array.ascendingOnValue = function ( a, b ) {
  return ( a[ 1 ] > b[ 1 ] ) ? 1 :
            ( a[ 1 ] === b[ 1 ] ) ? 0 : -1;
}; // ascendingOnValue()

// Sort helper to sort an array of `[ key, value ]` in descending order by **value**.
helpers.array.descendingOnValue = function ( a, b ) {
  return ( b[ 1 ] > a[ 1 ] ) ? 1 :
            ( b[ 1 ] === a[ 1 ] ) ? 0 : -1;
}; // descendingOnValue()

// The following two functions generate a suitable function for sorting on a single
// key or on a composite keys (max 2 only). Just a remider, the generated function
// does not sort on two keys; instead it will sort on a key composed of the two
// accessors.
// Sorts in ascending order on `accessor1` & `accessor2` (optional).
helpers.array.ascendingOn = function ( accessor1, accessor2 ) {
  if ( accessor2 ) {
    return ( function ( a, b ) {
      return ( a[ accessor1 ][ accessor2 ] > b[ accessor1 ][ accessor2 ] ) ? 1 :
              ( a[ accessor1 ][ accessor2 ] === b[ accessor1 ][ accessor2 ] ) ? 0 : -1;
    } );
  }
  return ( function ( a, b ) {
    return ( a[ accessor1 ] > b[ accessor1 ] ) ? 1 :
            ( a[ accessor1 ] === b[ accessor1 ] ) ? 0 : -1;
  } );
}; // ascendingOn()

// Sorts in descending order on `accessor1` & `accessor2` (optional).
helpers.array.descendingOn = function ( accessor1, accessor2 ) {
  if ( accessor2 ) {
    return ( function ( a, b ) {
      return ( b[ accessor1 ][ accessor2 ] > a[ accessor1 ][ accessor2 ] ) ? 1 :
              ( b[ accessor1 ][ accessor2 ] === a[ accessor1 ][ accessor2 ] ) ? 0 : -1;
    } );
  }
  return ( function ( a, b ) {
    return ( b[ accessor1 ] > a[ accessor1 ] ) ? 1 :
            ( b[ accessor1 ] === a[ accessor1 ] ) ? 0 : -1;
  } );
}; // descendingOn()

// #### pluck

// Plucks specified element from each element of an **array of array**, and
// returns the resultant array. The element is specified by `i` (default `0`) and
// number of elements to pluck are defined by `limit` (default `a.length`).
helpers.array.pluck = function ( a, key, limit ) {
  var k, plucked;
  k = a.length;
  var i = key || 0;
  var lim = limit || k;
  if ( lim > k ) lim = k;
  plucked = new Array( lim );
  for ( k = 0; k < lim; k += 1 ) plucked[ k ] = a[ k ][ i ];
  return plucked;
}; // pluck()

// #### product

// Finds the Cartesian Product of arrays present inside the array `a`. Therefore
// the array `a` must be an array of 1-dimensional arrays. For example,
// `product( [ [ 9, 8 ], [ 1, 2 ] ] )`
// will produce `[ [ 9, 1 ], [ 9, 2 ], [ 8, 1 ], [ 8, 2 ] ]`.
helpers.array.product = function ( a ) {
  return (
    a.reduce( productReducer, [ [] ] )
  );
};

// #### shuffle

// Randomly shuffles the elements of an array and returns the same.
// Reference: Chapter on Random Numbers/Shuffling in Seminumerical algorithms.
// The Art of Computer Programming Volume II by Donald E Kunth
helpers.array.shuffle = function ( array ) {
  var a = array;
  var balance = a.length;
  var candidate;
  var temp;

  while ( balance ) {
    candidate = Math.floor( Math.random() * balance );
    balance -= 1;

    temp = a[ balance ];
    a[ balance ] = a[ candidate ];
    a[ candidate ] = temp;
  }

  return ( a );
};


// ### Object Helpers

var objectKeys = Object.keys;
var objectCreate = Object.create;

helpers.object = Object.create( null );

// #### is Object

// Tests if argument `v` is a JS object; returns `true` if it is, otherwise returns `false`.
helpers.object.isObject = function ( v ) {
  return ( v && ( Object.prototype.toString.call( v ) === '[object Object]' ) ) ? true : false; // eslint-disable-line no-unneeded-ternary

}; // isObject()

// #### keys

// Returns keys of the `obj` in an array.
helpers.object.keys = function ( obj ) {
  return ( objectKeys( obj ) );
}; // keys()

// #### size

// Returns the number of keys of the `obj`.
helpers.object.size = function ( obj ) {
  return ( ( objectKeys( obj ) ).length );
}; // size()

// #### values

// Returns all values from each key/value pair of the `obj` in an array.
helpers.object.values = function ( obj ) {
  var keys = helpers.object.keys( obj );
  var length = keys.length;
  var values = new Array( length );
  for ( var i = 0; i < length; i += 1 ) {
    values[ i ] = obj[ keys[ i ] ];
  }
  return values;
}; // values()

// #### value Freq

// Returns the frequency of each unique value present in the `obj`, where the
// **key** is the *value* and **value** is the *frequency*.
helpers.object.valueFreq = function ( obj ) {
  var keys = helpers.object.keys( obj );
  var length = keys.length;
  var val;
  var vf = objectCreate( null );
  for ( var i = 0; i < length; i += 1 ) {
    val = obj[ keys[ i ] ];
    vf[ val ] = 1 + ( vf[ val ] || 0 );
  }
  return vf;
}; // valueFreq()

// #### table

// Converts the `obj` in to an array of `[ key, value ]` pairs in form of a table.
// Second argument - `f` is optional and it is a function, which is called with
// each `value`.
helpers.object.table = function ( obj, f ) {
  var keys = helpers.object.keys( obj );
  var length = keys.length;
  var pairs = new Array( length );
  var ak, av;
  for ( var i = 0; i < length; i += 1 ) {
    ak = keys[ i ];
    av = obj[ ak ];
    if ( typeof f === 'function' ) f( av );
    pairs[ i ] = [ ak, av ];
  }
  return pairs;
}; // table()

// ### Validation Helpers

helpers.validate = Object.create( null );

// Create aliases for isObject and isArray.
helpers.validate.isObject = helpers.object.isObject;
helpers.validate.isArray = helpers.array.isArray;

// #### isFiniteInteger

// Validates if `n` is a finite integer.
helpers.validate.isFiniteInteger = function ( n ) {
  return (
    ( typeof n === 'number' ) &&
    !isNaN( n ) &&
    isFinite( n ) &&
    ( n === Math.round( n ) )
  );
}; // isFiniteInteger()

// #### isFiniteNumber

// Validates if `n` is a valid number.
helpers.validate.isFiniteNumber = function ( n ) {
  return (
    ( typeof n === 'number' ) &&
    !isNaN( n ) &&
    isFinite( n )
  );
}; // isFiniteNumber()

// ### cross validation
/**
 *
 * Creates an instance of cross validator useful for machine learning tasks.
 *
 * @param {string[]} classLabels - array containing all the class labels.
 * @return {methods} object conatining set of API methods for tasks like evalutaion,
 * reset and metrics generation.
*/
helpers.validate.cross = function ( classLabels ) {
  // wink's const for unknown predictions!
  const unknown = 'unknown';
  // To ensure that metrics is not computed prior to evaluation.
  var evaluated = false;
  // The confusion matrix.
  var cm;
  var precision;
  var recall;
  var fmeasure;

  // The class labels is assigned to this variable.
  var labels;
  // The length of `labels` array.
  var labelCount;
  var labelsObj = Object.create( null );

  // Returned!
  var methods = Object.create( null );


  /**
   *
   * Resets the current instance for another round of evaluation; the class
   * labels defined at instance creation time are not touched.
   *
   * @return {undefined} nothing!
  */
  var reset = function ( ) {
    evaluated = false;
    cm = Object.create( null );
    precision = Object.create( null );
    recall = Object.create( null );
    fmeasure = Object.create( null );

    // Initialize confusion matrix and metrics.
    for ( var i = 0; i < labelCount; i += 1 ) {
      const row = labels[ i ];
      labelsObj[ row ] = true;
      cm[ row ] = Object.create( null );
      precision[ row ] = 0;
      recall[ row ] = 0;
      fmeasure[ row ] = 0;
      for ( var j = 0; j < labelCount; j += 1 ) {
        const col = labels[ j ];
        cm[ row ][ col ] = 0;
      }
    }
  }; // reset()

  /**
   *
   * Creates an instance of cross validator useful for machine learning tasks.
   *
   * @param {string} truth - the actual class label.
   * @param {string} guess - the predicted class label.
   * @return {boolean} returns true if the evaluation is successful. The evaluation
   * may fail if `truth` or `guess` is not in the array `classLabels` provided at
   * instance creation time; or if guess is equal to `unknown`.
  */
  var evaluate = function ( truth, guess ) {
    // If prediction failed then return false!
    if ( guess === unknown || !labelsObj[ truth ] || !labelsObj[ guess ] ) return false;
    // Update confusion matrix.
    if ( guess === truth ) {
      cm[ truth ][ guess ] += 1;
    } else {
      cm[ guess ][ truth ] += 1;
    }
    evaluated = true;
    return true;
  }; // evaluate()

  /**
   *
   * It computes a detailed metrics consisting of macro-averaged precision,
   * recall and f-measure along with their label-wise values and the confusion
   * matrix.
   *
   * @return {object} object containing macro-averaged `avgPrecision`, `avgRecall`,
   * `avgFMeasure` values along with other details such as label-wise values
   * and the confusion matrix. A value of `null` is returned if no evaluate()
   * has been called before.
  */
  var metrics = function ( ) {
    if ( !evaluated ) return null;
    // Numerators for every label; they are same for precision & recall both.
    var n = Object.create( null );
    // Only denominators differs for precision & recall
    var pd = Object.create( null );
    var rd = Object.create( null );
    // `row` and `col` of confusion matrix.
    var col, row;
    var i, j;
    // Macro average values for metrics.
    var avgPrecision = 0;
    var avgRecall = 0;
    var avgFMeasure = 0;

    // Compute label-wise numerators & denominators!
    for ( i = 0; i < labelCount; i += 1 ) {
      row = labels[ i ];
      for ( j = 0; j < labelCount; j += 1 ) {
        col = labels[ j ];
        if ( row === col ) {
          n[ row ] = cm[ row ][ col ];
        }
        pd[ row ] = cm[ row ][ col ] + ( pd[ row ] || 0 );
        rd[ row ] = cm[ col ][ row ] + ( rd[ row ] || 0 );
      }
    }
    // Ready to compute metrics.
    for ( i = 0; i < labelCount; i += 1 ) {
      row = labels[ i ];
      precision[ row ] = +( n[ row ] / pd[ row ] ).toFixed( 4 );
      // NaN can occur if a label has not been encountered.
      if ( isNaN( precision[ row ] ) ) precision[ row ] = 0;

      recall[ row ] = +( n[ row ] / rd[ row ] ).toFixed( 4 );
      if ( isNaN( recall[ row ] ) ) recall[ row ] = 0;

      fmeasure[ row ] = +( 2 * precision[ row ] * recall[ row ] / ( precision[ row ] + recall[ row ] ) ).toFixed( 4 );
      if ( isNaN( fmeasure[ row ] ) ) fmeasure[ row ] = 0;
    }
    // Compute thier averages, note they will be macro avegages.
    for ( i = 0; i < labelCount; i += 1 ) {
      avgPrecision += ( precision[ labels[ i ] ] / labelCount );
      avgRecall += ( recall[ labels[ i ] ] / labelCount );
      avgFMeasure += ( fmeasure[ labels[ i ] ] / labelCount );
    }
    // Return metrics.
    return (
      {
        // Macro-averaged metrics.
        avgPrecision: +avgPrecision.toFixed( 4 ),
        avgRecall: +avgRecall.toFixed( 4 ),
        avgFMeasure: +avgFMeasure.toFixed( 4 ),
        details: {
          // Confusion Matrix.
          confusionMatrix: cm,
          // Label wise metrics details, from those averages were computed.
          precision: precision,
          recall: recall,
          fmeasure: fmeasure
        }
      }
    );
  }; // metrics()

  if ( !helpers.validate.isArray( classLabels ) ) {
    throw Error( 'cross validate: class labels must be an array.' );
  }
  if ( classLabels.length < 2 ) {
    throw Error( 'cross validate: at least 2 class labels are required.' );
  }
  labels = classLabels;
  labelCount = labels.length;

  reset();

  methods.reset = reset;
  methods.evaluate = evaluate;
  methods.metrics = metrics;

  return methods;
}; // cross()

// ### Object Helpers

helpers.string = Object.create( null );

// Regex for [diacritical marks](https://en.wikipedia.org/wiki/Combining_Diacritical_Marks) removal.
var rgxDiacritical = /[\u0300-\u036f]/g;

/**
 *
 * Normalizes the token's value by converting it to lower case and stripping
 * the diacritical marks (if any).
 *
 * @param {string} str — that needs to be normalized.
 * @return {string} the normalized value.
 * @example
 * normalize( 'Nestlé' );
 * // -> nestle
*/
helpers.string.normalize = function ( str ) {
  return (
    str.toLowerCase().normalize( 'NFD' ).replace( rgxDiacritical, '' )
  );
}; // normalize()

helpers.getOptions = function (options,selected) {
  var options2 = {}
  selected.forEach(function (opt) { options2[opt]=options[opt] })
  return options2;
}
helpers.updateOptions = function (options,update) {
  for(var p in options) if (update[p]!=undefined) options[p]=update[p];
  return options;
}
module.exports = helpers;
};
FilesEmbedded['plugins/ml/help.md']=function (format){return Base64.decode('%23%20ML%0A%0A%23%23%20Utils%0A%0AScaling%20%3A%20%7B%7D%0A%20%20k%20%3A%20number%0A%20%20off%20%3A%20number%0A%20%20shift%20%3B%20number%0A%20%20min%20%3A%20number%0A%20%20max%20%3A%20number%0A%20%20%0AML.scale%20%3A%20function%20%28data%2Cscales%29%0A%20%20data%20%20%20%3A%20number%20%5B%5D%20%0A%20%20data%20%20%20%3A%20number%20%5B%5D%5B%5D%20%0A%20%20data%20%20%20%3A%20%7B%24attr%3Anumber%7D%20%0A%20%20data%20%20%20%3A%20%7B%24attr%3Anumber%7D%20%5B%5D%0A%20%20scales%20%3A%20Scaling%0A%20%20scales%20%3A%20Scaling%20%5B%5D%0A%20%20scales%20%3A%20%7B%20%24attr%20%3A%20Scaling%20%7D%0A%0AML.scale0%20%3A%20function%20%28data%2Clower%60%2Cupper%3F%29%0A%20%20data%20%20%20%3A%20number%20%5B%5D%0A%20%20data%20%20%20%3A%20number%20%5B%5D%5B%5D%0A%20%20data%20%20%20%3A%20%7B%20%24attr%3Anumber%20%7D%0A%20%20data%20%20%20%3A%20%7B%20%24attr%3Anumber%20%7D%20%5B%5D%0A%20%20%0A%23%23%20ANN%0A%0AWWW%20%3A%20https%3A//wagenaartje.github.io/neataptic/%0A%0ATrain%20Data%20%3A%20%7B%7D%20%5B%5D%20%23%20record%20array%0A%20%20input%20%3A%20number%20%5B%5D%0A%20%20output%20%3A%20number%20%20%5B%5D%0ATrain%20Data%20%3A%20%7B%7D%0A%20%20x%20%3A%20number%20%5B%5D%5B%5D%0A%20%20y%20%3A%20number%20%5B%5D%5B%5D%0A%0AData%20%3A%20number%20%5B%5D%0AData%20%3A%20number%20%5B%5D%5B%5D%20%0A%0AModel%20Paramter%20%3A%20%7B%7D%0A%20%20algorithm%20%3A%20ML.ML.ANN%0A%20%20activation%3F%3A%20string%20%5B%5D%20%23%20RELU%2C%20IDENTITY%2C%20LOGISTIC%2C%20STEP%0A%20%20layers%20%3A%20numebr%20%5B%5D%0A%0ATraining%20Parameter%20%3A%20%7B%7D%0A%20%20rate%3F%20%3A%20number%0A%20%20iterations%3F%20%3A%20number%0A%20%20error%3F%20%3A%20number%0A%20%20droput%3F%20%3A%20number%2C%0A%20%20momentum%3F%20%3A%20number%0A%20%20batchSize%3F%20%3A%20number%0A%20%20crossValidate%3F%20%3A%20%0A%20%20%20%20testSize%20%3A%20number%0A%20%20%20%20testError%20%3A%20number%0A%20%20clear%3F%20%3A%20boolean%0A%20%20log%3F%20%3A%20boolean%0A%20%20ratePolicy%3F%20%3A%20string%0A%0AML.learner%20%3A%20function%0A%20%20model%20%3A%20Model%20Paramter%20%0A%20%20return%20%3A%20model%20%7B%7D%0A%20%20%0AML.train%20%3A%20function%0A%20%20model%20%20%20%3A%20model%20%7B%7D%0A%20%20data%20%20%20%20%3A%20Train%20Data%0A%20%20options%20%3A%20Training%20Parameter%0A%0AML.predict%20%3A%20function%0A%20%20model%20%20%20%3A%20model%20%7B%7D%0A%20%20data%20%20%20%20%3A%20Data%0A%20%20%0A%23%23%20CNN%0A%0AWWW%20%3A%20https%3A//github.com/karpathy/convnetjs%0A%0ATrain%20Data%20%3A%20%7B%7D%0A%20%20x%20%3A%20number%20%5B%5D%5B%5D%20%23%20depth%3D1%0A%20%20y%20%3A%20number%20%5B%5D%0ATrain%20Data%20%3A%20%7B%7D%0A%20%20x%20%3A%20number%20%5B%5D%5B%5D%5B%5D%20%23%20depth%3E1%0A%20%20y%20%3A%20number%20%5B%5D%0ATrain%20Data%20%3A%20%7B%7D%0A%20%20x%20%3A%20buffer%20%5B%5D%20%23%20RGB/RGBA%0A%20%20y%20%3A%20number%20%5B%5D%0ATrain%20Data%20%3A%20%7B%7D%0A%20%20x%20%3A%20uint8array%20%5B%5D%20%23%20RGB/RGBA%0A%20%20y%20%3A%20number%20%5B%5D%0ATrain%20Data%20%3A%20%7B%7D%0A%20%20x%20%3A%20matrixTa%20%5B%5D%0A%20%20y%20%3A%20number%20%5B%5D%0A%0AData%20%3A%20number%20%5B%5D%5B%5D%0AData%20%3A%20number%20%5B%5D%5B%5D%5B%5D%0AData%20%3A%20buffer%20%5B%5D%0AData%20%3A%20matrixTA%20%5B%5D%0A%0AModel%20Parameter%20%3A%20%7B%7D%0A%20%20algorithm%20%3A%20ML.ML.CNN%0A%20%20layers%20%3A%20%5B%5D%0A%20%20%20%20%7Btype%20%3D%20%27input%27%2C%20out_sx%3Anumber%2C%20out_sy%3Anumber%2C%20out_depth%3Anumber%7D%0A%20%20%20%20%7Btype%20%3D%20%27conv%27%2C%20sx%3Anumber%2C%20filters%3Anumber%2C%20stride%3Anumber%2C%20pad%3Anumber%2C%20activation%3A%20string%20%3D%21%20%27relu%27%7D%0A%20%20%20%20%7Btype%20%3D%20%27pool%27%2C%20sx%3Anumber%2C%20stride%3Anumber%7D%0A%20%20%20%20%7Btype%20%3D%20%27softmax%27%2C%20num_classes%3Anumber%7D%0A%20%20trainer%20%3A%20%0A%20%20%20%20method%20%3A%20string%20%3D%20%27adadelta%27%20%0A%20%20%20%20l2_decay%20%3A%20number%20%3D%21%200.001%20%0A%20%20%20%20batch_size%20%3A%20number%20%3D%21%2010%0A%20%20datatype%3F%20%3A%20string%20%3D%20%27Float32%27%7C%27Float64%27%0A%0ATrain%20Parameter%20%3A%20%7B%7D%0A%20%20x%20%3A%20data%0A%20%20y%20%3A%20data%0A%20%20width%20%3A%20number%0A%20%20height%20%3A%20number%0A%20%20depth%20%3A%20number%0A%20%20normalize%20%3A%20number%20%5B2%5D%0A%20%20iterations%20%3A%20number%0A%20%20callback%20%3A%20function%20%28result%3A%7B%7D%2Citeration%29%20-%3E%20more%3F%3Aboolean%0A%20%20verbose%3F%20%3A%20number%0A%0AML.learner%20%3A%20function%0A%20%20model%20%3A%20Model%20Paramter%20%0A%20%20return%20%3A%20model%20%7B%7D%0A%20%20%0AML.train%20%3A%20function%0A%20%20model%20%20%20%3A%20model%20%7B%7D%0A%20%20data%20%20%20%20%3A%20Train%20Data%0A%20%20options%20%3A%20Training%20Parameter%0A%0AML.predict%20%3A%20function%0A%20%20model%20%20%20%3A%20model%20%7B%7D%0A%20%20data%20%20%20%20%3A%20Data%0A%0A%23%23%20MLP%0A%0ATrain%20Data%20%3A%20%0A%20%20x%20%3A%20number%20%5B%5D%5B%5D%0A%20%20y%20%3A%20number%20%5B%5D%0A%0AData%20%3A%20number%20%5B%5D%5B%5D%0A%0AModel%20Parameter%20%3A%0A%20%20algorithm%20%3A%20ML.ML.MLP%0A%20%20layers%20%3A%20%5B%5D%0A%0ATrain%20Parameter%0A%20%20x%20%3A%20data%0A%20%20y%20%3A%20data%0A%20%20epochs%20%3A%20number%0A%0AML.learner%20%3A%20function%0A%20%20model%20%3A%20Model%20Paramter%20%0A%20%20return%20%3A%20model%20%7B%7D%0A%20%20%0AML.train%20%3A%20function%0A%20%20model%20%20%20%3A%20model%20%7B%7D%0A%20%20data%20%20%20%20%3A%20Train%20Data%0A%20%20options%20%3A%20Training%20Parameter%0A%0AML.predict%20%3A%20function%0A%20%20model%20%20%20%3A%20model%20%7B%7D%0A%20%20data%20%20%20%20%3A%20Data%0A%0A%23%23%20RT%0A%0AWWW%20%3A%20https%3A//github.com/winkjs/wink-regression-tree%0A%0ATraining%20Data%20%3A%20%7B%7D%20%5B%5D%20%23%20record%20array%0A%20%20%24name%20%3A%20number%20%7C%20string%0A%0AData%20%3A%20%7B%7D%20%23%20record%20%0A%20%20%24name%20%3A%20number%20%7C%20string%0AData%20%3A%20%7B%7D%20%5B%5D%20%23%20record%20array%0A%20%20%24name%20%3A%20number%20%7C%20string%0A%0AModel%20Parameter%20%3A%0A%20%20algorithm%20%3A%20ML.ML.RT%0A%20%20features%20%3A%20%5B%5D%0A%20%20%20%20name%20%3A%20string%0A%20%20%20%20categorical%20%3A%20boolean%0A%20%20%20%20exclude%20%3A%20boolean%0A%20%20target%20%20%20%3A%0A%20%20%20%20name%20%3A%20string%0A%20%20%20%20categorical%20%3A%20boolean%20%3D%20false%0A%20%20minPercentVarianceReduction%20%3A%20number%20%3D%3F%200.5%0A%20%20minLeafNodeItems%20%3A%20number%20%3D%3F%2010%0A%20%20minSplitCandidateItems%20%3A%20number%20%3D%3F%2030%0A%20%20minAvgChildrenItems%20%3A%20number%20%3D%3F%202%0A%0A%20%20%20%20%0A%23%23%20SVM%0A%0AWWW%20%3A%20https%3A//github.com/karpathy/svmjs%0A%0ATrain%20Data%20%3A%20%7B%7D%0A%20%20x%20%3A%20number%20%5B%5D%5B%5D%0A%20%20y%20%3A%20number%20%7B-1%2C1%7D%5B%5D%0ATrain%20Data%20%3A%20%7B%7D%0A%20%20x%20%3A%20number%20%5B%5D%5B%5D%0A%20%20y%20%3A%20number%20string%20%5B%5D%20%23%20Multi-SVM%0A%0AData%20%20%20%3A%20number%20%5B%5D%0AData%20%20%20%3A%20number%20%5B%5D%5B%5D%0A%0AModel%20Parameter%20%3A%20%7B%7D%0A%20%20algorithm%20%20%20%3A%20ML.ML.SVM%0A%20%20C%3F%20%20%20%20%20%20%20%20%20%20%3A%20number%20%3D%3F%201.0%0A%20%20tol%3F%20%20%20%20%20%20%20%20%3A%20number%20%3D%3F%201e-4%0A%20%20max_passes%3F%20%3A%20number%20%3D%3F%2020%0A%20%20alpha_tol%3F%20%20%3A%20number%20%3D%3F%201e-5%0A%20%20kernel%3F%20%20%3A%20%20%23%20rbf%20kernel%0A%20%20%20%20%20type%20%20%3A%20%22rbf%22%0A%20%20%20%20%20sigma%20%3A%20number%20%3D%3F%200.5%0A%20%20kernel%3F%20%3A%20%20%23%20polynomial%20kernel%0A%20%20%20%20%20type%20%3A%20%22polynomial%22%0A%20%20%20%20%20c%20%20%20%20%3A%20number%20%3D%21%201%20%0A%20%20%20%20%20d%20%20%20%20%3A%20number%20%3D%21%205%0A%20%20labels%3F%20%3A%20string%5B%5D%20%20%20%23%20Multi-SVM%0A%0APredict%20Output%20%3A%20number%20%0APredict%20Output%20%3A%20%20%5B%5D%20%23%20Multi-SVM%0A%20%20%20value%20%3A%20string%0A%20%20%20prob%20%20%3A%20number%0A%20%20%0AML.learn%20%3A%20function%0A%20%20model%20%20%3A%20Model%20Paramter%20with%20Train%20Data%0A%20%20return%20%3A%20model%20%7B%7D%0A%0AML.learn%20%3A%20function%0A%20%20data%20%20%20%3A%20Data%0A%20%20model%20%20%3A%20model%20%7B%7D%0A%20%20return%20%3A%20Predict%20Output%0A%0A%0A')};

Base64=Require('os/base64');
//Buffer=Require('os/buffer').Buffer;
window.ML=ML = Require('plugins/ml/ml.js');
